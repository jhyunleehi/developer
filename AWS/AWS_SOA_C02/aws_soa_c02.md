https://free-braindumps.com/amazon/free-soa-c02-braindumps.html?p=60#answerQ54
https://www.secexams.com/exams/Amazon/aws-certified-developer-associate-dva-c02/view/?utm_source=mail


## 질문 #1 +++
한 회사에는 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 실행되는 지옥의 웹 애플리케이션이 있습니다. 

인스턴스는 단일 가용성 영역의 Amazon EC2 자동 확장 그룹에서 실행됩니다. SysOps 관리자는 애플리케이션을 고가용성으로 만들어야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

A. 최대 사용 시 필요한 용량을 충족시키기 위해 자동 크기 조정 그룹의 최대 인스턴스 수를 늘립니다.

B. 최대 사용 시 필요한 용량을 충족시키기 위해 자동 크기 조정 그룹의 최소 인스턴스 수를 늘립니다.

C. 동일한 AWS 지역의 두 번째 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다. 가장 많이 투표된

D. 두 번째 AWS 지역의 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다.

애플리케이션을 고가용성으로 만들기 위해 SysOps 관리자가 취해야 할 적절한 조치는 다음과 같습니다:

**C. 동일한 AWS 지역의 두 번째 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다.**

#### 이유:
- **고가용성**: 두 개 이상의 가용성 영역(AZ)에서 인스턴스를 실행하면, 한 AZ에서 장애가 발생하더라도 다른 AZ에서 인스턴스가 계속 운영될 수 있습니다. 이로 인해 애플리케이션의 가용성이 크게 향상됩니다.
- **자동 확장 그룹의 업데이트**: 자동 확장 그룹을 구성하여 여러 AZ에서 인스턴스를 배포하면 수요 변화에 따라 자동으로 인스턴스 수를 조정할 수 있습니다.

**C** 옵션이 고가용성을 위한 가장 효과적인 접근 방식입니다.


## 질문 #2 +

한 회사가 Auto Scaling 그룹에서 실행되는 여러 Amazon EC2 인스턴스에 웹사이트를 호스팅합니다. 

사용자는 매주 주말 오후 6시부터 오후 11시 사이의 피크 타임에 느린 응답을 보고합니다. SysOps 관리자는 이러한 피크 타임에 성능을 개선하기 위한 솔루션을 구현해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 피크 시간 전에 원하는 용량을 늘리기 위해 AWS Lambda 함수를 호출하는 예약된 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
B. 피크 시간 전후에 원하는 용량을 변경하기 위한 반복 옵션을 사용하여 예약된 확장 작업을 구성합니다. 
C. 메모리 사용률이 70%를 넘을 경우 더 많은 인스턴스를 추가하는 대상 추적 확장 정책을 만듭니다.
D. 자동 크기 조정 그룹의 쿨다운 기간을 구성하여 피크 시간 전후에 원하는 용량을 수정합니다.

**B. 피크 시간 전후에 원하는 용량을 변경하기 위한 반복 옵션을 사용하여 예약된 확장 작업을 구성합니다.**

이유:
예약된 확장 작업을 통해 피크 시간 전에 인스턴스 용량을 미리 늘리고, 피크 시간이 끝난 후 용량을 줄일 수 있습니다. 이렇게 하면 사용량 패턴에 따라 EC2 인스턴스의 수를 자동으로 조정할 수 있어 피크 타임 동안의 성능을 보장하면서도 비용을 효율적으로 관리할 수 있습니다.
반복 옵션을 사용하면 매주 주말 오후 6시부터 오후 11시 사이에 자동으로 확장 및 축소 작업을 실행할 수 있습니다. 이는 시스템을 수동으로 관리할 필요 없이 성능을 개선하는 운영 효율적인 방법입니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: Lambda 함수와 EventBridge 규칙을 사용하는 것은 가능하지만, 예약된 확장 작업을 구성하는 것보다 복잡하며 운영 효율성이 떨어집니다.
C: 대상 추적 확장 정책은 실시간으로 확장하지만, 피크 시간에 대한 사전 대비 없이 메모리 사용률이 높아졌을 때만 반응할 수 있어 즉각적인 성능 개선이 어렵습니다.
D: 쿨다운 기간은 인스턴스 수를 확장 또는 축소한 후에 추가 작업을 지연시키기 위한 설정으로, 피크 시간 전에 미리 확장하는 데는 적합하지 않습니다.


## 질문 #3 +

한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹사이트를 운영하고 있습니다. 

이 회사는 Amazon CloudFront 배포를 구성하고 ALB를 원점으로 설정했습니다. 이 회사는 모든 트래픽을 CloudFront 배포를 통해 보내기 위해 Amazon Route 53 CNAME 레코드를 만들었습니다. 의도치 않은 부작용으로 모바일 사용자에게 이제 데스크톱 버전의 웹사이트가 제공됩니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치를 취해야 합니까?

A. CloudFront 배포 동작을 구성하여 User-Agent 헤더를 전달합니다.
B. CloudFront 배포 오리진 설정을 구성합니다. 오리진 사용자 지정 헤더 목록에 User-Agent 헤더를 추가합니다.
C. ALB에서 IPv6를 활성화합니다. CloudFront 배포 원본 설정을 업데이트하여 dualstack 엔드포인트를 사용합니다.
D. CloudFront 배포에서 IPv6를 활성화합니다. Route 53 레코드를 업데이트하여 dualstack 엔드포인트를 사용합니다.


이 문제는 모바일 사용자가 데스크톱 버전의 웹사이트를 받는 문제와 관련이 있습니다. 
이를 해결하기 위해서는 CloudFront가 User-Agent 헤더를 올바르게 전달하여 원본 서버가 사용자의 디바이스 유형(모바일, 데스크톱)에 따라 적절한 버전을 제공할 수 있도록 해야 합니다.

**A. CloudFront 배포 동작을 구성하여 User-Agent 헤더를 전달합니다.**

이유:
User-Agent 헤더는 사용자가 모바일 기기인지 데스크톱 기기인지 등을 서버에 전달하는 중요한 정보입니다. CloudFront가 기본적으로 일부 헤더를 캐시하여 성능을 최적화하는데, User-Agent 헤더가 전달되지 않으면 원본 서버는 디바이스를 구분할 수 없고, 디바이스에 맞는 적절한 콘텐츠를 제공하지 못할 수 있습니다.
CloudFront 배포에서 User-Agent 헤더를 전달하면, 원본 서버(이 경우 Application Load Balancer 뒤의 Amazon EC2 인스턴스)는 각 디바이스 유형에 맞는 콘텐츠를 적절하게 반환할 수 있습니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

B: 오리진 사용자 지정 헤더 목록에 User-Agent를 추가하는 것은 일반적으로 캐시 구성을 제어하는 데 사용되지 않으며, 단순히 오리진으로 헤더를 추가하는 것만으로는 문제를 해결할 수 없습니다.
C와 D: IPv6를 활성화하는 것은 네트워크 수준에서 트래픽을 처리하는 방식일 뿐, 모바일과 데스크톱 사용자 간의 웹사이트 버전 문제와는 직접적인 관련이 없습니다.

## 질문 #4 +++

SysOps 관리자가 AWS 계정에서 AWS CloudTrail을 활성화했습니다.

CloudTrail이 비활성화된 경우 즉시 다시 활성화해야 합니다.
SysOps 관리자는 사용자 지정 코드를 작성하지 않고도 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. AWS 계정을 AWS Organizations에 추가합니다. 관리 계정에서 CloudTrail을 활성화합니다.
B. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용합니다. 가장 많이 투표된
C. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. CloudTrail을 활성화하기 위해 AWS Lambda 함수를 호출하도록 규칙을 구성합니다.
D. AWS Systems Manager Automation 문서를 실행하고 CloudTrail을 활성화하기 위한 일정 패턴을 사용하여 Amazon EventBridge(Amazon CloudWatch Event) 시간별 규칙을 만듭니다.


SysOps 관리자가 AWS CloudTrail이 비활성화될 때 자동으로 다시 활성화되도록 하려면, 사용자 지정 코드를 작성하지 않고 AWS에서 제공하는 자동화된 솔루션을 사용할 수 있습니다.

**B. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용합니다.**
이유:
AWS Config는 AWS 리소스 구성을 추적하고 모니터링하는 서비스로, CloudTrail과 같은 리소스의 구성이 변경되었을 때 규칙을 트리거할 수 있습니다.
AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용하면 CloudTrail이 비활성화되었을 때 자동으로 다시 활성화됩니다. 이 자동화된 작업은 사용자 정의 코드 없이도 CloudTrail 구성을 보장할 수 있는 매우 효율적인 방법입니다.
이 방법은 AWS에서 제공하는 기본 기능을 활용하므로 관리가 쉽고 확장 가능합니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: AWS Organizations의 관리 계정에서 CloudTrail을 활성화할 수 있지만, 이 방법은 비활성화된 CloudTrail을 자동으로 다시 활성화하는 요구 사항을 충족하지 않습니다.
C: Lambda 함수를 사용하는 방법도 가능하지만, 사용자 지정 코드를 작성해야 하므로 더 복잡하고 운영 오버헤드가 증가합니다.
D: EventBridge 시간별 규칙을 사용하면 주기적으로 CloudTrail을 활성화할 수 있지만, CloudTrail이 비활성화된 시점을 즉시 감지하여 다시 활성화하는 데는 적합하지 않습니다. Config 규칙을 사용하는 것이 더 효율적입니다.

## 질문 #5

한 회사가 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 웹사이트를 호스팅합니다. 

이 회사는 Amazon Route 53으로 DNS를 관리하고 도메인의 존 에이펙스를 웹사이트로 가리키고 싶어합니다.
이러한 요구 사항을 충족하려면 어떤 유형의 레코드를 사용해야 합니까?

A. 도메인의 존 정점에 대한 AAAA 레코드
B. 도메인의 영역 정점에 대한 A 레코드
C. 도메인의 존 정점에 대한 CNAME 레코드
D. 도메인의 존 정점에 대한 별칭 레코드

도메인의 존 에이펙스(Apex, 즉 example.com와 같은 최상위 도메인)를 Application Load Balancer(ALB)에 연결하려면, CNAME 레코드는 사용할 수 없습니다. 대신 Amazon Route 53에서 제공하는 별칭(Alìas) 레코드를 사용하는 것이 적합합니다.

**D. 도메인의 존 정점에 대한 별칭 레코드**


이유:
**별칭 레코드(Alìas Record)**는 Route 53에서 제공하는 기능으로, 특정 AWS 리소스(예: Application Load Balancer, CloudFront 배포, S3 버킷 등)로 도메인을 연결할 수 있습니다.
도메인의 존 에이펙스에는 CNAME 레코드를 사용할 수 없으므로, 별칭 레코드가 가장 적합한 선택입니다. 별칭 레코드는 또한 A 레코드와 유사하게 작동하여 IP 주소로의 변환을 처리합니다.
별칭 레코드는 Route 53이 제공하는 자동화된 기능을 활용해 트래픽 라우팅을 효율적으로 관리하며, 비용도 발생하지 않습니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: AAAA 레코드는 IPv6 주소를 가리키는 레코드입니다. ALB와 같은 AWS 리소스와 연결하는 데 일반적으로 사용되지 않습니다.
B: A 레코드는 IP 주소를 직접 가리키는 레코드로, AWS 리소스와 동적으로 연결할 수 없습니다.
C: CNAME 레코드는 존 정점(최상위 도메인)에 사용할 수 없으며, 하위 도메인(예: www.example.com)에서만 사용할 수 있습니다.

## 질문 #6 +++

회사는 S3 버킷에 업로드된 모든 객체가 암호화되도록 해야 합니다.

다음 중 어떤 조치가 이 요구 사항을 충족할까요? (두 가지를 선택하세요.)

A. S3 버킷에 저장된 암호화되지 않은 객체로부터 보호하기 위해 AWS Shield를 구현합니다.
B. 암호화되지 않은 객체가 S3 버킷에 업로드되는 것을 거부하기 위해 객체 액세스 제어 목록(ACL)을 구현합니다.
C. Amazon S3 기본 암호화를 구현하여 업로드되는 모든 객체가 저장되기 전에 암호화되도록 합니다.
D. Amazon Inspector를 구현하여 S3 버킷에 업로드된 객체가 암호화되었는지 검사합니다.
E. 암호화되지 않은 객체가 버킷에 업로드되는 것을 거부하기 위해 S3 버킷 정책을 구현합니다.

Amazon S3 버킷에 업로드된 모든 객체가 암호화되도록 보장하기 위해서는 두 가지 방법을 사용할 수 있습니다: S3 기본 암호화와 버킷 정책을 통한 암호화 강제 적용입니다.

정답:
**C. Amazon S3 기본 암호화를 구현하여 업로드되는 모든 객체가 저장되기 전에 암호화되도록 합니다.**
**E. 암호화되지 않은 객체가 버킷에 업로드되는 것을 거부하기 위해 S3 버킷 정책을 구현합니다.**


이유:
C: Amazon S3 기본 암호화를 설정하면 모든 객체가 업로드될 때 자동으로 암호화됩니다. 기본 암호화는 객체가 저장되기 전에 암호화되므로, 사용자가 별도의 암호화 설정을 하지 않더라도 모든 객체가 보호됩니다.
E: S3 버킷 정책을 통해 특정 조건을 강제할 수 있습니다. 예를 들어, 객체가 업로드될 때 반드시 암호화 헤더가 포함되도록 요구하는 정책을 설정할 수 있으며, 이를 따르지 않는 업로드는 자동으로 거부됩니다. 이 방식은 S3 기본 암호화와 함께 사용될 때 더욱 효과적입니다.

다른 옵션들은 적합하지 않은 이유:
A: AWS Shield는 DDoS(분산 서비스 거부) 공격으로부터 보호하기 위한 서비스이며, 객체 암호화와는 관련이 없습니다.
B: 객체 ACL은 객체에 대한 읽기 및 쓰기 권한을 제어하는 것이며, 암호화 여부와 관련이 없습니다.
D: Amazon Inspector는 EC2 인스턴스, 컨테이너 이미지 등의 취약성을 검사하는 서비스로, S3 버킷 객체의 암호화 여부를 검사하는 기능은 제공하지 않습니다.


## 질문 #7 +++

한 회사에는 Auto Scaling 그룹의 Amazon EC2 인스턴스에 호스팅된 상태 저장 웹 애플리케이션이 있습니다. 

인스턴스는 단일 대상 그룹이 있는 Application Load Balancer(ALB) 뒤에서 실행됩니다. ALB는 Amazon CloudFront 배포에서 원점으로 구성됩니다. 사용자는 웹 애플리케이션에서 무작위 로그아웃을 보고합니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. ALB 대상 그룹에서 가장 덜 처리된 요청 알고리즘으로 변경합니다.
B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.
C. CloudFront 배포 캐시 동작에서 헤더 전달을 구성합니다.
D. ALB 리스너 규칙에서 그룹 수준의 고정성을 활성화합니다.
E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.

무작위 로그아웃 문제는 세션이 EC2 인스턴스 간에 적절하게 유지되지 않기 때문에 발생할 수 있습니다. 특히 상태 저장 애플리케이션에서 세션 관리가 중요한데, 이는 스티키 세션(Sticky Session) 또는 세션 고정성을 통해 해결할 수 있습니다. 또한, CloudFront가 세션 관련 정보를 캐시하지 않도록 해야 합니다.

정답:
**B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.**
**E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.**

이유:
B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.

웹 애플리케이션이 세션 쿠키를 사용하여 사용자를 인증하고 세션을 유지한다면, CloudFront가 쿠키를 전달하지 않으면 세션 상태가 손실될 수 있습니다. CloudFront 배포에서 쿠키 전달을 구성하면, CloudFront가 세션 관련 정보를 제대로 처리하고 사용자에게 무작위 로그아웃 문제가 발생하지 않도록 할 수 있습니다.

E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.
스티키 세션(세션 고정성)을 활성화하면 사용자가 동일한 EC2 인스턴스에 지속적으로 연결됩니다. 이는 상태 저장 애플리케이션에서 사용자의 세션 상태를 유지하는 데 필수적입니다. 스티키 세션을 활성화하면 특정 
사용자가 같은 인스턴스로 계속 연결되므로 세션이 유지됩니다.

다른 옵션들은 적합하지 않은 이유:
A: 덜 처리된 요청 알고리즘으로 변경하는 것은 트래픽을 분산시키는 방법일 뿐, 세션 관련 문제 해결과는 관련이 없습니다.
C: 헤더 전달은 쿠키 전달보다 덜 중요하며, 헤더가 세션 문제에 직접적인 영향을 미치지 않을 수 있습니다.
D: 그룹 수준의 고정성은 특정 리스너 규칙에 의존하는 것이며, 대상 그룹의 세션 고정성 관리와는 무관합니다. ALB 대상 그룹의 스티키 세션 설정이 더 적합한 해결책입니다.

## 질문 #8

한 회사가 AWS Lambda에서 서버리스 애플리케이션을 실행하고 있습니다. 

이 애플리케이션은 Amazon RDS for MySQL DB 인스턴스에 데이터를 저장합니다. 사용량이 꾸준히 증가했고, 최근 Lambda 함수가 데이터베이스에 연결을 시도할 때 "연결이 너무 많음" 오류가 많이 발생했습니다. 이 회사는 이미 가능한 최대 max_connections 값을 사용하도록 데이터베이스를 구성했습니다.
SysOps 관리자는 이러한 오류를 해결하기 위해 무엇을 해야 합니까?

A. 데이터베이스의 읽기 복제본을 만듭니다. Amazon Route 53을 사용하여 두 데이터베이스를 모두 포함하는 가중 DNS 레코드를 만듭니다.
B. Amazon RDS Proxy를 사용하여 프록시를 만듭니다. Lambda 함수에서 연결 문자열을 업데이트합니다.
C. 데이터베이스가 사용하는 매개변수 그룹의 max_connect_errors 매개변수 값을 늘립니다.
D. Lambda 함수의 예약된 동시성을 더 높은 값으로 업데이트합니다.

Lambda 함수가 데이터베이스에 연결을 시도할 때 "연결이 너무 많음" 오류가 발생하는 문제는 데이터베이스 연결 수가 제한된 상황에서 흔히 발생하는 문제입니다. 이 문제를 해결하기 위해 Amazon RDS Proxy를 사용하는 것이 가장 적합한 방법입니다.

**Amazon RDS Proxy를 사용하여 프록시를 만듭니다. Lambda 함수에서 연결 문자열을 업데이트합니다.**

이유:
Amazon RDS Proxy는 데이터베이스 연결을 관리하여 여러 Lambda 함수가 데이터베이스에 동시에 연결하는 문제를 완화시켜줍니다. 프록시는 연결을 풀링(pooling)하여 Lambda 함수가 데이터베이스와 직접 연결하지 않고 프록시를 통해 연결을 관리함으로써 데이터베이스에 대한 연결 수를 줄일 수 있습니다. 이렇게 하면 데이터베이스에 대한 연결이 최적화되고, "연결이 너무 많음" 오류를 방지할 수 있습니다.
다른 옵션들이 적합하지 않은 이유:

A: 읽기 복제본을 만들고 Route 53 가중 DNS 레코드를 설정하는 것은 읽기 요청 분산에 적합하지만, 이 문제는 연결 수에 관련된 문제이므로 해결책이 되지 않습니다.
C: max_connect_errors 매개변수는 데이터베이스의 연결 시도 오류 허용 한도를 제어하는 매개변수로, 연결 수 제한 문제를 해결하지는 못합니다.
D: Lambda 함수의 동시성을 증가시키는 것은 Lambda 함수가 실행되는 빈도나 동시성을 조절하는 것이며, 이는 데이터베이스 연결 수 문제와 직접적으로 관련이 없습니다. 오히려 더 많은 동시성이 더 많은 연결을 생성할 수 있어 문제가 악화될 수 있습니다.
RDS Proxy는 연결 관리 문제를 해결하는 가장 적절한 방법입니다.

## 질문 #9

SysOps 관리자가 10개의 Amazon EC2 인스턴스에 애플리케이션을 배포하고 있습니다. 

애플리케이션은 고가용성이어야 합니다. 인스턴스는 별도의 기본 하드웨어에 배치되어야 합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 단일 AWS 지역의 클러스터 배치 그룹으로 인스턴스를 시작합니다.
B. 여러 AWS 지역의 파티션 배치 그룹으로 인스턴스를 시작합니다.
C. 여러 AWS 지역에 분산된 배치 그룹으로 인스턴스를 시작합니다.
D. 단일 AWS 지역의 분산된 배치 그룹으로 인스턴스를 시작합니다.

애플리케이션이 고가용성을 요구하고, 인스턴스가 별도의 기본 하드웨어에 배치되어야 한다면, 분산된 배치 그룹을 사용하는 것이 적합합니다. 분산된 배치 그룹은 인스턴스가 서로 다른 물리적 하드웨어에 배치되도록 보장하며, 장애를 격리하는 데 효과적입니다.

정답:
**단일 AWS 지역의 분산된 배치 그룹으로 인스턴스를 시작합니다.**

이유:
분산된 배치 그룹은 EC2 인스턴스를 서로 다른 물리적 하드웨어에 배치하여 단일 하드웨어 장애가 여러 인스턴스에 영향을 미치지 않도록 설계되었습니다. 따라서 고가용성을 보장하면서 인스턴스가 서로 다른 기본 하드웨어에 배치됩니다.
이 옵션은 단일 AWS 지역에서 고가용성을 유지하기 위한 적절한 선택입니다.

다른 옵션들이 적합하지 않은 이유:
A. 클러스터 배치 그룹은 저지연 네트워크 통신을 위해 인스턴스를 물리적으로 가까운 위치에 배치하는 방식으로, 하드웨어 중복성과 고가용성 요구사항에는 적합하지 않습니다.
B. 여러 AWS 지역의 파티션 배치 그룹은 지역 간 배포를 의미하지만, 파티션 배치 그룹은 특정 리소스 간의 장애 격리에 중점을 둡니다. 또한 다수의 지역을 사용할 필요는 없습니다.
C. 여러 AWS 지역에 분산된 배치 그룹은 고가용성을 위해 지역 간 배포를 의미하지만, 다중 지역 배포는 복잡성을 증가시키며 질문에서 요구하는 것은 단일 지역 내에서의 고가용성입니다.
따라서 단일 AWS 지역의 분산된 배치 그룹이 요구 사항을 충족하는 가장 적합한 선택입니다.

## 질문 #10

SysOps 관리자가 여러 Amazon EC2 인스턴스가 생성되는 AWS CloudFormation 템플릿의 문제를 해결하고 있습니다. 

템플릿은 us-east-1에서 작동하지만 us-west-2에서는
AMI [ami-12345678]이 존재하지 않음 이라는 오류 코드와 함께 실패합니다.
관리자는 AWS CloudFormation 템플릿이 모든 지역에서 작동하는지 어떻게 확인해야 합니까?

A. 소스 지역의 Amazon Machine Image(AMI)를 대상 지역에 복사하고 동일한 ID를 할당합니다.
B. AWS CloudFormation 템플릿을 편집하여 정규화된 AMI ID의 일부로 지역 코드를 지정합니다.
C. AWS::EC2::AMI::ImageID 컨트롤을 사용하여 AWS CloudFormation 템플릿을 편집하여 사용자에게 모든 AMI의 드롭다운 목록을 제공합니다.
D. "매핑" 섹션에 AMI ID를 포함하여 AWS CloudFormation 템플릿을 수정합니다. 적절한 AMI ID에 대한 템플릿 내의 적절한 매핑을 참조하세요.

이 문제는 특정 지역에서 사용 가능한 AMI가 다르기 때문에 발생합니다. 각 AWS 리전에서 고유한 AMI ID가 있으므로, 모든 지역에서 AWS CloudFormation 템플릿이 작동하도록 하려면 지역별로 다른 AMI ID를 지정할 수 있는 방법을 사용해야 합니다. 이를 위해 AWS CloudFormation 템플릿의 매핑 섹션을 사용하여 지역마다 올바른 AMI ID를 참조하게 할 수 있습니다.

정답:
**"매핑" 섹션에 AMI ID를 포함하여 AWS CloudFormation 템플릿을 수정합니다. 적절한 AMI ID에 대한 템플릿 내의 적절한 매핑을 참조하세요**.

이유:
매핑(Mappings) 섹션은 AWS CloudFormation에서 리전 또는 다른 조건에 따라 값을 달리 지정할 수 있게 해줍니다. 각 리전에 맞는 AMI ID를 매핑에 정의하고, Fn::FindInMap 함수로 적절한 값을 참조하도록 수정하면 템플릿이 여러 리전에서 작동하도록 할 수 있습니다.

예시 매핑 코드:
```yaml

Mappings:
  RegionMap:
    us-east-1:
      AMI: ami-12345678
    us-west-2:
      AMI: ami-87654321

Resources:
  MyEC2Instance:
    Type: "AWS::EC2::Instance"
    Properties:
      ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", AMI]
```

다른 옵션들이 적합하지 않은 이유:
A: 소스 지역의 AMI를 복사하고 동일한 ID를 할당하는 것은 불가능합니다. AWS에서는 AMI를 복사할 수 있지만, 복사된 AMI는 다른 리전에서 새로운 ID를 갖게 되므로 동일한 ID를 사용할 수 없습니다.
B: CloudFormation 템플릿에서 지역 코드에 따라 정규화된 AMI ID를 지정하는 방식은 존재하지 않습니다. AMI ID는 리전별로 고유합니다.
C: AWS::EC2::AMI::ImageID라는 리소스 타입은 존재하지 않으며, 사용자에게 AMI 목록을 제공하는 기능도 없습니다.
따라서 매핑을 통해 리전별 AMI ID를 설정하는 D 옵션이 가장 적합한 해결책입니다.


## 질문 #11 +

SysOps 관리자가 여러 Amazon EC2 인스턴스에서 공유 스토리지를 제공하기 위해 Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝하고 있습니다. 

인스턴스는 모두 여러 가용 영역에 걸쳐 동일한 VPC에 있습니다. 각 가용 영역에는 두 개의 인스턴스가 있습니다. SysOps 관리자는 가능한 가장 낮은 지연 시간으로 각 인스턴스에서 파일 시스템에 액세스할 수 있도록 해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. VPC에서 EFS 파일 시스템에 대한 마운트 대상을 만듭니다. 마운트 대상을 사용하여 각 인스턴스에서 파일 시스템을 마운트합니다.
B. VPC의 한 가용성 영역에 EFS 파일 시스템에 대한 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 파일 시스템을 마운트합니다. 다른 인스턴스와 디렉토리를 공유합니다.
C. 각 인스턴스에 대한 마운트 대상을 만듭니다. 각 마운트 대상을 사용하여 각 인스턴스에 EFS 파일 시스템을 마운트합니다.
D. VPC의 각 가용성 영역에 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 EFS 파일 시스템을 마운트합니다.


주어진 요구 사항에 따라 Amazon Elastic File System (EFS) 파일 시스템에 대한 최적의 솔루션을 선택해야 합니다. 이 경우, 모든 Amazon EC2 인스턴스가 여러 가용 영역에 걸쳐 동일한 VPC에 있으므로 각 인스턴스에서 가능한 가장 낮은 지연 시간으로 EFS에 액세스할 수 있도록 해야 합니다.

**VPC의 각 가용성 영역에 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 EFS 파일 시스템을 마운트합니다.**

이유:
- EFS는 여러 가용 영역에 걸쳐서 고가용성과 내구성을 제공할 수 있습니다.
- 각 가용 영역에 마운트 대상을 만들면, 해당 가용 영역의 인스턴스가 EFS 파일 시스템에 직접적으로 연결되어 가장 낮은 지연 시간으로 액세스할 수 있습니다.
- 마운트 대상을 각 가용 영역에 설정하면, 네트워크 지연을 최소화하고 각 인스턴스가 EFS 파일 시스템에 효과적으로 접근할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
- **A**: 모든 인스턴스가 단일 마운트 대상을 사용할 경우, 네트워크 지연이 발생할 수 있습니다.
- **B**: 한 가용 영역에만 마운트 대상을 두면 다른 가용 영역의 인스턴스에서 높은 지연 시간으로 EFS에 액세스해야 합니다.
- **C**: 각 인스턴스에 대해 별도의 마운트 대상을 만드는 것은 비효율적이며, EFS의 이점을 제대로 활용하지 못합니다.


## 질문 #12 +++

SysOps 관리자가 AWS CloudFormation 템플릿을 사용하여 VPC를 성공적으로 배포했습니다. 

SysOps 관리자는 AWS Organizations를 통해 관리되는 여러 계정에 동일한 템플릿을 배포하려고 합니다.
어떤 솔루션이 가장 적은 운영 오버헤드로 이 요구 사항을 충족할까요?

A. 관리 계정에서 OrganizationAccountAccessRole IAM 역할을 맡습니다. 각 계정에 템플릿을 배포합니다.
B. 각 계정에서 역할을 맡을 AWS Lambda 함수를 만듭니다. AWS CloudFormation CreateStack API 호출을 사용하여 템플릿을 배포합니다.
C. 계정 목록을 쿼리하기 위한 AWS Lambda 함수를 만듭니다. AWS CloudFormation CreateStack API 호출을 사용하여 템플릿을 배포합니다.
D. 관리 계정의 AWS CloudFormation StackSets를 사용하여 각 계정에 템플릿을 배포합니다.

**관리 계정의 AWS CloudFormation StackSets를 사용하여 각 계정에 템플릿을 배포합니다.**

이유:
- **AWS CloudFormation StackSets**를 사용하면 여러 AWS 계정 및 리전에서 CloudFormation 스택을 동시에 관리하고 배포할 수 있습니다. 
- StackSets를 사용하면 단일 템플릿을 기반으로 여러 계정에 변경 사항을 쉽게 적용할 수 있으며, 중앙에서 관리하므로 운영 오버헤드가 줄어듭니다.
- 또한, StackSets는 IAM 권한과 관련하여 각 계정에 적절한 역할을 자동으로 처리할 수 있어 관리가 용이합니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
- A: 역할을 맡아 개별적으로 템플릿을 배포하는 것은 운영 오버헤드가 크고 관리가 복잡합니다.
- B: 각 계정에서 Lambda 함수를 만들어야 하며, 관리해야 할 코드가 많아져 운영 오버헤드가 증가합니다.
- C: 계정 목록을 쿼리하는 Lambda 함수를 만드는 것은 여전히 복잡성을 증가시키고, 여러 계정에 대해 수동으로 API 호출을 해야 하므로 비효율적입니다.


## 질문 #13 ++

한 회사에서 계산을 위해 20개의 Amazon EC2 인스턴스로 구성된 플릿을 관리하기 위해 분산 컴퓨팅 소프트웨어를 실행하고 있습니다. 

플릿에는 계산을 실행하기 위한 2개의 제어 노드와 18개의 작업 노드가 포함되어 있습니다. 제어 노드는 자동으로 작업 노드를 시작할 수 있습니다.
현재 모든 노드는 주문형으로 실행됩니다. 제어 노드는 주 7일, 하루 24시간 이용 가능해야 합니다. 작업 노드는 매일 4시간씩 실행됩니다. SysOps 관리자는 이 솔루션의 비용을 최적화해야 합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하세요.)

A. 제어 노드에 대한 EC2 인스턴스 절약 플랜을 구매합니다. 가장 많이 투표된
B. 제어 노드에 전용 호스트를 사용합니다.
C. 작업 노드에 예약 인스턴스를 사용합니다.
D. 제어 노드에 Spot Instances를 사용합니다. Spot 가용성이 없는 경우 On-Demand Instances를 사용합니다.
E. 작업 노드에 Spot 인스턴스를 사용합니다. Spot 가용성이 없는 경우 On-Demand 인스턴스를 사용합니다. 가장 많이 투표된

이 시나리오에서 비용을 최적화하기 위한 두 가지 주요 선택지는 다음과 같습니다:

 A. **제어 노드에 대한 EC2 인스턴스 절약 플랜을 구매합니다.**
- **이유**: 제어 노드는 24/7 가동되어야 하기 때문에, 주문형(On-Demand) 인스턴스를 계속 사용하면 비용이 많이 듭니다. 대신 **EC2 절약 플랜(Savings Plan)**을 구매하면 특정 인스턴스 유형에 대해 장기적으로 비용을 절감할 수 있습니다. 절약 플랜은 특정 인스턴스 유형에 고정되지 않고, 다른 인스턴스 유형이나 AWS 서비스에도 적용될 수 있기 때문에 유연성이 높습니다. 이 플랜은 항상 가동해야 하는 제어 노드에 적합한 선택입니다.

 E. **작업 노드에 Spot 인스턴스를 사용합니다. Spot 가용성이 없는 경우 On-Demand 인스턴스를 사용합니다.**
- **이유**: 작업 노드는 매일 4시간만 사용되기 때문에 **Spot 인스턴스**를 활용하여 비용을 크게 절감할 수 있습니다. Spot 인스턴스는 미사용 EC2 용량을 저렴하게 제공하며, 짧은 시간 동안의 작업에 적합합니다. Spot 인스턴스가 가용하지 않을 때는 **On-Demand 인스턴스**를 사용하여 작업을 보장할 수 있습니다. 이는 작업 노드의 가동 시간을 충분히 고려하면서 비용 절감을 극대화할 수 있는 전략입니다.




## 질문 #14 +++++

회사는 Amazon S3 버킷에서 매 시간 데이터 파일을 수신해야 합니다. 

S3 이벤트 알림은 파일이 도착할 때마다 AWS Lambda 함수를 호출합니다. 이 함수는 애플리케이션에서 사용할 수 있도록 데이터를 처리합니다.
애플리케이션 팀은 때때로 파일이 도착하지 않는다는 것을 알아차립니다. 애플리케이션 팀은 파일이 도착하지 않을 때마다 알림을 받고 싶어합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 지난 1시간 동안 생성된 객체로 제한된 범위로 S3 버킷에 S3 수명 주기 규칙을 추가합니다. 전환된 객체 수가 0일 때 수명 주기 전환에 의해 호출되는 다른 S3 이벤트 알림을 구성합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하여 애플리케이션 팀에 알립니다.
B. Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Lambda 함수를 호출하도록 다른 S3 이벤트 알림을 구성합니다. 대기열의 ApproximateAgeOfOldestMessage 메트릭이 1시간보다 클 때 애플리케이션 팀에 알리기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다.
C. Lambda 함수의 Invocations 메트릭이 1시간 동안 0일 때 애플리케이션 팀에 경고하기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다. 누락된 데이터를 위반으로 처리하도록 알람을 구성합니다.
D. S3 버킷에서 가장 최신 파일의 타임스탬프를 가져오는 새 Lambda 함수를 만듭니다. 타임스탬프가 1시간 전이면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하여 애플리케이션 팀에 알립니다. 매시간 새 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.

가장 운영 효율적인 솔루션은 옵션 C입니다.

**C. Lambda 함수의 Invocations 메트릭이 1시간 동안 0일 때 애플리케이션 팀에 경고하기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다. 누락된 데이터를 위반으로 처리하도록 알람을 구성합니다.**

이 솔루션은 다음과 같은 이유로 적합합니다:

* 운영 효율성: Lambda 함수의 Invocations 메트릭을 사용해 파일이 도착하지 않을 때 알림을 받을 수 있습니다. Lambda 함수가 호출되지 않으면 알림이 생성되므로 추가적인 커스텀 코드를 작성할 필요가 없습니다.

* 간단한 구성: AWS Lambda와 CloudWatch는 이미 설정된 메트릭을 기반으로 경고를 설정할 수 있으므로 추가적인 구성이나 복잡한 시스템 모니터링을 필요로 하지 않습니다.

* 자동화된 알림: Lambda가 호출되지 않는 상황을 바로 감지하여 SNS를 통해 알림을 받을 수 있습니다.
다른 옵션들에 비해 이 방법이 가장 직관적이고 관리하기 쉬운 방식입니다.


## 질문 #15 +++

한 회사가 최근에 다른 회사와 그 회사의 모든 AWS 계정을 인수했습니다. 재무 분석가는 이러한 계정의 비용 데이터가 필요합니다.

SysOps 관리자는 Cost Explorer를 사용하여 비용 및 사용 보고서를 생성합니다. SysOps 관리자는 "No Tagkey"가 월 비용의 20%를 차지한다는 것을 알아챘습니다.
SysOps 관리자는 "No Tagkey" 리소스에 태그를 지정하기 위해 무엇을 해야 합니까?

A. AWS Organizations에 계정을 추가합니다. 서비스 제어 정책(SCP)을 사용하여 태그가 지정되지 않은 모든 리소스에 태그를 지정합니다.
B. AWS Config 규칙을 사용하여 태그가 지정되지 않은 리소스를 찾습니다. 리소스를 종료하기 위한 수정 작업을 설정합니다.
C. 비용 탐색기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다.
D. 태그 편집기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다.

**D. 태그 편집기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다**입니다.

**태그 편집기(Tag Editor)**는 AWS Management Console에서 제공하는 도구로, 여러 AWS 리소스를 한 번에 태그할 수 있습니다. SysOps 관리자는 태그가 지정되지 않은 리소스를 검색하고, 해당 리소스에 태그를 적용하여 "No Tagkey" 문제를 해결할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 서비스 제어 정책(SCP)은 태그를 지정하도록 강제할 수 없으며, AWS Organizations는 리소스를 직접 태그 지정하는 데 사용되지 않습니다.
- **B**: AWS Config 규칙을 사용하면 태그가 없는 리소스를 감지할 수 있지만, 리소스를 종료하는 것은 적절한 조치가 아닙니다.
- **C**: 비용 탐색기는 비용과 사용량 데이터를 분석할 수 있지만, 리소스에 직접 태그를 지정하는 기능은 제공하지 않습니다.

따라서, 가장 효율적인 방법은 태그 편집기를 사용하는 것이므로 **D**가 맞습니다.


## 질문 #16 +++++

AWS 관리형 VPN 연결을 설정하는 동안 SysOps 관리자가 AWS에서 고객 게이트웨이 리소스를 만듭니다. 

고객 게이트웨이 장치는 NAT 게이트웨이가 앞에 있는 데이터 센터에 있습니다.
고객 게이트웨이 리소스를 만드는 데 어떤 주소를 사용해야 합니까?

A. 고객 게이트웨이 장치의 개인 IP 주소
B. 고객 게이트웨이 장비 앞의 NAT 장비의 MAC 주소
C. 고객 게이트웨이 장치의 공용 IP 주소
D. 고객 게이트웨이 장치 앞에 있는 NAT 장치의 공용 IP 주소

**D. 고객 게이트웨이 장치 앞에 있는 NAT 장치의 공용 IP 주소**입니다.

AWS 관리형 VPN 연결에서 **고객 게이트웨이**는 AWS와 고객의 온프레미스 네트워크 간의 터널을 설정하는 데 사용됩니다. 고객 게이트웨이가 NAT 장치 뒤에 있을 경우, AWS는 고객 게이트웨이에 대한 직접적인 접근이 불가능하기 때문에 **NAT 장치의 공용 IP 주소**를 사용하여 VPN 터널을 설정해야 합니다.

다른 선택지에 대한 설명:
- **A**: 고객 게이트웨이 장치의 개인 IP 주소는 AWS에서 접근할 수 없으므로 사용할 수 없습니다.
- **B**: MAC 주소는 VPN 설정에 필요하지 않습니다.
- **C**: NAT 장치가 앞에 있으므로 고객 게이트웨이 장치의 공용 IP 주소가 아니라, NAT 장치의 공용 IP 주소를 사용해야 합니다.

따라서, **D**가 정답입니다.

## 질문 #17 +++

한 회사에 매일 밤 여러 번 성능 문제가 발생하는 웹 애플리케이션이 있습니다. 

근본 원인 분석 결과 Amazon EC2 Linux 인스턴스에서 5분 동안 지속되는 CPU 사용률의 갑작스러운 증가가 나타났습니다. 
SysOps 관리자는 CPU를 더 많이 사용하는 서비스 또는 프로세스의 프로세스 ID(PID)를 찾아야 합니다. SysOps
관리자는 최소한의 노력으로 프로세스 사용률 정보를 수집하기 위해 무엇을 해야 합니까?

A. Amazon CloudWatch 에이전트 procstat 플러그인을 구성하여 CPU 프로세스 메트릭을 캡처합니다.
B. PID를 캡처하고 알림을 보내기 위해 1분마다 실행되도록 AWS Lambda 함수를 구성합니다.
C. 매일 밤 .pem 키를 사용하여 EC2 인스턴스에 로그인합니다. 그런 다음 top 명령을 실행합니다.
D. 기본 Amazon CloudWatch CPU 사용률 지표를 사용하여 CloudWatch에서 PID를 캡처합니다.

**A. Amazon CloudWatch 에이전트 procstat 플러그인을 구성하여 CPU 프로세스 메트릭을 캡처합니다**입니다.

**procstat 플러그인**은 Amazon CloudWatch 에이전트에서 제공하는 기능으로, 개별 프로세스의 CPU, 메모리 등의 성능 지표를 수집할 수 있습니다. 이를 통해 특정 프로세스의 CPU 사용률과 관련된 상세한 데이터를 얻고, 문제의 근본 원인을 쉽게 파악할 수 있습니다.

다른 선택지에 대한 설명:
- **B**: AWS Lambda 함수는 일반적으로 이벤트 기반 작업에 사용되며, PID 정보를 수집하기 위해 매 분마다 Lambda를 실행하는 것은 비효율적입니다.
- **C**: 매일 밤 EC2에 로그인하고 수동으로 `top` 명령을 실행하는 것은 자동화가 부족하고, 장기적으로 비효율적인 방법입니다.
- **D**: 기본 CloudWatch CPU 사용률 지표는 EC2 인스턴스 수준에서만 제공되며, 개별 프로세스(PID) 수준의 정보를 제공하지 않습니다.

따라서, **A**가 최선의 선택입니다.


## 질문 #18

SysOps 관리자가 하나의 Amazon Elastic Block Store(Amazon EBS) 볼륨이 연결된 단일 Amazon EC2 인스턴스에서 스냅샷을 캡처하도록 AWS Backup을 구성했습니다. 

첫 번째 스냅샷에서 EBS 볼륨에는 10GiB의 데이터가 있습니다. 두 번째 스냅샷에서 EBS 볼륨에는 여전히 10GiB의 데이터가 있지만 4GiB
가 변경되었습니다. 세 번째 스냅샷에서 2GiB의 데이터가 볼륨에 추가되어 총 12GiB가 되었습니다.
이러한 스냅샷을 저장하는 데 필요한 총 스토리지는 얼마입니까?

1. 12기가바이트
2. 16기가바이트 가장 많이 투표된
3. 26기가바이트
4. 32기가바이트

정답은 **B. 16기가바이트**입니다.

스냅샷은 Amazon EBS 볼륨의 **증분 백업**을 수행합니다. 즉, 첫 번째 스냅샷은 전체 데이터를 저장하지만, 이후 스냅샷은 변경된 데이터만 저장합니다. 이 경우, 스토리지 계산은 다음과 같이 이루어집니다:

1. **첫 번째 스냅샷**: 전체 데이터인 10GiB가 저장됩니다.
2. **두 번째 스냅샷**: 변경된 데이터 4GiB만 저장됩니다.
3. **세 번째 스냅샷**: 추가된 2GiB의 데이터만 저장됩니다.

따라서, 총 저장되는 데이터는 **10GiB + 4GiB + 2GiB = 16GiB**입니다.

따라서, 정답은 **B. 16기가바이트**입니다.

## 질문 #19 +++

한 팀이 AWS Organizations의 조직 구성원인 AWS 계정을 관리하고 있습니다. 

조직은 통합 청구 기능을 활성화했습니다. 계정은 여러 애플리케이션을 호스팅합니다.
SysOps 관리자가 환경을 반영하기 위해 계정 내 리소스에 태그를 적용했습니다. 팀에는 환경별 요금 내역 보고서가 필요합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 태그 편집기에서 리소스 그룹을 필터링, 매핑하고 분류합니다.
B. 조직의 서비스 제어 정책(SCP)이 비용 할당 태그에 대한 액세스를 허용하는지 확인합니다.
C. Cost Explorer에 액세스하는 데 사용되는 IAM 자격 증명에 태그별로 비용을 그룹화할 수 있는 권한이 있는지 확인하세요.
D. 조직의 관리 계정에서 비용 할당을 위한 태그 키를 활성화합니다. 

**D. 조직의 관리 계정에서 비용 할당을 위한 태그 키를 활성화합니다**입니다.

AWS에서는 **비용 할당 태그**를 사용하여 비용을 태그별로 세분화하고 분석할 수 있습니다. SysOps 관리자는 태그를 사용하여 환경별 비용 보고서를 생성하려면, 먼저 AWS Organizations 관리 계정에서 비용 할당을 위한 태그 키를 활성화해야 합니다. 이렇게 하면 해당 태그를 사용해 리소스 비용을 Cost Explorer에서 그룹화하고 분석할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 태그 편집기는 리소스를 태그별로 그룹화하는 데 사용될 수 있지만, 비용 분석을 위해서는 Cost Explorer와 비용 할당 태그가 필요합니다.
- **B**: SCP는 태그 액세스와 직접적인 관련이 없으며, 비용 할당 태그 활성화에 필요하지 않습니다.
- **C**: IAM 권한이 중요하지만, 우선적으로 비용 할당 태그를 활성화해야 태그별 비용을 그룹화할 수 있습니다.

따라서, **D**가 정답입니다.

## 질문 #20 ++

한 회사에서 AWS CloudFormation 템플릿을 사용하여 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스를 프로비저닝합니다. 

SysOps 관리자는 EC2 인스턴스가 시작되기 전에 DB 인스턴스가 생성되도록 템플릿을 업데이트해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 템플릿에 대기 조건을 추가합니다. EC2 인스턴스가 시작된 후 신호를 보내도록 EC2 인스턴스 사용자 데이터 스크립트를 업데이트합니다.
B. EC2 인스턴스 리소스에 DependsOn 특성을 추가하고 RDS 리소스의 논리적 이름을 제공합니다. 가장 많이 투표된
C. 템플릿에서 리소스 순서를 변경하여 RDS 리소스가 EC2 인스턴스 리소스보다 앞에 나열되도록 합니다.
D. 여러 템플릿을 만듭니다. AWS CloudFormation StackSets를 사용하여 두 번째 스택이 생성되기 전에 한 스택이 완료될 때까지 기다립니다.

정답은 **B. EC2 인스턴스 리소스에 DependsOn 특성을 추가하고 RDS 리소스의 논리적 이름을 제공합니다**입니다.

AWS CloudFormation에서는 **DependsOn 특성**을 사용하여 리소스 간의 종속성을 정의할 수 있습니다. 이를 통해 특정 리소스가 다른 리소스가 완전히 생성된 후에 시작되도록 할 수 있습니다. 이 경우, EC2 인스턴스 리소스에 DependsOn 특성을 추가하여 RDS DB 인스턴스가 먼저 생성된 후 EC2 인스턴스가 시작되도록 지정할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 대기 조건과 신호는 리소스가 특정 상태에 도달했을 때까지 기다리도록 하는 방법이지만, 이 경우보다 간단하게 DependsOn을 사용하는 것이 더 적합합니다.
- **C**: 템플릿에서 리소스 순서를 변경하는 것은 리소스 생성 순서에 영향을 미치지 않습니다. CloudFormation은 리소스의 논리적 순서가 아닌 종속성을 기반으로 리소스를 생성합니다.
- **D**: 여러 템플릿을 만드는 것은 불필요하게 복잡한 방법이며, 하나의 템플릿 내에서 해결할 수 있습니다.

따라서, **B**가 가장 적절한 선택입니다.

## 질문 #21

한 회사가 Amazon S3에 정적 웹사이트를 호스팅합니다. 

이 웹사이트는 기본 TTL이 86,400초인 Amazon CloudFront 배포판에서 제공됩니다.
이 회사는 최근 웹사이트의 업데이트된 버전을 Amazon S3에 업로드했습니다. 그러나 사용자는 사이트를 새로 고칠 때 여전히 이전 콘텐츠를 봅니다. SysOps 관리자는 가능한 한 빨리 사용자에게 새 버전의 웹사이트를 표시해야 합니다.
이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. CloudFront 배포를 가리키는 DNS CNAME 레코드의 TTL 값을 조정합니다.
B. CloudFront 배포에서 이전 S3 객체에 대한 무효화를 생성합니다. 
C. 새 CloudFront 배포를 만듭니다. DNS 레코드를 업데이트하여 새 CloudFront 배포를 가리킵니다.
D. 웹사이트의 DNS 레코드를 업데이트하여 S3 버킷을 가리키도록 합니다.

정답은 **B. CloudFront 배포에서 이전 S3 객체에 대한 무효화를 생성합니다**입니다.

Amazon CloudFront는 기본적으로 객체를 캐시하여 성능을 최적화합니다. 웹사이트를 업데이트한 후에도 사용자가 여전히 이전 콘텐츠를 보는 이유는 캐시된 콘텐츠가 만료되지 않았기 때문입니다. CloudFront에서 **무효화(invalidation)**를 생성하면 캐시된 객체를 제거하여 사용자에게 최신 콘텐츠를 제공할 수 있습니다. 

다른 선택지에 대한 설명:
- **A**: DNS CNAME 레코드의 TTL 값은 CloudFront 캐시와 관련이 없으며, 이를 조정해도 캐시된 콘텐츠 문제는 해결되지 않습니다.
- **C**: 새 CloudFront 배포를 만드는 것은 불필요하게 복잡한 작업입니다. 무효화를 통해 문제를 해결할 수 있습니다.
- **D**: S3 버킷을 직접 가리키도록 DNS를 업데이트하면 CloudFront의 캐싱 및 성능 이점을 잃게 됩니다. 이는 최선의 방법이 아닙니다.

따라서, **B**가 가장 적절한 솔루션입니다.


## 질문 #22 +++++

SysOps 관리자는 AWS CloudFormation을 사용하여 회사의 클라우드 인프라를 관리할 책임이 있습니다. 

SysOps 관리자는 여러 AWS 서비스로 구성된 단일 리소스를 만들어야 합니다. 리소스는 CloudFormation 콘솔을 통한 생성 및 삭제를 지원해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 CloudFormation 리소스 유형을 만들어야 합니까?

A. cfn-init 헬퍼 스크립트가 있는 AWS::EC2::Instance
B. AWS::OpsWorks::인스턴스
C. AWS::SSM::문서
D. 사용자 정의::MyCustomType 

**D. 사용자 정의::MyCustomType**입니다.

AWS CloudFormation에서 **사용자 정의 리소스**를 사용하면 여러 AWS 서비스로 구성된 복잡한 리소스를 만들 수 있습니다. 
사용자 정의 리소스를 사용하면 CloudFormation 콘솔을 통해 리소스를 생성하고 삭제할 수 있으며, 필요에 따라 특정 로직이나 기능을 구현할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: `AWS::EC2::Instance`는 단일 EC2 인스턴스를 생성하는 리소스이며, 여러 AWS 서비스로 구성된 단일 리소스를 지원하지 않습니다.
- **B**: `AWS::OpsWorks::Instance`는 OpsWorks 서비스를 사용하는 인스턴스를 생성하는 리소스이지만, 여러 서비스로 구성된 리소스를 직접 지원하지는 않습니다.
- **C**: `AWS::SSM::Document`는 AWS Systems Manager에서 사용할 수 있는 문서 리소스를 생성하지만, CloudFormation 콘솔을 통한 리소스 생성 및 삭제의 요구 사항을 충족하지 않습니다.

따라서, 여러 AWS 서비스로 구성된 단일 리소스를 만들고 관리하기 위해서는 **D. 사용자 정의::MyCustomType**을 사용하는 것이 가장 적절합니다.

## 질문 #23

새로운 웹사이트는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 

Amazon Route 53은 DNS 레코드를 관리하는 데 사용됩니다.
웹사이트의 정점 도메인 이름(예: `company.com`)을 Application Load Balancer로 가리키기 위해 Route 53에 어떤 유형의 레코드를 설정해야 합니까?

1. CNAME
2. SOA
3. 텍스트
4. 별칭 

정답은 **D. 별칭**입니다.

Amazon Route 53에서 **별칭 레코드**는 Route 53에서 제공하는 특별한 레코드 유형으로, Amazon Web Services(AWS) 리소스를 직접 가리킬 수 있습니다. Application Load Balancer(ALB)와 같은 AWS 리소스에 대해 별칭 레코드를 설정하면, ALB의 DNS 이름을 Route 53에서 가리킬 수 있으며, 사용자가 ALB를 통해 웹사이트에 접근할 수 있습니다. 

별칭 레코드는 루트 도메인(예: `company.com`)에서도 사용할 수 있어 CNAME 레코드보다 더 유용합니다. CNAME 레코드는 루트 도메인에 사용할 수 없기 때문입니다.

다른 선택지에 대한 설명:
- **A. CNAME**: CNAME 레코드는 서브도메인에 사용할 수 있지만, 루트 도메인에는 사용할 수 없습니다.
- **B. SOA**: SOA 레코드는 도메인 존의 시작을 나타내는 레코드로, DNS를 관리하는 데 필요하지만, ALB를 가리키기 위한 레코드는 아닙니다.
- **C. 텍스트**: TXT 레코드는 도메인에 대한 텍스트 정보를 저장하는 데 사용되며, ALB와는 관련이 없습니다.

따라서, 웹사이트의 정점 도메인 이름을 Application Load Balancer로 가리키기 위해서는 **D. 별칭** 레코드를 설정하는 것이 정답입니다.

## 질문 #24 +++

한 회사가 AWS Trusted Advisor를 사용하여 보안 및 규정 준수를 구현하고 있습니다. 

회사의 SysOps 팀은 액세스할 수 있는 Trusted Advisor 검사 목록을 검증하고 있습니다.
사용 가능한 Trusted Advisor 검사의 양에 영향을 미치는 요소는 무엇입니까?

A. 최소한 하나의 Amazon EC2 인스턴스가 실행 상태인지 여부
B. AWS 지원 계획
C. AWS Organizations 서비스 제어 정책(SCP)
D. AWS 계정 루트 사용자가 다중 요소 인증(MFA)을 활성화했는지 여부

정답은 **B. AWS 지원 계획**입니다.

AWS Trusted Advisor의 기능은 고객이 선택한 **AWS 지원 계획**에 따라 다릅니다. 기본적인 지원 계획에서는 제한된 검사만 사용할 수 있지만, **Developer**, **Business**, 또는 **Enterprise** 지원 계획을 이용하면 더 많은 검사 및 권장 사항에 접근할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: EC2 인스턴스의 실행 여부는 Trusted Advisor의 검사 수에 직접적인 영향을 미치지 않습니다.
- **C**: 서비스 제어 정책(SCP)은 AWS Organizations 내에서 계정의 권한을 관리하는 데 사용되지만, Trusted Advisor 검사 목록에 직접적인 영향을 주지는 않습니다.
- **D**: MFA 활성화 여부는 보안 측면에서 중요하지만, Trusted Advisor 검사 수와는 관련이 없습니다.

따라서, Trusted Advisor에서 사용할 수 있는 검사의 양에 영향을 미치는 요소는 **B. AWS 지원 계획**입니다.

## 질문 #25 +++++

SysOps 관리자가 MariaDB DB 인스턴스용 Amazon RDS에서 문제를 조사하고 있습니다. 

SysOps 관리자는 자세한 대기 이벤트로 분류된 데이터베이스 부하를 표시하려고 합니다.
SysOps 관리자는 어떻게 이 목표를 달성할 수 있습니까?

A. Amazon CloudWatch 대시보드를 만듭니다.
B. Amazon RDS 성능 통찰력을 활성화합니다. 
C. 향상된 모니터링을 활성화하고 구성합니다.
D. Amazon CloudWatch Logs에서 데이터베이스 로그를 검토합니다.

SysOps 관리자가 MariaDB DB 인스턴스용 Amazon RDS에서 자세한 대기 이벤트로 분류된 데이터베이스 부하를 표시하려면 다음 옵션을 선택해야 합니다:

**B. Amazon RDS 성능 통찰력을 활성화합니다.**

### 이유:
- **Amazon RDS 성능 통찰력**은 데이터베이스 성능 문제를 식별하고 분석할 수 있는 강력한 도구입니다. 이 기능을 활성화하면 대기 이벤트, 쿼리 성능 및 기타 중요한 메트릭을 시각화하여 데이터베이스 부하를 더 잘 이해하고 문제를 해결할 수 있습니다. 

다른 옵션들은 다음과 같은 기능을 제공하지만, 대기 이벤트를 상세히 분석하는 데에는 성능 통찰력이 가장 적합합니다:

- **A. Amazon CloudWatch 대시보드**: CloudWatch 대시보드는 메트릭을 모니터링하는 데 유용하지만 대기 이벤트에 대한 자세한 정보를 제공하지는 않습니다.
- **C. 향상된 모니터링**: 이 기능은 인스턴스 수준의 메트릭을 제공하지만, 대기 이벤트에 대한 상세한 분석에는 성능 통찰력이 필요합니다.
- **D. Amazon CloudWatch Logs에서 데이터베이스 로그를 검토**: 로그를 검토하는 것도 도움이 되지만, 대기 이벤트를 분류하고 시각화하는 데에는 성능 통찰력이 더 효과적입니다. 

따라서 **B. Amazon RDS 성능 통찰력을 활성화합니다**가 가장 적합한 선택입니다.


## 질문 #26 +++++

한 회사가 여러 가용성 영역에 분산된 Amazon EC2 인스턴스 세트에서 애플리케이션을 호스팅할 계획입니다. 

애플리케이션은 매초 수백만 건의 요청으로 확장할 수 있어야 합니다.
SysOps 관리자는 트래픽을 EC2 인스턴스로 분산하는 솔루션을 설계해야 합니다. 
솔루션은 각 가용성 영역에 단일 정적 IP 주소를 사용하면서 갑작스럽고 불안정한 트래픽 패턴을 처리하도록 최적화되어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. Amazon Simple Queue Service(Amazon SQS) 대기열
B. 애플리케이션 로드 밸런서
C. AWS 글로벌 엑셀러레이터
D. 네트워크 로드 밸런서 가장 많이 투표된

정답은 **D. 네트워크 로드 밸런서**입니다.

**네트워크 로드 밸런서(NLB)**는 고속 TCP 및 UDP 트래픽을 처리할 수 있으며, 각 가용성 영역(AZ)에 단일 정적 IP 주소를 제공하는 기능을 가지고 있습니다. 이는 트래픽이 EC2 인스턴스로 효과적으로 분산되도록 하며, 갑작스럽고 불안정한 트래픽 패턴을 처리하는 데 최적화되어 있습니다. 

다른 선택지에 대한 설명:
- **A. Amazon Simple Queue Service (Amazon SQS) 대기열**: SQS는 메시지 큐 서비스로, 메시지를 비동기적으로 처리하는 데 적합하지만, 실시간 트래픽 분산에는 적합하지 않습니다.
- **B. 애플리케이션 로드 밸런서**: 애플리케이션 로드 밸런서는 HTTP/HTTPS 트래픽을 처리하는 데 최적화되어 있지만, 단일 정적 IP 주소를 제공하는 기능은 없으며, TCP 트래픽 처리에 있어 NLB보다 성능이 떨어질 수 있습니다.
- **C. AWS 글로벌 엑셀러레이터**: 글로벌 엑셀러레이터는 전 세계에 분산된 애플리케이션의 성능을 향상시키기 위한 서비스이지만, EC2 인스턴스 간의 트래픽 분산에는 직접적인 영향을 주지 않습니다.

따라서, **D. 네트워크 로드 밸런서**가 이러한 요구 사항을 충족하는 최적의 솔루션입니다.

## 질문 #27 ++

SysOps 관리자가 AWS CloudFormation StackSets를 사용하여 동일한 AWS 계정의 두 AWS 리전에 AWS 리소스를 만들고 있습니다. 

한 리전에서 스택 작업이 실패하고 스택 인스턴스 상태가 OUTDATED로 반환됩니다.
이 실패의 원인은 무엇입니까?

A. CloudFormation 템플릿이 로컬 디스크에서 변경되어 CloudFormation에 제출되지 않았습니다.
B. CloudFormation 템플릿은 고유하지 않은 글로벌 리소스를 만들려고 합니다. 
C. 스택이 아직 해당 지역에 배포되지 않았습니다.
D. SysOps 관리자가 CloudFormation API의 이전 버전을 사용하고 있습니다.

**B. CloudFormation 템플릿은 고유하지 않은 글로벌 리소스를 만들려고 합니다**입니다.

AWS CloudFormation StackSets는 여러 AWS 리전 또는 계정에 리소스를 배포할 수 있는 기능을 제공하지만, 글로벌 리소스(예: IAM, Route 53, S3 등)는 특정 리전에 종속되지 않으며, 이를 여러 리전에서 동시에 생성하려고 하면 충돌이 발생할 수 있습니다. 이러한 이유로 인해 스택 작업이 실패하고 상태가 OUTDATED로 반환될 수 있습니다.

다.

## 질문 #28 +++

SysOps 관리자는 Amazon S3를 구성하여 간단한 비생산 웹페이지를 호스팅해야 합니다.

SysOps 관리자는 AWS Management Console에서 빈 S3 버킷을 만들었습니다. S3 버킷에는 기본 구성이 있습니다.
SysOps 관리자는 이 프로세스를 완료하기 위해 어떤 작업 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. "객체에 대한 요청 리디렉션" 기능을 사용하여 버킷 루트 URL을 가리키도록 S3 버킷을 구성합니다.
B. "모든 퍼블릭 액세스 차단" 설정을 끕니다. <Permission>WEBSITE</Permission>가 포함된 버킷 ACL을 사용하여 퍼블릭 액세스를 허용합니다.
C. "모든 퍼블릭 액세스 차단" 설정을 끕니다. AuthenticatedUsers 수혜자에게 액세스를 허용하는 버킷 ACL을 사용하여 퍼블릭 액세스를 허용합니다.
D. "모든 퍼블릭 액세스 차단" 설정을 끕니다. "Principal"을 허용하는 버킷 정책을 설정합니다: s3:GetObject 작업. 
E. index.html 문서를 만듭니다. 정적 웹사이트 호스팅을 구성하고 인덱스 문서를 S3 버킷에 업로드합니다. 


**D. "모든 퍼블릭 액세스 차단" 설정을 끕니다. "Principal"을 허용하는 버킷 정책을 설정합니다: s3:GetObject 작업.**
**E. index.html 문서를 만듭니다. 정적 웹사이트 호스팅을 구성하고 인덱스 문서를 S3 버킷에 업로드합니다.**입니다.

## 선택 이유:
1. **D**: S3 버킷에 대해 "모든 퍼블릭 액세스 차단" 설정을 끄고, **버킷 정책**을 설정하여 공개적으로 객체에 접근할 수 있도록 허용해야 합니다. 이 정책은 `s3:GetObject` 작업을 허용하여 사용자가 S3 버킷의 콘텐츠를 접근할 수 있게 합니다.

2. **E**: 정적 웹사이트 호스팅을 활성화하려면 `index.html` 문서를 생성하고 이를 S3 버킷에 업로드해야 합니다. 그런 다음 S3에서 정적 웹사이트 호스팅을 설정하여 `index.html`을 기본 문서로 지정해야 합니다.

## 다른 선택지:
- **A**: "객체에 대한 요청 리디렉션" 기능은 정적 웹사이트를 호스팅하는 데 필요하지 않으며, 기본 구성이 필요합니다.
- **B**: "모든 퍼블릭 액세스 차단"을 끄는 것은 맞지만, **버킷 ACL**로 퍼블릭 액세스를 설정하는 것은 최선의 방법이 아닙니다. **버킷 정책**을 사용하는 것이 더 권장됩니다.
- **C**: AuthenticatedUsers 수혜자에게 액세스를 허용하는 것은 비생산 웹페이지의 목적에 부합하지 않으며, 퍼블릭 액세스를 완전히 허용하지 않습니다.

따라서, 올바른 조합은 **D**와 **E**입니다.


## 질문 #29 ++++

한 회사에서는 point-in-time 복구, 백트래킹, 자동 백업이 활성화된 Amazon Aurora MySQL DB 클러스터를 사용하고 있습니다. 

SysOps 관리자는 DB 클러스터를 이전 72시간 내의 특정 복구 지점으로 롤백할 수 있어야 합니다. 복원은 동일한 프로덕션 DB 클러스터에서 완료해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. Aurora Replica를 생성합니다. 복제본을 홍보하여 ​​기본 DB 인스턴스를 대체합니다.
B. 기존 DB 클러스터에 자동 백업을 복원하는 AWS Lambda 함수를 생성합니다.
C. 백트래킹을 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 되돌립니다. 
D. 지정 시점 복구를 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 복원합니다.

**C. 백트래킹을 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 되돌립니다**입니다.

## 선택 이유:
- **C. 백트래킹**: Amazon Aurora MySQL의 백트래킹 기능을 사용하면 DB 클러스터를 특정 시점으로 쉽게 되돌릴 수 있습니다. 이 기능은 72시간 이내의 복구 지점으로 롤백할 수 있는 기능을 제공합니다. 백트래킹은 실제 데이터를 변경하지 않고 특정 시점으로 데이터베이스를 되돌리는 매우 유용한 방법입니다.


## 질문 #30

Amazon EC2 콘솔에서 작업하는 사용자가 Amazon EC2 Windows 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨의 크기를 늘렸습니다. 

변경 사항은 파일 시스템에 반영되지 않습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 운영 체제 수준 도구로 파일 시스템을 확장하여 새로운 저장 용량을 활용합니다. 가장 많이 투표된
B. EBS 볼륨을 EC2 인스턴스에 다시 연결합니다.
C. EBS 볼륨에 연결된 EC2 인스턴스를 재부팅합니다.
D. EBS 볼륨의 스냅샷을 찍습니다. 원래 볼륨을 스냅샷에서 생성된 볼륨으로 바꿉니다.


정답은 **A. 운영 체제 수준 도구로 파일 시스템을 확장하여 새로운 저장 용량을 활용합니다**입니다.

## 선택 이유:
- **A. 운영 체제 수준 도구로 파일 시스템을 확장**: Amazon EBS 볼륨의 크기를 늘린 후, 운영 체제의 파일 시스템도 해당 변경 사항을 인식하도록 확장해야 합니다. Windows에서는 Disk Management 도구를 사용하여 볼륨의 크기를 늘리거나 `diskpart` 명령어를 사용하여 크기를 조정할 수 있습니다. 이 단계를 수행해야만 새로 할당된 저장 용량을 사용할 수 있습니다.

따라서, **A**가 문제를 해결하기 위한 올바른 방법입니다.


## 질문 #31 +++

SysOps 관리자가 Amazon EC2 인스턴스를 사용하여 애플리케이션을 호스팅하고 있습니다. 

SysOps 관리자는 애플리케이션이 Amazon DynamoDB 테이블에 액세스할 수 있는 권한을 부여해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. DynamoDB 테이블에 액세스하기 위한 액세스 키를 만듭니다. 액세스 키를 EC2 인스턴스 프로필에 할당합니다.
B. DynamoDB 테이블에 액세스하기 위한 EC2 키 쌍을 만듭니다. 키 쌍을 EC2 인스턴스 프로필에 할당합니다.
C. DynamoDB 테이블에 액세스하기 위한 IAM 사용자를 만듭니다. EC2 인스턴스 프로필에 IAM 사용자를 할당합니다.
D. DynamoDB 테이블에 액세스하기 위한 IAM 역할을 만듭니다. EC2 인스턴스 프로필에 IAM 역할을 할당합니다.

**D. DynamoDB 테이블에 액세스하기 위한 IAM 역할을 만듭니다. EC2 인스턴스 프로필에 IAM 역할을 할당합니다**입니다.

## 선택 이유:
- **D. IAM 역할을 사용하여 EC2 인스턴스에 권한 부여**: IAM 역할은 AWS 서비스에 대한 권한을 관리하는 안전한 방법입니다. EC2 인스턴스에 IAM 역할을 할당하면, 해당 인스턴스에서 실행되는 애플리케이션이 IAM 역할에 부여된 권한을 사용하여 DynamoDB 테이블에 액세스할 수 있습니다. 이 방법은 보안성을 높이고, 액세스 키를 관리할 필요 없이 자동으로 자격 증명을 관리합니다.



## 질문 #32 ++

SysOps 관리자가 Amazon S3 버킷의 객체를 실수로 덮어쓰거나 삭제하지 못하도록 보호하려고 합니다. 

현재가 아닌 객체는 90일 동안 보관한 다음 영구적으로 삭제해야 합니다. 객체는 원래 S3 버킷과 동일한 AWS 리전에 있어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. S3 버킷에 대한 Amazon Data Lifecycle Manager(Amazon DLM) 수명 주기 정책을 만듭니다. 90일 후에 비현재 객체를 삭제하는 규칙을 수명 주기 정책에 추가합니다.
B. S3 버킷에 대한 AWS 백업 정책을 만듭니다. 90일 후에 비현재 객체를 만료하는 라이프사이클을 포함하는 백업 규칙을 만듭니다.
C. S3 버킷에서 S3 크로스 리전 복제를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다.
D. S3 버킷에서 S3 버전 관리를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다. 

**D. S3 버킷에서 S3 버전 관리를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다.**


결론적으로, **D 옵션**은 S3 버전 관리를 통해 실수로 객체가 삭제되거나 덮어쓰여지는 것을 방지하고, 라이프사이클 정책을 통해 90일 후에 비현재 객체를 삭제하는 요구 사항을 충족합니다.


## 질문 #33

한 회사에 고객이 웹사이트에서 레코드를 검색하는 데 사용하는 애플리케이션이 있습니다. 

애플리케이션의 데이터는 Amazon Aurora DB 클러스터에 저장됩니다. 애플리케이션의 사용은 계절과 요일에 따라 다릅니다.
웹사이트의 인기가 증가하고 있으며, 활동이 가장 많은 기간에 DB 클러스터에 부하가 증가하여 웹사이트 성능이 저하되고 있습니다. 
애플리케이션 로그에 따르면 성능 문제는 사용자가 정보를 검색할 때 발생합니다. 동일한 검색을 여러 번 수행하는 경우는 드뭅니다.
SysOps 관리자는 리소스 효율성을 극대화하는 솔루션을 사용하여 플랫폼의 성능을 개선해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. DB 클러스터 앞에 Amazon ElastiCache for Redis 클러스터를 배포합니다. 애플리케이션이 데이터베이스에 새 쿼리를 발행하기 전에 캐시를 확인하도록 애플리케이션을 수정합니다. 모든 쿼리의 결과를 캐시에 추가합니다.
B. DB 클러스터에 Aurora Replica를 배포합니다. 검색 작업에 리더 엔드포인트를 사용하도록 애플리케이션을 수정합니다. Aurora Auto Scaling을 사용하여 부하에 따라 복제본 수를 확장합니다. 
C. DB 클러스터를 지원하는 스토리지 볼륨에서 프로비저닝된 IOPS를 사용하여 애플리케이션의 최대 부하를 지원할 수 있을 만큼 성능을 ​​향상시킵니다.
D. DB 클러스터의 인스턴스 크기를 애플리케이션의 최대 부하를 지원하기에 충분한 크기로 늘립니다. Aurora Auto Scaling을 사용하여 부하에 따라 인스턴스 크기를 조정합니다.

이 문제에서 성능 저하의 주요 원인은 데이터베이스에 대한 읽기 부하입니다. 애플리케이션 로그에 따르면, 사용자가 정보를 검색할 때 성능 문제가 발생하고, 동일한 검색이 여러 번 발생하지는 않습니다. 따라서 효율적으로 데이터를 캐싱하거나 읽기 성능을 확장할 수 있는 방법이 필요합니다.

가장 적합한 솔루션은 **B. DB 클러스터에 Aurora Replica를 배포합니다. 검색 작업에 리더 엔드포인트를 사용하도록 애플리케이션을 수정합니다. Aurora Auto Scaling을 사용하여 부하에 따라 복제본 수를 확장합니다.**

1. **Aurora Replica를 사용한 읽기 성능 확장**:
   - Aurora는 읽기 작업을 처리하기 위해 **읽기 전용 복제본(Replica)**을 추가할 수 있습니다. 복제본을 추가하면 읽기 요청을 이 복제본으로 분산시켜 DB 클러스터의 **읽기 부하를 완화**할 수 있습니다. 이는 사용자가 데이터를 검색할 때 성능 문제를 해결하는 데 매우 효과적입니다.
   
2. **Aurora Auto Scaling**:
   - Aurora는 **Auto Scaling**을 지원하므로, 복제본의 수를 자동으로 확장하거나 축소하여 애플리케이션의 부하에 맞춰 DB 성능을 최적화할 수 있습니다. 계절성과 요일에 따라 애플리케이션의 부하가 달라진다면 Auto Scaling이 유연한 확장 및 축소 기능을 제공합니다.
   
3. **리더 엔드포인트 사용**:
   - 애플리케이션에서 **리더 엔드포인트**를 사용하도록 수정하면 여러 Aurora 복제본으로 읽기 요청을 자동으로 라우팅할 수 있습니다. 이를 통해 데이터베이스의 부하를 분산시키고 성능을 개선할 수 있습니다.


따라서 **B 옵션**은 부하를 효과적으로 분산시키고, Aurora의 자동 확장 기능을 통해 유동적인 트래픽 변화에 대응할 수 있으므로 가장 적합한 솔루션입니다.

## 질문 #34

한 회사가 AWS Organizations를 사용하여 여러 AWS 계정을 관리합니다. 

회사 정책에 따라 특정 AWS 지역만 고객 데이터를 저장하고 처리하는 데 사용할 수 있습니다. SysOps 관리자는 회사의 모든 사람이 승인되지 않은 지역에서 Amazon EC2 인스턴스를 프로비저닝하는 것을 방지해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 모든 리전에서 AWS CloudTrail을 구성하여 모든 API 활동을 기록합니다. 모든 승인되지 않은 리전에서 ec2:RunInstances 이벤트에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. AWS Lambda를 사용하여 시작된 EC2 인스턴스를 종료합니다.

B. 각 AWS 계정에서 Region 조건을 사용하여 모든 승인되지 않은 Region에서 ec2:RunInstances 작업을 거부하는 관리형 IAM 정책을 만듭니다. 이 정책을 각 AWS 계정의 모든 IAM 그룹에 연결합니다.

C. 각 AWS 계정에서 Region 조건을 사용하여 모든 승인되지 않은 Region에서 ec2:RunInstances 작업을 거부하는 IAM 권한 경계 정책을 만듭니다. 각 AWS 계정의 모든 IAM 사용자에게 권한 경계 정책을 연결합니다.

D. AWS Organizations에서 서비스 제어 정책(SCP)을 만들어 모든 승인되지 않은 Regions에서 ec2:RunInstances 작업을 거부합니다. 이 정책을 조직의 루트 수준에 연결합니다. 


이 시나리오에서 회사의 모든 AWS 계정이 승인되지 않은 지역에서 Amazon EC2 인스턴스를 프로비저닝하는 것을 방지하기 위한 가장 운영 효율적인 솔루션은 
**D. AWS Organizations에서 서비스 제어 정책(SCP)을 만들어 모든 승인되지 않은 Regions에서 ec2:RunInstances 작업을 거부합니다. 이 정책을 조직의 루트 수준에 연결합니다.**



## 질문 #35 +++

회사의 공개 웹사이트는 Amazon CloudFront 배포판 뒤에 있는 us-east-1 지역의 Amazon S3 버킷에 호스팅됩니다. 

회사는 웹사이트가 DDoS 공격으로부터 보호되도록 하려고 합니다. SysOps 관리자는 회사가 DDoS 보호가 적용되는 속도 제한을 제어할 수 있는 솔루션을 배포해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 기본 작업 허용을 사용하여 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다.
B. us-east-1에서 allow default action을 사용하여 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 S3 버킷과 연결합니다.
C. 블록 기본 작업으로 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 허용하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다.
D. us-east-1에서 block default action을 사용하여 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 허용하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 S3 버킷과 연결합니다.
회사의 공개 웹사이트를 DDoS 공격으로부터 보호하기 위해 가장 적합한 솔루션은 다음과 같습니다:

**A. 기본 작업 허용을 사용하여 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다.**

이 솔루션의 장점은 다음과 같습니다:

1. **DDoS 보호**: AWS WAF는 DDoS 공격을 방어하기 위한 다양한 규칙을 설정할 수 있어, 높은 트래픽 속도를 감지하고 차단할 수 있습니다.
2. **CloudFront 통합**: CloudFront 배포와 통합하여 웹사이트의 전반적인 성능과 보안을 향상시킬 수 있습니다.
3. **속도 제한**: 속도 기반 규칙을 통해 비정상적으로 높은 요청 속도를 차단할 수 있어, DDoS 공격으로부터 추가적인 보호를 제공합니다.

따라서 A 옵션이 요구 사항을 충족하는 가장 적절한 선택입니다.


## 질문 #36 +

SysOps 관리자가 AWS SDK를 사용하여 여러 유지 관리 작업을 수행하는 Python 스크립트를 개발했습니다.

스크립트는 매일 밤 자동으로 실행되어야 합니다.
이 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. Python 스크립트를 AWS Lambda 함수로 변환합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 매일 밤 함수를 호출합니다.
B. Python 스크립트를 AWS Lambda 함수로 변환합니다. AWS CloudTrail을 사용하여 매일 밤 함수를 호출합니다.
C. Python 스크립트를 Amazon EC2 인스턴스에 배포합니다. Amazon EventBride(Amazon CloudWatch Events)를 사용하여 인스턴스가 매일 밤 시작 및 중지되도록 예약합니다.
D. Python 스크립트를 Amazon EC2 인스턴스에 배포합니다. AWS Systems Manager를 사용하여 매일 밤 인스턴스가 시작되고 중지되도록 예약합니다.

AWS SDK를 사용하여 여러 유지 관리 작업을 수행하는 Python 스크립트를 매일 밤 자동으로 실행하기 위해 가장 운영 효율적인 솔루션은 다음과 같습니다:

**A. Python 스크립트를 AWS Lambda 함수로 변환합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 매일 밤 함수를 호출합니다.**

이 솔루션의 장점은 다음과 같습니다:

1. **운영 효율성**: AWS Lambda는 서버리스 환경에서 실행되므로 인프라를 관리할 필요가 없습니다. 코드만 업로드하면 Lambda가 자동으로 스케일링 및 관리됩니다.
2. **비용 효율성**: Lambda는 사용한 만큼만 비용을 지불하므로, 매일 밤 한 번 실행되는 작업에 적합합니다.
3. **자동화**: Amazon EventBridge를 사용하여 특정 시간에 자동으로 Lambda 함수를 호출할 수 있습니다.

따라서 A 옵션이 가장 적절한 선택입니다.

## 질문 #37 +++

SysOps 관리자는 AWS Lambda 함수에 오류가 발생하면 소프트웨어 개발자에게 즉시 알리는 솔루션을 만들어야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?


A. 각 개발자에 대한 이메일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. Errors 메트릭과 Lambda 함수 이름을 차원으로 사용하여 Amazon CloudWatch 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다. 

B. 각 개발자에 대한 모바일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. LambdaError를 이벤트 패턴으로, SNS 토픽 이름을 리소스로 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다.

C. Amazon Simple Email Service(Amazon SES)에서 각 개발자 이메일 주소를 확인합니다. LambdaError 메트릭과 개발자 이메일 주소를 차원으로 사용하여 Amazon CloudWatch 규칙을 만듭니다. 규칙 상태가 ALARM에 도달하면 Amazon SES를 통해 이메일을 보내도록 규칙을 구성합니다.

D. Amazon Simple Email Service(Amazon SES)에서 각 개발자 모바일 폰을 확인합니다. 이벤트 패턴으로 Error를 사용하고 리소스로 Lambda 함수 이름을 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 규칙 상태가 ALARM에 도달하면 Amazon SES를 통해 푸시 알림을 보내도록 규칙을 구성합니다.


AWS Lambda 함수에서 오류가 발생할 때 소프트웨어 개발자에게 즉시 알리는 솔루션으로 가장 적합한 옵션은 다음과 같습니다:

**A. 각 개발자에 대한 이메일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. Errors 메트릭과 Lambda 함수 이름을 차원으로 사용하여 Amazon CloudWatch 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다.** 

이 솔루션은 다음과 같은 이유로 요구 사항을 충족합니다:

1. **즉시 알림**: CloudWatch 알람이 오류 발생 시 즉시 알림을 발송하므로 개발자는 빠르게 대응할 수 있습니다.
2. **유연성**: SNS를 사용하면 여러 개발자에게 동시에 알림을 보낼 수 있습니다.
3. **손쉬운 관리**: SNS 토픽을 통해 구독자를 쉽게 추가하거나 제거할 수 있어 관리가 용이합니다.

따라서 A 옵션이 가장 적절한 선택입니다.


## 질문 #38 ++

한 회사에는 민감한 정보가 들어 있는 개인 Amazon S3 버킷이 있습니다. 

SysOps 관리자는 버킷의 객체에 액세스하려는 시도로 인해 발생하는 인증 실패의 IP 주소 로그를 보관해야 합니다. 로그는 90일 동안 덮어쓰거나 삭제할 수 없도록 저장해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. AWS CloudTrail 트레일을 만듭니다. Amazon CloudWatch Logs에 저장할 로그 파일을 구성합니다. 보관 기간이 90일인 로그 그룹을 구성합니다.
B. AWS CloudTrail 트레일을 만듭니다. 로그 파일을 다른 S3 버킷에 저장하도록 구성합니다. CloudTrail 로그 파일 무결성 검증을 90일 동안 켭니다.
C. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 Amazon CloudWatch Logs에 저장되도록 구성합니다. 보관 기간이 90일인 로그 그룹을 구성합니다.
D. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 두 번째 S3 버킷에 저장되도록 구성합니다. 두 번째 S3 버킷에서 S3 객체 잠금을 켜고 기본 보관 기간을 90일로 구성합니다. 

가장 적합한 솔루션은 **D. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 두 번째 S3 버킷에 저장되도록 구성합니다. 두 번째 S3 버킷에서 S3 객체 잠금을 켜고 기본 보관 기간을 90일로 구성합니다.**


결론적으로, **D 옵션**은 **S3 객체 잠금을 사용해** 로그 파일이 90일 동안 보호되도록 하고, 로그 무결성 및 데이터 보존을 확실하게 관리할 수 있는 솔루션이므로 요구 사항을 가장 잘 충족합니다.

## 질문 #39 +++

SysOps 관리자가 NAT 인스턴스를 NAT 게이트웨이로 마이그레이션합니다. 

마이그레이션 후 프라이빗 서브넷의 Amazon EC2 인스턴스에 호스팅된 애플리케이션은 인터넷에 액세스할 수 없습니다.
다음 중 이 문제의 가능한 이유는 무엇입니까? (두 가지를 선택하세요.)

A. 해당 애플리케이션은 NAT 게이트웨이가 지원하지 않는 프로토콜을 사용하고 있습니다. 
B. NAT 게이트웨이가 보안 그룹에 없습니다.
C. NAT 게이트웨이가 지원되지 않는 가용성 영역에 있습니다.
D. NAT 게이트웨이가 사용 가능한 상태가 아닙니다. 
E. 포트 포워딩 설정으로 인해 인터넷에서 내부 서비스에 접근할 수 없습니다.


NAT 인스턴스를 NAT 게이트웨이로 마이그레이션한 후, 프라이빗 서브넷의 Amazon EC2 인스턴스에 호스팅된 애플리케이션이 인터넷에 액세스할 수 없는 가능한 이유는 다음과 같습니다:

**A. 해당 애플리케이션은 NAT 게이트웨이가 지원하지 않는 프로토콜을 사용하고 있습니다.**  
NAT 게이트웨이는 TCP와 UDP 프로토콜만 지원하므로, 다른 프로토콜을 사용하는 경우 인터넷에 접근할 수 없습니다.

**D. NAT 게이트웨이가 사용 가능한 상태가 아닙니다.**  
NAT 게이트웨이가 비활성 상태이거나 구성에 문제가 있는 경우, 프라이빗 서브넷의 EC2 인스턴스가 인터넷에 액세스할 수 없습니다.

이 두 가지가 NAT 게이트웨이로의 마이그레이션 후 발생할 수 있는 문제의 원인입니다.

## 질문 #40 +++

한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

SysOps 관리자가 수요 증가를 처리하기 위해 Auto Scaling 그룹과 Application Load Balancer(ALB)를 만듭니다. 하지만 EC2 인스턴스가 상태 검사에 실패합니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 자동 확장 그룹이 모든 AWS 지역을 사용하도록 구성되었는지 확인합니다.
B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인합니다. 
C. ALB에서 리스너 우선순위를 확인합니다. 필요한 경우 우선순위를 변경합니다.
D. Auto Scaling 그룹의 최대 인스턴스 수를 확인합니다. 필요한 경우 숫자를 변경합니다.


EC2 인스턴스가 상태 검사에 실패하는 문제를 해결하기 위해 SysOps 관리자가 수행해야 할 조치는 다음과 같습니다:

**B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인합니다.**  
Application Load Balancer(ALB)의 상태 검사에서는 EC2 인스턴스에서 특정 프로토콜(HTTP 또는 HTTPS)과 포트(예: 80 또는 443)로 애플리케이션이 정상적으로 실행되고 있는지 확인합니다. 애플리케이션이 해당 포트에서 올바르게 실행되고 있는지, 그리고 보안 그룹 설정이 이를 허용하는지 확인하는 것이 중요합니다.

이 외에도 ALB와 Auto Scaling 그룹이 올바르게 구성되었는지, 인스턴스가 올바른 서브넷에 배치되어 있는지 확인하는 것도 좋은 접근입니다. 하지만 주어진 옵션 중에서는 B가 가장 중요한 첫 번째 단계입니다.
InsufficientInstance


## 질문 #41 +

SysOps 관리자가 AWS Service Catalog 포트폴리오를 생성하고 회사의 두 번째 AWS 계정과 포트폴리오를 공유했습니다. 

두 번째 계정은 다른 관리자가 제어합니다.
두 번째 계정의 관리자는 어떤 작업을 수행할 수 있습니까?

A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가합니다. 가장 많이 투표된
B. 가져온 포트폴리오에 새로운 제품을 추가합니다.
C. 가져온 포트폴리오에 포함된 제품에 대한 출시 역할을 변경합니다.
D. 가져온 포트폴리오의 제품을 맞춤화합니다.


AWS Service Catalog에서 포트폴리오를 공유한 경우, 두 번째 계정의 관리자가 수행할 수 있는 작업은 다음과 같습니다:

**A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가합니다.**

두 번째 계정의 관리자는 공유된 포트폴리오에서 제품을 로컬 포트폴리오로 가져오는 작업을 수행할 수 있습니다. 그러나 가져온 포트폴리오에 새로운 제품을 추가하거나, 기존 제품의 출시 역할을 변경하거나, 제품을 맞춤화하는 등의 작업은 일반적으로 포트폴리오를 소유한 계정의 권한을 요구합니다. 

따라서 가장 적절한 선택은 A입니다.



## 질문 #42 ++

한 회사가 애플리케이션을 AWS로 마이그레이션했습니다. 

이 회사는 여러 인스턴스 패밀리의 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다.
초기 테스트 중에 SysOps 관리자가 선택한 EC2 인스턴스에서 성능 문제를 식별합니다. 
이 회사는 엄격한 예산 할당 정책을 가지고 있으므로 SysOps 관리자는 워크로드에 맞는 성능 특성을 가진 올바른 리소스 유형을 사용해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 즉각적인 비용 절감을 위해 지역별 예약 인스턴스(RI)를 구매합니다. Cost Explorer에서 EC2 적정 크기 조정 권장 사항을 검토하고 조치를 취합니다. 적정 크기 조정 후 RI를 최적의 인스턴스 패밀리로 교환합니다.
B. 기존 인스턴스에 대한 영역별 예약 인스턴스(RI)를 구매합니다. AWS Billing and Cost Management 콘솔에서 RI 활용도를 모니터링합니다. 활용도를 최적화하기 위해 인스턴스 크기를 조정합니다.
C. AWS Compute Optimizer 권장 사항을 검토하고 조치를 취합니다. 컴퓨팅 리소스를 실행하는 데 필요한 비용을 줄이기 위해 Compute Savings Plans를 구매합니다. 가장 많이 투표된
D. AWS 비용 및 사용 보고서에서 리소스 활용도 지표를 검토합니다. EC2 인스턴스를 적정 크기로 조정합니다. 적정 크기의 리소스에 대한 주문형 용량 예약을 만듭니다.



SysOps 관리자가 워크로드에 맞는 성능 특성을 가진 올바른 리소스 유형을 사용하기 위해 수행할 수 있는 가장 효과적인 조치는 다음과 같습니다:

**C. AWS Compute Optimizer 권장 사항을 검토하고 조치를 취합니다. 컴퓨팅 리소스를 실행하는 데 필요한 비용을 줄이기 위해 Compute Savings Plans를 구매합니다.**

AWS Compute Optimizer는 EC2 인스턴스의 성능을 분석하여 올바른 인스턴스 유형을 추천하고, 이러한 권장 사항을 기반으로 적절한 리소스를 선택할 수 있게 합니다. 또한, Compute Savings Plans를 구매하면 필요할 때 할인을 받을 수 있으므로 예산 관리에도 유리합니다.

다른 옵션들은 특정한 경우에 유용할 수 있지만, 성능 문제를 해결하고 올바른 리소스를 선택하는 데 가장 적합한 접근 방식은 Compute Optimizer를 사용하는 것입니다.



## 질문 #43 +++++

SysOps 관리자는 회사의 인프라를 코드로 배포하는 업무를 맡고 있습니다. 

SysOps 관리자는 여러 환경에서 재사용할 수 있는 단일 템플릿을 작성하려고 합니다. 
SysOps 관리자는 AWS CloudFormation을 사용하여 솔루션을 만드는 방법은 무엇입니까?

A. CloudFormation 템플릿에서 Amazon EC2 사용자 데이터를 사용합니다.
B. 중첩된 스택을 사용하여 리소스를 프로비저닝합니다.
C. CloudFormation 템플릿에서 매개변수를 사용합니다. 가장 많이 투표된
D. 스택 정책을 사용하여 리소스를 프로비저닝합니다.

SysOps 관리자가 여러 환경에서 재사용할 수 있는 단일 템플릿을 작성하기 위해 AWS CloudFormation을 사용할 때 가장 적합한 방법은 다음과 같습니다:

**C. CloudFormation 템플릿에서 매개변수를 사용합니다.**

매개변수를 사용하면 CloudFormation 템플릿을 다양한 환경에서 재사용할 수 있도록 동적으로 구성할 수 있습니다. 이를 통해 템플릿을 사용할 때마다 환경에 따라 다른 값을 입력하여 리소스를 생성할 수 있습니다. 예를 들어, 인스턴스 유형, VPC ID, 서브넷 ID 등과 같은 값을 매개변수로 정의하여 유연성을 높일 수 있습니다.

다른 옵션들도 유용할 수 있지만, 매개변수를 사용한 접근 방식이 템플릿의 재사용성을 극대화하는 데 가장 효과적입니다.



## 질문 #44

SysOps 관리자는 Amazon EC2 인스턴스의 대규모 플릿을 담당하며, 다가올 하드웨어 유지 관리로 인해 인스턴스가 영향을 받을지 여부를 알아야 합니다.

어떤 옵션이 가장 적은 관리 오버헤드로 이 정보를 제공할까요?

A. 타사 모니터링 솔루션을 배포하여 실시간 EC2 인스턴스 모니터링을 제공합니다.
B. AWS Management Console을 사용하여 시스템 상태 검사에 실패한 모든 인스턴스를 나열합니다.
C. AWS CloudTrail에서 StopInstances API 호출을 모니터링합니다.
D. AWS 개인 건강 대시보드를 검토합니다. 가장 많이 투표된


SysOps 관리자가 Amazon EC2 인스턴스의 대규모 플릿에 대한 하드웨어 유지 관리 영향을 파악하는 데 가장 적은 관리 오버헤드로 정보를 제공하는 옵션은:

**D. AWS 개인 건강 대시보드를 검토합니다.**

AWS Personal Health Dashboard는 AWS 계정에 대한 중요한 상태 정보를 제공하며, 특정 인스턴스가 하드웨어 유지 관리 작업에 영향을 받을 경우 이를 사전에 알림으로써 관리자가 즉각적으로 대처할 수 있게 합니다. 이 대시보드는 자동으로 업데이트되며, 추가적인 설정이나 외부 도구 없이도 관련 정보를 제공합니다. 

다른 옵션은 보다 많은 관리 오버헤드가 필요하거나 실시간 모니터링을 위한 추가 설정이 필요할 수 있습니다.


## 질문 #45 +++++

SysOps 관리자가 AWS CloudFormation 템플릿을 사용하여 리소스를 배포하려고 합니다. 

템플릿에 정의된 Amazon EC2 인스턴스가 시작되지 않고 InsufficientInstanceCapacity 오류가 발생합니다.
SysOps 관리자는 이 오류를 해결하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. EC2 인스턴스에 대해 별도의 AWS CloudFormation 템플릿을 만듭니다.
B. EC2 인스턴스에 대한 가용성 영역을 지정하지 않도록 AWS CloudFormation 템플릿을 수정합니다. 가장 많이 투표된
C. AWS CloudFormation 템플릿을 수정하여 다른 EC2 인스턴스 유형을 사용합니다. 가장 많이 투표된
D. EC2 인스턴스에 다른 Amazon Machine Image(AMI)를 사용합니다.
E. 템플릿에서 스택을 생성하기 전에 AWS CLI의 validate-template 명령을 사용합니다.

SysOps 관리자가 AWS CloudFormation 템플릿에서 `InsufficientInstanceCapacity` 오류를 해결하기 위해 취할 수 있는 두 가지 조치는 다음과 같습니다:

**B. EC2 인스턴스에 대한 가용성 영역을 지정하지 않도록 AWS CloudFormation 템플릿을 수정합니다.**  
- 가용성 영역을 지정하지 않으면 AWS가 자동으로 가용성 영역을 선택하여 인스턴스를 시작할 수 있으며, 이는 용량이 부족한 특정 가용성 영역에 대한 의존성을 줄여줍니다.

**C. AWS CloudFormation 템플릿을 수정하여 다른 EC2 인스턴스 유형을 사용합니다.**  
- 특정 인스턴스 유형이 현재 가용성 영역에서 용량이 부족할 수 있으므로, 다른 인스턴스 유형으로 변경하면 이 문제를 해결할 수 있습니다.

이 두 가지 방법은 `InsufficientInstanceCapacity` 오류를 해결하는 데 효과적입니다.



## 질문 #46 +++

한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 

이 회사는 Amazon Route 53을 사용하여 트래픽을 라우팅합니다.
이 회사는 또한 Amazon S3 버킷에 구성된 정적 웹사이트를 가지고 있습니다.

SysOps 관리자는 정적 웹사이트를 웹 애플리케이션의 백업으로 사용해야 합니다. 정적 웹사이트로의 장애 조치는 완전히 자동화되어야 합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하십시오.)

A. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다.
B. 상태 검사에 실패하면 기본 웹사이트에서 보조 웹사이트로 전환하는 AWS Lambda 함수를 생성합니다.
C. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다. 가장 많이 투표된
D. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다.
E. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다. 가장 많이 투표된



SysOps 관리자가 정적 웹사이트를 웹 애플리케이션의 백업으로 사용하고 장애 조치를 완전히 자동화하려면 다음 두 가지 작업 조합을 선택해야 합니다:

**C. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다.**  
- 이 옵션은 ALB에 대한 트래픽을 기본적으로 라우팅하며, 상태 검사를 통해 ALB의 가용성을 확인합니다.

**E. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다.**  
- 이 옵션은 ALB가 상태 검사에 실패하는 경우 정적 웹사이트로 트래픽을 자동으로 라우팅하는 보조 장애 조치 정책을 설정합니다.

이 조합을 사용하면 ALB가 실패할 경우 자동으로 정적 웹사이트로 장애 조치가 이루어지며, 요구 사항을 충족할 수 있습니다.




## 질문 #47 +++++

데이터 분석 애플리케이션이 Amazon EC2 인스턴스에서 실행 중입니다. 

SysOps 관리자는 Amazon CloudWatch 에이전트가 수집한 메트릭에 사용자 지정 차원을 추가해야 합니다.
SysOps 관리자는 이 요구 사항을 어떻게 충족할 수 있습니까?

A. Amazon CloudWatch 에이전트를 사용하여 차원을 추출하고 메트릭을 수집하는 사용자 지정 셸 스크립트를 만듭니다.
B. 필요한 사용자 정의 차원을 평가하고 해당 지표를 Amazon Simple Notification Service(Amazon SNS)로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
C. AWS CloudTrail에서 지표를 수집하고 해당 지표를 Amazon CloudWatch Logs 그룹으로 전송하는 AWS Lambda 함수를 생성합니다.
D. Amazon CloudWatch 에이전트 구성 파일에 append_dimensions 필드를 만들어 메트릭을 수집합니다. 가장 많이 투표된


SysOps 관리자가 Amazon CloudWatch 에이전트가 수집한 메트릭에 사용자 지정 차원을 추가하려면 다음과 같은 방법이 가장 적절합니다:

**D. Amazon CloudWatch 에이전트 구성 파일에 append_dimensions 필드를 만들어 메트릭을 수집합니다.**  
- 이 옵션을 사용하면 CloudWatch 에이전트의 구성 파일에 `append_dimensions` 필드를 추가하여 사용자 지정 차원을 정의할 수 있습니다. 이렇게 하면 메트릭이 수집될 때 지정한 차원이 함께 전송되어, 해당 메트릭에 대한 추가적인 컨텍스트를 제공할 수 있습니다.

이 방법은 사용자 지정 차원을 메트릭 수집 과정에 통합하는 간단하고 효과적인 방법입니다.


## 질문 #48 +

한 회사가 Amazon S3 버킷에 데이터를 저장합니다. 

회사는 데이터를 분류하고 S3 파일에서 민감한 개인 정보를 찾아야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. S3 파일에서 민감한 개인 정보를 검색하고 이를 비준수로 표시하는 AWS Config 규칙을 생성합니다.
B. Amazon Rekognition을 사용하여 민감한 개인 정보를 분류하기 위한 S3 이벤트 기반 인공 지능/머신 러닝(AI/ML) 파이프라인을 생성합니다.
C. Amazon GuardDuty를 활성화합니다. Amazon S3 내부의 모든 데이터를 모니터링하도록 S3 보호를 구성합니다.
D. Amazon Macie를 활성화합니다. 관리되는 데이터 식별자를 사용하는 검색 작업을 만듭니다. 가장 많이 투표된

회사가 Amazon S3 버킷에 저장된 데이터에서 민감한 개인 정보를 찾아야 하는 경우, 가장 적절한 솔루션은 다음과 같습니다:

**D. Amazon Macie를 활성화합니다. 관리되는 데이터 식별자를 사용하는 검색 작업을 만듭니다.**  
- Amazon Macie는 S3 버킷 내에서 민감한 데이터(예: 개인 식별 정보(PII)와 같은)를 자동으로 식별하고 분류하는 데 특화된 서비스입니다. Macie를 활성화하면 관리되는 데이터 식별자를 사용하여 S3 버킷의 데이터를 스캔하고, 민감한 정보를 찾아내고 이를 비준수로 표시할 수 있습니다.  

이 방법은 민감한 데이터에 대한 가시성을 높이고 보안을 강화하는 데 매우 효과적입니다.




## 질문 #49 +++++

한 회사가 Amazon EC2 인스턴스에서 웹 포털을 호스팅합니다. 

웹 포털은 퍼블릭 DNS 서비스에 Elastic Load Balancer(ELB)와 Amazon Route 53을 사용합니다.
ELB와 EC2 인스턴스는 us-east-1 리전에서 단일 AWS CloudFormation 스택을 통해 배포됩니다. 웹 포털은 여러 리전에서 고가용성이어야 합니다.
이러한 요구 사항을 충족하는 구성은 무엇입니까?

A. us-west-2 지역에 스택 사본을 배포합니다. Route 53에 각 ELB의 IP 주소를 포함하는 단일 권한 시작(SOA) 레코드를 만듭니다. 상태 검사를 사용하여 SOA 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다.

B. us-west-2 Region에 스택 사본을 배포합니다. Route 53에 별칭 대상으로 us-west-2의 ELB를 포함하는 추가 A 레코드를 만듭니다. 장애 조치 라우팅 정책 및 상태 검사를 사용하여 A 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다. 가장 많이 투표된

C. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 새로운 EC2 인스턴스를 기존 ELB와 연결하고 모든 EC2 인스턴스에서 로드 밸런서 상태 검사를 구성합니다. us-west-2의 EC2 인스턴스가 상태 검사에 실패하면 Route 53을 업데이트하도록 ELB를 구성합니다.
D. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 각 지역의 모든 EC2 인스턴스에 EC2 상태 검사를 구성합니다. VPC 간에 피어링 연결을 구성합니다. us-east-1의 VPC를 기본 레코드로 사용하고 us-west-2의 VPC를 보조 레코드로 사용합니다.



웹 포털의 고가용성을 보장하기 위해서는 여러 리전에서 인프라를 배포하고, Route 53을 사용하여 트래픽을 관리할 필요가 있습니다. 이를 충족하기 위한 가장 적절한 구성은 다음과 같습니다:

**B. us-west-2 Region에 스택 사본을 배포합니다. Route 53에 별칭 대상으로 us-west-2의 ELB를 포함하는 추가 A 레코드를 만듭니다. 장애 조치 라우팅 정책 및 상태 검사를 사용하여 A 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다.**

이 구성은 다음과 같은 이유로 적합합니다:

- **여러 리전 배포**: us-west-2에 스택 사본을 배포함으로써 웹 포털의 고가용성을 확보합니다.
- **Route 53 장애 조치 라우팅**: Route 53의 장애 조치 라우팅 정책을 사용하면, 기본 리전(us-east-1)에서 ELB가 다운되거나 상태 검사에 실패할 경우, 보조 리전(us-west-2)으로 트래픽을 자동으로 전환할 수 있습니다.
- **상태 검사**: 각 ELB의 상태를 모니터링하여 문제가 발생했을 때 신속하게 대처할 수 있습니다.

이러한 구성을 통해 웹 포털은 여러 리전에서 고가용성을 유지할 수 있습니다.


## 질문 #50 ++

SysOps 관리자가 사용자가 RDP를 사용하여 홈 컴퓨터에서 Amazon EC2 Windows 인스턴스에서 실행되는 베스천 서버에 인터넷을 통해 연결할 수 없는 이유를 조사하고 있습니다.

다음 중 이 문제의 가능한 원인은 무엇입니까? (두 가지를 선택하세요.)

A. 요새 서브넷과 연결된 네트워크 ACL이 네트워크 트래픽을 차단하고 있습니다. 가장 많이 투표된
B. 인스턴스에 개인 IP 주소가 없습니다.
C. 배스천의 서브넷과 연결된 경로 테이블에 인터넷 게이트웨이로 가는 경로가 없습니다. 가장 많이 투표된
D. 인스턴스의 보안 그룹에 포트 22에 대한 인바운드 규칙이 없습니다.
E. 인스턴스의 보안 그룹에 포트 3389에 대한 아웃바운드 규칙이 없습니다.

사용자가 RDP를 사용하여 Amazon EC2 Windows 인스턴스에서 실행되는 베스천 서버에 연결할 수 없는 이유를 조사할 때, 가능한 원인은 다음과 같습니다:

**A. 요새 서브넷과 연결된 네트워크 ACL이 네트워크 트래픽을 차단하고 있습니다.**

- 네트워크 ACL이 RDP(포트 3389) 트래픽을 차단하면 사용자가 베스천 서버에 연결할 수 없게 됩니다. 따라서 ACL을 검토하여 인바운드 및 아웃바운드 규칙이 올바르게 설정되었는지 확인해야 합니다.

**C. 배스천의 서브넷과 연결된 경로 테이블에 인터넷 게이트웨이로 가는 경로가 없습니다.**

- EC2 인스턴스가 인터넷에 접근하려면 서브넷의 경로 테이블에 인터넷 게이트웨이(IGW)로 향하는 경로가 필요합니다. 경로 테이블에 IGW로 향하는 경로가 없으면 RDP 연결이 실패할 수 있습니다.

이 두 가지는 RDP 연결 문제를 유발할 수 있는 중요한 요소입니다. 나머지 선택지들은 다음과 같은 이유로 관련이 없습니다:

- **B. 인스턴스에 개인 IP 주소가 없습니다.**: EC2 인스턴스는 기본적으로 개인 IP 주소를 할당받습니다.
- **D. 인스턴스의 보안 그룹에 포트 22에 대한 인바운드 규칙이 없습니다.**: 포트 22는 SSH에 사용되며, Windows 인스턴스에서는 RDP에 포트 3389가 사용됩니다.
- **E. 인스턴스의 보안 그룹에 포트 3389에 대한 아웃바운드 규칙이 없습니다.**: 보통 보안 그룹은 인바운드 규칙이 필요한데, 아웃바운드 규칙이 없다면 다른 곳에 연결하는 데 문제가 생길 수 있지만 RDP 연결 자체에 영향을 미치지 않습니다.


## 질문 #51 +

SysOps 관리자가 다음 AWS CloudFormation 템플릿을 검토하고 있습니다.

스택 생성이 실패하는 이유는 무엇일까요?
A. CloudFormation 템플릿의 출력 섹션이 생략되었습니다.
B. CloudFormation 템플릿의 매개변수 섹션이 생략되었습니다.
C. PrivateDnsName은 CloudFormation 템플릿에서 설정할 수 없습니다. 가장 많이 투표된
D. CloudFormation 템플릿에 VPC가 지정되지 않았습니다.



**VPC (Virtual Private Cloud)**는 AWS 리소스를 격리된 네트워크 환경에서 실행하기 위한 가상 네트워크입니다. 많은 리소스는 VPC 내에서 동작해야 하며, VPC가 지정되지 않으면 해당 리소스가 올바르게 생성되지 않을 수 있습니다. 특히, 서브넷이나 보안 그룹과 같은 리소스는 반드시 VPC 내에서 정의되어야 합니다.

결론
주어진 선택지 중에서 스택 생성이 실패할 가능성이 높은 이유는 D. CloudFormation 템플릿에 VPC가 지정되지 않았습니다입니다. VPC는 많은 AWS 리소스가 올바르게 동작하기 위해 필수적인 요소이며, 이를 지정하지 않으면 리소스 생성이 실패할 수 있습니다.

따라서, SysOps 관리자는 템플릿에 VPC가 제대로 지정되었는지 확인해야 합니다. VPC가 지정되지 않았다면, 이를 추가하여 스택을 다시 생성해보는 것이 좋습니다.


## 질문 #52 +++

새로운 애플리케이션이 Amazon EC2 인스턴스에서 실행되고 Amazon RDS 데이터베이스 인스턴스의 데이터에 액세스합니다. 

프로덕션에 완전히 배포되면 애플리케이션이 실패합니다. 데이터베이스는 배스천 호스트의 콘솔에서 쿼리할 수 있습니다. 웹 서버 로그를 살펴보면 다음 오류가 여러 번 반복됩니다.
*** 데이터베이스 연결 설정 오류
다음 중 연결 문제의 원인은 무엇일까요? (두 가지를 선택하세요.)


A. 데이터베이스의 보안 그룹에 데이터베이스에서 웹 서버로의 적절한 탈출 규칙이 없습니다.
B. 웹 서버에서 사용하는 인증서를 RDS 인스턴스에서 신뢰하지 않습니다.
C. 데이터베이스의 보안 그룹에 웹 서버에서 데이터베이스로의 적절한 유입 규칙이 없습니다. 가장 많이 투표된
D. 애플리케이션 개발자가 사용하는 포트가 RDS 구성에 지정된 포트와 일치하지 않습니다. 가장 많이 투표된
E. 데이터베이스가 아직 생성 중이므로 연결할 수 없습니다.

주어진 시나리오에서 애플리케이션이 Amazon EC2 인스턴스에서 실행되고 Amazon RDS 데이터베이스 인스턴스에 연결할 수 없는 이유를 분석할 때, 다음 두 가지가 문제의 원인일 가능성이 높습니다:

### **정답:**
1. **C. 데이터베이스의 보안 그룹에 웹 서버에서 데이터베이스로의 적절한 유입 규칙이 없습니다.**
   - 이 항목은 웹 서버가 RDS 데이터베이스에 연결하기 위한 인바운드 규칙이 보안 그룹에 설정되지 않았음을 나타냅니다. 따라서, 웹 서버에서 데이터베이스로의 트래픽이 차단되어 연결할 수 없습니다.

2. **D. 애플리케이션 개발자가 사용하는 포트가 RDS 구성에 지정된 포트와 일치하지 않습니다.**
   - 이 항목은 애플리케이션이 RDS 인스턴스와 연결하는 데 사용하는 포트가 RDS 인스턴스의 설정에 지정된 포트와 일치하지 않아 발생할 수 있는 문제를 설명합니다. 기본적으로 RDS 인스턴스는 MySQL의 경우 3306, PostgreSQL의 경우 5432와 같은 특정 포트를 사용합니다. 포트가 일치하지 않으면 연결 오류가 발생합니다.

### **잘못된 선택:**
- **A. 데이터베이스의 보안 그룹에 데이터베이스에서 웹 서버로의 적절한 탈출 규칙이 없습니다.**
  - 데이터베이스에서 웹 서버로의 아웃바운드 규칙은 일반적으로 문제가 되지 않으며, 연결 문제의 주된 원인이 아닙니다.

- **B. 웹 서버에서 사용하는 인증서를 RDS 인스턴스에서 신뢰하지 않습니다.**
  - 이 문제는 SSL 연결을 사용할 때 문제가 될 수 있지만, 일반적인 데이터베이스 연결 오류의 주된 원인은 아닙니다. 인증서 문제는 별도의 오류 메시지로 나타날 수 있습니다.

- **E. 데이터베이스가 아직 생성 중이므로 연결할 수 없습니다.**
  - 데이터베이스가 생성 중일 경우 일반적으로 연결 시도가 실패하지만, 로그에 명시된 "데이터베이스 연결 설정 오류"는 주로 보안 그룹 또는 포트 문제로 인한 것일 가능성이 더 큽니다.

따라서, 올바른 선택은 **C**와 **D**입니다.



## 질문 #53


규정 준수 팀은 Amazon RDS DB 인스턴스의 모든 관리자 비밀번호를 최소 1년에 한 번 변경하도록 요구합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족합니까?

A. AWS Secrets Manager에 데이터베이스 자격 증명을 저장합니다. 365일마다 비밀에 대한 자동 로테이션을 구성합니다. 가장 많이 투표된
B. 데이터베이스 자격 증명을 RDS 매개변수 그룹의 매개변수로 저장합니다. 365일마다 비밀번호를 회전하는 데이터베이스 트리거를 만듭니다.
C. 데이터베이스 자격 증명을 개인 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 예약하여 365일마다 새로운 자격 증명 세트를 생성합니다.
D. AWS Systems Manager Parameter Store에 데이터베이스 자격 증명을 안전한 문자열 매개변수로 저장합니다. 365일마다 매개변수에 대한 자동 로테이션을 구성합니다.

주어진 시나리오에서 Amazon RDS DB 인스턴스의 관리자 비밀번호를 최소 1년에 한 번 변경하는 요구 사항을 운영적으로 효율적으로 충족하기 위한 가장 적합한 솔루션은 다음과 같습니다:

### **정답:**
**A. AWS Secrets Manager에 데이터베이스 자격 증명을 저장합니다. 365일마다 비밀에 대한 자동 로테이션을 구성합니다.**
- AWS Secrets Manager는 데이터베이스 자격 증명을 안전하게 저장하고, 자동 로테이션을 구성할 수 있는 기능을 제공합니다. 이를 통해 규정 준수 팀의 요구 사항인 비밀번호를 매년 변경하는 것을 쉽게 관리할 수 있습니다.

### **잘못된 선택:**
- **B. 데이터베이스 자격 증명을 RDS 매개변수 그룹의 매개변수로 저장합니다. 365일마다 비밀번호를 회전하는 데이터베이스 트리거를 만듭니다.**
  - RDS 매개변수 그룹은 데이터베이스 구성에 대한 설정을 관리하지만, 비밀번호 로테이션을 자동으로 관리할 수는 없습니다. 또한 데이터베이스 트리거는 비밀번호 변경을 트리거할 수 없으므로 효율적이지 않습니다.

- **C. 데이터베이스 자격 증명을 개인 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 예약하여 365일마다 새로운 자격 증명 세트를 생성합니다.**
  - S3에 자격 증명을 저장하는 것은 보안상 위험할 수 있으며, Lambda 함수를 사용하여 자격 증명을 생성하는 과정은 관리가 복잡하고 비효율적입니다.

- **D. AWS Systems Manager Parameter Store에 데이터베이스 자격 증명을 안전한 문자열 매개변수로 저장합니다. 365일마다 매개변수에 대한 자동 로테이션을 구성합니다.**
  - Systems Manager Parameter Store는 자격 증명을 저장할 수 있지만, 자동 로테이션 기능이 Secrets Manager만큼 강력하지 않으며, 매개변수를 수동으로 업데이트해야 할 수 있습니다.

결론적으로, AWS Secrets Manager를 사용하는 것이 가장 안전하고 운영적으로 효율적인 방법입니다.


## 질문 #54 +++

SysOps 관리자는 Amazon EC2 인스턴스 플릿을 관리할 책임이 있습니다. 

이러한 EC2 인스턴스는 빌드 아티팩트를 타사 서비스에 업로드합니다. 타사 서비스는 최근 모든 빌드 업로드가 단일 IP 주소에서 이루어져야 하는 엄격한 IP 허용 목록을 구현했습니다.
시스템 관리자는 이 새로운 요구 사항을 준수하기 위해 기존 빌드 플릿에 어떤 변경을 해야 합니까?


A. 모든 EC2 인스턴스를 NAT 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다. 가장 많이 투표된
B. 모든 EC2 인스턴스를 인터넷 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.
C. 모든 EC2 인스턴스를 단일 가용성 영역으로 이동하고 가용성 영역 IP 주소를 서비스에 제공합니다.
D. 모든 EC2 인스턴스를 피어링된 VPC로 이동하고 VPC IP 주소를 서비스에 제공합니다.


주어진 시나리오에서 EC2 인스턴스 플릿이 타사 서비스에 빌드 아티팩트를 업로드할 때, 서비스가 단일 IP 주소에서 업로드를 요구하고 있습니다. 이를 충족하기 위해 SysOps 관리자가 해야 할 가장 적절한 변경 사항은 다음과 같습니다:

### **정답:**
**A. 모든 EC2 인스턴스를 NAT 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.**
- NAT 게이트웨이를 사용하면 모든 EC2 인스턴스에서 인터넷으로 나가는 트래픽이 NAT 게이트웨이를 통해 전송되며, 이 경우 모든 인스턴스의 외부 IP 주소가 NAT 게이트웨이의 IP 주소로 통일됩니다. 따라서 타사 서비스는 단일 IP 주소에서 오는 모든 요청을 허용할 수 있습니다.

### **잘못된 선택:**
- **B. 모든 EC2 인스턴스를 인터넷 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.**
  - 인터넷 게이트웨이를 사용하면 각 EC2 인스턴스가 고유한 공인 IP 주소를 가지므로, 타사 서비스의 요구 사항인 단일 IP 주소를 충족하지 못합니다.

- **C. 모든 EC2 인스턴스를 단일 가용성 영역으로 이동하고 가용성 영역 IP 주소를 서비스에 제공합니다.**
  - 가용성 영역 IP 주소를 서비스에 제공하는 것은 가용성 영역의 IP 주소가 고정된 것이 아니기 때문에 단일 IP 요구 사항을 충족하지 않습니다.

- **D. 모든 EC2 인스턴스를 피어링된 VPC로 이동하고 VPC IP 주소를 서비스에 제공합니다.**
  - 피어링된 VPC의 IP 주소를 사용하는 것은 해당 VPC 내에서만 적용될 수 있으며, 외부와의 통신에는 영향을 미치지 않기 때문에 단일 IP 요구 사항을 충족하지 않습니다.

따라서 NAT 게이트웨이를 사용하여 모든 인스턴스의 출발 IP를 통일하는 것이 최선의 해결책입니다.


## 질문 #55 +++

한 회사가 Amazon CloudFront 배포를 사용하여 웹사이트를 제공합니다. 

웹사이트의 트래픽 로그는 중앙에 저장되어야 하며 모든 데이터는 저장 시 암호화되어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?


A. 기본 AWS 관리형 고객 마스터 키(CMK)를 사용하는 인터넷 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용하도록 CloudFront를 구성합니다.
B. AES-256을 사용하는 VPC 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. CloudFront를 구성하여 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용합니다.
C. AES-256을 사용하는 기본 서버 측 암호화로 구성된 Amazon S3 버킷을 만듭니다. S3 버킷을 로그 대상으로 사용하도록 CloudFront를 구성합니다. 
D. 기본 암호화 없이 구성된 Amazon S3 버킷을 만듭니다. CloudFront 배포에서 암호화를 활성화하고 S3 버킷을 로그 대상으로 사용합니다.


주어진 요구 사항에 따라 웹사이트의 트래픽 로그를 중앙에서 저장하고 저장 시 암호화해야 합니다. 이러한 요구 사항을 충족하는 최적의 솔루션은 다음과 같습니다:

### **정답:**
**C. AES-256을 사용하는 기본 서버 측 암호화로 구성된 Amazon S3 버킷을 만듭니다. S3 버킷을 로그 대상으로 사용하도록 CloudFront를 구성합니다.**
- Amazon S3는 데이터를 안전하게 저장할 수 있는 서비스이며, 서버 측 암호화를 사용하여 저장 시 데이터 암호화를 자동으로 처리할 수 있습니다. AES-256 암호화를 사용하면 데이터가 저장될 때 자동으로 암호화되므로 보안 요구 사항을 충족합니다. CloudFront의 로그를 S3 버킷에 저장하도록 구성하면 중앙 로그 저장소도 쉽게 관리할 수 있습니다.

### **잘못된 선택:**
- **A. 기본 AWS 관리형 고객 마스터 키(CMK)를 사용하는 인터넷 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용하도록 CloudFront를 구성합니다.**
  - OpenSearch Service는 로그 데이터를 저장할 수 있지만, 일반적으로 CloudFront 로그의 경우 Amazon S3를 사용하는 것이 더 일반적입니다. 추가적인 관리와 복잡성이 발생할 수 있습니다.

- **B. AES-256을 사용하는 VPC 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. CloudFront를 구성하여 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용합니다.**
  - OpenSearch를 사용하는 것이 가능하나, S3에 비해 로그 저장 및 관리의 복잡성이 증가합니다. 

- **D. 기본 암호화 없이 구성된 Amazon S3 버킷을 만듭니다. CloudFront 배포에서 암호화를 활성화하고 S3 버킷을 로그 대상으로 사용합니다.**
  - S3 버킷에서 기본 암호화를 활성화하지 않고 생성하는 것은 저장된 데이터의 암호화 요건을 충족하지 않으므로 이 선택지는 적합하지 않습니다.

따라서 Amazon S3 버킷을 사용하여 기본 서버 측 암호화(AES-256)를 구성하는 것이 요구 사항을 가장 잘 충족합니다.

## 질문 #56 +++

한 조직에서 파일 시스템 ID가 fs-85ba41fc인 Amazon Elastic File System(Amazon EFS) 볼륨을 생성했고, 10개의 Amazon EC2 호스트에서 활발하게 사용되고 있습니다. 

이 조직은 파일 시스템이 암호화되지 않은 것에 대해 우려하고 있습니다.
이를 어떻게 해결할 수 있을까요?

A. Amazon EFS 볼륨에 대한 각 호스트 연결에서 암호화를 활성화합니다. 암호화가 적용되려면 각 연결을 다시 만들어야 합니다.
B. AWS 명령줄 인터페이스를 사용하여 기존 EFS 볼륨에서 암호화를 활성화합니다.
C. 각 호스트의 로컬 드라이브에서 암호화를 활성화합니다. 각 호스트를 다시 시작하여 드라이브를 암호화합니다.
D. 새로 생성된 볼륨에서 암호화를 활성화하고 원래 볼륨에서 모든 데이터를 복사합니다. 각 호스트를 새 볼륨에 다시 연결합니다. 


Amazon Elastic File System (Amazon EFS) 볼륨이 암호화되지 않은 것에 대한 우려를 해결하는 가장 적절한 방법은 다음과 같습니다:

### **정답:**
**D. 새로 생성된 볼륨에서 암호화를 활성화하고 원래 볼륨에서 모든 데이터를 복사합니다. 각 호스트를 새 볼륨에 다시 연결합니다.**
- EFS는 기존 파일 시스템에서 암호화를 활성화하는 기능을 제공하지 않으므로, 암호화된 새 EFS 볼륨을 생성하고 기존 데이터를 복사하여 각 EC2 호스트를 새 볼륨에 다시 연결하는 방법이 가장 안전하고 효과적입니다.

### **잘못된 선택:**
- **A. Amazon EFS 볼륨에 대한 각 호스트 연결에서 암호화를 활성화합니다. 암호화가 적용되려면 각 연결을 다시 만들어야 합니다.**
  - EFS는 특정 연결에서 암호화를 활성화하는 것이 아니라, EFS 파일 시스템 자체에서 암호화를 활성화해야 합니다. 기존 파일 시스템에서 암호화를 활성화할 수는 없습니다.

- **B. AWS 명령줄 인터페이스를 사용하여 기존 EFS 볼륨에서 암호화를 활성화합니다.**
  - 기존 EFS 볼륨에서 암호화를 활성화할 수 있는 방법은 없으며, 암호화를 활성화하려면 새 파일 시스템을 생성해야 합니다.

- **C. 각 호스트의 로컬 드라이브에서 암호화를 활성화합니다. 각 호스트를 다시 시작하여 드라이브를 암호화합니다.**
  - 이는 EFS와 관련이 없는 방법이며, EFS 자체의 데이터 보호와는 관계가 없습니다. EFS 볼륨의 암호화는 EFS 파일 시스템 레벨에서 관리됩니다.

따라서, 암호화된 EFS 볼륨을 만들고 데이터를 복사하는 방법이 가장 적합합니다.


## 질문 #57 ++

한 회사가 AWS Service Catalog 포트폴리오를 사용하여 리소스를 만들고 관리합니다.

SysOps 관리자는 새 AWS 계정에서 회사의 기존 AWS 인프라의 복제본을 만들어야 합니다.
이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. 새로운 AWS 계정에서 AWS Service Catalog 포트폴리오를 사용하려면 AWS CloudFormation 템플릿을 만듭니다.
B. 새로운 AWS 계정에서 원래 포트폴리오를 복제하는 AWS Service Catalog 포트폴리오를 수동으로 생성합니다.
C. AWS Lambda 함수를 실행하여 DescribePortfolio API 작업의 출력을 기반으로 새로운 AWS Service Catalog 포트폴리오를 생성합니다.
D. AWS Service Catalog 포트폴리오를 새 AWS 계정과 공유합니다. 포트폴리오를 새 AWS 계정으로 가져옵니다. 

AWS Service Catalog 포트폴리오를 사용하여 리소스를 생성하고 관리하는 경우, 기존 인프라의 복제본을 새 AWS 계정에 효율적으로 만드는 방법은 다음과 같습니다:

### **정답:**
**D. AWS Service Catalog 포트폴리오를 새 AWS 계정과 공유합니다. 포트폴리오를 새 AWS 계정으로 가져옵니다.**
- 이 방법은 기존 포트폴리오를 새 계정과 공유하고 가져오는 과정으로, 기존 리소스를 수동으로 재구성할 필요 없이 효율적으로 기존 인프라를 복제할 수 있습니다.

### **잘못된 선택:**
- **A. 새로운 AWS 계정에서 AWS Service Catalog 포트폴리오를 사용하려면 AWS CloudFormation 템플릿을 만듭니다.**
  - CloudFormation 템플릿을 만들고 관리하는 것은 가능하지만, 이는 수작업으로 템플릿을 작성해야 하므로 운영 효율성이 떨어질 수 있습니다.

- **B. 새로운 AWS 계정에서 원래 포트폴리오를 복제하는 AWS Service Catalog 포트폴리오를 수동으로 생성합니다.**
  - 수동으로 포트폴리오를 복제하는 것은 시간이 많이 걸리고 오류가 발생할 수 있으므로 비효율적입니다.

- **C. AWS Lambda 함수를 실행하여 DescribePortfolio API 작업의 출력을 기반으로 새로운 AWS Service Catalog 포트폴리오를 생성합니다.**
  - Lambda 함수를 사용하는 방법은 가능하지만, API 호출 및 처리 로직을 작성해야 하므로, 운영 효율성 측면에서 불필요하게 복잡할 수 있습니다.

따라서, 기존 포트폴리오를 새 계정과 공유하여 가져오는 것이 가장 운영 효율적인 방법입니다.


## 질문 #58 +++

SysOps 관리자는 AWS 계정의 보안을 관리해야 합니다. 

최근에 IAM 사용자의 액세스 키가 실수로 공개 코드 저장소에 업로드되었습니다.
SysOps 관리자는 이 액세스 키를 사용하여 변경된 모든 것을 식별해야 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?


A. 모든 IAM 이벤트를 분석을 위해 AWS Lambda 함수로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
B. Amazon CloudWatch Logs Insights를 사용하여 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 Amazon EC2 로그를 쿼리합니다.
C. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 AWS CloudTrail 이벤트 기록을 검색합니다. 가장 많이 투표된
D. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 VPC 흐름 로그를 검색합니다.


AWS 계정의 보안을 관리하고 손상된 IAM 사용자의 액세스 키를 통해 발생한 변경 사항을 식별하기 위해 SysOps 관리자는 다음 방법을 사용해야 합니다:

### **정답:**
**C. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 AWS CloudTrail 이벤트 기록을 검색합니다.**
- AWS CloudTrail은 AWS 계정의 API 호출을 기록하고, 특정 IAM 사용자의 액세스 키로 실행된 모든 작업을 추적할 수 있습니다. 따라서 손상된 키로 시작된 이벤트를 검색하여 어떤 변경이 있었는지 식별할 수 있습니다.

### **잘못된 선택:**
- **A. 모든 IAM 이벤트를 분석을 위해 AWS Lambda 함수로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.**
  - EventBridge를 통해 IAM 이벤트를 처리할 수 있지만, 이 방법은 이미 발생한 이벤트를 식별하는 데는 적합하지 않습니다.

- **B. Amazon CloudWatch Logs Insights를 사용하여 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 Amazon EC2 로그를 쿼리합니다.**
  - EC2 로그는 AWS 서비스의 인스턴스 활동을 추적하지만, IAM 액세스 키와 관련된 이벤트를 파악하는 데 적합하지 않습니다.

- **D. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 VPC 흐름 로그를 검색합니다.**
  - VPC 흐름 로그는 네트워크 트래픽을 기록하지만 IAM 이벤트에 대한 정보를 제공하지 않으므로 이 목적에는 적합하지 않습니다.

따라서, CloudTrail 이벤트 기록을 검색하는 것이 손상된 액세스 키로 발생한 모든 변경 사항을 식별하는 가장 효과적인 방법입니다.


## 질문 #59 +++++

한 회사가 Application Load Balancer(ALB) 뒤의 여러 Amazon EC2 인스턴스에서 리테일 웹사이트를 운영합니다. 

이 회사는 HTTPS 연결을 통해 웹사이트로의 트래픽을 보호해야 합니다.
이러한 요구 사항을 충족하기 위해 SysOps 관리자는 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. 각 EC2 인스턴스에 인증서를 첨부합니다.
B. ALB에 인증서를 첨부합니다. 
C. AWS Certificate Manager(ACM)에서 개인 인증서를 만듭니다.
D. AWS Certificate Manager(ACM)에서 공용 인증서를 만듭니다. 
E. 인증서를 내보내어 웹사이트에 첨부합니다.

HTTPS 연결을 통해 웹사이트로의 트래픽을 보호하기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### **정답:**
1. **B. ALB에 인증서를 첨부합니다.**
   - Application Load Balancer(ALB)에 SSL/TLS 인증서를 첨부하면 ALB가 HTTPS 요청을 처리하고, 클라이언트와 ALB 간의 트래픽을 암호화할 수 있습니다. ALB가 SSL 종료를 수행하게 되면, 뒤에 있는 EC2 인스턴스는 HTTP로 통신할 수 있습니다.

2. **D. AWS Certificate Manager(ACM)에서 공용 인증서를 만듭니다.**
   - AWS Certificate Manager(ACM)를 사용하여 공용 SSL/TLS 인증서를 생성하고 관리할 수 있습니다. ACM에서 생성된 인증서는 ALB에 쉽게 연결할 수 있으며, SSL/TLS 암호화를 지원합니다.

### **잘못된 선택:**
- **A. 각 EC2 인스턴스에 인증서를 첨부합니다.**
  - ALB가 SSL 종료를 수행하는 경우, 각 EC2 인스턴스에 인증서를 첨부할 필요는 없습니다. ALB가 HTTPS 요청을 처리하므로, EC2 인스턴스는 HTTP로 통신할 수 있습니다.

- **C. AWS Certificate Manager(ACM)에서 개인 인증서를 만듭니다.**
  - 일반적으로 공용 인증서가 HTTPS 연결을 위한 목적에 적합합니다. 개인 인증서는 일반적으로 내부 네트워크에서 사용됩니다.

- **E. 인증서를 내보내어 웹사이트에 첨부합니다.**
  - ALB에 인증서를 첨부하는 것이 더 효율적이며, 내보내는 방식은 필요하지 않습니다. 

따라서 ALB에 인증서를 첨부하고 ACM에서 공용 인증서를 만드는 것이 HTTPS 연결을 보호하는 데 가장 효과적인 조합입니다.

## 질문 #60
시뮬레이션 -

지침 -
환경에서 복사-붙여넣기 기능이 작동하지 않는 경우 VM 데스크톱의 지침 파일을 참조하고 Ctrl+C, Ctrl+V 또는 Command-C,
Command-V를 사용합니다.
다음 요구 사항을 충족하도록 Amazon EventBridge를 구성합니다.

1. 모든 리소스에 us-east-2 리전을 사용합니다.
2. 아래에 지정되지 않은 경우 기본 구성 설정을 사용합니다.
3. 아래에 리소스 이름이 지정되지 않은 경우 고유한 리소스 명명을 사용합니다.
4. 기본 이벤트 버스의 모든 Amazon EC2 이벤트가 지난 45일 동안 재생 가능한지 확인합니다.
5. RunFunction이라는 규칙을 만들어 15분마다 정확한 메시지 {"name":"example")를 LogEventFunction이라는 기존 AWS Lambda 함수로 보냅니다.
6. SpotWarning이라는 규칙을 만들어 Amazon EC2 Spot Instance가 중단될 때마다 TopicEvents라는 새 표준 Amazon SNS 토픽으로 알림을 보냅니다. 토픽 구독을 만들지 마십시오. 알림은 다음 구조와 일치해야 합니다.
7. 
입력 경로:
{`instance`:`detail.instance-id}
입력 템플릿:
`EC2 Spot 인스턴스 <instance>가 중단되었습니다.`
중요: 다음 버튼을 클릭하여 이 랩을 완료하고 다음 랩으로 넘어가세요. 다음 버튼을 클릭하면 이 랩으로 돌아갈 수 없습니다.


## 질문 #61 ++

한 회사가 단일 xlarge 범용 Amazon EC2 온디맨드 인스턴스에서 상태가 유지되는 장기 실행 워크로드를 보유하고 있습니다. 

메트릭은 서비스가 항상 사용 가능한 메모리의 80%와 사용 가능한 CPU의 40%를 사용하고 있음을 보여줍니다. 
SysOps 관리자는 성능에 부정적인 영향을 미치지 않으면서 서비스 비용을 줄여야 합니다.
이러한 요구 사항을 충족하는 인스턴스 유형의 변경은 무엇입니까?

A. 하나의 대규모 컴퓨팅 최적화 온디맨드 인스턴스로 변경합니다.
B. 대용량 메모리 최적화된 단일 온디맨드 인스턴스로 변경합니다. 
C. 하나의 xlarge 범용 스팟 인스턴스로 변경합니다.
D. 두 개의 대규모 일반 용도 온디맨드 인스턴스로 변경합니다.

주어진 시나리오에서, SysOps 관리자가 성능에 부정적인 영향을 미치지 않으면서 서비스 비용을 줄이기 위해 변경해야 할 인스턴스 유형은 
**B. 대용량 메모리 최적화된 단일 온디맨드 인스턴스로 변경합니다**입니다.

### 이유:
- 현재 인스턴스는 사용 가능한 메모리의 80%를 사용하고 있으므로, 메모리 최적화된 인스턴스를 선택하면 메모리 사용량을 더 잘 지원할 수 있습니다.
- **대용량 메모리 최적화 인스턴스**는 메모리 집약적인 애플리케이션에 대해 최적화되어 있어 서비스 성능을 유지하면서 비용을 절감할 수 있습니다.

### 나머지 옵션 분석:
- **A. 하나의 대규모 컴퓨팅 최적화 온디맨드 인스턴스로 변경합니다**: CPU 사용률이 낮기 때문에 CPU 최적화 인스턴스는 적합하지 않을 수 있습니다.
  
- **C. 하나의 xlarge 범용 스팟 인스턴스로 변경합니다**: 스팟 인스턴스는 가격이 낮지만, 항상 사용 가능한 상태를 보장하지 않으므로 적합하지 않습니다.
  
- **D. 두 개의 대규모 일반 용도 온디맨드 인스턴스로 변경합니다**: 비용 절감이 아닌 인스턴스 수가 증가하므로, 성능이나 관리 측면에서 비효율적일 수 있습니다.

따라서 메모리 사용을 효율적으로 최적화하기 위해 대용량 메모리 최적화 인스턴스로 변경하는 것이 가장 좋은 선택입니다.



## 질문 #62

한 회사에서 SysOps 관리자에게 AWS CloudTrail 파일이 생성된 후 변조되지 않도록 해달라고 요청했습니다. 

현재 이 회사는 AWSIdentity and Access Management(IAM)를 사용하여 특정 트레일에 대한 액세스를 제한합니다. 이 회사의 보안 팀은 각 파일의 무결성을 추적할 수 있어야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 새 파일이 전달될 때 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 파일에서 MD5 해시 검사를 계산하고 결과를 Amazon DynamoDB 테이블에 저장합니다. 보안 팀은 DynamoDB에 저장된 값을 사용하여 전달된 파일의 무결성을 확인할 수 있습니다.
B. CloudTrail 버킷에 새 파일이 전달될 때마다 호출되는 AWS Lambda 함수를 만듭니다. Lambda 함수를 구성하여 파일에 대한 MD5 해시 검사를 계산하고 결과를 Amazon 53 객체의 태그로 저장합니다. 보안 팀은 태그의 정보를 사용하여 전달된 파일의 무결성을 확인할 수 있습니다.
C. Amazon S3 버킷에서 CloudTrail 파일 무결성 기능을 활성화합니다. 보안 팀에 S3 버킷에 저장된 파일 무결성 로그에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다.
D. 트레일에서 CloudTrail 파일 무결성 기능을 활성화합니다. 보안 팀은 CloudTrail에서 생성한 다이제스트 파일을 사용하여 전달된 파일의 무결성을 확인할 수 있습니다. 가장 많이 투표된

이 경우 회사의 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 
**D. 트레일에서 CloudTrail 파일 무결성 기능을 활성화합니다. 보안 팀은 CloudTrail에서 생성한 다이제스트 파일을 사용하여 전달된 파일의 무결성을 확인할 수 있습니다**입니다.

### 이유:
1. **CloudTrail 파일 무결성 기능**: 이 기능을 활성화하면 AWS CloudTrail이 자동으로 각 로그 파일의 SHA-256 해시 다이제스트 파일을 생성합니다. 이 다이제스트 파일은 로그 파일이 변경되지 않았는지 확인하는 데 사용됩니다.
  
2. **자동화 및 효율성**: AWS에서 제공하는 기본 기능을 활용하여 운영 효율성을 높이며, 별도의 Lambda 함수나 DynamoDB 테이블을 설정할 필요가 없습니다.

3. **무결성 확인**: 보안 팀은 생성된 다이제스트 파일을 통해 CloudTrail 로그의 무결성을 확인할 수 있습니다.

### 나머지 옵션 분석:
- **A. Lambda 함수와 DynamoDB 사용**: 이 방법은 추가적인 설정과 관리 오버헤드가 필요하며, AWS에서 제공하는 기본적인 무결성 검사를 사용하지 않기 때문에 비효율적입니다.
  
- **B. Lambda 함수와 S3 객체 태그**: 객체 태그를 사용하는 것도 운영 효율성이 떨어지며, 파일 무결성을 직접적으로 확인하기 위한 기본 기능을 사용하지 않습니다.
  
- **C. S3 버킷에서 CloudTrail 파일 무결성 기능 활성화**: S3 자체에서의 무결성 확인이 아닌 CloudTrail의 기능을 활용하는 것이 더 적합합니다.

따라서 **D** 옵션이 가장 적합하며 운영 효율적인 솔루션입니다.


## 질문 #63 +++

AWS 클라우드 인프라에서 조직에 영향을 미칠 수 있는 이벤트가 발생하는 경우, 어떤 AWS 서비스를 사용하여 조직의 어떤 리소스가 영향을 받는지 확인할 수 있습니까?

A. AWS 서비스 상태 대시보드
B. AWS 신뢰할 수 있는 고문
C. AWS 개인 건강 대시보드 가장 많이 투표된
D. AWS 시스템 관리자

조직에 영향을 미칠 수 있는 이벤트가 발생하는 경우, 어떤 AWS 리소스가 영향을 받는지 확인할 수 있는 서비스는 다음과 같습니다:

### **정답:**
**C. AWS 개인 건강 대시보드**
- AWS Personal Health Dashboard는 AWS에서 발생하는 이벤트에 대한 조직의 리소스에 대한 영향을 모니터링하고 알려주는 서비스를 제공합니다. 이 대시보드는 AWS 서비스의 상태와 관련된 정보를 제공하며, 특정 계정 및 리소스에 영향을 미치는 이벤트에 대한 경고를 받을 수 있습니다.

### **잘못된 선택:**
- **A. AWS 서비스 상태 대시보드**: 이 대시보드는 AWS 서비스의 전반적인 상태를 보여주지만, 특정 고객의 리소스에 대한 영향은 보여주지 않습니다.
  
- **B. AWS 신뢰할 수 있는 고문**: AWS Trusted Advisor는 모범 사례에 따라 리소스를 최적화하는 데 도움을 주는 서비스입니다. 서비스 상태와는 관계가 없습니다.
  
- **D. AWS 시스템 관리자**: AWS Systems Manager는 관리 작업을 자동화하는 도구이지만, 특정 이벤트에 대한 리소스 영향을 추적하는 기능은 없습니다.

따라서, **C**가 올바른 선택입니다.

## 질문 #64 +++++

한 회사에서 가져온 키 자료가 있는 AWS KMS 고객 마스터 키(CMK)를 사용하고 있습니다. 

이 회사는 Java 애플리케이션에서 별칭으로 CMK를 참조하여 데이터를 암호화합니다. CMK는 6개월마다 순환해야 합니다.
키를 순환하는 프로세스는 무엇입니까?

A. CMK에 대해 자동 키 회전을 활성화하고 6개월 기간을 지정합니다.
B. 새로 가져온 자료로 새 CMK를 만들고 키 별칭을 업데이트하여 새 CMK를 가리키도록 합니다. 가장 많이 투표된
C. 현재 키 자료를 삭제하고 새 자료를 기존 CMK로 가져옵니다.
D. 기존 키 자료의 사본을 백업용으로 새 CMK로 가져오고, 순환 일정을 6개월로 설정합니다.


AWS KMS 고객 마스터 키(CMK)를 사용하여 데이터를 암호화하는 경우, CMK의 순환 프로세스는 다음과 같이 수행해야 합니다:

### **정답:**
**B. 새로 가져온 자료로 새 CMK를 만들고 키 별칭을 업데이트하여 새 CMK를 가리키도록 합니다.**
- CMK는 AWS KMS에서 자동으로 회전할 수 없습니다. 따라서, 새 CMK를 생성하고 별칭을 업데이트하여 새로운 CMK가 사용되도록 하는 방법이 필요합니다.

### **잘못된 선택:**
- **A. CMK에 대해 자동 키 회전을 활성화하고 6개월 기간을 지정합니다.**
  - KMS는 자동으로 키 회전 기능을 제공하지만, 이 기능은 연간 키 회전만 지원하며, 6개월 주기는 지원하지 않습니다.

- **C. 현재 키 자료를 삭제하고 새 자료를 기존 CMK로 가져옵니다.**
  - KMS는 기존 키 자료를 삭제하는 방식으로 키 회전을 지원하지 않습니다. 기존 CMK에 대한 암호화된 데이터는 영향을 받지 않습니다.

- **D. 기존 키 자료의 사본을 백업용으로 새 CMK로 가져오고, 순환 일정을 6개월로 설정합니다.**
  - KMS는 암호화된 키 자료를 백업하는 기능을 제공하지 않으며, 키 회전 일정 설정은 별도로 지원되지 않습니다.

따라서 **B**가 올바른 선택입니다.

## 질문 #65 +++

보안팀은 환경에서 사용되는 AWS Identity and Access Management(IAM) 정책의 수가 증가하고 있기 때문에 우려하고 있습니다. 

팀은 SysOps 관리자에게 현재 사용 중인 IAM 정책의 수와 사용 가능한 총 IAM 정책에 대해 보고하도록 했습니다.
관리자는 현재 IAM 정책 사용량을 현재 서비스 한도와 비교하기 위해 어떤 AWS 서비스를 사용해야 합니까?

A. AWS 신뢰할 수 있는 고문 
B. 아마존 인스펙터
C. AWS 구성
D. AWS 조직


SysOps 관리자가 현재 IAM 정책 사용량을 현재 서비스 한도와 비교하기 위해 사용할 수 있는 AWS 서비스는 **C. AWS 구성**입니다.

### 이유:
- **AWS 구성**: AWS 구성은 리소스 구성을 기록하고 평가하는 서비스로, IAM 정책을 포함하여 다양한 AWS 리소스의 구성을 추적하고 변경 사항을 감지할 수 있습니다. 이를 통해 IAM 정책의 수와 사용량을 쉽게 모니터링할 수 있습니다.

- AWS 구성은 IAM 정책 사용 현황을 점검하고 이를 서비스 한도와 비교하는 데 필요한 정보를 제공할 수 있는 기능을 갖추고 있습니다.

### 나머지 옵션 분석:
- **A. AWS 신뢰할 수 있는 고문**: 이 서비스는 AWS 환경에서의 보안과 모범 사례를 안내하지만 IAM 정책 사용량 보고에는 적합하지 않습니다.

- **B. 아마존 인스펙터**: 이 서비스는 보안 취약점 평가를 위해 사용되며, IAM 정책의 수를 확인하는 데는 사용되지 않습니다.

- **D. AWS 조직**: 이 서비스는 여러 AWS 계정을 관리하는 데 사용되지만 IAM 정책 사용량 보고와는 관련이 없습니다.

따라서 IAM 정책 사용량을 보고하기 위해 가장 적합한 서비스는 **C. AWS 구성**입니다.


## 질문 #66 +++

SysOps 관리자가 Amazon S3에 호스팅된 웹사이트로 트래픽을 라우팅하기 위해 Amazon Route 53 도메인 이름을 설정하려고 합니다. 

웹사이트의 도메인 이름은 www.example.com이고 S3 버킷 이름은 DOC-EXAMPLE-BUCKET입니다. 
Route 53에서 레코드 세트를 설정한 후 도메인 이름 www.anycompany.com이 작동하지 않는 듯하고 정적 웹사이트가 브라우저에 표시되지 않습니다.
다음 중 어떤 것이 원인일까요?

A. S3 버킷은 먼저 Amazon CloudFront로 구성되어야 합니다.
B. Route 53 레코드 세트에는 S3 버킷에 대한 액세스를 허용하는 IAM 역할이 있어야 합니다.
C. Route 53 레코드 세트는 S3 버킷과 동일한 지역에 있어야 합니다.
D. S3 버킷 이름은 Route 53의 레코드 세트 이름과 일치해야 합니다.


Amazon S3에 호스팅된 웹사이트에 대한 트래픽을 라우팅하기 위해 Amazon Route 53 도메인 이름을 설정하는 과정에서 웹사이트가 작동하지 않는 이유는 다음과 같습니다.

### **정답:**
**D. S3 버킷 이름은 Route 53의 레코드 세트 이름과 일치해야 합니다.**
- S3에서 정적 웹사이트 호스팅을 설정할 때, S3 버킷 이름은 사용하려는 도메인 이름과 일치해야 합니다. 즉, `www.example.com`을 호스팅하기 위한 S3 버킷은 `www.example.com`으로 명명되어야 합니다. 현재 버킷 이름이 `DOC-EXAMPLE-BUCKET`인 경우, Route 53의 레코드 세트가 이 버킷과 연결되지 않아 웹사이트가 표시되지 않습니다.

### **잘못된 선택:**
- **A. S3 버킷은 먼저 Amazon CloudFront로 구성되어야 합니다.**
  - S3 버킷은 CloudFront 없이도 직접 정적 웹사이트를 호스팅할 수 있습니다. CloudFront는 선택 사항입니다.

- **B. Route 53 레코드 세트에는 S3 버킷에 대한 액세스를 허용하는 IAM 역할이 있어야 합니다.**
  - Route 53 레코드 세트는 IAM 역할을 요구하지 않습니다. S3 버킷의 퍼블릭 액세스를 적절히 설정하면 됩니다.

- **C. Route 53 레코드 세트는 S3 버킷과 동일한 지역에 있어야 합니다.**
  - Route 53은 전 세계적으로 DNS 서비스를 제공하므로 레코드 세트와 S3 버킷이 동일한 리전에 있을 필요는 없습니다.

따라서 **D**가 문제의 원인입니다.

## 질문 #67 +++

SysOps 관리자가 AWS CloudFormation을 사용하여 서버리스 애플리케이션을 프로덕션 VPC에 배포했습니다. 

이 애플리케이션은 AWS Lambda 함수, Amazon DynamoDB 테이블, Amazon API Gateway API로 구성되어 있습니다. SysOps 관리자는 DynamoDB 테이블을 삭제하지 않고 AWS CloudFormation 스택을 삭제해야 합니다.
SysOps 관리자는 AWS CloudFormation 스택을 삭제하기 전에 어떤 조치를 취해야 합니까?

A. AWS CloudFormation 스택의 DynamoDB 리소스에 보존 삭제 정책을 추가합니다. 가장 많이 투표된
B. AWS CloudFormation 스택의 DynamoDB 리소스에 스냅샷 삭제 정책을 추가합니다.
C. AWS CloudFormation 스택에서 종료 보호를 활성화합니다.
D. dynamodb:DeleteTable 작업에 대한 Deny 문으로 애플리케이션의 IAM 정책을 업데이트합니다.

SysOps 관리자가 AWS CloudFormation 스택을 삭제하기 전에 DynamoDB 테이블을 삭제하지 않도록 하려면 다음 조치를 취해야 합니다:

**A. AWS CloudFormation 스택의 DynamoDB 리소스에 보존 삭제 정책을 추가합니다.**

### 이유:
- **보존 삭제 정책 (Retain Deletion Policy)**: 이 정책을 DynamoDB 리소스에 추가하면 CloudFormation 스택이 삭제될 때 해당 리소스(이 경우 DynamoDB 테이블)가 삭제되지 않습니다. 대신, 이 리소스는 보존되어 다른 작업에 사용할 수 있습니다.

### 나머지 옵션 분석:
- **B. AWS CloudFormation 스택의 DynamoDB 리소스에 스냅샷 삭제 정책을 추가**: DynamoDB는 스냅샷 삭제 정책을 지원하지 않으므로 이 옵션은 올바르지 않습니다.

- **C. AWS CloudFormation 스택에서 종료 보호를 활성화**: 종료 보호는 CloudFormation 스택 자체가 삭제되지 않도록 하는 기능입니다. 하지만 개별 리소스의 삭제를 방지하지는 않으므로 이 옵션은 DynamoDB 테이블을 유지하는 데 적합하지 않습니다.

- **D. dynamodb:DeleteTable 작업에 대한 Deny 문으로 애플리케이션의 IAM 정책을 업데이트**: IAM 정책을 수정하여 테이블 삭제를 방지하는 방법은 가능하지만, CloudFormation 스택을 삭제할 때 DynamoDB 테이블이 삭제되지 않도록 하기 위한 더 간단하고 효율적인 방법은 보존 삭제 정책을 사용하는 것입니다.

따라서 DynamoDB 테이블을 삭제하지 않고 AWS CloudFormation 스택을 삭제하기 위한 올바른 조치는 **A. AWS CloudFormation 스택의 DynamoDB 리소스에 보존 삭제 정책을 추가하는 것**입니다.


## 질문 #68 +++

SysOps 관리자는 Amazon EC2 인스턴스가 응답을 멈췄다는 알림을 받습니다. 

AWS Management Console은 시스템 검사가 실패하고 있다고 표시합니다.
이 문제를 해결하기 위해 관리자는 먼저 무엇을 해야 합니까?

A. EC2 인스턴스를 재부팅하여 새 호스트에서 시작할 수 있도록 합니다.
B. EC2 인스턴스를 중지한 다음 다시 시작하여 새 호스트에서 시작할 수 있도록 합니다. 가장 많이 투표된
C. EC2 인스턴스를 종료하고 다시 시작합니다.
D. AWS CloudTrail 로그를 보고 EC2 인스턴스에서 어떤 변경 사항이 발생했는지 조사합니다.

AWS Management Console에서 EC2 인스턴스의 시스템 검사가 실패하고 있다는 알림을 받았을 때, 문제를 해결하기 위해 관리자가 먼저 수행해야 할 가장 적절한 조치는 다음과 같습니다.

### **정답:**
**B. EC2 인스턴스를 중지한 다음 다시 시작하여 새 호스트에서 시작할 수 있도록 합니다.**
- 시스템 검사 실패는 일반적으로 인스턴스가 물리적 하드웨어 또는 호스트 시스템에 문제가 있음을 나타냅니다. 인스턴스를 중지한 후 다시 시작하면 EC2가 새로운 호스트에서 인스턴스를 시작하게 되어 이 문제를 해결할 수 있습니다.

### **잘못된 선택:**
- **A. EC2 인스턴스를 재부팅하여 새 호스트에서 시작할 수 있도록 합니다.**
  - 단순한 재부팅은 인스턴스가 동일한 호스트에서 다시 시작되므로 문제를 해결하지 못할 수 있습니다.

- **C. EC2 인스턴스를 종료하고 다시 시작합니다.**
  - 인스턴스를 종료하면 모든 데이터가 사라질 수 있습니다. (EBS 볼륨이 아닌 인스턴스 스토어에서 실행 중인 경우) 이 방법은 비즈니스 요구 사항에 따라 바람직하지 않을 수 있습니다.

- **D. AWS CloudTrail 로그를 보고 EC2 인스턴스에서 어떤 변경 사항이 발생했는지 조사합니다.**
  - 로그를 조사하는 것은 도움이 될 수 있지만, 인스턴스의 시스템 검사가 실패한 문제를 해결하는 데 즉각적인 조치는 아닙니다. 먼저 인스턴스를 다시 시작하여 문제를 해결하는 것이 우선입니다.

따라서 **B**가 문제를 해결하기 위한 가장 적절한 조치입니다.

## 질문 #69 ++

소프트웨어 개발 회사에는 동일한 제품을 작업하는 여러 개발자가 있습니다. 

각 개발자는 자체 개발 환경을 가져야 하며 이러한 개발 환경은 동일해야 합니다. 
각 개발 환경은 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스로 구성됩니다. 개발 환경은 필요할 때만 만들어야 하며 비용을 최소화하기 위해 매일 밤 종료해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 각 개발 인스턴스에서 매일 밤 cron 작업을 예약하여 실행 중인 모든 프로세스를 중지하고 CPU 사용률을 거의 0으로 줄입니다.

B. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 AWS CloudFormation 스택을 삭제합니다. 가장 많이 투표된

C. 개발자에게 CLI 명령을 제공하여 필요할 때 자체 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 모든 EC2 인스턴스와 DB 인스턴스를 종료합니다.

D. 개발자에게 CLI 명령을 제공하여 필요할 때 자체 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS CloudFormation이 모든 개발 환경 리소스를 삭제하도록 합니다.

주어진 시나리오에서 소프트웨어 개발 회사의 요구 사항을 충족하기 위해 가장 운영 효율적인 솔루션은 다음과 같습니다.

### **정답:**
**B. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 AWS CloudFormation 스택을 삭제합니다.**

### **이유:**
- **일관성:** CloudFormation 템플릿을 사용하면 모든 개발자가 동일한 환경을 쉽게 프로비저닝할 수 있습니다. 이는 환경 간 일관성을 보장합니다.
  
- **비용 효율성:** 매일 밤 CloudFormation 스택을 삭제함으로써 모든 리소스를 제거하고 비용을 절감할 수 있습니다. 필요한 경우에만 환경을 재구성하므로 리소스를 항상 유지하지 않아도 됩니다.

- **자동화:** EventBridge 규칙을 사용하면 매일 밤 자동으로 Lambda 함수를 호출하여 스택을 삭제하는 프로세스를 자동화할 수 있습니다. 이는 관리자가 직접 개입할 필요 없이 효율적으로 작업할 수 있게 합니다.

### **잘못된 선택:**
- **A.** EC2 인스턴스에서 cron 작업을 사용하는 방법은 인스턴스를 계속 유지하게 되어 비용을 증가시킬 수 있습니다. 또한, 프로비저닝 및 삭제를 위한 수동 작업이 필요할 수 있습니다.

- **C.** CLI 명령을 통해 EC2 인스턴스와 DB 인스턴스를 종료할 수 있지만, 모든 리소스를 자동으로 제거하지는 않습니다. 필요할 때마다 수동으로 프로비저닝해야 하며, 매일 밤 실행 중인 인스턴스를 종료하는 방식은 개발 환경을 완전히 삭제하지 않으므로 비용 효율적이지 않을 수 있습니다.

- **D.** AWS CloudFormation이 모든 개발 환경 리소스를 삭제하도록 하여 CLI 명령을 제공하는 것은 유용하지만, 개발자가 템플릿을 기반으로 환경을 쉽게 재구성할 수 있는 유연성을 고려할 때, CloudFormation 스택을 삭제하는 것보다 필요할 때 프로비저닝하는 것이 더 효율적입니다.

따라서 **B**가 모든 요구 사항을 가장 효율적으로 충족하는 방법입니다.


## 질문 #70 +++
회사가 외부 공급업체와 협력하여 데이터 처리 서비스를 제공하고 있습니다. 

이 통합을 위해 공급업체는 공급업체의 AWS 계정에서 Amazon S3 버킷에 회사 데이터를 호스팅해야 합니다. (공급업체의 AWS S3 계정의 버킷) 
공급업체는 회사가 AWS Key Management Service(AWS KMS) 키를 제공하여 회사 데이터를 암호화하도록 허용합니다. 공급업체는 이 통합을 위해 회사에 IAM 역할 Amazon Resources Name(ARN)을 제공했습니다.
SysOps 관리자는 이 통합을 구성하기 위해 무엇을 해야 합니까?

A. 새 KMS 키를 만듭니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 새 KMS 키 ARN을 제공합니다. 가장 많이 투표된

B. 새 KMS 키를 만듭니다. 새 IAM 키를 만듭니다. 공급업체의 IAM 역할 ARN을 IAM 사용자에게 연결된 인라인 정책에 추가합니다. 공급업체에 새 IAM 사용자 ARN을 제공합니다.

C. KMS 관리형 S3 키를 사용하여 암호화를 구성합니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 KMS 관리형 S3 키 ARN을 제공합니다.

D. KMS 관리 S3 키를 사용하여 암호화를 구성합니다. S3 버킷을 만듭니다. 공급업체의 IAM 역할 ARN을 S3 버킷 정책에 추가합니다. 공급업체에 S3 버킷 ARN을 제공합니다.

이 통합을 구성하기 위해 SysOps 관리자가 수행해야 하는 가장 적절한 조치는 다음과 같습니다:

### **A. 새 KMS 키를 만듭니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 새 KMS 키 ARN을 제공합니다.**
=> 공급업체에서 KMS 키를 읽어 갈수 있도록 해주면 되는 것이다.  


#### **설명**:
- **KMS 키 생성**: 새로운 AWS KMS 키를 생성하면 회사 데이터에 대한 암호화를 제공할 수 있습니다.
- **IAM 역할 ARN 추가**: 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가하면 해당 역할이 이 KMS 키를 사용하여 데이터를 암호화하거나 복호화할 수 있게 됩니다.
- **KMS 키 ARN 제공**: 마지막으로, 공급업체에게 KMS 키 ARN을 제공하여 공급업체가 해당 키를 사용하여 암호화된 데이터에 접근할 수 있도록 합니다.

### **기타 옵션 설명**:
B. **새 KMS 키를 만듭니다. 새 IAM 키를 만듭니다. 공급업체의 IAM 역할 ARN을 IAM 사용자에게 연결된 인라인 정책에 추가합니다. 공급업체에 새 IAM 사용자 ARN을 제공합니다.**
- IAM 사용자 및 인라인 정책을 만드는 것은 불필요하게 복잡하며, KMS 키를 통한 직접적인 권한 부여가 필요합니다.

C. **KMS 관리형 S3 키를 사용하여 암호화를 구성합니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 KMS 관리형 S3 키 ARN을 제공합니다.**
- KMS 관리형 S3 키는 특정한 경우에만 사용되며, 직접적인 데이터 처리와 관련된 암호화 작업에는 적합하지 않을 수 있습니다.

D. **KMS 관리 S3 키를 사용하여 암호화를 구성합니다. S3 버킷을 만듭니다. 공급업체의 IAM 역할 ARN을 S3 버킷 정책에 추가합니다. 공급업체에 S3 버킷 ARN을 제공합니다.**
- S3 버킷 정책에 IAM 역할 ARN을 추가하는 것은 데이터 접근 제어를 위한 방법이지만, KMS 키를 통한 암호화를 명시적으로 설정하는 것이 더 중요합니다.

결론적으로, **A**가 가장 효과적인 접근 방법입니다. 새로운 KMS 키를 생성하고 공급업체의 IAM 역할 ARN을 추가하여 암호화에 대한 적절한 권한을 제공함으로써, 회사 데이터를 안전하게 관리할 수 있습니다.


## 질문 #71 +++

SysOps 관리자가 AWS Systems Manager Patch Manager를 사용하여 Amazon EC2 인스턴스 플릿에 패치를 적용하고 있습니다. 

SysOps 관리자는 패치 기준선과 유지 관리 기간을 구성했습니다. 
SysOps 관리자는 또한 인스턴스 태그를 사용하여 패치할 인스턴스를 식별했습니다. SysOps 관리자는 Systems Manager에 EC2 인스턴스에 액세스할 수 있는 권한을 부여해야 합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자가 수행해야 하는 추가 작업은 무엇입니까?

A. 인스턴스 보안 그룹에 인바운드 규칙을 추가합니다.
B. Systems Manager에 대한 액세스 권한이 있는 IAM 인스턴스 프로필을 인스턴스에 연결합니다. 가장 많이 투표된
C. Systems Manager 활성화를 만듭니다. 그런 다음 인스턴스 플릿을 활성화합니다.
D. 태그 기반 선택을 사용하는 대신 패치할 인스턴스를 수동으로 지정합니다.


이 요구 사항을 충족하기 위해 SysOps 관리자가 수행해야 하는 추가 작업은 다음과 같습니다:

### **B. Systems Manager에 대한 액세스 권한이 있는 IAM 인스턴스 프로필을 인스턴스에 연결합니다.**

#### **설명**:
- **IAM 인스턴스 프로필**: Amazon EC2 인스턴스가 AWS Systems Manager와 상호 작용할 수 있도록 하려면 해당 인스턴스에 적절한 IAM 역할을 부여해야 합니다. 이 역할은 Systems Manager에 대한 액세스를 포함해야 하며, 이를 통해 인스턴스가 패치 작업을 수행할 수 있습니다.
- **역할 연결**: 인스턴스 프로필을 인스턴스에 연결하면, 해당 인스턴스가 Systems Manager API를 호출할 수 있는 권한을 갖게 됩니다.

### **기타 옵션 설명**:
A. **인스턴스 보안 그룹에 인바운드 규칙을 추가합니다.**
- 이 작업은 일반적으로 필요하지 않으며, Systems Manager는 인스턴스와의 연결을 위해 인바운드 규칙을 요구하지 않습니다. Systems Manager는 주로 HTTPS를 사용하여 AWS 서비스와 통신합니다.

C. **Systems Manager 활성화를 만듭니다. 그런 다음 인스턴스 플릿을 활성화합니다.**
- 활성화는 Systems Manager의 기능 중 하나이지만, 인스턴스에 권한을 부여하는 데 직접적으로 관련이 없습니다.

D. **태그 기반 선택을 사용하는 대신 패치할 인스턴스를 수동으로 지정합니다.**
- 태그 기반 선택을 사용하는 것이 더 유연하고 관리하기 쉬운 방법입니다. 수동으로 지정하는 것은 비효율적이며 관리 부담을 증가시킵니다.

결론적으로, **B**가 올바른 선택입니다. IAM 인스턴
A. 두 지역 간에 VPC 피어링 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다. 가장 많이 투표된스 프로필을 인스턴스에 연결함으로써 AWS Systems Manager에 대한 액세스를 제공하고, EC2 인스턴스에서 패치를 적용할 수 있는 권한을 보장할 수 있습니다.


## 질문 #72 +++

한 회사가 us-east-1 지역의 Amazon EC2 인스턴스에 웹사이트를 호스팅합니다. 

이 회사는 웹사이트를 eu-central-1 지역으로 확장할 준비를 하고 있지만, 데이터베이스는 us-east-1에만 있어야 합니다. 
배포 후 eu-central-1의 EC2 인스턴스는 us-east-1의 데이터베이스에 연결할 수 없습니다.
이 연결 문제를 해결할 가장 운영 효율적인 솔루션은 무엇입니까?

A. 두 지역 간에 VPC 피어링 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.
B. 두 지역 간에 VPC 피어링 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
C. 두 지역 간에 VPN 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
D. 두 지역 간에 VPN 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.


이 문제를 해결하기 위해 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **A. 두 지역 간에 VPC 피어링 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.**

#### **설명**:
- **VPC 피어링 연결**: 두 개의 Amazon VPC(Virtual Private Cloud)를 서로 연결하여 인스턴스가 서로 통신할 수 있도록 하는 방법입니다. 이는 전용 네트워크 경로를 생성하여 낮은 지연 시간과 높은 대역폭을 제공합니다.
- **보안 그룹 규칙**: us-east-1에 있는 데이터베이스의 보안 그룹에 eu-central-1의 EC2 인스턴스의 개인 IP 주소 범위를 인바운드 규칙으로 추가하면, 해당 인스턴스가 데이터베이스에 접근할 수 있는 권한을 부여합니다.

### **기타 옵션 설명**:
B. **두 지역 간에 VPC 피어링 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.**
- 아웃바운드 규칙은 트래픽이 EC2 인스턴스에서 나가는 방향을 정의하며, 데이터베이스에 접근하기 위한 인바운드 규칙을 설정하는 것이 필요합니다.

C. **두 지역 간에 VPN 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.**
- VPN 연결은 두 네트워크 간의 보안을 강화할 수 있지만, VPC 피어링이 더 간단하고 관리하기 쉬운 솔루션입니다. 또한 보안 그룹 규칙은 아웃바운드가 아닌 인바운드 규칙을 설정해야 합니다.

D. **두 지역 간에 VPN 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.**
- VPN 연결을 사용하는 것은 복잡성을 추가하며, VPC 피어링이 이 경우 더 효율적입니다.

결론적으로, **A**가 올바른 선택입니다. VPC 피어링을 설정하고 보안 그룹의 인바운드 규칙을 업데이트하여 eu-central-1의 인스턴스가 us-east-1의 데이터베이스에 연결할 수 있도록 합니다.

## 질문 #73 +

한 회사에서는 AWS Organizations에서 관리하는 모든 계정에 대해 자동화된 솔루션을 만들어 인바운드 트래픽의 소스 주소로 0.0.0.0/0을 사용하는 모든 보안 그룹을 감지하려고 합니다. 

또한 회사는 회사 인트라넷과 일치하는 특정 CIDR 블록에 대한 액세스를 제한하여 모든 비준수 보안 그룹을 자동으로 수정하려고 합니다.
SysOps 관리자는 솔루션을 만들기 위해 어떤 작업을 수행해야 합니까?

A. 규정을 준수하지 않는 보안 그룹을 감지하기 위한 AWS Config 규칙을 만듭니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다. 가장 많이 투표된
B. 소스 주소가 0.0.0.0/0인 보안 그룹 생성을 거부하는 IAM 정책을 만듭니다. 이 IAM 정책을 회사의 모든 사용자에게 첨부합니다.
C. 새 보안 그룹과 기존 보안 그룹을 검사하기 위한 AWS Lambda 함수를 만듭니다. 비준수 0.0.0.0/0 소스 주소를 확인하고 소스 주소를 승인된 CIDR 블록으로 변경합니다.
D. 조직 단위(OU)에 대한 서비스 제어 정책(SCP)을 만들어 0.0.0.0/0 소스 주소가 있는 보안 그룹 생성을 거부합니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다.

이 요구 사항을 충족하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### **A. 규정을 준수하지 않는 보안 그룹을 감지하기 위한 AWS Config 규칙을 만듭니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다.**

#### **설명**:
- **AWS Config 규칙**: AWS Config를 사용하여 특정 리소스의 구성 상태를 평가하고 지속적으로 모니터링할 수 있습니다. 이를 통해 인바운드 트래픽 소스 주소가 `0.0.0.0/0`인 보안 그룹을 감지할 수 있습니다.
- **자동 수정**: AWS Config 규칙을 설정하여 비준수 보안 그룹을 자동으로 수정하도록 지정할 수 있습니다. 이 자동 수정 프로세스를 통해 0.0.0.0/0 소스 주소를 회사 인트라넷에 맞는 승인된 CIDR 블록으로 변경할 수 있습니다.

### **기타 옵션 설명**:
B. **소스 주소가 0.0.0.0/0인 보안 그룹 생성을 거부하는 IAM 정책을 만듭니다. 이 IAM 정책을 회사의 모든 사용자에게 첨부합니다.**
- IAM 정책으로 보안 그룹 생성을 차단할 수 있지만, 이미 존재하는 보안 그룹을 수정할 수는 없습니다. 이미 생성된 보안 그룹에 대한 접근성을 관리할 수는 없습니다.

C. **새 보안 그룹과 기존 보안 그룹을 검사하기 위한 AWS Lambda 함수를 만듭니다. 비준수 0.0.0.0/0 소스 주소를 확인하고 소스 주소를 승인된 CIDR 블록으로 변경합니다.**
- AWS Lambda 함수를 사용하여 비준수 보안 그룹을 검사하고 수정하는 것은 가능하지만, 관리 및 유지보수의 복잡성을 증가시킵니다. AWS Config를 사용하면 보다 간단하게 자동화할 수 있습니다.

D. **조직 단위(OU)에 대한 서비스 제어 정책(SCP)을 만들어 0.0.0.0/0 소스 주소가 있는 보안 그룹 생성을 거부합니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다.**
- SCP를 사용하여 조직의 모든 계정에 대해 보안 그룹 생성을 제한할 수는 있지만, 이미 생성된 보안 그룹에 대한 수정은 SCP로는 해결할 수 없습니다.

결론적으로, **A**가 올바른 선택입니다. AWS Config 규칙을 설정하여 비준수 보안 그룹을 감지하고, 자동 수정 기능을 통해 이들 보안 그룹을 조정하여 요구 사항을 충족합니다.

## 질문 #74 +++++

회사에서는 AWS 계정의 모든 활동을 AWS CloudTrail을 사용하여 기록해야 합니다. 

또한 SysOps 관리자는 CloudTrail 로그 파일이 수정되거나 삭제되는 시점을 알아야 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?

A. 로그 파일 무결성 검증을 활성화합니다. AWS CLI를 사용하여 로그 파일을 검증합니다. 가장 많이 투표된
B. 로그 파일 무결성 검증을 활성화합니다. AWS CloudTrail Processing Library를 사용하여 로그 파일을 검증합니다.
C. CloudTrail Insights를 사용하여 로그 파일의 수정 사항을 모니터링합니다.
D. Amazon CloudWatch Logs를 사용하여 로그 파일의 수정 사항을 모니터링합니다.

이 요구 사항을 충족하기 위한 가장 적합한 솔루션은 다음과 같습니다:

### **B. 로그 파일 무결성 검증을 활성화합니다. AWS CloudTrail Processing Library를 사용하여 로그 파일을 검증합니다.**

#### **설명**:
- **로그 파일 무결성 검증**: CloudTrail에서 로그 파일 무결성 검증을 활성화하면, CloudTrail은 각 로그 파일에 대한 해시를 생성하여 로그 파일이 수정되지 않았음을 보장합니다. 이를 통해 로그 파일이 안전하게 유지되고 있다는 것을 확인할 수 있습니다.
- **AWS CloudTrail Processing Library**: 이 라이브러리를 사용하면 로그 파일을 검증하고, 무결성을 확인하는 데 필요한 프로세스를 자동화할 수 있습니다. 이를 통해 수동 검증의 필요성을 줄이고, 로그 파일의 수정 여부를 보다 쉽게 확인할 수 있습니다.

### **기타 옵션 설명**:
A. **로그 파일 무결성 검증을 활성화합니다. AWS CLI를 사용하여 로그 파일을 검증합니다.**
- AWS CLI를 사용하여 로그 파일을 검증할 수 있지만, CloudTrail Processing Library를 사용하면 더 효율적이고 안전하게 검증할 수 있습니다.

C. **CloudTrail Insights를 사용하여 로그 파일의 수정 사항을 모니터링합니다.**
- CloudTrail Insights는 비정상적인 활동을 감지하는 데 유용하지만, 로그 파일의 무결성을 보장하지 않으며, 직접적인 수정 사항을 모니터링하는 데는 적합하지 않습니다.

D. **Amazon CloudWatch Logs를 사용하여 로그 파일의 수정 사항을 모니터링합니다.**
- CloudWatch Logs는 로그의 모니터링 및 알림을 설정할 수 있지만, CloudTrail 로그 파일의 무결성을 검증하거나 직접적인 수정 사항을 확인하는 데는 사용할 수 없습니다.

결론적으로, **B**가 올바른 선택입니다. 로그 파일 무결성 검증을 활성화하고 AWS CloudTrail Processing Library를 사용하여 로그 파일을 검증함으로써 수정이나 삭제 여부를 확인할 수 있습니다.

## 질문 #75 +++

한 회사가 AWS에서 상태 저장 웹 기반 애플리케이션을 호스팅할 계획입니다. 

SysOps 관리자가 Amazon EC2 인스턴스의 자동 확장 그룹을 사용하고 있습니다. 
웹 애플리케이션은 연중무휴 24시간 실행됩니다. 회사는 트래픽 및 사용 패턴에 따라 올해 말에 동일한 인스턴스 패밀리 내에서 인스턴스 유형을 변경할 수 있어야 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족할 EC2 인스턴스 구매 옵션은 무엇입니까?

A. 변환 가능한 예약 인스턴스 가장 많이 투표된
B. 주문형 인스턴스
C. 스팟 인스턴스
D. 표준 예약 인스턴스

이러한 요구 사항을 가장 비용 효율적으로 충족할 EC2 인스턴스 구매 옵션은 다음과 같습니다:

### **A. 변환 가능한 예약 인스턴스**

#### **설명**:
- **변환 가능한 예약 인스턴스**는 특정 인스턴스 유형에 대한 예약 인스턴스이지만, 필요에 따라 동일한 인스턴스 패밀리 내에서 다른 인스턴스 유형으로 변환할 수 있는 유연성을 제공합니다. 따라서 회사는 트래픽 및 사용 패턴에 따라 인스턴스 유형을 변경할 수 있으며, 이러한 변경은 동일한 인스턴스 패밀리 내에서 가능합니다.
- 이는 연중무휴 24시간 실행되는 애플리케이션에 적합하며, 예측 가능한 사용량에 따라 비용을 절감할 수 있습니다.

### **기타 옵션 설명**:
B. **주문형 인스턴스**:
- 주문형 인스턴스는 사용한 만큼만 비용을 지불하는 유연한 옵션이지만, 장기적으로 비용이 더 많이 발생할 수 있으며 인스턴스 유형 변경의 유연성이 없습니다.

C. **스팟 인스턴스**:
- 스팟 인스턴스는 저렴한 가격으로 사용할 수 있지만, AWS의 수요와 공급에 따라 인스턴스가 종료될 수 있어 연중무휴 24시간 안정적인 서비스 제공에는 적합하지 않습니다.

D. **표준 예약 인스턴스**:
- 표준 예약 인스턴스는 특정 인스턴스 유형에 대해 1년 또는 3년 동안 예약할 수 있지만, 변경할 수 있는 유연성이 없으므로 이 요구 사항에 적합하지 않습니다.

따라서, **A. 변환 가능한 예약 인스턴스**가 요구 사항을 가장 비용 효율적으로 충족할 수 있는 옵션입니다.

## 질문 #76 +++

애플리케이션은 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 

EC2 인스턴스에 새 기능을 배포한 후 일부 인스턴스가 비정상으로 표시되고 Auto Scaling 그룹으로 대체되었습니다. 
SysOps 관리자가 상태 변경의 원인을 파악하기 전에 EC2 인스턴스가 종료되었습니다. 이 문제를 해결하기 위해 SysOps 관리자는 이 상황에서 AWS Lambda 함수가 호출되도록 하려고 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?

A. Auto Scaling 그룹에 대한 인스턴스 축소 보호 설정을 활성화합니다. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출합니다.
B. Auto Scaling 그룹에 대한 인스턴스 축소 보호 설정을 활성화합니다. Amazon Route 53을 통해 Lambda 함수를 호출합니다.
C. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 라이프사이클 후크를 추가합니다. 가장 많이 투표된
D. Amazon Route 53을 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 수명 주기 후크를 추가합니다.

이러한 요구 사항을 충족하기 위한 최선의 방법은 다음과 같습니다:

**C. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 라이프사이클 후크를 추가합니다.**

#### **설명**:
- **라이프사이클 후크**는 Auto Scaling 그룹의 인스턴스가 종료되기 전에 특정 작업을 수행할 수 있는 기회를 제공합니다. 이 후크를 사용하여 EC2 인스턴스가 종료되기 전에 Lambda 함수를 호출할 수 있습니다.
- 이를 통해 SysOps 관리자는 인스턴스가 비정상으로 표시되었을 때 상태 변경의 원인을 파악하기 위해 추가적인 로깅이나 알림 기능을 수행할 수 있습니다.
- EventBridge(이전의 CloudWatch Events)는 라이프사이클 후크와 함께 Lambda 함수를 트리거하는 데 적합합니다.

### **기타 옵션 설명**:
A. **Auto Scaling 그룹에 대한 인스턴스 축소 보호 설정을 활성화합니다**:
- 축소 보호는 인스턴스가 종료되지 않도록 보호할 수 있지만, 이 경우 이미 종료되었거나 종료될 예정인 인스턴스에 대해 어떤 작업을 수행하지 않습니다.

B. **Amazon Route 53을 통해 Lambda 함수를 호출합니다**:
- Route 53은 DNS 서비스로, Auto Scaling 그룹과 Lambda 간의 직접적인 트리거를 제공하지 않습니다.

D. **Amazon Route 53을 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 수명 주기 후크를 추가합니다**:
- Route 53은 라이프사이클 후크와 직접 관련이 없습니다. Lambda 호출을 위해서는 EventBridge를 사용하는 것이 적합합니다.

따라서, **C. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 라이프사이클 후크를 추가합니다.**가 가장 적절한 선택입니다.


## 질문 #77 +

한 회사가 여러 클라이언트의 중요 데이터를 호스팅하는 애플리케이션을 실행합니다. 

이 회사는 AWS CloudTrail을 사용하여 다양한 AWS 리소스에서 사용자 활동을 추적합니다. 
새로운 보안 요구 사항을 충족하기 위해 이 회사는 CloudTrail 로그 파일이 수정, 삭제 또는 위조되지 않도록 보호해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. CloudTrail 로그 파일 무결성 검증을 활성화합니다. 가장 많이 투표된
B. CloudTrail 로그 파일이 저장된 S3 버킷에서 Amazon S3 MFA Delete를 사용합니다.
C. Amazon S3 버전 관리를 사용하여 CloudTrail 로그 파일의 모든 버전을 보관합니다.
D. AWS Key Management Service(AWS KMS) 보안 키를 사용하여 CloudTrail 로그 파일을 보호합니다.


CloudTrail 로그 파일이 수정, 삭제 또는 위조되지 않도록 보호하기 위해 가장 적절한 솔루션은:

**A. CloudTrail 로그 파일 무결성 검증을 활성화합니다.**

### 이유:
- **CloudTrail 로그 파일 무결성 검증**: 이 기능을 활성화하면 CloudTrail이 생성한 로그 파일의 무결성을 확인할 수 있습니다. CloudTrail은 각 로그 파일에 대한 SHA-256 해시를 생성하고, 이 해시를 AWS S3 버킷에 저장합니다. 무결성 검증을 통해 로그 파일이 수정되지 않았는지 확인할 수 있습니다.

### 나머지 옵션 분석:
- **B. CloudTrail 로그 파일이 저장된 S3 버킷에서 Amazon S3 MFA Delete를 사용합니다**: MFA Delete는 객체 삭제와 같은 중요한 작업에 대해 추가적인 보안 계층을 제공하지만, 로그 파일의 수정이나 위조를 방지하지는 않습니다.

- **C. Amazon S3 버전 관리를 사용하여 CloudTrail 로그 파일의 모든 버전을 보관합니다**: S3 버전 관리는 파일의 이전 버전을 보관하여 실수로 삭제되거나 덮어쓴 경우 복구할 수 있도록 하지만, 로그 파일의 무결성을 직접적으로 보장하지 않습니다.

- **D. AWS Key Management Service(AWS KMS) 보안 키를 사용하여 CloudTrail 로그 파일을 보호합니다**: KMS는 로그 파일을 암호화하는 데 사용되지만, 수정이나 삭제를 방지하는 데는 직접적인 역할을 하지 않습니다.

따라서 CloudTrail 로그 파일의 수정, 삭제 또는 위조를 방지하기 위한 가장 효과적인 솔루션은 **A. CloudTrail 로그 파일 무결성 검증을 활성화하는 것**입니다.


## 질문 #78 ++

글로벌 기업이 5개의 AWS 지역에서 운영됩니다. 

SysOps 관리자가 회사의 모든 태그가 지정되고 지정되지 않은 Amazon EC2 인스턴스를 식별하려고 합니다.
이 회사는 인스턴스 ID와 태그를 표시하는 출력이 필요합니다.

SysOps 관리자가 이러한 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. AWS 리소스 그룹에서 태그 기반 리소스 그룹을 만듭니다.
B. AWS Trusted Advisor를 사용합니다. Trusted Advisor에서 EC2 On-Demand Instances 확인 결과를 내보냅니다.
C. Cost Explorer를 사용합니다. EC2-Instances의 서비스 유형을 선택하고 리소스별로 그룹화합니다.
D. AWS 리소스 그룹에서 태그 편집기를 사용합니다. 모든 리전을 선택하고 AWS::EC2::Instance의 리소스 유형을 선택합니다. 

이 요구 사항을 충족하기 위한 최선의 방법은 다음과 같습니다:

### **D. AWS 리소스 그룹에서 태그 편집기를 사용합니다. 모든 리전을 선택하고 AWS::EC2::Instance의 리소스 유형을 선택합니다.**

#### **설명**:
- **AWS 리소스 그룹의 태그 편집기**를 사용하면 여러 리전의 리소스를 동시에 검색하고 태그를 검토할 수 있습니다.
- 모든 리전에서 EC2 인스턴스를 선택하고, 각 인스턴스에 대한 태그를 확인하여 태그가 지정된 인스턴스와 지정되지 않은 인스턴스를 쉽게 식별할 수 있습니다.
- 결과를 CSV 형식으로 내보낼 수 있으므로 태그와 인스턴스 ID를 출력하는 데 유용합니다.

### **기타 옵션 설명**:
A. **AWS 리소스 그룹에서 태그 기반 리소스 그룹을 만듭니다**:
- 태그 기반 리소스 그룹은 태그가 지정된 리소스에만 적용되므로, 태그가 지정되지 않은 인스턴스를 식별하는 데 도움이 되지 않습니다.

B. **AWS Trusted Advisor를 사용합니다**:
- Trusted Advisor는 EC2 인스턴스에 대한 몇 가지 확인을 제공하지만, 모든 태그가 지정된 인스턴스와 지정되지 않은 인스턴스를 표시하는 데 필요한 상세한 정보는 제공하지 않습니다.

C. **Cost Explorer를 사용합니다**:
- Cost Explorer는 비용 분석 도구로, 태그 정보를 제공하지만 인스턴스 ID와 태그를 직접적으로 표시하는 기능은 제한적입니다.

따라서, **D. AWS 리소스 그룹에서 태그 편집기를 사용합니다. 모든 리전을 선택하고 AWS::EC2::Instance의 리소스 유형을 선택합니다.**가 가장 적절한 선택입니다.


## 질문 #79 ++++

회사는 매일 기가바이트의 파일을 업로드해야 합니다. 

회사는 Amazon S3에 더 높은 처리량과 업로드 속도를 달성해야 합니다.
이 요구 사항을 충족하기 위해 SysOps 관리자는 어떤 조치를 취해야 합니까?


A. GET HTTP 메서드를 허용하고 S3 버킷을 원본으로 하여 Amazon CloudFront 배포를 생성합니다.
B. Amazon ElastiCache 클러스터를 생성하고 S3 버킷에 대한 캐싱을 활성화합니다.
C. AWS Global Accelerator를 설정하고 S3 버킷으로 구성합니다.
D. S3 전송 가속을 활성화하고 파일을 업로드할 때 가속 엔드포인트를 사용합니다.

회사가 Amazon S3에 더 높은 처리량과 업로드 속도를 달성하기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### **D. S3 전송 가속을 활성화하고 파일을 업로드할 때 가속 엔드포인트를 사용합니다.**

#### **설명**:
- **S3 전송 가속**은 Amazon CloudFront의 엣지 로케이션을 활용하여 데이터 전송 속도를 높이는 기능입니다. 이를 통해 사용자는 가까운 엣지 로케이션에 파일을 먼저 업로드하고, 이후 이 파일이 S3 버킷으로 전송됩니다.
- 이 방식은 장거리 데이터 전송 시의 지연을 줄이고, 특히 대용량 파일의 업로드에 있어 성능을 크게 개선할 수 있습니다.

### **기타 옵션 설명**:
A. **GET HTTP 메서드를 허용하고 S3 버킷을 원본으로 하여 Amazon CloudFront 배포를 생성합니다**:
- CloudFront는 콘텐츠 배포에 유용하지만, 파일 업로드 속도를 향상시키기 위한 직접적인 방법이 아닙니다.

B. **Amazon ElastiCache 클러스터를 생성하고 S3 버킷에 대한 캐싱을 활성화합니다**:
- ElastiCache는 주로 데이터베이스 쿼리 결과 캐싱에 사용되며, S3 파일 업로드 성능 향상에는 직접적인 영향을 미치지 않습니다.

C. **AWS Global Accelerator를 설정하고 S3 버킷으로 구성합니다**:
- Global Accelerator는 애플리케이션의 가용성과 성능을 향상시키기 위한 서비스이지만, S3 버킷에 대한 파일 업로드 성능을 직접적으로 개선하는 데는 적합하지 않습니다.

따라서, **D. S3 전송 가속을 활성화하고 파일을 업로드할 때 가속 엔드포인트를 사용합니다.**가 가장 적절한 선택입니다.

## 질문 #80 +

SysOps 관리자는 회사의 AWS 계정의 보안 및 규정 준수를 유지합니다. 

회사의 Amazon EC2 인스턴스가 회사 정책을 따르도록 하기 위해 SysOps 관리자는 부서 태그가 없는 모든 EC2 인스턴스를 종료하려고 합니다. 규정을 준수하지 않는 리소스는 거의 실시간으로 종료해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 필수 태그 관리 규칙으로 AWS Config 규칙을 만들어 비준수 리소스를 식별합니다. AWS-TerminateEC2Instance 자동화 문서를 실행하여 비준수 리소스를 종료하도록 자동 수정을 구성합니다. 가장 많이 투표된
B. 새로운 EC2 인스턴스가 생성될 때 모니터링하기 위한 새로운 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 자동 수정을 위해 이벤트를 Simple Notification Service(Amazon SNS) 토픽으로 보냅니다.
C. EC2 인스턴스를 생성할 수 있는 모든 사용자에게 ec2:CreateTags 및 ec2:DescribeTags 작업을 사용할 수 있는 권한도 있는지 확인합니다. 인스턴스의 종료 동작을 종료로 변경합니다.
D. AWS Systems Manager Compliance가 EC2 인스턴스를 관리하도록 구성되어 있는지 확인합니다. AWS-StopEC2Instances 자동화 문서를 호출하여 비준수 리소스를 중지합니다.


SysOps 관리자가 부서 태그가 없는 모든 EC2 인스턴스를 종료하여 보안 및 규정 준수를 유지하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### **A. 필수 태그 관리 규칙으로 AWS Config 규칙을 만들어 비준수 리소스를 식별합니다. AWS-TerminateEC2Instance 자동화 문서를 실행하여 비준수 리소스를 종료하도록 자동 수정을 구성합니다.**

#### **설명**:
- **AWS Config**를 사용하여 리소스의 구성을 평가하고 규정 준수를 확인할 수 있습니다. 필수 태그를 확인하는 규칙을 설정하면 태그가 없는 EC2 인스턴스를 쉽게 식별할 수 있습니다.
- **자동 수정** 기능을 활용하여 비준수 리소스를 자동으로 종료할 수 있는 AWS 자동화 문서인 `AWS-TerminateEC2Instance`를 실행할 수 있습니다. 이를 통해 거의 실시간으로 비준수 리소스를 종료할 수 있습니다.

### **기타 옵션 설명**:
B. **새로운 EC2 인스턴스가 생성될 때 모니터링하기 위한 새로운 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 자동 수정을 위해 이벤트를 Simple Notification Service(Amazon SNS) 토픽으로 보냅니다**:
- 이 접근 방식은 인스턴스 생성 시점에만 대응할 수 있으며, 기존 비준수 인스턴스에 대해 즉각적으로 종료할 수 없습니다.

C. **EC2 인스턴스를 생성할 수 있는 모든 사용자에게 ec2:CreateTags 및 ec2:DescribeTags 작업을 사용할 수 있는 권한도 있는지 확인합니다. 인스턴스의 종료 동작을 종료로 변경합니다**:
- 이 방법은 태그가 없는 인스턴스를 종료하는 직접적인 접근법이 아니며, 기존 인스턴스에 대한 자동화된 처리를 제공하지 않습니다.

D. **AWS Systems Manager Compliance가 EC2 인스턴스를 관리하도록 구성되어 있는지 확인합니다. AWS-StopEC2Instances 자동화 문서를 호출하여 비준수 리소스를 중지합니다**:
- 이 접근은 비준수 인스턴스를 중지하는 것이지 종료하는 것이 아니므로, 요구 사항을 완전히 충족하지 않습니다.

따라서, **A. 필수 태그 관리 규칙으로 AWS Config 규칙을 만들어 비준수 리소스를 식별합니다. AWS-TerminateEC2Instance 자동화 문서를 실행하여 비준수 리소스를 종료하도록 자동 수정을 구성합니다.**가 가장 적절한 선택입니다.

## 질문 #81 ++

한 회사가 S3 버전 관리가 활성화된 Amazon S3 버킷에 웹사이트 파일을 업로드했습니다. 

이 회사는 S3 버킷을 원본으로 하는 Amazon CloudFront 배포판을 사용합니다. 이 회사는 최근에 파일을 수정했지만 객체 이름은 동일하게 유지되었습니다. 사용자들은 오래된 콘텐츠가 여전히 웹사이트에 표시된다고 보고합니다.
SysOps 관리자는 이 문제를 어떻게 해결해야 합니까?

A. CloudFront 무효화를 생성하고 업데이트된 파일의 경로를 추가합니다. 
B. CloudFront 서명 URL을 생성하여 각 객체를 즉시 업데이트합니다.
C. S3 원본 액세스 ID(OAI)를 구성하여 사용자에게 업데이트된 파일만 표시합니다.
D. S3 버킷에서 S3 버전 관리를 비활성화하여 업데이트된 파일이 이전 파일을 대체할 수 있도록 합니다.


사용자들이 오래된 콘텐츠를 여전히 웹사이트에서 보고하는 문제를 해결하기 위해 SysOps 관리자가 취할 수 있는 가장 적절한 조치는 다음과 같습니다:

### **A. CloudFront 무효화를 생성하고 업데이트된 파일의 경로를 추가합니다.**

#### **설명**:
- **CloudFront 무효화**는 캐시된 콘텐츠를 삭제하고 업데이트된 콘텐츠를 가져오는 방법입니다. S3 버킷에서 파일이 수정되었더라도, CloudFront가 해당 파일을 캐시하고 있을 경우 사용자는 여전히 이전 버전의 파일을 보게 됩니다.
- 따라서, CloudFront 무효화를 생성하여 업데이트된 파일의 경로를 추가하면 캐시된 콘텐츠를 무효화하고 사용자가 최신 파일을 볼 수 있게 됩니다.

### **기타 옵션 설명**:
B. **CloudFront 서명 URL을 생성하여 각 객체를 즉시 업데이트합니다.**
- 서명된 URL은 보안 액세스를 제공하지만, 캐시된 콘텐츠를 무효화하는 데는 도움이 되지 않습니다.

C. **S3 원본 액세스 ID(OAI)를 구성하여 사용자에게 업데이트된 파일만 표시합니다.**
- OAI는 CloudFront가 S3 버킷에 액세스할 수 있도록 하는 방법이지만, 오래된 콘텐츠를 표시하는 문제를 해결하지 않습니다.

D. **S3 버킷에서 S3 버전 관리를 비활성화하여 업데이트된 파일이 이전 파일을 대체할 수 있도록 합니다.**
- S3 버전 관리를 비활성화하면 이전 버전의 파일이 삭제되지만, 이는 데이터 손실을 초래할 수 있으며, 이 문제를 해결하는 최선의 방법이 아닙니다.

결론적으로, **A**가 가장 효과적인 해결책입니다. CloudFront 무효화를 통해 사용자가 최신 콘텐츠를 즉시 볼 수 있게 됩니다.



## 질문 #82 +++++
한 회사에 VPC A와 VPC B라는 두 개의 VPC 네트워크가 있습니다. 

VPC A CIDR 블록은 10.0.0.0/16이고 VPC B CIDR 블록은 172.31.0.0/16입니다. 이 회사는 두 VPC 사이에 pcx-12345라는 VPC 피어링 연결을 설정하려고 합니다.
구성 후 VPC A의 경로 테이블에 어떤 규칙이 나타나야 합니까? (두 가지를 선택하세요.)

A. 목적지: 10.0.0.0/16, 타겟: 로컬 가장 많이 투표된
B. 목적지: 172.31.0.0/16, 타겟: 로컬
C. 대상: 10.0.0.0/16, 대상: pcx-12345
D. 목적지: 172.31.0.0/16, 타겟: pcx-12345 가장 많이 투표된
E. 대상: 10.0.0.0/16, 대상: 172.31.0.0/16

VPC A와 VPC B 간의 VPC 피어링 연결을 설정한 후, VPC A의 경로 테이블에 나타나야 할 규칙은 다음과 같습니다:

### **정답:**
**A. 목적지: 10.0.0.0/16, 타겟: 로컬**
**D. 목적지: 172.31.0.0/16, 타겟: pcx-12345**




## 질문 #83 ++++

한 회사가 고객의 판매 데이터를 분석합니다. 

고객이 회사의 Amazon S3 버킷 중 하나에 파일을 업로드하면 Amazon Simple Queue Service(Amazon SQS) 대기열에 Amazon Resource Name(ARN) 개체가 게시됩니다. Amazon EC2 인스턴스에서 실행되는 애플리케이션이 대기열을 폴링하고 메시지를 처리합니다. 처리 시간은 파일 크기에 따라 다릅니다.
고객이 파일 처리가 지연된다고 보고합니다. 
SysOps 관리자가 첫 번째 단계로 Amazon EC2 Auto Scaling을 구성하기로 결정했습니다. SysOps 관리자가 기존 EC2 인스턴스를 기반으로 하는 Amazon Machine Image(AMI)를 만듭니다. SysOps 관리자는 또한 AMI를 참조하는 시작 템플릿을 만듭니다. SysOps 관리자는 응답 시간을 개선하기 위해 Auto Scaling 정책을 어떻게 구성해야 합니까?

A. 시작 템플릿에 여러 다른 인스턴스 크기를 추가합니다. ApproximateNumberOfMessagesVisible 메트릭을 기반으로 자동 크기 조정 정책을 만들어 큐의 메시지 수에 따라 인스턴스 크기를 선택합니다.
B. 대기열에 있는 지연된 메시지 수에 따라 인스턴스 수를 조정하기 위해 ApproximateNumberOfMessagesDelayed 메트릭을 기반으로 자동 크기 조정 정책을 만듭니다.
C. ASGAverageCPUUtilization 메트릭과 Auto Scaling 그룹의 GroupPendingInstances 메트릭을 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다.
D. ApproximateNumberOfMessagesVisible 메트릭과 Auto Scaling 그룹의 InService 상태 인스턴스 수를 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다. 가장 많이 투표된

고객의 파일 처리 지연 문제를 해결하기 위해 Amazon EC2 Auto Scaling을 구성하는 가장 효과적인 방법은 다음과 같습니다:

### **B. 대기열에 있는 지연된 메시지 수에 따라 인스턴스 수를 조정하기 위해 ApproximateNumberOfMessagesDelayed 메트릭을 기반으로 자동 크기 조정 정책을 만듭니다.**

#### **설명**:
- **ApproximateNumberOfMessagesDelayed 메트릭**은 SQS 대기열에 지연된 메시지의 수를 나타냅니다. 이 메트릭을 사용하여 대기열에 지연된 메시지가 많을수록 추가 인스턴스를 시작하도록 자동 확장 정책을 설정할 수 있습니다. 
- 지연된 메시지가 많다는 것은 처리할 메시지가 많고, 현재 인스턴스의 처리 능력이 부족하다는 것을 의미하므로, 이 메트릭을 기반으로 인스턴스를 추가로 실행하면 지연을 줄일 수 있습니다.

### **기타 옵션 설명**:
A. **시작 템플릿에 여러 다른 인스턴스 크기를 추가합니다. ApproximateNumberOfMessagesVisible 메트릭을 기반으로 자동 크기 조정 정책을 만들어 큐의 메시지 수에 따라 인스턴스 크기를 선택합니다.**
- 이 방법은 큐의 전체 메시지 수에 따라 인스턴스를 크기를 조정하려고 하지만, 지연된 메시지 수가 문제의 핵심이므로 효과적이지 않을 수 있습니다.

C. **ASGAverageCPUUtilization 메트릭과 Auto Scaling 그룹의 GroupPendingInstances 메트릭을 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다.**
- CPU 사용량은 처리가 지연되는 직접적인 원인이 아닐 수 있으므로 이 옵션은 적절하지 않을 수 있습니다.

D. **ApproximateNumberOfMessagesVisible 메트릭과 Auto Scaling 그룹의 InService 상태 인스턴스 수를 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다.**
- Visible 메시지 수는 대기열에 대기 중인 메시지 수를 의미하지만, 지연된 메시지 수를 다루지 않기 때문에 처리 지연 문제를 완전히 해결하지는 못할 수 있습니다.

따라서 **B**가 가장 적합한 솔루션입니다.



## 질문 #84 ++

한 회사가 us-east-1 지역의 한 가용성 영역에 두 개의 Amazon EC2 인스턴스가 있는 다중 계층 웹 애플리케이션을 실행합니다. 

SysOps 관리자는 EC2 인스턴스 중 하나를 새 가용성 영역으로 마이그레이션해야 합니다.
어떤 솔루션이 이를 달성할까요?

A. EC2 인스턴스를 다른 가용성 영역으로 복사합니다. 원래 인스턴스를 종료합니다.
B. EC2 인스턴스에서 Amazon Machine Image(AMI)를 생성하고 다른 가용성 영역에서 시작합니다. 원래 인스턴스를 종료합니다. 
C. AWS CLI를 사용하여 EC2 인스턴스를 다른 가용성 영역으로 이동합니다.
D. EC2 인스턴스를 중지하고 가용성 영역을 수정한 다음 인스턴스를 시작합니다.

한 회사가 Amazon EC2 인스턴스를 새로운 가용성 영역으로 마이그레이션해야 할 때, 가장 적절한 솔루션은:

**B. EC2 인스턴스에서 Amazon Machine Image(AMI)를 생성하고 다른 가용성 영역에서 시작합니다. 원래 인스턴스를 종료합니다.**

### 이유:
- **AMI 생성 및 인스턴스 시작**: AMI를 생성하면 현재 EC2 인스턴스의 상태와 구성을 포함한 이미지를 저장할 수 있습니다. 그런 다음 이 AMI를 사용하여 새 가용성 영역에서 인스턴스를 시작할 수 있습니다. 이를 통해 새로운 가용성 영역에서 동일한 인스턴스를 쉽게 만들 수 있으며, 필요한 경우 원래 인스턴스를 종료할 수 있습니다.

### 나머지 옵션 분석:
- **A. EC2 인스턴스를 다른 가용성 영역으로 복사합니다. 원래 인스턴스를 종료합니다.**: EC2 인스턴스를 직접 다른 가용성 영역으로 복사하는 기능은 제공되지 않습니다. AMI를 사용해야 합니다.

- **C. AWS CLI를 사용하여 EC2 인스턴스를 다른 가용성 영역으로 이동합니다.**: EC2 인스턴스를 직접 이동하는 명령어는 없으며, AMI를 사용하여 새로운 인스턴스를 생성해야 합니다.

- **D. EC2 인스턴스를 중지하고 가용성 영역을 수정한 다음 인스턴스를 시작합니다.**: 현재 EC2 인스턴스는 가용성 영역을 직접 수정할 수 없으며, AMI를 사용하여 새로운 인스턴스를 생성해야 합니다.

결론적으로, EC2 인스턴스를 새로운 가용성 영역으로 마이그레이션하기 위한 가장 효과적인 방법은 **B. AMI를 생성하고 새로운 가용성 영역에서 인스턴스를 시작하는 것**입니다.

## 질문 #85 ++++

한 회사가 트래픽 증가가 예상되기 전에 Amazon EC2 인스턴스의 플릿을 확장하고 있습니다. 

SysOps 관리자가 인스턴스를 더 추가하려고 하면 InstanceLimitExceeded 오류가 반환됩니다.
SysOps 관리자는 이 오류를 해결하기 위해 무엇을 해야 합니까?

A. VPC에 추가 CIDR 블록을 추가합니다.
B. 다른 가용성 영역에서 EC2 인스턴스를 시작합니다.
C. 다른 VPC에서 새로운 EC2 인스턴스를 시작합니다.
D. 서비스 할당량을 사용하여 EC2 할당량 증가를 요청합니다. 


SysOps 관리자가 Amazon EC2 인스턴스를 추가하려고 할 때 `InstanceLimitExceeded` 오류가 발생하는 경우, 이 오류를 해결하기 위한 적절한 조치는 다음과 같습니다:

**D. 서비스 할당량을 사용하여 EC2 할당량 증가를 요청합니다.**

### 이유:
- **InstanceLimitExceeded 오류**: 이 오류는 현재 계정에서 허용된 EC2 인스턴스 수의 상한선에 도달했음을 의미합니다. AWS는 각 리전 및 계정에 대해 인스턴스 수에 대한 기본 제한(할당량)을 설정하고 있으며, 이 제한을 초과하려고 할 경우 오류가 발생합니다. 따라서 할당량 증가를 요청하여 더 많은 인스턴스를 시작할 수 있도록 해야 합니다.

### 나머지 옵션 분석:
- **A. VPC에 추가 CIDR 블록을 추가합니다.**: CIDR 블록을 추가하는 것은 IP 주소 범위를 확장하는 것이며, EC2 인스턴스 수의 할당량 문제를 해결하는 데는 도움이 되지 않습니다.

- **B. 다른 가용성 영역에서 EC2 인스턴스를 시작합니다.**: 가용성 영역 간에 인스턴스 수의 할당량이 다를 수 있지만, 기본적으로 계정의 전체 인스턴스 수에 대한 제한이 적용되므로 이 방법으로는 오류를 해결할 수 없습니다.

- **C. 다른 VPC에서 새로운 EC2 인스턴스를 시작합니다.**: 다른 VPC를 사용하는 것이 인스턴스 수의 할당량을 늘리지는 않으며, 여전히 계정에 설정된 전체 인스턴스 수의 제한이 적용됩니다.

결론적으로, `InstanceLimitExceeded` 오류를 해결하기 위해서는 **D. 서비스 할당량을 사용하여 EC2 할당량 증가를 요청하는 것**이 가장 적절한 방법입니다.



## 질문 #86

한 회사가 개발자가 특정 Amazon EC2 인스턴스 패밀리를 사용하는 것을 금지하려고 합니다. 

이 회사는 AWS Organizations를 사용하고 여러 계정에 제한을 적용하려고 합니다.
이 회사가 이러한 요구 사항을 충족하기 위해 서비스 제어 정책(SCP)을 적용하는 가장 운영 효율적인 방법은 무엇입니까?

A. 조직 단위(OU)에 계정을 추가합니다. OU에 SCP를 적용합니다. 
B. AWS Resource Groups의 리소스 그룹에 계정을 추가합니다. SCP를 리소스 그룹에 적용합니다.
C. 각 개발자 계정에 SCP 적용
D. AWS Control Tower에 계정을 등록합니다. AWS Control Tower 관리 계정에 SCP를 적용합니다.


회사가 특정 Amazon EC2 인스턴스 패밀리를 사용하는 것을 금지하기 위해 AWS Organizations를 사용하여 서비스 제어 정책(SCP)을 적용하는 가장 운영 효율적인 방법은 다음과 같습니다:

**A. 조직 단위(OU)에 계정을 추가합니다. OU에 SCP를 적용합니다.**

### 이유:
- **조직 단위(OU)**: AWS Organizations에서는 계정을 OU에 구성할 수 있으며, 이를 통해 특정 정책(SCP)을 적용하여 하위 계정에 대한 액세스를 제어할 수 있습니다. OU에 SCP를 적용하면 해당 OU에 속한 모든 계정에 대해 일관된 정책을 쉽게 관리하고 적용할 수 있습니다.
  
- **효율성**: OU에 SCP를 적용하면 여러 계정에 동시에 정책을 적용할 수 있으므로 관리 오버헤드를 줄일 수 있습니다. 개별 계정에 정책을 적용하는 것보다 중앙 집중식으로 관리하는 것이 더 효율적입니다.

### 나머지 옵션 분석:
- **B. AWS Resource Groups의 리소스 그룹에 계정을 추가합니다. SCP를 리소스 그룹에 적용합니다.**: AWS Resource Groups는 리소스를 그룹화하는 데 사용되며, SCP는 조직 단위 및 계정에 적용되는 것이므로 리소스 그룹은 SCP 적용에 적합하지 않습니다.

- **C. 각 개발자 계정에 SCP 적용**: 각 계정에 개별적으로 SCP를 적용하는 것은 관리의 복잡성을 증가시키고 비효율적입니다.

- **D. AWS Control Tower에 계정을 등록합니다. AWS Control Tower 관리 계정에 SCP를 적용합니다.**: AWS Control Tower는 여러 계정을 설정하고 관리하는 데 유용하지만, SCP는 AWS Organizations의 기능이므로 OU를 통해 직접 관리하는 것이 더 효율적입니다.

결론적으로, **A. 조직 단위(OU)에 계정을 추가하고 OU에 SCP를 적용하는 것**이 특정 Amazon EC2 인스턴스 패밀리를 금지하기 위한 가장 운영 효율적인 방법입니다.


## 질문 #87 +++++

애플리케이션은 기본 DHCP 옵션이 설정된 VPC의 Amazon EC2 인스턴스에서 실행 중입니다. 

애플리케이션은 DNS 이름 mssql.example.com을 사용하여 온프레미스 Microsoft SQL Server 데이터베이스에 연결합니다 . 애플리케이션은 데이터베이스 DNS 이름을 확인할 수 없습니다.
어떤 솔루션이 이 문제를 해결할까요?


A. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 전달 규칙을 추가합니다. 전달 규칙을 VPC와 연결합니다.
B. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 시스템 규칙을 추가합니다. 시스템 규칙을 VPC와 연결합니다.
C. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 전달 규칙을 추가합니다. 전달 규칙을 VPC와 연결합니다. 
D. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 시스템 규칙을 추가합니다. 시스템 규칙을 VPC와 연결합니다.


애플리케이션이 온프레미스 Microsoft SQL Server 데이터베이스에 연결할 때 DNS 이름을 확인할 수 없는 문제를 해결하기 위해 가장 적합한 솔루션은 다음과 같습니다:

**C. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 전달 규칙을 추가합니다. 전달 규칙을 VPC와 연결합니다.**

### 이유:
- **아웃바운드 엔드포인트**: Amazon Route 53 Resolver 아웃바운드 엔드포인트를 사용하면 VPC 내의 리소스가 온프레미스 DNS 서버에 대한 DNS 요청을 전달할 수 있습니다. 이를 통해 VPC의 EC2 인스턴스가 온프레미스 데이터베이스의 DNS 이름(mssql.example.com)을 확인할 수 있습니다.

- **전달 규칙**: 전달 규칙을 추가함으로써, Route 53 Resolver는 특정 도메인(이 경우 `example.com`)에 대한 요청을 지정된 온프레미스 DNS 서버로 전달하게 됩니다. 이 설정은 온프레미스 네트워크와 통신하기 위해 DNS 요청을 올바른 경로로 보낼 수 있게 해줍니다.

### 나머지 옵션 분석:
- **A. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 전달 규칙을 추가합니다. 전달 규칙을 VPC와 연결합니다.**: 인바운드 엔드포인트는 VPC 외부에서 DNS 요청을 받아들이는 데 사용되며, 이 경우에는 적합하지 않습니다.

- **B. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 시스템 규칙을 추가합니다. 시스템 규칙을 VPC와 연결합니다.**: 시스템 규칙은 AWS가 관리하는 규칙으로, 온프레미스 DNS 서버와의 통신에는 적합하지 않습니다.

- **D. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 시스템 규칙을 추가합니다. 시스템 규칙을 VPC와 연결합니다.**: 시스템 규칙은 특정 DNS 이름을 위한 사용자 정의 전달을 설정하는 데 사용되지 않으므로, 원하는 목적에 부합하지 않습니다.

결론적으로, **C. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만들고, 도메인 example.com에 대한 전달 규칙을 추가하는 것**이 DNS 이름 확인 문제를 해결하는 가장 적합한 방법입니다.


## 질문 #88 +++++

회사의 애플리케이션은 app.example.com에서 인터넷 제공자에 의해 호스팅됩니다. 

회사는 Amazon Route 53으로 소유하고 관리하는 www.company.com을 사용하여 애플리케이션에 액세스하려고 합니다.
이를 해결하기 위해 어떤 Route 53 레코드를 만들어야 합니까?

A. 기록
B. 별칭 기록
C. CNAME 레코드 
D. 포인터(PTR) 레코드


회사가 Amazon Route 53을 사용하여 `www.company.com` 도메인을 `app.example.com`으로 리다이렉트하려면, 다음과 같은 Route 53 레코드를 생성해야 합니다:

**C. CNAME 레코드**

### 이유:
- **CNAME 레코드**: CNAME(Canonical Name) 레코드는 한 도메인 이름을 다른 도메인 이름에 매핑하는 데 사용됩니다. 이 경우, `www.company.com`을 `app.example.com`에 매핑하여 사용자가 `www.company.com`을 입력할 때 `app.example.com`의 콘텐츠가 표시되도록 합니다.

### 다른 옵션 분석:
- **A. 기록**: 이 옵션은 불명확합니다. 어떤 종류의 기록인지 명시되어 있지 않으므로 적합하지 않습니다.

- **B. 별칭 기록**: 별칭(Alias) 레코드는 Route 53에서 사용되는 특별한 유형의 레코드로, AWS 리소스(예: CloudFront 배포, ELB 등)에 대해 사용할 수 있습니다. 그러나 일반적으로 CNAME 레코드와 같은 방식으로 도메인을 매핑할 때는 사용되지 않습니다.

- **D. 포인터(PTR) 레코드**: PTR(포인터) 레코드는 IP 주소를 도메인 이름에 매핑하는 데 사용되며, 주로 역방향 DNS 조회에 사용됩니다. 이 경우에는 적합하지 않습니다.

결론적으로, `www.company.com`을 `app.example.com`으로 리다이렉트하기 위해서는 **C. CNAME 레코드**를 생성하는 것이 적절합니다.



## 질문 #89 +++

한 회사가 전 세계 청중에게 서비스를 제공하기 위해 웹 애플리케이션을 확장했습니다. 

SysOps 관리자가 모든 프로덕션 인프라에 대해 다중 지역 AWS 배포를 구현했습니다. SysOps 관리자는 리소스의 위치를 ​​기반으로 트래픽을 라우팅해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 Amazon Route 53 라우팅 정책을 사용해야 합니까?

A. 지리적 위치 라우팅 정책
B. 지근거리 라우팅 정책 가장 많이 투표된
C. 지연 기반 라우팅 정책
D. 다중값 답변 라우팅 정책


이 경우 SysOps 관리자가 리소스의 위치를 기반으로 트래픽을 라우팅하려면 다음 Amazon Route 53 라우팅 정책을 사용해야 합니다:

**A. 지리적 위치 라우팅 정책**

### 이유:
- **지리적 위치 라우팅 정책**: 이 정책은 사용자의 위치(예: 국가 또는 지역)에 따라 트래픽을 특정 리소스로 라우팅할 수 있습니다. 전 세계 청중에게 서비스를 제공하는 경우, 사용자의 지리적 위치에 따라 가장 가까운 리소스(예: 데이터 센터 또는 애플리케이션 인스턴스)로 트래픽을 전송할 수 있습니다. 이를 통해 사용자에게 최적의 성능과 응답 시간을 제공할 수 있습니다.

### 다른 옵션 분석:
- **B. 지근거리 라우팅 정책**: 이 정책은 주로 DNS 쿼리 응답 시간을 최소화하는 데 사용되며, 사용자의 위치에 가장 가까운 리소스를 선택하는 것이 아니라, 사용자의 위치를 고려하지 않고 최적의 응답을 제공하는 데 초점을 맞춥니다.

- **C. 지연 기반 라우팅 정책**: 이 정책은 사용자의 요청에 대한 응답 지연 시간이 가장 짧은 리소스를 선택합니다. 하지만 특정 지역으로의 트래픽 라우팅이 아니라 지연 시간을 기반으로 선택합니다.

- **D. 다중값 답변 라우팅 정책**: 이 정책은 여러 리소스에 대해 동일한 DNS 쿼리 응답을 반환하며, 특정 지역이나 위치 기반 라우팅을 제공하지 않습니다.

결론적으로, **A. 지리적 위치 라우팅 정책**이 리소스의 위치를 기반으로 트래픽을 라우팅하는 요구 사항을 충족하는 가장 적합한 선택입니다.


## 질문 #90

SysOps 관리자가 온프레미스에서 Amazon S3 버킷으로 멀티파트 업로드를 사용하여 1TB 크기의 파일을 업로드하려고 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. S3 콘솔을 사용하여 파일을 업로드합니다.
B. s3api copy-object 명령을 사용합니다.
C. s3api put-object 명령을 사용합니다.
D. s3 cp 명령을 사용합니다. 

SysOps 관리자가 온프레미스에서 Amazon S3 버킷으로 멀티파트 업로드를 사용하여 1TB 크기의 파일을 업로드하려면 다음을 선택해야 합니다:

**D. s3 cp 명령을 사용합니다.**

### 이유:
- **s3 cp 명령**: 이 명령은 AWS CLI에서 S3 버킷으로 파일을 복사하는 데 사용됩니다. 대용량 파일을 업로드할 때, `--storage-class`와 같은 추가 옵션을 사용할 수 있으며, AWS CLI는 자동으로 멀티파트 업로드를 처리하여 대용량 파일의 업로드를 최적화합니다.

### 다른 옵션 분석:
- **A. S3 콘솔을 사용하여 파일을 업로드합니다.**: S3 콘솔을 사용하여 파일을 업로드할 수 있지만, 1TB와 같은 대용량 파일의 경우 CLI를 사용하여 멀티파트 업로드를 활용하는 것이 더 효율적입니다.

- **B. s3api copy-object 명령을 사용합니다.**: 이 명령은 S3 내에서 객체를 복사하는 데 사용되며, 멀티파트 업로드를 위한 것이 아닙니다.

- **C. s3api put-object 명령을 사용합니다.**: 이 명령은 객체를 S3 버킷에 업로드하는 데 사용되지만, 대용량 파일의 경우 멀티파트 업로드를 지원하지 않기 때문에 적합하지 않습니다.

결론적으로, **D. s3 cp 명령을 사용합니다**는 대용량 파일을 멀티파트 업로드를 통해 S3에 효율적으로 업로드하는 가장 적절한 방법입니다.

## 질문 #91 +++++

애플리케이션 팀은 SysOps 관리자와 협력하여 애플리케이션에 대한 Amazon CloudWatch 알람을 정의하고 있습니다. 

애플리케이션 팀은 애플리케이션의 예상 사용량이나 예상 성장을 알지 못합니다.
SysOps 관리자는 어떤 솔루션을 추천해야 합니까?

A. 이상 감지를 기반으로 CloudWatch 알람을 생성합니다. 
B. 복합 알람 세트를 사용하여 CloudWatch 알람을 만듭니다.
C. 정적 임계값을 사용하여 CloudWatch 경보를 만듭니다.
D. 누락된 데이터를 침해로 처리하는 CloudWatch 알람을 생성합니다.

SysOps 관리자가 애플리케이션 팀에 추천해야 할 솔루션은 다음과 같습니다:

**A. 이상 감지를 기반으로 CloudWatch 알람을 생성합니다.**

### 이유:
- **이상 감지 알람**: 이 기능은 특정 메트릭의 정상 동작 패턴을 학습하여, 이 패턴에서 벗어난 경우에 알람을 생성합니다. 예상 사용량이나 성장에 대한 정보가 없을 때 매우 유용하며, 트래픽이 급증하거나 감소할 때 알람을 통해 즉각적으로 대응할 수 있습니다. 이는 자동으로 애플리케이션의 동작을 모니터링하여 불규칙한 트래픽 패턴이나 성능 문제를 신속하게 감지할 수 있게 해줍니다.

### 다른 옵션 분석:
- **B. 복합 알람 세트를 사용하여 CloudWatch 알람을 만듭니다.**: 복합 알람은 여러 개의 알람을 결합하여 조건을 설정하는 것이지만, 기본적인 이상 감지 기능과는 다소 거리가 있습니다. 

- **C. 정적 임계값을 사용하여 CloudWatch 경보를 만듭니다.**: 정적 임계값은 사전에 정의된 값을 기준으로 하므로, 애플리케이션의 예상 사용량이나 성장에 대한 정보가 부족할 때는 효과적이지 않을 수 있습니다.

- **D. 누락된 데이터를 침해로 처리하는 CloudWatch 알람을 생성합니다.**: 이 옵션은 누락된 데이터를 경고하는 것이지만, 예상 사용량이나 성장을 알지 못하는 상황에서는 유용성이 떨어집니다.

결론적으로, **A. 이상 감지를 기반으로 CloudWatch 알람을 생성합니다**는 예상 사용량이나 성장이 불확실한 상황에서 애플리케이션의 이상 징후를 효과적으로 모니터링할 수 있는 최선의 선택입니다.


## 질문 #92 ++

한 회사가 Amazon EC2 인스턴스에 호스팅된 상태 없는 애플리케이션을 실행합니다. 

사용자들이 성능 문제를 보고하고 있습니다. SysOps 관리자가 애플리케이션에 대한 Amazon CloudWatch 메트릭을 검토하고 인스턴스의 CPU 사용률이 업무 시간 동안 자주 90%에 도달한다는 것을 알아챘습니다.
애플리케이션의 응답성을 개선할 가장 운영 효율적인 솔루션은 무엇입니까?

A. EC2 인스턴스에서 CloudWatch 로깅을 구성합니다. CPU 사용률이 90%를 넘을 때 SysOps 관리자에게 경고하도록 CPU 사용률에 대한 CloudWatch 알람을 구성합니다.
B. 애플리케이션 사용자가 EC2 인스턴스 개인 IP 주소에 직접 연결하여 지연 시간을 줄일 수 있도록 AWS 클라이언트 VPN 연결을 구성합니다.
C. 자동 스케일링 그룹을 만들고 이를 애플리케이션 로드 밸런서에 할당합니다. 자동 스케일링 그룹의 평균 CPU 사용률을 기반으로 하는 대상 추적 스케일링 정책을 구성합니다. 
D. EC2 인스턴스의 CPU 사용률이 80%를 넘을 때 활성화되는 CloudWatch 알람을 만듭니다. 인스턴스를 수직으로 확장하는 AWS Lambda 함수를 호출하도록 알람을 구성합니다.

SysOps 관리자가 성능 문제를 해결하고 애플리케이션의 응답성을 개선하기 위한 가장 운영 효율적인 솔루션은 다음과 같습니다:

**C. 자동 스케일링 그룹을 만들고 이를 애플리케이션 로드 밸런서에 할당합니다. 자동 스케일링 그룹의 평균 CPU 사용률을 기반으로 하는 대상 추적 스케일링 정책을 구성합니다.**

### 이유:
- **자동 스케일링**: 자동 스케일링 그룹을 통해 애플리케이션의 부하에 따라 EC2 인스턴스를 동적으로 추가하거나 제거할 수 있습니다. CPU 사용률이 90%에 도달하는 것을 관찰한 만큼, 자동 스케일링을 통해 수요에 맞춰 인스턴스를 자동으로 확장하면 성능 문제를 효과적으로 해결할 수 있습니다.
- **로드 밸런서와의 통합**: 애플리케이션 로드 밸런서를 통해 트래픽을 여러 인스턴스에 분산할 수 있어, 각 인스턴스의 부하를 줄이고 응답성을 향상시킵니다.
- **효율성**: 자동 스케일링은 사용량이 적은 시간대에는 인스턴스를 줄여 비용을 절감할 수 있는 반면, 피크 시간대에는 필요한 만큼 인스턴스를 확장하여 안정적인 성능을 유지할 수 있습니다.

### 다른 옵션 분석:
- **A. EC2 인스턴스에서 CloudWatch 로깅을 구성합니다.**: CloudWatch 알람을 설정하는 것은 유용하지만, 문제가 발생했을 때 즉각적인 해결책이 되지는 않습니다. 경고만으로는 성능 문제를 해결할 수 없습니다.

- **B. 애플리케이션 사용자가 EC2 인스턴스 개인 IP 주소에 직접 연결하도록 AWS 클라이언트 VPN 연결을 구성합니다.**: 이는 사용자와 인스턴스 간의 연결 방식만 변경할 뿐, 성능 문제의 근본 원인을 해결하지 않습니다.

- **D. EC2 인스턴스의 CPU 사용률이 80%를 넘을 때 활성화되는 CloudWatch 알람을 만듭니다.**: CPU 사용률이 80%를 넘는 상황에서는 이미 성능 문제가 발생하고 있을 가능성이 큽니다. 수직 확장은 단기적으로 해결할 수 있지만, 장기적으로는 자동 스케일링과 같은 수평 확장이 더 효과적입니다.

결론적으로, **C. 자동 스케일링 그룹을 만들고 이를 애플리케이션 로드 밸런서에 할당하는 것**이 애플리케이션의 응답성을 개선하는 가장 운영 효율적인 방법입니다.




## 질문 #93 +++

전자상거래 회사는 쇼핑 사이트에서 인기 있는 제품 쿼리의 메모리 내 캐싱을 위해 Amazon ElastiCache for Memcached 클러스터를 사용합니다. 

ElastiCache 클러스터에 대한 최근 Amazon CloudWatch 메트릭 데이터를 볼 때 SysOps 관리자는 많은 수의 퇴거를 알아차립니다.
다음 중 어떤 조치가 이러한 퇴거를 줄일 수 있을까요? (두 가지를 선택하세요.)


A. ElastiCache 클러스터에 추가 노드를 추가합니다. 
B. ElastiCache의 TTL(수명)을 늘립니다.
C. ElastiCache 클러스터 내의 개별 노드 크기를 늘립니다. 
D. ElastiCache 클러스터 앞에 Elastic Load Balancer를 배치합니다.
E. Amazon Simple Queue Service(Amazon SQS)를 사용하여 ElastiCache 클러스터를 분리합니다.

Amazon ElastiCache for Memcached 클러스터에서 퇴거를 줄이기 위해 SysOps 관리자가 취할 수 있는 조치는 다음 두 가지입니다:

### A. ElastiCache 클러스터에 추가 노드를 추가합니다.
- **이유**: 클러스터에 노드를 추가하면 캐시할 수 있는 데이터의 총 용량이 증가하므로, 퇴거가 발생할 가능성이 줄어듭니다. 노드를 추가하면 부하 분산도 개선되어 더 많은 쿼리를 처리할 수 있습니다.

### C. ElastiCache 클러스터 내의 개별 노드 크기를 늘립니다.
- **이유**: 각 노드의 크기를 늘리면 각 노드가 보유할 수 있는 데이터의 양이 증가합니다. 따라서 퇴거를 줄이고 더 많은 데이터를 메모리에 캐시할 수 있습니다. 

### 다른 옵션 분석:
- **B. ElastiCache의 TTL(수명)을 늘립니다.**: TTL을 늘리면 캐시된 데이터가 더 오래 유지될 수 있지만, 이는 퇴거를 직접적으로 줄이지는 않습니다. 캐시된 데이터가 오래 남는다면 메모리를 더 차지하게 되어 오히려 더 많은 퇴거가 발생할 수 있습니다.

- **D. ElastiCache 클러스터 앞에 Elastic Load Balancer를 배치합니다.**: ELB는 요청을 분산시키는 데 도움이 될 수 있지만, 퇴거 문제를 해결하는 데 직접적인 도움이 되지는 않습니다. 퇴거는 메모리의 용량과 관련된 문제이므로, 노드 수나 크기를 조정하는 것이 더 효과적입니다.

- **E. Amazon Simple Queue Service(Amazon SQS)를 사용하여 ElastiCache 클러스터를 분리합니다.**: SQS는 메시지 큐 서비스로, 캐시와는 다른 사용 사례입니다. ElastiCache의 퇴거 문제를 해결하는 데 도움이 되지 않습니다.

결론적으로, **A. ElastiCache 클러스터에 추가 노드를 추가하고, C. ElastiCache 클러스터 내의 개별 노드 크기를 늘리는 것**이 퇴거를 줄이는 데 효과적입니다.



## 질문 #94 ++++

SysOps 관리자가 여러 IAM 사용자에게 IAM 정책을 연결하여 AWS 서비스에 대한 액세스를 제공하려고 합니다. 

SysOps 관리자는 또한 정책을 변경하고 새 버전을 만들 수 있기를 원합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하십시오.)

A. 사용자를 IAM 서비스 연결 역할에 추가합니다. 정책을 역할에 연결합니다.
B. 사용자를 IAM 사용자 그룹에 추가합니다. 정책을 그룹에 연결합니다. 
C. AWS 관리 정책을 생성합니다.
D. 고객 관리 정책을 만듭니다. 
E. 인라인 정책을 만듭니다.


SysOps 관리자가 여러 IAM 사용자에게 IAM 정책을 연결하고 정책을 변경 및 새 버전을 만들 수 있는 요구 사항을 충족하기 위해 선택해야 할 두 가지 작업은 다음과 같습니다:

### B. 사용자를 IAM 사용자 그룹에 추가합니다. 정책을 그룹에 연결합니다.
- **이유**: IAM 사용자 그룹에 정책을 연결하면 그룹에 속한 모든 사용자가 해당 정책의 권한을 상속받습니다. 이는 관리 및 정책 적용을 간소화하는 데 도움이 됩니다.

### D. 고객 관리 정책을 만듭니다.
- **이유**: 고객 관리 정책을 사용하면 사용자가 작성하고 관리할 수 있는 정책을 정의할 수 있습니다. 이를 통해 필요에 따라 정책을 변경하고 새 버전을 만들 수 있습니다. 고객 관리 정책은 특정 계정에서만 유효하며, IAM 사용자가 정책의 버전을 변경할 수 있습니다.

### 다른 옵션 분석:
- **A. 사용자를 IAM 서비스 연결 역할에 추가합니다. 정책을 역할에 연결합니다.**: IAM 역할은 다른 AWS 서비스나 IAM 사용자에게 권한을 부여하는 데 사용됩니다. 그러나 일반 사용자에게 직접 권한을 부여하기 위해 역할을 사용하는 것은 일반적이지 않습니다.

- **C. AWS 관리 정책을 생성합니다.**: AWS 관리 정책은 AWS에서 관리하며, 사용자가 정책을 수정할 수 없습니다. 따라서 이 선택은 SysOps 관리자의 요구 사항인 정책 변경 및 버전 생성을 충족하지 않습니다.

- **E. 인라인 정책을 만듭니다.**: 인라인 정책은 특정 사용자에게만 연결되며, 해당 사용자와 함께 삭제됩니다. 관리 측면에서 그룹에 연결된 정책이 더 효율적이며, 인라인 정책은 여러 사용자에게 적용할 수 없으므로 관리가 더 어렵습니다.

결론적으로, **B. 사용자를 IAM 사용자 그룹에 추가하고, D. 고객 관리 정책을 만드는 것**이 요구 사항을 충족하는 최선의 선택입니다.



## 질문 #95 +++

한 회사가 Amazon S3 버킷에 중요한 데이터를 저장합니다. 

SysOps 관리자는 모든 S3 API 활동을 기록하는 솔루션을 구축해야 합니다.
어떤 작업이 이 요구 사항을 충족할까요?

A. S3 버킷 메트릭을 구성하여 객체 액세스 로그를 기록합니다.
B. 모든 S3 객체에 대한 데이터 이벤트를 기록하기 위한 AWS CloudTrail 트레일을 생성합니다. 
C. 각 S3 버킷에 대해 S3 서버 액세스 로깅을 활성화합니다.
D. Amazon S3용 AWS IAM Access Analyzer를 사용하여 객체 액세스 로그를 저장합니다.


Amazon S3 버킷에 중요한 데이터를 저장하는 회사가 모든 S3 API 활동을 기록하는 솔루션을 구축해야 할 때 가장 적합한 작업은 다음과 같습니다:

### **B. 모든 S3 객체에 대한 데이터 이벤트를 기록하기 위한 AWS CloudTrail 트레일을 생성합니다.**
- **이유**: AWS CloudTrail은 AWS 계정 내에서 수행된 모든 API 호출을 기록하고 이를 CloudTrail 로그에 저장합니다. S3 API 활동을 포함하여 사용자가 S3 버킷에 대한 모든 작업을 모니터링하고 감사할 수 있습니다. 따라서 S3 API 활동을 포괄적으로 기록하는 데 가장 효과적입니다.

### 다른 옵션 분석:
- **A. S3 버킷 메트릭을 구성하여 객체 액세스 로그를 기록합니다.**: S3 버킷 메트릭은 주로 퍼포먼스를 모니터링하는 데 사용되며, API 호출을 기록하지 않습니다. 따라서 이 옵션은 요구 사항을 충족하지 않습니다.

- **C. 각 S3 버킷에 대해 S3 서버 액세스 로깅을 활성화합니다.**: S3 서버 액세스 로깅은 S3 버킷에 대한 요청 로그를 생성합니다. 하지만 이는 특정 요청에 대한 세부 정보만 제공하며 API 호출을 포괄적으로 기록하는 데는 한계가 있습니다.

- **D. Amazon S3용 AWS IAM Access Analyzer를 사용하여 객체 액세스 로그를 저장합니다.**: AWS IAM Access Analyzer는 리소스에 대한 액세스 권한을 분석하는 데 유용하지만, API 호출을 기록하는 기능은 제공하지 않습니다.

결론적으로, **B. 모든 S3 객체에 대한 데이터 이벤트를 기록하기 위한 AWS CloudTrail 트레일을 생성하는 것**이 요구 사항을 충족하는 가장 적합한 솔루션입니다.



## 질문 #96 ++

한 회사가 Amazon EC2 인스턴스에서 MySQL 데이터베이스를 사용하는 애플리케이션을 실행합니다. 

EC2 인스턴스에는 General Purpose SSD Amazon Elastic BlockStore(Amazon EBS) 볼륨이 있습니다. 이 회사는 애플리케이션 코드를 변경했고 이제 코드 변경의 영향을 평가하기 위해 부하 테스트를 수행하려고 합니다.
SysOps 관리자는 기존 프로덕션 인스턴스의 스냅샷에서 새 MySQL 인스턴스를 만들어야 합니다. 이 새 인스턴스는 프로덕션 인스턴스와 가능한 한 비슷하게 수행되어야 합니다.
이러한 요구 사항을 충족하는 복원 옵션은 무엇입니까?

A. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성합니다. 가장 많이 투표된
B. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 프로비저닝된 IOPS SSD EBS 볼륨을 생성합니다.
C. EBS 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성합니다.
D. EBS 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 Provisioned IOPS SSD EBS 볼륨을 생성합니다.


MySQL 데이터베이스를 사용하는 애플리케이션의 부하 테스트를 위해 기존 프로덕션 인스턴스의 스냅샷에서 새 MySQL 인스턴스를 생성하는 데 가장 적합한 복원 옵션은 다음과 같습니다:

### **A. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성합니다.**

#### 이유:
- **빠른 스냅샷 복원**: EBS의 빠른 스냅샷 복원 기능을 사용하면 스냅샷에서 새로운 볼륨을 거의 즉시 사용할 수 있습니다. 이는 부하 테스트를 수행할 때 중요합니다.
- **범용 SSD EBS 볼륨**: 이미 프로덕션 인스턴스에서 범용 SSD EBS 볼륨을 사용하고 있으므로, 새 인스턴스에서도 동일한 유형의 볼륨을 사용하는 것이 성능을 가장 잘 반영합니다.

### 다른 옵션 분석:
- **B. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 프로비저닝된 IOPS SSD EBS 볼륨을 생성합니다.**: 프로비저닝된 IOPS SSD는 성능이 뛰어나지만, 원래 프로덕션 인스턴스에서 사용한 볼륨 유형과 다르기 때문에 부하 테스트 결과가 프로덕션 환경과 일치하지 않을 수 있습니다.

- **C. EBS 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성합니다.**: 이 옵션은 스냅샷 복원 속도가 느릴 수 있어 부하 테스트 진행 시 지연이 발생할 수 있습니다. 

- **D. EBS 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 Provisioned IOPS SSD EBS 볼륨을 생성합니다.**: 이 옵션도 프로덕션 인스턴스와 다른 볼륨 유형을 사용하므로 부하 테스트 결과의 일관성을 보장하지 못합니다.

결론적으로, **A. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성하는 것**이 요구 사항을 충족하는 최적의 복원 옵션입니다.



## 질문 #97 ++++

대기 엔지니어 팀은 문제를 해결하고 명령을 실행하기 위해 프라이빗 서브넷의 Amazon EC2 인스턴스에 자주 연결해야 합니다. 

인스턴스는 최신 AWS 제공 Windows Amazon Machine Images(AMI) 또는 Amazon Linux AMI를 사용합니다.
팀에는 권한 부여를 위한 기존 1AM 역할이 있습니다. SysOps 관리자는 이 역할에 IAM 권한을 부여하여 팀에 인스턴스에 대한 액세스 권한을 제공해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. 인스턴스에서 ssm:StartSession 작업을 허용하기 위해 1AM 역할 정책에 명령문을 추가합니다. 팀에 AWS Systems Manager Session Manager를 사용하여 가정된 IAM 역할을 사용하여 인스턴스에 연결하도록 지시합니다. 가장 많이 투표된
B. 각 인스턴스에 Elastic IP 주소와 보안 그룹을 연결합니다. 엔지니어의 IP 주소를 보안 그룹 인바운드 규칙에 추가합니다. 팀이 인스턴스에 연결할 수 있도록 ec2:AuthorizeSecurityGrouplngress 작업을 허용하는 IAM 역할 정책에 명령문을 추가합니다.
C. EC2 인스턴스로 배스천 호스트를 만들고 배스천 호스트를 VPC와 연결합니다. 배스천 호스트에서 ec2:CreateVpnConnection 작업을 허용하도록 1AM 역할 정책에 명령문을 추가합니다. 팀에 배스천 호스트 엔드포인트를 사용하여 인스턴스에 연결하도록 지시합니다.
D. 인터넷 연결 네트워크 로드 밸런서를 만듭니다. 두 개의 리스너를 사용합니다. 포트 22를 Linux 인스턴스의 대상 그룹으로 전달합니다. 포트 3389를 Windows 인스턴스의 대상 그룹으로 전달합니다. 팀이 인스턴스에 연결할 수 있도록 ec2:CreateRoute 작업을 허용하는 IAM 역할 정책에 명령문을 추가합니다.

프라이빗 서브넷의 Amazon EC2 인스턴스에 안전하고 효율적으로 접근하기 위해서 가장 적합한 솔루션은 다음과 같습니다:

**A. 인스턴스에서 ssm:StartSession 작업을 허용하기 위해 IAM 역할 정책에 명령문을 추가합니다. 팀에 AWS Systems Manager Session Manager를 사용하여 가정된 IAM 역할을 사용하여 인스턴스에 연결하도록 지시합니다.**

#### 이유:
- **AWS Systems Manager Session Manager**: 이 서비스는 EC2 인스턴스에 대한 안전한 셸 액세스를 제공하며, 인스턴스가 퍼블릭 IP 주소를 갖지 않더라도 연결할 수 있습니다. 이를 통해 프라이빗 서브넷에 있는 인스턴스에 접근할 수 있습니다.
- **IAM 역할과 정책**: 기존 IAM 역할에 `ssm:StartSession` 작업을 허용하는 명령문을 추가하면 팀이 Session Manager를 통해 EC2 인스턴스에 연결할 수 있는 권한을 부여할 수 있습니다.
- **보안**: 이 접근 방식은 SSH 포트나 RDP 포트를 열지 않아도 되므로 보안상 이점이 있습니다.

### 다른 옵션 분석:
- **B. 각 인스턴스에 Elastic IP 주소와 보안 그룹을 연결합니다.**: 이 방법은 보안상 좋지 않습니다. Elastic IP를 사용하면 인터넷에 노출되고, 보안 그룹에서 IP 주소를 추가하는 것은 관리가 복잡해질 수 있습니다.

- **C. EC2 인스턴스로 배스천 호스트를 만들고 배스천 호스트를 VPC와 연결합니다.**: 배스천 호스트를 사용하는 방법도 가능합니다. 그러나 이 경우 추가적인 관리 및 보안 설정이 필요하고, Session Manager를 사용하는 것이 더 간편하고 안전합니다.

- **D. 인터넷 연결 네트워크 로드 밸런서를 만듭니다.**: 이 옵션은 필요하지 않은 복잡성을 더하고, 보안 위험이 높습니다. 인스턴스를 인터넷에 노출하게 되어 더 많은 보안 고려사항이 필요합니다.

결론적으로, **A. 인스턴스에서 ssm:StartSession 작업을 허용하기 위해 IAM 역할 정책에 명령문을 추가하는 것**이 요구 사항을 가장 잘 충족하는 솔루션입니다.



## 질문 #98 ++++

한 회사는 AWS에 배포된 25개 애플리케이션에 대한 예산을 엄격히 준수해야 합니다. 

별도의 팀이 스토리지, 컴퓨팅 및 데이터베이스 비용을 담당합니다. 
SysOps 관리자는 재무 부서에서 설정한 분기별 금액을 예상 지출이 초과할 경우 각 팀에 경고하는 자동화된 솔루션을 구현해야 합니다. 
이 솔루션은 추가 컴퓨팅, 스토리지 또는 데이터베이스 비용을 발생시킬 수 없습니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. AWS 비용 및 사용 보고서를 구성하여 Amazon S3 버킷에 일일 보고서를 보냅니다. 서비스별 지출을 평가하고 Amazon Simple Notification Service(Amazon SNS) 알림을 사용하여 각 팀에 알리는 AWS Lambda 함수를 만듭니다. 보고서가 S3 버킷에 배치되면 Lambda 함수를 호출합니다.
B. AWS 비용 및 사용 보고서를 구성하여 Amazon S3 버킷에 일일 보고서를 보냅니다. Amazon EventBridge(Amazon CloudWatch Events)에서 서비스별 지출을 평가하고 비용 임계값을 초과하면 Amazon Simple Queue Service(Amazon SQS)를 사용하여 각 팀에 알리는 규칙을 만듭니다.
C. AWS Budgets를 사용하여 하나의 비용 예산을 만들고 사용 중인 각 서비스를 선택합니다. 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다. 예산에 대한 적절한 이메일 수신자를 입력합니다.
D. AWS Budgets를 사용하여 각 팀에 대한 비용 예산을 만들고, 팀이 소유한 서비스로 필터링합니다. 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다. 각 예산에 대한 적절한 이메일 수신자를 입력합니다. 가장 많이 투표된


각 팀에 대한 예산을 관리하고 경고를 자동화하는 데 가장 적합한 솔루션은 다음과 같습니다:

### **D. AWS Budgets를 사용하여 각 팀에 대한 비용 예산을 만들고, 팀이 소유한 서비스로 필터링합니다. 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다. 각 예산에 대한 적절한 이메일 수신자를 입력합니다.**

#### 이유:
- **팀별 예산 관리**: 각 팀에 대해 별도의 예산을 설정할 수 있어, 각 팀의 책임과 지출을 명확히 할 수 있습니다.
- **자동 경고**: AWS Budgets는 비용 임계값이 초과될 경우 이메일 알림을 자동으로 발송할 수 있습니다. 이를 통해 팀은 미리 경고를 받을 수 있으며, 추가 비용이 발생하지 않도록 조치를 취할 수 있습니다.
- **비용 발생 없음**: AWS Budgets는 서비스 사용량에 따라 비용이 발생하지 않으므로 예산 관리와 경고를 추가 비용 없이 효율적으로 수행할 수 있습니다.

### **다른 옵션 설명:**

A. **AWS 비용 및 사용 보고서를 구성하여 Amazon S3 버킷에 일일 보고서를 보냅니다. Lambda 함수를 통해 알림을 받는 방법.**
   - 이 방법은 AWS Lambda를 사용하여 추가적인 비용을 발생시킬 수 있으며, 자동화 설정이 복잡할 수 있습니다.

B. **Amazon EventBridge를 사용하여 알림을 SQS로 보내는 방법.**
   - 이 방법은 EventBridge와 SQS를 설정하는 데 추가적인 관리 작업이 필요하고, 이로 인해 간접적으로 추가 비용이 발생할 수 있습니다.

C. **하나의 비용 예산을 만들어 모든 서비스에 대해 설정하는 방법.**
   - 모든 서비스에 대한 단일 예산으로 관리하게 되면, 개별 팀의 책임을 분리하기 어려워 각 팀의 예산을 효과적으로 관리할 수 없습니다.

따라서 **D** 옵션이 각 팀의 예산 관리와 경고 자동화를 가장 효과적으로 지원하는 솔루션입니다.


## 질문 #99 ++

한 회사가 Amazon S3에 정적 웹사이트를 호스팅합니다. 

Amazon CloudFront 배포판은 이 사이트를 글로벌 사용자에게 제공합니다. 
이 회사는 Managed-CachingDisabled CloudFront 캐시 정책을 사용합니다. 이 회사의 개발자는 Amazon S3의 파일을 새 정보로 자주 업데이트한다고 확인합니다.
사용자는 웹사이트가 처음 파일을 로드할 때 올바른 정보를 제공한다고 보고합니다. 그러나 사용자의 브라우저는 새로 고침 후 업데이트된 파일을 검색하지 않습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 권장해야 합니까?

A. S3 객체에 max-age=0인 Cache-Control 헤더 필드를 추가합니다. 가장 많이 투표된
B. CloudFront 캐시 정책을 Managed-CachingOptimized로 변경합니다.
C. S3 버킷 구성에서 버킷 버전 관리를 비활성화합니다.
D. CloudFront 구성에서 콘텐츠 압축을 활성화합니다.

이 문제를 해결하기 위해 권장하는 방법은 다음과 같습니다:

### **A. S3 객체에 max-age=0인 Cache-Control 헤더 필드를 추가합니다.**

#### 이유:
- **Cache-Control 헤더**: `max-age=0`을 설정하면 브라우저가 항상 서버에서 최신 정보를 확인하도록 강제할 수 있습니다. 이로 인해 브라우저가 캐시된 버전 대신 S3에서 직접 최신 파일을 요청하게 됩니다.
- **파일 업데이트**: S3의 파일이 자주 업데이트되므로, Cache-Control 헤더를 통해 브라우저가 업데이트된 정보를 항상 받아올 수 있도록 설정하는 것이 중요합니다.

### **다른 옵션 설명:**

B. **CloudFront 캐시 정책을 Managed-CachingOptimized로 변경합니다.**
   - 이 옵션은 캐시 최적화를 통해 성능을 개선할 수 있지만, 캐시 무효화의 문제를 직접적으로 해결하지는 않습니다.

C. **S3 버킷 구성에서 버킷 버전 관리를 비활성화합니다.**
   - 버전 관리를 비활성화하면 이전 버전의 객체에 대한 접근이 불가능해지므로, 문제를 해결하는 데 도움이 되지 않습니다.

D. **CloudFront 구성에서 콘텐츠 압축을 활성화합니다.**
   - 콘텐츠 압축은 페이지 로딩 속도를 개선할 수 있지만, 파일 업데이트가 반영되지 않는 문제와는 관련이 없습니다.

따라서 **A** 옵션이 가장 적합하며, 이를 통해 브라우저가 업데이트된 정보를 제대로 반영하도록 할 수 있습니다.


## 질문 #100 +

어떤 회사에서는 모든 Amazon EC2 인스턴스에 특정 태그 집합이 있어야 한다는 정책을 가지고 있습니다. 

EC2 인스턴스에 필수 태그가 없으면, 규정을 준수하지 않는 인스턴스를 종료해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?


A. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 모든 EC2 인스턴스 상태 변경 사항을 AWS Lambda 함수로 전송하여 각 인스턴스가 규정을 준수하는지 확인합니다. 규정을 준수하지 않는 인스턴스는 모두 종료합니다.
B. 모든 EC2 인스턴스 태그 요구 사항을 적용하는 IAM 정책을 만듭니다. 인스턴스에 필요한 태그가 없으면 정책은 비준수 인스턴스를 종료합니다.
C. 각 EC2 인스턴스가 규정을 준수하는지 확인하고 규정을 준수하지 않는 경우 인스턴스를 종료하는 AWS Lambda 함수를 만듭니다. Lambda 함수가 5분마다 호출되도록 예약합니다.
D. 필수 태그가 있는지 확인하기 위해 AWS Config 규칙을 만듭니다. EC2 인스턴스가 비준수인 경우 AWS Systems Manager Automation 문서를 호출하여 인스턴스를 종료합니다. 가장 많이 투표된

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **D. 필수 태그가 있는지 확인하기 위해 AWS Config 규칙을 만듭니다. EC2 인스턴스가 비준수인 경우 AWS Systems Manager Automation 문서를 호출하여 인스턴스를 종료합니다.**

#### 이유:
- **AWS Config**: AWS Config를 사용하면 리소스의 구성을 지속적으로 모니터링하고 평가할 수 있습니다. 이 서비스는 특정 규칙을 정의하고, 리소스가 이러한 규칙을 준수하는지 여부를 자동으로 검사할 수 있습니다.
- **비준수 인스턴스 종료**: EC2 인스턴스가 필수 태그를 충족하지 않는 경우 AWS Config가 이를 감지하고, AWS Systems Manager를 사용하여 자동으로 인스턴스를 종료하는 작업을 수행할 수 있습니다.
- **자동화 및 운영 효율성**: 이 접근 방식은 수동으로 인스턴스를 확인하고 종료할 필요가 없으므로 운영 효율성을 높이고 오류 가능성을 줄입니다.

### **다른 옵션 설명:**

A. **Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 모든 EC2 인스턴스 상태 변경 사항을 AWS Lambda 함수로 전송하여 각 인스턴스가 규정을 준수하는지 확인합니다. 규정을 준수하지 않는 인스턴스는 모두 종료합니다.**
   - 이 방법도 가능하지만, AWS Config가 제공하는 내장된 모니터링 및 평가 기능에 비해 수동적인 접근 방식이므로 운영 효율성이 떨어집니다.

B. **모든 EC2 인스턴스 태그 요구 사항을 적용하는 IAM 정책을 만듭니다. 인스턴스에 필요한 태그가 없으면 정책은 비준수 인스턴스를 종료합니다.**
   - IAM 정책은 리소스의 태그 요구 사항을 강제하는 데 사용될 수 없으며, 이미 생성된 인스턴스에 대해 실행할 수 없습니다.

C. **각 EC2 인스턴스가 규정을 준수하는지 확인하고 규정을 준수하지 않는 경우 인스턴스를 종료하는 AWS Lambda 함수를 만듭니다. Lambda 함수가 5분마다 호출되도록 예약합니다.**
   - 이 방법도 작동하지만, 수동으로 Lambda 함수를 예약하고 실행해야 하므로 운영 효율성이 떨어집니다.

결론적으로, **D** 옵션이 가장 적합하며 자동화된 규정 준수 관리를 통해 운영 효율성을 극대화할 수 있습니다.


## 질문 #101 +++

SysOps 관리자가 AWS Elastic Beanstalk로 웹 서버 애플리케이션을 관리하려고 합니다. 

Elastic Beanstalk 서비스는 항상 새로운 배포에 대한 전체 용량을 유지해야 합니다.
어떤 배포 정책이 이 요구 사항을 충족합니까? (두 가지를 선택하세요.)

A. 한꺼번에
B. 불변 
C. 재건
D. 롤링
E. 추가 배치로 롤링 

AWS Elastic Beanstalk에서 새로운 배포에 대한 전체 용량을 유지하기 위한 적절한 배포 정책은 다음 두 가지입니다:

### **B. 불변 (Immutable)**
- **설명**: 불변 배포 정책은 새로운 인스턴스를 임시로 생성하여 배포하는 방식입니다. 기존 인스턴스는 유지되고, 새로운 인스턴스가 준비되면 트래픽이 이 새로운 인스턴스로 전환됩니다. 이를 통해 배포 중에 서비스 가용성을 높일 수 있습니다.

### **D. 롤링 (Rolling)**
- **설명**: 롤링 배포 정책은 기존 인스턴스를 점진적으로 업데이트합니다. 즉, 일부 인스턴스를 업데이트하면서 나머지 인스턴스는 계속해서 서비스를 제공하게 됩니다. 이렇게 하면 배포 중에도 서비스 가용성을 유지할 수 있습니다.

### **기타 옵션 설명**:
A. **한꺼번에 (All-at-once)**:
- 모든 인스턴스를 동시에 업데이트하므로 가용성이 일시적으로 중단될 수 있습니다.

C. **재건 (Rebuild)**:
- 기존 인스턴스를 제거하고 새 인스턴스를 만드는 방식으로, 이 경우도 가용성이 중단될 수 있습니다.

E. **추가 배치로 롤링 (Rolling with additional batch)**:
- 롤링 배포 방식에 추가 인스턴스를 함께 배포하여 가용성을 높이는 방식입니다. 하지만 기존 인스턴스의 가용성을 반드시 유지한다고 보장할 수 없기 때문에 이 옵션은 항상 전체 용량을 유지하는 데 최선은 아닙니다.

결론적으로, **B (불변)** 및 **D (롤링)**이 요구 사항을 충족하는 최적의 선택입니다.

## 질문 #102 +++

한 회사에는 평균 CPU 사용률에 따라 확장되는 Amazon EC2 인스턴스의 Auto Scaling 그룹이 있습니다. 

Auto Scaling 그룹 이벤트 로그는 InsufficientInstanceCapacity 오류를 나타냅니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. 회사에서 사용 중인 인스턴스 유형을 변경합니다.
B. 다양한 가용성 영역에서 자동 크기 조정 그룹을 구성합니다. 
C. 다양한 Amazon Elastic Block Store(Amazon EBS) 볼륨 크기를 사용하도록 자동 크기 조정 그룹을 구성합니다.
D. 자동 크기 조정 그룹의 최대 크기를 늘립니다.
E. 인스턴스 서비스 할당량 증가를 요청합니다.

Amazon EC2 인스턴스의 Auto Scaling 그룹에서 **InsufficientInstanceCapacity** 오류를 해결하기 위한 두 가지 적절한 조치는 다음과 같습니다:

### **A. 회사에서 사용 중인 인스턴스 유형을 변경합니다.**
- **설명**: 현재 사용 중인 인스턴스 유형에 대한 가용성이 부족할 수 있습니다. 다른 인스턴스 유형으로 변경하면 해당 유형의 가용성이 더 높을 수 있으므로 오류를 해결하는 데 도움이 됩니다.

### **B. 다양한 가용성 영역에서 자동 크기 조정 그룹을 구성합니다.**
- **설명**: Auto Scaling 그룹을 여러 가용성 영역(AZ)으로 확장하면 인스턴스가 다양한 위치에 분산되어 가용성이 증가합니다. 이는 특정 AZ에서 인스턴스를 사용할 수 없는 경우에도 다른 AZ에서 인스턴스를 사용할 수 있게 해줍니다.

### **기타 옵션 설명**:
C. **다양한 Amazon Elastic Block Store(Amazon EBS) 볼륨 크기를 사용하도록 자동 크기 조정 그룹을 구성합니다.**
- EBS 볼륨 크기는 인스턴스의 가용성에 영향을 주지 않습니다. 이는 CPU 사용률 문제와 직접적인 연관이 없습니다.

D. **자동 크기 조정 그룹의 최대 크기를 늘립니다.**
- 최대 크기를 늘려도 현재 가용성이 부족하다면 문제를 해결할 수 없습니다. 오히려 다른 문제를 유발할 수 있습니다.

E. **인스턴스 서비스 할당량 증가를 요청합니다.**
- 서비스 할당량이 문제인 경우 유용할 수 있지만, 인스턴스 가용성 문제를 직접적으로 해결하지는 않습니다. 현재 상황에서 가용성을 높이는 즉각적인 조치로는 적합하지 않습니다.

결론적으로, **A (인스턴스 유형 변경)** 및 **B (다양한 가용성 영역 구성)**이 InsufficientInstanceCapacity 오류를 해결하는 데 가장 효과적인 조치입니다.


## 질문 #103 +++++

SysOps 관리자는 AWS Systems Manager Session Manager를 사용하여 Amazon EC2 인스턴스 그룹에 대한 액세스를 제어해야 합니다. 

EC2 인스턴스의 특정 태그는 이미 추가되었습니다.
관리자는 액세스를 제어하기 위해 어떤 추가 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. EC2 인스턴스에 액세스해야 하는 사용자 또는 그룹에 IAM 정책을 연결합니다. 
B. EC2 인스턴스에 대한 액세스를 제어하기 위해 IAM 역할을 연결합니다.
C. EC2 인스턴스에 대한 배치 그룹을 만들고 특정 태그를 추가합니다.
D. 서비스 계정을 생성하여 제어해야 하는 EC2 인스턴스에 연결합니다.
E. Condition 요소에 지정된 태그가 있는 모든 EC2 인스턴스에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다.

AWS Systems Manager Session Manager를 사용하여 Amazon EC2 인스턴스 그룹에 대한 액세스를 제어하기 위해 SysOps 관리자가 취해야 할 두 가지 추가 조치는 다음과 같습니다:

### **A. EC2 인스턴스에 액세스해야 하는 사용자 또는 그룹에 IAM 정책을 연결합니다.**
- **설명**: IAM 정책을 통해 특정 사용자나 그룹이 EC2 인스턴스에 접근할 수 있도록 권한을 부여합니다. 이를 통해 사용자가 Session Manager를 통해 인스턴스에 액세스할 수 있는 권한을 설정할 수 있습니다.

### **E. Condition 요소에 지정된 태그가 있는 모든 EC2 인스턴스에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다.**
- **설명**: IAM 정책의 Condition 요소를 사용하여 특정 태그를 가진 EC2 인스턴스에 대한 액세스를 세밀하게 제어할 수 있습니다. 이렇게 하면 지정된 태그가 있는 인스턴스에만 접근할 수 있게 되어, 보안성을 높이고 관리 효율성을 개선합니다.

### **기타 옵션 설명**:에서 계정 B의 역할을 맡을 Lambda 실행 역할을 만듭니
B. **EC2 인스턴스에 대한 액세스를 제어하기 위해 IAM 역할을 연결합니다.**
- IAM 역할은 인스턴스에 연결할 수 있지만, 사용자 액세스 제어와는 관련이 없습니다. Session Manager에서 액세스를 제어하는 데 직접적인 도움이 되지 않습니다.

C. **EC2 인스턴스에 대한 배치 그룹을 만들고 특정 태그를 추가합니다.**
- 배치 그룹은 EC2 인스턴스의 배치 방법을 정의하지만, 액세스 제어와는 직접적인 관련이 없습니다.

D. **서비스 계정을 생성하여 제어해야 하는 EC2 인스턴스에 연결합니다.**
- 서비스 계정은 Kubernetes와 관련된 개념으로, EC2 인스턴스에 직접 연결할 필요가 없습니다. 이 옵션은 현재 상황에 적합하지 않습니다.

결론적으로, **A (IAM 정책을 사용자 또는 그룹에 연결)** 및 **E (Condition 요소에 지정된 태그를 사용한 IAM 정책 생성)**가 EC2 인스턴스 그룹에 대한 액세스를 제어하는 데 가장 효과적인 조치입니다.


## 질문 #104 +++++

한 회사가 계정 A에 AWS Lambda 함수를 가지고 있습니다. 

Lambda 함수는 계정 B의 Amazon S3 버킷에 있는 객체를 읽어야 합니다. SysOps 관리자는 두 계정 모두에 해당 IAM 역할을 만들어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 계정 A에서 계정 B의 역할을 맡을 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다. 가장 많이 투표된
B. 계정 A에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 맡을 수 있는 역할을 만듭니다.
C. 계정 A에서 함수가 맡을 수 있는 역할을 만듭니다. 계정 B에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다.
D. 계정 A에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다. 계정 B에서 계정 A의 역할을 맡을 Lambda 실행 역할을 만듭니다.

계정 A의 AWS Lambda 함수가 계정 B의 Amazon S3 버킷에 있는 객체를 읽기 위해 필요한 IAM 역할을 설정하는 가장 효과적인 솔루션은 다음과 같습니다:

### **A. 계정 A에서 계정 B의 역할을 맡을 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다.**

#### **설명**:
1. **계정 A에서 Lambda 실행 역할 생성**:
   - 계정 A에 Lambda 함수를 실행하는 역할을 생성하고, 이 역할이 계정 B의 IAM 역할을 맡을 수 있는 권한을 부여합니다.

2. **계정 B에서 IAM 역할 생성**:
   - 계정 B에서 Lambda 함수가 S3 버킷에 액세스할 수 있도록 권한을 가진 IAM 역할을 생성합니다. 이 역할은 필요한 S3 읽기 권한을 포함해야 하며, `trust policy`를 설정하여 계정 A의 Lambda 함수가 이 역할을 맡을 수 있도록 합니다.

이 접근 방식을 통해 계정 A의 Lambda 함수는 계정 B의 S3 버킷에 대한 권한을 안전하게 사용하여 객체를 읽을 수 있습니다.

### **기타 옵션 설명**:
B. **계정 A에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 맡을 수 있는 역할을 만듭니다.**
- 이 옵션은 계정 A의 Lambda 함수가 계정 B의 IAM 역할을 맡는 것을 명시적으로 정의하지 않아, 필요한 권한이 없을 수 있습니다.

C. **계정 A에서 함수가 맡을 수 있는 역할을 만듭니다. 계정 B에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다.**
- 이 옵션은 계정 A의 Lambda 함수가 계정 B의 역할을 직접적으로 맡지 않기 때문에 요구 사항을 충족하지 않습니다.

D. **계정 A에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다. 계정 B에서 계정 A의 역할을 맡을 Lambda 실행 역할을 만듭니다.**
- 이 옵션은 잘못된 방향입니다. 계정 B에서 계정 A의 역할을 맡는 것은 필요하지 않으며, 계정 A의 Lambda가 S3에 액세스할 수 있도록 설정해야 합니다.

따라서 **A**가 가장 적합한 솔루션입니다.


#### 참고 
AWS Lambda 함수가 회사의 공유 AWS 계정에서 실행 중입니다. 이 함수는 회사의 개발 계정을 대상으로 하는 추가 ec2:DescribeInstances 작업을 수행해야 합니다. 개발자는 계정 전체에서 필요한 권한을 구성해야 합니다.

개발자는 최소 권한 원칙을 준수하기 위해 어떻게 권한을 구성해야 합니까?

B. 개발 계정에서 IAM 역할을 만듭니다. 역할에 ec2:DescribeInstances 권한을 추가합니다. 이 역할에 대한 공유 계정과 신뢰 관계를 설정합니다. iam:AssumeRole 권한을 추가하여 공유 계정에서 Lambda 함수 IAM 역할을 업데이트합니다.



## 질문 #105 +++++

AWS Lambda 함수가 하루에 여러 번 간헐적으로 실패합니다. 

SysOps 관리자는 지난 7일 동안 이 오류가 얼마나 자주 발생했는지 알아내야 합니다.
어떤 조치가 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족할까요?

A. Amazon Athena를 사용하여 Lambda 함수와 관련된 Amazon CloudWatch 로그를 쿼리합니다.
B. Amazon Athena를 사용하여 Lambda 함수와 연결된 AWS CloudTrail 로그를 쿼리합니다.
C. Amazon CloudWatch Logs Insights를 사용하여 연관된 Lambda 함수 로그를 쿼리합니다. 
D. Amazon OpenSearch Service(Amazon Elasticsearch Service)를 사용하여 Lambda 함수에 대한 Amazon CloudWatch 로그를 스트리밍합니다.


정답은 **C. Amazon CloudWatch Logs Insights를 사용하여 연관된 Lambda 함수 로그를 쿼리합니다.**

**이유:**
- **Amazon CloudWatch Logs Insights**는 CloudWatch 로그 그룹에 저장된 로그 데이터를 효율적으로 쿼리하고 분석할 수 있는 강력한 도구입니다. Lambda 함수의 로그는 기본적으로 CloudWatch Logs에 저장되므로, 바로 로그 데이터를 분석할 수 있습니다. 이를 통해 실패한 호출이나 오류 패턴을 쉽게 식별할 수 있으며, 간헐적으로 발생하는 문제를 조사하기에 적합합니다.
  
**다른 선택지 분석:**
- **A. Amazon Athena를 사용하여 Lambda 함수와 관련된 Amazon CloudWatch 로그를 쿼리**는 가능하나, 데이터를 Athena로 전송하고 스키마를 정의하는 추가적인 작업이 필요해 운영적으로 복잡해집니다.
- **B. Amazon Athena를 사용하여 Lambda 함수와 연결된 AWS CloudTrail 로그를 쿼리**는 Lambda 호출과 관련된 이벤트를 추적할 수 있지만, CloudTrail은 주로 API 호출 로그를 수집하므로 함수 실행 중 발생한 세부 오류를 찾는 데는 적합하지 않습니다.
- **D. Amazon OpenSearch Service를 사용하여 로그를 스트리밍**하는 것은 복잡한 설정이 필요하며, 간헐적 오류 조사 목적으로는 과도한 해결책일 수 있습니다.



## 질문 #106 +++

한 회사가 Amazon CloudFront를 사용하여 웹 애플리케이션의 정적 콘텐츠를 사용자에게 제공하고 있습니다. 

CloudFront 배포는 기존 온프레미스 웹사이트를 사용자 지정 오리진으로 사용합니다.
이 회사는 CloudFront와 오리진 서버 간에 TLS를 사용해야 합니다. 이 구성은 몇 달 동안 예상대로 작동했습니다. 
그러나 이제 사용자는 CloudFront 배포의 콘텐츠가 포함된 웹 페이지를 볼 때 HTTP 502(잘못된 게이트웨이) 오류를 경험하고 있습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 원본 사이트의 인증서 만료일을 검사합니다. 인증서가 만료되지 않았는지 확인합니다. 필요한 경우 인증서를 교체합니다. 가장 많이 투표된
B. 원본 사이트의 인증서에서 호스트 이름을 검사합니다. 호스트 이름이 CloudFront 배포의 호스트 이름 중 하나와 일치하는지 확인합니다. 필요한 경우 인증서를 교체합니다.
C. 원본 서버와 연관된 방화벽 규칙을 검사합니다. 인터넷에서 들어오는 트래픽에 대해 포트 443이 열려 있는지 확인합니다. 필요한 경우 인바운드 규칙을 만듭니다.
D. CloudFront 배포와 연관된 네트워크 ACL 규칙을 검토합니다. 포트 443이 오리진 서버로의 아웃바운드 트래픽에 열려 있는지 확인합니다. 필요한 경우 아웃바운드 규칙을 만듭니다.



정답은 **A. 원본 사이트의 인증서 만료일을 검사합니다. 인증서가 만료되지 않았는지 확인합니다. 필요한 경우 인증서를 교체합니다.**

**이유:**
- **HTTP 502(잘못된 게이트웨이) 오류**는 CloudFront가 사용자 지정 오리진 서버에 연결할 수 없을 때 발생하는 일반적인 오류입니다. CloudFront와 오리진 서버 간의 TLS 연결에서 발생하는 문제는 자주 인증서 만료 또는 잘못된 인증서로 인해 발생할 수 있습니다. 인증서가 만료되면 CloudFront가 오리진 서버와의 TLS 연결을 설정할 수 없으므로 502 오류가 발생할 수 있습니다. 따라서 인증서의 만료 여부를 먼저 확인하는 것이 합리적입니다.

**다른 선택지 분석:**
- **B. 호스트 이름 검사**는 중요할 수 있지만, 몇 달 동안 문제없이 작동했던 시스템에서 새로운 호스트 이름 불일치는 가능성이 낮습니다.
- **C. 원본 서버의 방화벽 규칙 검사**는 TLS 연결이 이미 설정되어 잘 작동하고 있었다면 문제가 되지 않았을 가능성이 큽니다.
- **D. 네트워크 ACL 규칙 검토**는 문제가 발생한 원인일 가능성이 낮습니다. ACL 규칙은 일반적으로 설정 후 자주 변경되지 않으며, 몇 달 동안 문제없이 동작했다면 다른 원인을 먼저 확인하는 것이 바람직합니다.
- 


## 질문 #107

Amazon CloudFront 배포판에는 단일 Amazon S3 버킷이 원본으로 있습니다. 

SysOps 관리자는 사용자가 CloudFront 엔드포인트의 요청을 통해서만 S3 버킷에 액세스할 수 있도록 해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. S3 버킷에서 S3 Block Public Access를 구성합니다. CloudFront 배포에서만 GetObject 작업을 허용하도록 S3 버킷 정책을 업데이트합니다.
B. CloudFront 배포에서 Origin Shield를 구성합니다. CloudFront 오리진을 업데이트하여 사용자 지정 Origin_Shield 헤더를 포함합니다.
C. 원본 액세스 ID(OAI)를 만듭니다. OAI를 CloudFront 배포에 할당합니다. S3 버킷 정책을 업데이트하여 OAI에 대한 액세스를 제한합니다. 가장 많이 투표된
D. 원본 액세스 ID(OAI)를 만듭니다. S3 버킷에 OAI를 할당합니다. CloudFront 원본을 업데이트하여 OAI 값이 있는 사용자 지정 원본 헤더를 포함합니다.

정답은 **C. 원본 액세스 ID(OAI)를 만듭니다. OAI를 CloudFront 배포에 할당합니다. S3 버킷 정책을 업데이트하여 OAI에 대한 액세스를 제한합니다.**

**이유:**
- **원본 액세스 ID(OAI)**는 CloudFront 배포를 통해서만 Amazon S3 버킷에 액세스할 수 있도록 제한하는 데 사용됩니다. OAI를 생성하고 CloudFront에 할당한 후, S3 버킷 정책을 OAI에 맞게 설정하면 S3 버킷에 직접적인 공용 액세스를 차단하고 CloudFront를 통해서만 콘텐츠를 제공할 수 있게 됩니다.

**다른 선택지 분석:**
- **A. S3 Block Public Access를 구성**하는 것은 S3 버킷의 공용 액세스를 차단하는 데 도움이 되지만, CloudFront를 통해서만 액세스하는 기능을 구현하려면 OAI를 사용해야 합니다.
- **B. Origin Shield**는 캐싱 성능을 개선하는 기능으로, S3 버킷에 대한 접근 제한과는 관련이 없습니다.
- **D. OAI를 사용한 사용자 지정 원본 헤더**는 잘못된 방법입니다. OAI를 S3 버킷에 직접 할당하고, CloudFront 배포에 OAI를 적용하는 것이 표준적인 방법입니다.

## 질문 #108

SysOps 관리자가 Amazon RDS for PostgreSQL DB 인스턴스에 대한 솔루션을 설계하고 있습니다. 

데이터베이스 자격 증명은 매월 저장하고 순환해야 합니다. DB 인스턴스에 연결하는 애플리케이션은 가변적인 클라이언트 연결로 쓰기 집약적 트래픽을 전송하며, 이는 때때로 단시간에 크게 증가합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 선택해야 합니까?

A. AWS Key Management Service(AWS KMS)를 구성하여 DB 인스턴스의 키를 자동으로 순환합니다. RDS Proxy를 사용하여 데이터베이스 연결 증가를 처리합니다.
B. AWS Key Management Service(AWS KMS)를 구성하여 DB 인스턴스의 키를 자동으로 순환합니다. RDS 읽기 복제본을 사용하여 데이터베이스 연결 증가를 처리합니다.
C. AWS Secrets Manager를 구성하여 DB 인스턴스의 자격 증명을 자동으로 회전합니다. RDS Proxy를 사용하여 데이터베이스 연결 증가를 처리합니다. 가장 많이 투표된
D. AWS Secrets Manager를 구성하여 DB 인스턴스의 자격 증명을 자동으로 순환합니다. RDS 읽기 복제본을 사용하여 데이터베이스 연결 증가를 처리합니다.

정답은 **C. AWS Secrets Manager를 구성하여 DB 인스턴스의 자격 증명을 자동으로 회전합니다. RDS Proxy를 사용하여 데이터베이스 연결 증가를 처리합니다.**

**이유:**
- **AWS Secrets Manager**는 데이터베이스 자격 증명을 안전하게 저장하고 자동으로 회전할 수 있는 기능을 제공합니다. 매월 자격 증명을 순환하는 요구 사항을 충족하기에 적합합니다.
- **RDS Proxy**는 애플리케이션의 가변적인 연결을 관리하고, 데이터베이스에 대한 연결 풀링을 통해 갑작스러운 트래픽 급증을 효율적으로 처리할 수 있는 기능을 제공합니다. 이는 특히 쓰기 집약적인 트래픽을 처리할 때 도움이 됩니다.

**다른 선택지 분석:**
- **A. AWS KMS**는 데이터 암호화 키를 관리하지만, 자격 증명 회전에는 적합하지 않습니다. 또한 RDS Proxy를 사용하는 것은 맞지만 KMS는 자격 증명 회전 요구 사항을 해결하지 못합니다.
- **B. KMS와 RDS 읽기 복제본**은 자격 증명 관리와 쓰기 트래픽 처리에는 적합하지 않습니다. 읽기 복제본은 읽기 성능을 향상시키지만, 쓰기 집약적 트래픽에는 적합하지 않습니다.
- **D. Secrets Manager와 RDS 읽기 복제본**의 조합은 자격 증명 회전에는 맞지만, 쓰기 집약적 트래픽 처리에는 적합하지 않습니다. 읽기 복제본은 쓰기 성능을 향상시키지 않습니다.
- 

## 질문 #109 +

회사는 언제든지 완료할 수 있는 작업의 비용을 줄이고자 합니다. 

현재 작업은 여러 Amazon EC2 On-Demand 인스턴스를 사용하여 실행되고 있으며 작업을 완료하는 데 약 2시간도 걸리지 않습니다. 어떤 이유로든 작업이 중단되면 처음부터 다시 시작해야 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. 작업에 대한 예약 인스턴스를 구매합니다.
B. 해당 작업에 대한 일회성 스팟 인스턴스에 대한 요청을 제출합니다.
C. 작업에 대해 정의된 기간으로 스팟 인스턴스에 대한 요청을 제출합니다. 가장 많이 투표된
D. 작업에 대해 온디맨드 인스턴스와 스팟 인스턴스를 혼합하여 사용합니다.

정답은 **C. 작업에 대해 정의된 기간으로 스팟 인스턴스에 대한 요청을 제출합니다.**

**이유:**
- **정의된 기간 스팟 인스턴스**는 일정 시간 동안 인스턴스가 중단되지 않을 것을 보장받으면서도 비용 절감을 할 수 있는 옵션입니다. 이 회사의 작업은 약 2시간이 걸리며, 작업이 중단되면 처음부터 다시 시작해야 하므로, 중단 위험이 없는 기간 정의된 스팟 인스턴스가 가장 적합한 선택입니다. 이는 **비용 효율적**이면서도 **작업 중단을 방지**할 수 있는 좋은 방법입니다.

**다른 선택지 분석:**
- **A. 예약 인스턴스**는 장기적인 사용 시 비용 절감에 유리하지만, 짧은 작업에 대해서는 비용 효율적이지 않습니다.
- **B. 일회성 스팟 인스턴스**는 중단될 수 있어 작업이 중간에 실패하면 다시 시작해야 하기 때문에 이 작업에는 적합하지 않습니다.
- **D. 온디맨드 인스턴스와 스팟 인스턴스를 혼합**하는 것은 중단 위험을 줄일 수 있지만, 스팟 인스턴스가 중단될 수 있는 가능성을 여전히 감안해야 하므로 확실한 비용 절감과 중단 방지를 보장하지 않습니다.
- 

## 질문 #110 +++

환경은 100개의 Amazon EC2 Windows 인스턴스로 구성되어 있습니다. 

Amazon CloudWatch 에이전트는 모든 EC2 인스턴스에 배포되어 실행 중이며, 로그 파일을 캡처하기 위한 기준 구성 파일이 있습니다. 
인스턴스 50개에 있는 DHCP 로그 파일을 캡처해야 하는 새로운 요구 사항이 있습니다.
이 새로운 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. DHCP 로그를 캡처하기 위해 추가 CloudWatch 에이전트 구성 파일을 만듭니다. AWS Systems Manager Run Command를 사용하여 각 EC2 인스턴스에서 CloudWatch 에이전트를 다시 시작하고 append-config 옵션을 사용하여 추가 구성 파일을 적용합니다. 가장 많이 투표된
B. 관리자 권한으로 각 EC2 인스턴스에 로그인합니다. 필요한 기준 로그 파일과 DHCP 로그 파일을 CloudWatch에 푸시하는 PowerShell 스크립트를 만듭니다.
C. 각 EC2 인스턴스에서 CloudWatch 에이전트 구성 파일 마법사를 실행합니다. 기준 로그 파일이 포함되어 있는지 확인하고 마법사 생성 프로세스 중에 DHCP 로그 파일을 추가합니다.
D. 각 EC2 인스턴스에서 CloudWatch 에이전트 구성 파일 마법사를 실행하고 고급 세부 정보 수준을 선택합니다. 이렇게 하면 운영 체제 로그 파일이 캡처됩니다.


정답은 **A. DHCP 로그를 캡처하기 위해 추가 CloudWatch 에이전트 구성 파일을 만듭니다. AWS Systems Manager Run Command를 사용하여 각 EC2 인스턴스에서 CloudWatch 에이전트를 다시 시작하고 append-config 옵션을 사용하여 추가 구성 파일을 적용합니다.**

**이유:**
- **AWS Systems Manager Run Command**는 중앙에서 여러 인스턴스에 명령을 실행할 수 있는 기능을 제공합니다. 이를 통해 50개의 EC2 인스턴스에 대해 DHCP 로그 파일을 추가할 수 있으며, 각 인스턴스에 수동으로 로그인할 필요 없이 효율적으로 에이전트를 다시 시작할 수 있습니다.
- **append-config 옵션**을 사용하면 기존 CloudWatch 에이전트 구성을 유지하면서도 추가적인 로그 파일을 캡처하는 설정을 적용할 수 있습니다. 이는 운영 효율성을 극대화하는 방법입니다.

**다른 선택지 분석:**
- **B. PowerShell 스크립트**를 각 인스턴스에 배포하는 것은 수작업이 많아 운영 효율성이 떨어집니다.
- **C. 구성 파일 마법사를 수동으로 실행**하는 것은 시간이 많이 소요되며, 50개 인스턴스에서 수동 작업이 필요하므로 비효율적입니다.
- **D. 고급 세부 정보 수준 선택**은 DHCP 로그 파일을 특정하지 않으며, 운영 시스템의 모든 로그 파일을 캡처하게 되어 불필요한 데이터가 전송될 수 있습니다.
- 

## 질문: 111 : +

한 회사가 프로덕션 계정에 Amazon EC2 인스턴스 10개를 보유하고 있습니다. 

SysOps 관리자는 EC2 인스턴스 상태가 변경될 때마다 이메일 알림이 관리자에게 전송되도록 해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. EC2 인스턴스 상태가 변경될 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon Route 53 단순 라우팅 정책을 구성합니다. 그러면 이 SNS 토픽이 이메일 구독자에게 알림을 보냅니다.
B. EC2 인스턴스 상태가 변경될 때 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Amazon Route 53 단순 라우팅 정책을 구성합니다. 그런 다음 이 SQS 대기열은 이메일 구독자에게 알림을 보냅니다.
C. EC2 인스턴스 상태가 변경될 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 그러면 이 SNS 토픽이 이메일 구독자에게 알림을 보냅니다.
D. EC2 인스턴스 상태가 변경될 때 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 그런 다음 이 SQS 대기열은 이메일 구독자에게 알림을 보냅니다.


정답은 **C. EC2 인스턴스 상태가 변경될 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 그러면 이 SNS 토픽이 이메일 구독자에게 알림을 보냅니다.**

**이유:**
- **Amazon EventBridge(Amazon CloudWatch Events)**는 EC2 인스턴스의 상태 변경 이벤트(예: 시작, 중지, 재부팅 등)를 감지할 수 있습니다. EventBridge 규칙을 사용하여 상태 변경 이벤트가 발생할 때 특정 작업을 수행하도록 설정할 수 있습니다.
- **Amazon SNS**는 이벤트 발생 시 이메일 알림을 전송할 수 있는 서비스입니다. EventBridge 규칙이 EC2 상태 변경 이벤트를 감지하고, 해당 이벤트에 대한 알림을 SNS 토픽에 게시함으로써 이메일 구독자에게 전송할 수 있습니다.
  
**다른 선택지 분석:**
- **A와 B. Amazon Route 53 단순 라우팅 정책**은 EC2 상태 변경과 관련이 없습니다. Route 53은 DNS 관련 서비스를 제공하며, 인스턴스 상태와는 관련이 없습니다.
- **D. Amazon SQS 대기열을 사용**하는 것은 이메일 전송보다는 메시지 큐잉을 위한 방식으로, 이메일 구독자에게 직접적으로 알림을 보내기에는 적합하지 않습니다. SQS는 메시지를 큐에 저장하고 처리해야 하므로 불필요한 복잡성을 추가하게 됩니다.


## 질문: 112 ++

한 회사에는 Elastic Load Balancer 뒤에 있는 Amazon EC2 인스턴스 플릿에서 실행되는 애플리케이션이 있습니다. 

인스턴스는 Auto Scaling 그룹에서 실행됩니다. 애플리케이션의 성능은 매일 대부분 일관되게 유지됩니다. 그러나 사용자 트래픽이 증가하면 매일 같은 4시간 동안 성능이 느려집니다.
이 문제를 해결할 가장 운영 효율적인 솔루션은 무엇입니까?

1. 가중치 라우팅 정책을 사용하여 Auto Scaling 그룹 앞에 두 번째 Elastic Load Balancer를 구성합니다.
2. 사용자 트래픽 증가를 지원하기 위해 더 큰 인스턴스 유형에서 실행되도록 EC2 인스턴스 플릿을 구성합니다.
3. 사용자 트래픽이 증가하기 직전에 EC2 인스턴스 수를 확장하기 위해 예약된 확장 작업을 만듭니다.
4. 사용자 트래픽 증가에 대응하기 위해 Auto Scaling 그룹에 몇 개의 EC2 인스턴스를 수동으로 추가합니다.

가장 운영 효율적인 솔루션은 **3. 사용자 트래픽이 증가하기 직전에 EC2 인스턴스 수를 확장하기 위해 예약된 확장 작업을 만듭니다.**

**이유:**
- **예약된 확장 작업**은 트래픽이 예상되는 시간에 맞춰 Auto Scaling 그룹의 인스턴스 수를 미리 확장하여, 트래픽 증가로 인한 성능 저하를 방지할 수 있는 효율적인 방법입니다. 매일 같은 시간에 트래픽 증가가 발생하므로, 이 시간대에 맞춰 EC2 인스턴스 수를 증가시키면 성능 문제를 예방할 수 있습니다.
- 이 방법은 **자동화된 확장**으로 관리 부담을 줄이면서 비용 효율성을 유지할 수 있으며, 트래픽 패턴이 반복될 때 적합합니다.

**다른 선택지 분석:**
1. **가중치 라우팅 정책을 사용한 두 번째 ELB 구성**은 복잡도를 높이지만 트래픽 문제를 해결하지는 못합니다.
2. **더 큰 인스턴스 유형으로 전환**하면 비용이 증가할 수 있으며, 일시적인 성능 문제 해결에 적합하지 않습니다.
4. **EC2 인스턴스 수동 추가**는 매일 트래픽 증가에 대응해야 하므로 비효율적이고 운영 부담이 큽니다.


## 질문: 113  +++++

한 회사가 단일 AWS 리전의 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 

이 애플리케이션은 비 HTTP TCP 트래픽과 HTTP 트래픽에 대한 지원이 필요합니다.
이 회사는 AWS 네트워크를 활용하여 낮은 지연 시간으로 콘텐츠를 제공하려고 합니다. 또한 이 회사는 Elastic Load Balancer가 있는 Auto Scaling 그룹을 구현하려고 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?

1. Application Load Balancer(ALB)로 자동 확장 그룹을 만듭니다. ALB를 원본으로 하는 Amazon CloudFront 배포를 추가합니다.
2. Application Load Balancer(ALB)로 자동 스케일링 그룹을 만듭니다. ALB를 엔드포인트로 사용하여 AWS Global Accelerator로 가속기를 추가합니다.
3. 네트워크 로드 밸런서(NLB)로 자동 확장 그룹을 만듭니다. NLB를 원본으로 하는 Amazon CloudFront 배포를 추가합니다.
4. 네트워크 로드 밸런서(NLB)로 자동 스케일링 그룹을 만듭니다. NLB를 엔드포인트로 사용하여 AWS Global Accelerator로 가속기를 추가합니다.

가장 적합한 솔루션은 
**4. 네트워크 로드 밸런서(NLB)로 자동 스케일링 그룹을 만듭니다. NLB를 엔드포인트로 사용하여 AWS Global Accelerator로 가속기를 추가합니다.**

**이유:**
- **네트워크 로드 밸런서(NLB)**는 비 HTTP TCP 트래픽과 HTTP 트래픽 모두를 지원하며, 높은 처리량과 낮은 지연 시간을 제공합니다. NLB는 TCP, UDP 및 기타 비 HTTP 프로토콜을 처리할 수 있기 때문에 비 HTTP 트래픽을 다루는 데 적합합니다.
- **AWS Global Accelerator**는 사용자로부터의 트래픽을 AWS 글로벌 네트워크를 통해 라우팅하여 지연 시간을 줄이고 성능을 향상시킬 수 있습니다. 이를 통해 전 세계 사용자에게 빠르게 콘텐츠를 제공할 수 있습니다.
- NLB와 **Global Accelerator**의 조합은 비 HTTP 트래픽 및 HTTP 트래픽에 대한 최적의 지연 시간을 제공하는 동시에, Auto Scaling 그룹을 사용하여 트래픽 증가에 대응할 수 있는 유연성도 확보할 수 있습니다.

**다른 선택지 분석:**
1. **ALB와 CloudFront**는 HTTP/HTTPS 트래픽에 최적화되어 있지만, 비 HTTP 트래픽을 지원하지 않습니다.
2. **ALB와 Global Accelerator**는 HTTP/HTTPS 트래픽에 적합하지만, 비 HTTP 트래픽을 처리하기에는 적합하지 않습니다.
3. **NLB와 CloudFront**는 비 HTTP 트래픽을 지원하지만, CloudFront는 주로 HTTP 기반 콘텐츠를 캐싱하는 데 사용됩니다. 비 HTTP 트래픽에는 적합하지 않습니다.


## 질문: 114

SysOps 관리자는 암호화된 Amazon Machine Image(AMI)를 배포하는 데 사용되는 AWS CloudFormation 템플릿을 가지고 있습니다. 

CloudFormation 템플릿은 두 번째 계정에서 사용되므로 SysOps 관리자는 암호화된 AMI를 두 번째 계정에 복사합니다. 두 번째 계정에서 새 CloudFormation 스택을 시작하면 실패합니다.
SysOps 관리자는 문제를 해결하기 위해 어떤 조치를 취해야 합니까?

1. AMI 권한을 변경하여 AMI를 공개로 표시합니다.
2. 소스 계정에서 AMI 등록을 해제합니다.
3. 대상 계정의 AWS Key Management Service(AWS KMS) 키로 대상 AMI를 다시 암호화합니다.
4. 대상 계정의 AMI ID로 CloudFormation 템플릿을 업데이트합니다.

가장 적합한 솔루션은 **4. 대상 계정의 AMI ID로 CloudFormation 템플릿을 업데이트합니다.**

**이유:**
- 암호화된 AMI를 복사할 때, 복사된 AMI는 새로 생성된 AMI ID를 갖습니다. 두 번째 계정에서 CloudFormation 스택을 생성하려면, 해당 계정의 AMI ID를 사용해야 합니다.
- 따라서, 원본 CloudFormation 템플릿에 있는 소스 계정의 AMI ID를 두 번째 계정의 새 AMI ID로 **업데이트**해야 스택 생성이 성공할 수 있습니다.

**다른 선택지 분석:**
1. **AMI를 공개로 표시**하는 것은 보안 문제가 될 수 있고, 암호화된 AMI에서는 필요하지 않습니다.
2. **소스 계정에서 AMI 등록 해제**는 문제 해결과 관련이 없으며, 오히려 AMI를 사용할 수 없게 만들 수 있습니다.
3. **AWS KMS 키로 대상 AMI를 다시 암호화**하는 것은 필요하지 않습니다. 이미 두 번째 계정으로 복사된 AMI가 암호화된 상태로 존재하므로, 키 관련 문제는 아닙니다.4. 

## 질문: 115 +++

회사의 SysOps 관리자가 표준 Amazon Linux 2 Amazon Machine Image(AMI)를 사용하여 4개의 새로운 Amazon EC2 인스턴스를 배포합니다. 

회사는 AWS Systems Manager를 사용하여 인스턴스를 관리할 수 있어야 합니다. SysOps 관리자는 인스턴스가 Systems Manager 콘솔에 나타나지 않는다는 것을 알아챘습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1. SSH를 사용하여 각 인스턴스에 연결합니다. 각 인스턴스에 Systems Manager Agent를 설치합니다. 인스턴스가 시작될 때 Systems Manager Agent가 자동으로 시작되도록 구성합니다.
2. AWS Certificate Manager(ACM)를 사용하여 TLS 인증서를 만듭니다. 인증서를 각 인스턴스로 가져옵니다. Systems Manager Agent를 구성하여 보안 통신에 TLS 인증서를 사용합니다.
3. SSH를 사용하여 각 인스턴스에 연결합니다. ssm-user 계정을 만듭니다. ssm-user 계정을 /etc/sudoers.d 디렉토리에 추가합니다.
4. 인스턴스에 IAM 인스턴스 프로필을 연결합니다. 인스턴스 프로필에 AmazonSSMManagedInstanceCore 정책이 포함되어 있는지 확인합니다.

가장 적합한 솔루션은 
**4. 인스턴스에 IAM 인스턴스 프로필을 연결합니다. 인스턴스 프로필에 AmazonSSMManagedInstanceCore 정책이 포함되어 있는지 확인합니다.**

**이유:**
- **AWS Systems Manager**는 인스턴스가 AWS 계정에 등록되고 관리될 수 있도록 IAM 역할(인스턴스 프로필)을 통해 권한을 부여받아야 합니다. `AmazonSSMManagedInstanceCore` 정책은 Systems Manager의 필수 권한을 제공하며, 이 정책이 있는 IAM 인스턴스 프로필이 EC2 인스턴스에 연결되어 있어야 합니다.
- 또한, EC2 인스턴스에 **Systems Manager Agent (SSM Agent)**가 기본적으로 설치되어 있어야 하며, 표준 Amazon Linux 2 AMI에는 SSM Agent가 미리 설치되어 있습니다. 하지만 IAM 인스턴스 프로필이 없다면 Systems Manager 콘솔에 나타나지 않습니다.

**다른 선택지 분석:**
1. **SSM Agent를 설치**하는 것은 필요하지 않습니다. Amazon Linux 2 AMI에는 기본적으로 설치되어 있으므로, 이 방법은 비효율적입니다.
2. **AWS Certificate Manager(ACM)**와 TLS 인증서는 Systems Manager와의 통신과 관련이 없으며, 이 문제 해결에 필요하지 않습니다.
3. **ssm-user 계정을 만드는 것**은 SSM 기능과는 관련이 없으며, IAM 인스턴스 프로필을 통해 권한을 부여하는 것이 적절합니다.


## 질문: 116 +

SysOps 관리자가 Amazon CloudFront 웹 배포, Application Load Balancer(ALB), Amazon RDS, Amazon EC2를 VPC에 사용하여 웹 애플리케이션을 유지 관리하고 있습니다. 

모든 서비스에서 로깅이 활성화되어 있습니다. 관리자는 웹 애플리케이션의 HTTP Layer 7 상태 코드를 조사해야 합니다.
어떤 로그 소스에 상태 코드가 포함되어 있습니까? (두 가지를 선택하세요.)

1. VPC 흐름 로그
2. AWS CloudTrail 로그
3. ALB 액세스 로그
4. CloudFront 액세스 권한
5. RDS 로그

웹 애플리케이션의 HTTP Layer 7 상태 코드를 조사하기 위해 다음 두 가지 로그 소스를 선택해야 합니다:

**3. ALB 액세스 로그**  
**4. CloudFront 액세스 로그**

### 이유:
- **ALB 액세스 로그**: Application Load Balancer의 액세스 로그에는 HTTP 요청에 대한 상태 코드가 포함되어 있습니다. 각 요청의 처리 결과를 반영하는 상태 코드를 확인할 수 있습니다.

- **CloudFront 액세스 로그**: Amazon CloudFront의 액세스 로그 역시 요청에 대한 상태 코드를 포함하고 있습니다. 이는 CloudFront 배포를 통해 서비스되는 모든 HTTP 요청에 대한 정보를 제공합니다.

### 다른 선택지 분석:
1. **VPC 흐름 로그**: VPC 흐름 로그는 네트워크 트래픽에 대한 메타데이터(예: 소스 및 대상 IP, 포트 번호, 프로토콜 등)를 포함하지만, HTTP 상태 코드는 포함하지 않습니다.
2. **AWS CloudTrail 로그**: AWS CloudTrail 로그는 AWS 리소스에 대한 API 호출 기록을 저장하며, HTTP 상태 코드를 포함하지 않습니다.
5. **RDS 로그**: Amazon RDS 로그는 데이터베이스와 관련된 로그로, HTTP 상태 코드와는 관련이 없습니다.



## 질문: 117 +

한 회사가 AWS 계정 내에서 IAM CreateUser API 호출이 이루어질 때 이메일로 알림을 받고 싶어합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. 이벤트 소스로 AWS CloudTrail을, 이벤트 패턴에 대한 특정 API 호출로 IAM CreateUser를 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
2. 이벤트 소스로 Amazon CloudSearch를 지정하고 이벤트 패턴에 대한 특정 API 호출로 IAM CreateUser를 지정하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
3. AWS IAM Access Analyzer를 이벤트 소스로, IAM CreateUser를 이벤트 패턴에 대한 특정 API 호출로 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
4. 이메일 구독을 통해 Amazon Simple Notification Service(Amazon SNS) 주제를 이벤트 대상으로 사용합니다.
5. 이메일 구독을 통해 Amazon Simple Email Service(Amazon SES) 알림을 이벤트 대상으로 사용합니다.

이 요구 사항을 충족하기 위해 선택해야 할 두 가지 조치는 다음과 같습니다:

**1. 이벤트 소스로 AWS CloudTrail을, 이벤트 패턴에 대한 특정 API 호출로 IAM CreateUser를 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.**  
**4. 이메일 구독을 통해 Amazon Simple Notification Service(Amazon SNS) 주제를 이벤트 대상으로 사용합니다.**

### 이유:

1. **AWS CloudTrail을 이벤트 소스로 사용**: AWS CloudTrail은 AWS 계정 내의 API 호출을 기록하고, 이를 EventBridge와 통합하여 특정 이벤트를 감지할 수 있습니다. IAM `CreateUser` API 호출이 이루어질 때 이 이벤트를 감지하는 규칙을 생성할 수 있습니다.

4. **Amazon SNS 주제를 이벤트 대상으로 사용**: EventBridge 규칙을 사용하여 감지한 `CreateUser` 이벤트를 Amazon SNS 주제로 전송할 수 있습니다. SNS 주제에 이메일 구독자를 추가하면, 해당 이벤트가 발생할 때마다 이메일로 알림을 받을 수 있습니다.

### 다른 선택지 분석:

2. **Amazon CloudSearch를 이벤트 소스로 지정하는 것은 올바르지 않습니다.** CloudSearch는 검색 엔진 서비스이며 이벤트를 생성하는 데 사용되지 않습니다.

3. **AWS IAM Access Analyzer를 이벤트 소스로 사용하는 것은 적절하지 않습니다.** Access Analyzer는 IAM 정책을 분석하는 도구이며 API 호출에 대한 이벤트를 생성하지 않습니다.

5. **Amazon SES를 이벤트 대상으로 사용하기는 적절하지 않습니다.** SES는 이메일 발송 서비스이지만, EventBridge와 직접 연결되어 이벤트를 수신할 수 없습니다. SNS를 통해 이메일 알림을 처리하는 것이 더 일반적입니다.



## 질문: 118 ++

데이터베이스가 Amazon RDS Multi-AZ DB 인스턴스에서 실행 중입니다. 

최근 보안 감사에서 데이터베이스가 암호화되지 않았기 때문에 규정을 준수하지 않는 것으로 나타났습니다.
어떤 접근 방식으로 암호화 요구 사항을 해결할 수 있을까요?

1. RDS 콘솔에 로그인하고 암호화 상자를 선택하여 데이터베이스를 암호화합니다.
2. 새로운 암호화된 Amazon EBS 볼륨을 생성하여 인스턴스에 연결합니다.
3. 보조 가용성 영역의 대기 복제본을 암호화하고 기본 인스턴스로 승격시킵니다.
4. RDS 인스턴스의 스냅샷을 찍고, 스냅샷을 복사하고 암호화한 다음, 새 RDS 인스턴스로 복원합니다.

데이터베이스의 암호화 요구 사항을 해결하기 위한 적절한 접근 방식은 
**4. RDS 인스턴스의 스냅샷을 찍고, 스냅샷을 복사하고 암호화한 다음, 새 RDS 인스턴스로 복원합니다.**입니다.

### 이유:
- **RDS 인스턴스의 스냅샷을 찍고 복사하는 과정**에서 암호화 옵션을 선택할 수 있습니다. 이를 통해 기존 RDS 인스턴스를 유지하면서 암호화된 새로운 인스턴스를 생성할 수 있습니다.
- **새 RDS 인스턴스로 복원**하는 과정에서 Multi-AZ 설정도 유지할 수 있으므로 가용성 요구 사항도 충족됩니다.

### 다른 선택지 분석:
1. **RDS 콘솔에 로그인하고 암호화 상자를 선택하여 데이터베이스를 암호화하는 것은 불가능합니다.** RDS 인스턴스를 생성할 때만 암호화를 설정할 수 있으며, 기존 인스턴스에 대해 직접적으로 암호화를 활성화할 수는 없습니다.
  
2. **새로운 암호화된 Amazon EBS 볼륨을 생성하여 인스턴스에 연결하는 것은 RDS와 관련이 없습니다.** Amazon RDS는 EBS 볼륨을 관리하며 사용자가 EBS 볼륨을 직접 연결하거나 수정할 수 없습니다.

3. **보조 가용성 영역의 대기 복제본을 암호화하는 방법은 Multi-AZ 구성을 지원하지 않으며**, 대기 복제본을 직접적으로 암호화할 수 없습니다. 대신, 복제본을 생성할 때 암호화를 설정해야 합니다.



## 질문: 119 ++

AWS Organizations를 사용하는 회사에서는 프로덕션 계정의 Amazon S3 버킷을 절대 삭제해서는 안 됩니다.

SysOps 관리자가 해당 계정의 S3 버킷을 절대 삭제하지 않도록 하기 위해 취할 수 있는 가장 간단한 방법은 무엇입니까?

1. 버킷이 삭제되는 것을 방지하려면 모든 S3 버킷에 MFA 삭제를 설정합니다.
2. 서비스 제어 정책을 사용하여 프로덕션 계정의 모든 버킷에서 s3:DeleteBucket 작업을 거부합니다.
3. 프로덕션 계정의 모든 버킷에 대해 s3:DeleteBucket 작업을 거부하는 IAM 정책이 있는 IAM 그룹을 생성합니다.
4. AWS Shield를 사용하여 모든 S3 버킷이 아닌 AWS 계정에서만 s3:DeleteBucket 작업을 거부합니다.

S3 버킷의 삭제를 방지하기 위해 SysOps 관리자가 취할 수 있는 가장 간단한 방법은 
**2. 서비스 제어 정책을 사용하여 프로덕션 계정의 모든 버킷에서 s3:DeleteBucket 작업을 거부합니다.**입니다.

### 이유:
- **서비스 제어 정책(SCP)**는 AWS Organizations의 구성원 계정에서 허용되는 작업을 중앙 집중식으로 관리할 수 있는 강력한 도구입니다. SCP를 사용하여 특정 작업, 이 경우 `s3:DeleteBucket`을 거부함으로써 해당 계정의 모든 사용자가 S3 버킷을 삭제하지 못하도록 강제할 수 있습니다.
- SCP는 계정의 모든 IAM 사용자 및 역할에 적용되므로, 해당 계정의 모든 버킷에 대한 삭제를 효과적으로 방지합니다.

### 다른 선택지 분석:
1. **MFA 삭제를 설정하는 것은 효과적일 수 있지만,** 사용자 또는 IAM 역할이 MFA를 사용하지 않으면 여전히 삭제할 수 있습니다. 또한, MFA 삭제는 버킷의 객체에 대해만 작동하고 버킷 자체에는 적용되지 않습니다.

3. **IAM 정책을 생성하는 것은 특정 사용자 또는 그룹에 대한 권한을 제한하는 데 사용할 수 있지만,** 새로운 사용자나 역할이 추가될 경우 모든 사용자에게 일관되게 적용되기 어려울 수 있습니다. SCP를 사용하는 것이 더 효과적입니다.

4. **AWS Shield는 DDoS 공격으로부터 보호하는 서비스로,** S3 버킷의 삭제와는 관련이 없습니다. 따라서 이 옵션은 문제 해결에 도움이 되지 않습니다.



## 질문: 120

한 회사에 VPC의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 

이 애플리케이션은 인터넷에서 소프트웨어 업데이트를 다운로드할 수 있는 액세스 권한이 필요합니다. 
VPC에는 퍼블릭 서브넷과 프라이빗 서브넷이 있습니다. 이 회사의 보안 정책에 따라 모든 EC2 인스턴스는 프라이빗 서브넷에 배포해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. VPC에 인터넷 게이트웨이를 추가합니다. 프라이빗 서브넷의 경로 테이블에서 인터넷 게이트웨이로의 경로를 추가합니다.
2. 개인 서브넷에 NAT 게이트웨이를 추가합니다. 개인 서브넷의 경로 테이블에서 NAT 게이트웨이로의 경로를 추가합니다.
3. 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. 프라이빗 서브넷의 경로 테이블에서 NAT 게이트웨이로의 경로를 추가합니다.
4. VPC에 두 개의 인터넷 게이트웨이를 추가합니다. 프라이빗 서브넷과 퍼블릭 서브넷의 경로 테이블에서 각 인터넷 게이트웨이에 대한 경로를 추가합니다.

SysOps 관리자가 애플리케이션이 인터넷에서 소프트웨어 업데이트를 다운로드할 수 있도록 하려면 
**3. 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. 프라이빗 서브넷의 경로 테이블에서 NAT 게이트웨이로의 경로를 추가합니다.**를 선택해야 합니다.

### 이유:
- **NAT 게이트웨이(NAT Gateway)**는 프라이빗 서브넷의 EC2 인스턴스가 인터넷과 통신할 수 있도록 해주는 서비스입니다. NAT 게이트웨이를 퍼블릭 서브넷에 배치하면, 프라이빗 서브넷의 EC2 인스턴스가 소프트웨어 업데이트를 다운로드하기 위해 NAT 게이트웨이를 통해 인터넷에 접근할 수 있습니다.
- NAT 게이트웨이는 EC2 인스턴스의 IP 주소를 숨기고 인터넷에 대한 요청을 프라이빗 서브넷에서 처리할 수 있게 해주므로 보안 정책을 준수하는 데도 적합합니다.

### 다른 선택지 분석:
1. **인터넷 게이트웨이를 추가하고 프라이빗 서브넷에서 경로를 설정하는 것은** 잘못된 접근 방식입니다. 프라이빗 서브넷은 인터넷과 직접 연결될 수 없으므로, 퍼블릭 서브넷에 있는 NAT 게이트웨이를 통해 인터넷에 접근해야 합니다.

2. **프라이빗 서브넷에 NAT 게이트웨이를 추가하는 것은** 불가능합니다. NAT 게이트웨이는 퍼블릭 서브넷에 위치해야만 외부 인터넷과의 연결이 가능하므로, 이 방법은 올바르지 않습니다.

4. **두 개의 인터넷 게이트웨이를 추가하는 것은** 불필요하며, 하나의 VPC에 여러 개의 인터넷 게이트웨이를 추가하는 것은 지원되지 않습니다.

## 질문: 121

개발팀은 최근 웹 애플리케이션의 새 버전을 프로덕션에 배포했습니다. 

출시 후 침투 테스트에서 사용자 데이터를 노출할 수 있는 크로스 사이트 스크립팅 취약성이 드러났습니다.

어떤 AWS 서비스가 이 문제를 완화할까요?

1. AWS Shield 표준
2. AWS 웹 애플리케이션 방화벽
3. 탄력적 부하 분산
4. 아마존 코그니토

정답은 **2. AWS 웹 애플리케이션 방화벽(AWS WAF)**입니다.

## 선택 이유:
- **AWS WAF**: AWS WAF는 웹 애플리케이션에 대한 HTTP(S) 요청을 필터링하고 모니터링하는 서비스로, 크로스 사이트 스크립팅(XSS) 같은 일반적인 웹 공격으로부터 애플리케이션을 보호할 수 있습니다. 개발팀이 배포한 웹 애플리케이션에서 XSS 취약성이 발견되었으므로, WAF를 사용하여 해당 공격 패턴을 탐지하고 차단할 수 있습니다.

## 다른 선택지:
- **1. AWS Shield 표준**: AWS Shield는 주로 DDoS(Distributed Denial of Service) 공격을 방어하는 데 사용되며, 크로스 사이트 스크립팅 같은 애플리케이션 레벨의 취약성을 완화하지는 않습니다.
  
- **3. 탄력적 부하 분산(ELB)**: ELB는 트래픽 분산과 확장성에 중점을 두며, 보안 기능이 있지만 XSS와 같은 웹 애플리케이션의 취약성을 직접적으로 보호하지는 않습니다.
  
- **4. 아마존 코그니토**: Amazon Cognito는 인증 및 사용자 관리에 사용되며, XSS 공격 방어와는 관련이 없습니다.

따라서, 크로스 사이트 스크립팅 취약성을 완화하려면 **AWS WAF**를 사용하는 것이 적절한 해결책입니다.

## 질문: 122 ++

SysOps 관리자는 고성능 컴퓨팅(HPC) 애플리케이션을 위해 Amazon EC2 인스턴스의 복원성 계층을 구성해야 합니다. 

HPC 애플리케이션은 노드 간에 최소 지연 시간이 필요합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

1. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만듭니다. 사용자 데이터를 사용하여 파일 시스템을 EC2 인스턴스에 마운트합니다.
2. EC2 인스턴스 앞에 다중 AZ 네트워크 로드 밸런서를 생성합니다.
3. EC2 인스턴스를 단일 서브넷 내의 자동 확장 그룹에 배치합니다.
4. EC2 인스턴스를 클러스터 배치 그룹으로 시작합니다.
5. EC2 인스턴스를 파티션 배치 그룹으로 시작합니다.

SysOps 관리자가 고성능 컴퓨팅(HPC) 애플리케이션의 복원성 계층을 구성하기 위해 취해야 할 조치는 
**3. EC2 인스턴스를 단일 서브넷 내의 자동 확장 그룹에 배치합니다.**와 
**4. EC2 인스턴스를 클러스터 배치 그룹으로 시작합니다.**입니다.

### 이유:
1. **EC2 인스턴스를 단일 서브넷 내의 자동 확장 그룹에 배치합니다.**
   - 단일 서브넷 내에서 인스턴스를 배치하면 노드 간의 지연 시간을 최소화할 수 있습니다. 이는 데이터 전송 및 통신이 같은 서브넷 내에서 이루어지기 때문에 지연 시간이 줄어드는 결과를 가져옵니다.

2. **EC2 인스턴스를 클러스터 배치 그룹으로 시작합니다.**
   - 클러스터 배치 그룹은 HPC와 같은 낮은 지연 시간과 높은 대역폭이 필요한 애플리케이션에 최적화되어 있습니다. 클러스터 배치 그룹을 사용하면 인스턴스가 물리적으로 가까운 위치에 배치되어 서로 간의 네트워크 지연 시간을 최소화할 수 있습니다.

### 다른 선택지 분석:
1. **Amazon Elastic File System(Amazon EFS) 파일 시스템을 만듭니다.**
   - EFS는 공유 스토리지로, 성능이 높은 컴퓨팅 환경에서는 필요한 최소 지연 시간을 보장하지 못할 수 있습니다. EFS는 지연 시간이 더 높을 수 있기 때문에 HPC에 적합하지 않습니다.

2. **EC2 인스턴스 앞에 다중 AZ 네트워크 로드 밸런서를 생성합니다.**
   - 다중 AZ 네트워크 로드 밸런서는 고가용성을 제공하지만, HPC 애플리케이션에서는 노드 간의 최소 지연 시간이 더 중요합니다. 로드 밸런서 사용은 오히려 추가적인 지연 시간을 초래할 수 있습니다.

5. **EC2 인스턴스를 파티션 배치 그룹으로 시작합니다.**
   - 파티션 배치 그룹은 스토리지 대역폭을 분산하여 활용하는 데 적합하지만, HPC 애플리케이션의 경우는 클러스터 배치 그룹이 더 적합합니다. 파티션 배치 그룹은 성능을 보장하지 않으므로 이 요구 사항에 맞지 않습니다.


 

## 질문: 123

한 회사의 고객이 Amazon S3에서 정적 웹 콘텐츠에 액세스하는 동안 지연 시간이 증가했다고 보고하고 있습니다. 

SysOps 관리자가 특정 S3 버킷에서 매우 높은 읽기 작업률을 관찰했습니다.

S3 버킷의 부하를 줄여서 지연 시간을 최소화하려면 어떻게 해야 할까요?

1. S3 버킷을 최종 사용자의 지리적 위치에 더 가까운 지역으로 마이그레이션합니다.
2. 교차 지역 복제를 사용하여 모든 데이터를 다른 지역으로 복제합니다.
3. S3 버킷을 원본으로 하는 Amazon CloudFront 배포를 생성합니다.
4. Amazon S3에서 제공되는 데이터를 캐시하려면 Amazon ElastiCache를 사용하세요.

정답: **3. S3 버킷을 원본으로 하는 Amazon CloudFront 배포를 생성합니다.**

### 이유:
- **CloudFront는 콘텐츠 전송 네트워크(CDN)**로, 전 세계에 분산된 엣지 로케이션에서 S3의 정적 웹 콘텐츠를 캐시합니다. 이를 통해 사용자가 콘텐츠에 접근할 때 S3 버킷이 아닌 가까운 엣지 로케이션에서 요청이 처리되어, 지연 시간이 줄어듭니다.
- **부하 분산**: 높은 읽기 작업률로 인한 S3 버킷의 부하를 줄이고, 대규모 트래픽을 효과적으로 관리할 수 있습니다. 

다른 옵션들은 S3의 지연 시간을 직접적으로 개선하는 데 효과적이지 않습니다. 

- **1. S3 버킷을 최종 사용자의 지리적 위치에 더 가까운 지역으로 마이그레이션**: 이동이 필요할 수 있지만, 이미 S3에서 콘텐츠를 제공하는 방법에는 영향을 미치지 않습니다.
  
- **2. 교차 지역 복제를 사용하여 모든 데이터를 다른 지역으로 복제**: 데이터의 가용성을 높일 수는 있지만, 지연 시간을 개선하지는 않습니다.
  
- **4. Amazon S3에서 제공되는 데이터를 캐시하려면 Amazon ElastiCache를 사용하세요**: S3는 파일 저장소이므로 ElastiCache는 적합하지 않습니다. ElastiCache는 일반적으로 데이터베이스 쿼리 결과나 자주 조회되는 데이터에 사용됩니다.


## 질문: 124

SysOps 관리자는 이메일 알림을 제공하고 Amazon S3 버킷에 파일이 들어갈 때마다 데이터베이스에 레코드를 삽입하는 솔루션을 개발해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 하는 S3 이벤트 알림을 설정합니다. SNS 주제에 대한 두 개의 구독을 만듭니다. 한 구독을 사용하여 이메일 알림을 보냅니다. 다른 구독을 사용하여 레코드를 데이터베이스에 삽입하는 AWS Lambda 함수를 호출합니다.
2. S3 버킷에 객체가 생성될 때마다 ALARM 상태로 전환되는 Amazon CloudWatch 알람을 설정합니다. 이메일 알림을 보내고 레코드를 데이터베이스에 삽입하는 AWS Lambda 함수를 호출하도록 알람을 구성합니다.
3. S3 버킷에서 새 객체가 감지될 때마다 이메일 알림을 보내고 데이터베이스에 레코드를 삽입하는 AWS Lambda 함수를 만듭니다. Amazon EventBridge(Amazon CloudWatch Events) 예약된 규칙으로 1분마다 함수를 호출합니다.
4. 두 개의 S3 이벤트 알림을 설정합니다. 각 알림에 별도의 AWS Lambda 함수를 타겟팅합니다. 한 함수는 이메일 알림을 보내도록 구성합니다. 다른 함수는 레코드를 데이터베이스에 삽입하도록 구성합니다.


정답: **1. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 하는 S3 이벤트 알림을 설정합니다. SNS 주제에 대한 두 개의 구독을 만듭니다. 한 구독을 사용하여 이메일 알림을 보냅니다. 다른 구독을 사용하여 레코드를 데이터베이스에 삽입하는 AWS Lambda 함수를 호출합니다.**

### 이유:
- **운영 효율성**: SNS를 사용하면 여러 소비자에게 메시지를 전송할 수 있으며, 이메일 알림과 데이터베이스 레코드 삽입을 동일한 이벤트 소스에서 쉽게 관리할 수 있습니다. 두 개의 구독을 통해 각 작업을 독립적으로 처리할 수 있으므로 코드와 리소스를 재사용할 수 있습니다.
- **간결함**: 이 접근 방식은 이벤트 발생 시 SNS 주제에 메시지를 게시하는 간단한 방법으로, S3와 Lambda, SNS 간의 통합을 활용하여 효율성을 높입니다.
- **유연성**: 필요에 따라 추가 구독을 추가하거나 수정하기 쉽기 때문에 요구 사항이 변경될 때 유연하게 대응할 수 있습니다.

다른 옵션들의 단점은 다음과 같습니다:

- **2. Amazon CloudWatch 알람을 설정하는 방법**: S3 버킷의 객체 생성 이벤트를 감지하는 데 적합하지 않으며, CloudWatch는 주로 메트릭과 로그에 기반하여 작동하므로 이 솔루션은 과도한 설정과 복잡성을 초래합니다.

- **3. AWS Lambda 함수를 EventBridge로 예약 호출하는 방법**: 이 방법은 S3 객체가 생성될 때마다 즉시 반응하지 않으며, 1분마다 호출하기 때문에 비효율적입니다.

- **4. 두 개의 S3 이벤트 알림을 설정하는 방법**: 이 방법은 기능적으로는 맞지만, SNS를 사용하는 것이 더 효율적이며 관리가 용이합니다. 이벤트에 대한 별도의 설정이 필요하고, 유지 관리 측면에서 더 복잡해질 수 있습니다.


## 질문: 125 ++

한 회사가 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 

인스턴스는 Amazon EC2 Auto Scaling 그룹에 있습니다. 애플리케이션은 공개 URL로 액세스합니다.
SysOps 관리자는 애플리케이션의 가용성을 확인하고 고객과 동일한 경로와 작업을 따르는 모니터링 솔루션을 구현해야 합니다. 
모니터링 실행의 95% 미만에서 오류가 발견되지 않으면 SysOps 관리자는 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 고객 경로를 따르는 스크립트로 Amazon CloudWatch Synthetics 카나리아를 만듭니다. 카나리아가 반복 일정에 따라 실행되도록 예약합니다. SuccessPercent 메트릭이 95% 미만일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 CloudWatch 알람을 만듭니다.
2. 엔드포인트의 가용성을 모니터링하는 Amazon Route 53 상태 확인을 만듭니다. HealthCheckPercentageHealthy 지표가 95% 미만일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다.
3. 각 고객 경로에 대해 엔드포인트를 사용할 수 있는지 확인하기 위해 단일 AWS Lambda 함수를 만듭니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 Lambda 함수를 예약합니다. 엔드포인트가 오류를 반환하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 Lambda 함수를 구성합니다.
4. 각 고객 경로에 대해 AWS Lambda 함수를 만들어 해당 엔드포인트를 사용할 수 있는지 확인합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 Lambda 함수를 예약합니다. 각 Lambda 함수를 구성하여 엔드포인트 상태에 대한 사용자 지정 메트릭을 Amazon CloudWatch에 게시합니다. 각 사용자 지정 메트릭을 기반으로 CloudWatch 알람을 만들어 알람이 ALARM 상태일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시합니다.
 

정답: **1. 고객 경로를 따르는 스크립트로 Amazon CloudWatch Synthetics 카나리아를 만듭니다. 카나리아가 반복 일정에 따라 실행되도록 예약합니다. SuccessPercent 메트릭이 95% 미만일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 CloudWatch 알람을 만듭니다.**

### 이유:
- **고객 경로 모니터링**: Amazon CloudWatch Synthetics 카나리아를 사용하면 고객이 실제로 사용하는 경로와 동일한 경로를 따라 애플리케이션의 가용성을 모니터링할 수 있습니다. 이는 사용자의 경험을 정확하게 반영합니다.
- **자동화된 스케줄링**: 카나리아는 정기적으로 실행될 수 있도록 예약할 수 있으며, 이에 따라 지속적인 모니터링이 가능합니다.
- **상황에 맞는 알림**: SuccessPercent 메트릭이 95% 미만일 때 SNS를 통해 알림을 받을 수 있어, 문제를 신속하게 인지하고 대응할 수 있습니다.

다른 옵션들의 단점은 다음과 같습니다:

- **2. Amazon Route 53 상태 확인**: 이 방법은 URL 가용성 모니터링에 적합하지만, 고객 경로에 대한 구체적인 테스트는 수행하지 않으므로 모니터링의 정확성이 떨어질 수 있습니다.

- **3. 단일 AWS Lambda 함수 사용**: 이 방법은 고객 경로를 따르지 않으며, Lambda 함수를 별도로 작성해야 하므로 관리의 복잡성이 증가합니다.

- **4. 사용자 지정 메트릭을 사용하는 AWS Lambda 함수**: 이 방법은 고객 경로를 따르긴 하지만, 구현과 관리가 더 복잡하며, 단일 Lambda 함수 대신 여러 함수를 생성해야 할 수 있습니다. 또한 사용자 지정 메트릭을 CloudWatch에 게시하는 것은 추가적인 오버헤드를 초래할 수 있습니다.


## 질문: 126  ++

SysOps 관리자는 AWS Systems Manager Session Manager를 사용하여 인스턴스에 연결합니다. 

SysOps 관리자가 새 Amazon EC2 인스턴스를 시작한 후 EC2 인스턴스는 연결 가능한 시스템의 Session Manager 목록에 나타나지 않습니다. 
SysOps 관리자는 Systems Manager Agent가 EC2 인스턴스에 설치, 업데이트 및 실행 중인지 확인합니다.

이 문제의 이유는 무엇입니까?

1. SysOps 관리자는 연결에 필요한 키 쌍에 액세스할 수 없습니다.
2. SysOps 관리자가 포트 22에서 SSH를 허용하기 위해 EC2 인스턴스에 보안 그룹을 연결하지 않았습니다.
3. EC2 인스턴스에는 Session Manager가 EC2 인스턴스에 연결할 수 있도록 허용하는 연결된 IAM 역할이 없습니다.
4. EC2 인스턴스 ID가 세션 관리자 구성에 입력되지 않았습니다.

정답: **3. EC2 인스턴스에는 Session Manager가 EC2 인스턴스에 연결할 수 있도록 허용하는 연결된 IAM 역할이 없습니다.**

### 이유:
- **IAM 역할 필수**: AWS Systems Manager Session Manager를 사용하여 EC2 인스턴스에 연결하려면, 해당 인스턴스에 적절한 IAM 역할이 연결되어 있어야 합니다. 이 역할은 Systems Manager가 인스턴스에 연결할 수 있도록 허용하는 정책을 포함해야 합니다. 예를 들어, `AmazonSSMManagedInstanceCore` 정책이 필요합니다.
  
- **Agent 설치 여부와는 무관**: SysOps 관리자가 SSM Agent가 설치되어 있고 실행 중인 것을 확인했더라도, IAM 역할이 없으면 Session Manager를 통해 인스턴스에 연결할 수 없습니다. 

다른 옵션들의 단점은 다음과 같습니다:

1. **키 쌍 문제**: Session Manager는 SSH 연결을 사용하지 않으므로, 키 쌍이 없거나 액세스할 수 없는 것은 문제가 되지 않습니다.

2. **SSH 보안 그룹**: Session Manager는 SSH를 사용하지 않기 때문에, 포트 22에서 SSH를 허용하기 위한 보안 그룹 설정은 관련이 없습니다.

4. **EC2 인스턴스 ID 문제**: Session Manager는 EC2 인스턴스 ID를 따로 등록할 필요가 없으며, IAM 역할이 올바르게 설정되면 인스턴스는 자동으로 Session Manager에 표시됩니다.


## 질문: 127 ++

SysOps 관리자가 VPC에 사용 가능한 프라이빗 IPv4 주소가 없기 때문에 Amazon EC2 인스턴스를 VPC로 시작할 수 없습니다.

SysOps 관리자가 인스턴스를 시작하기 위해 취해야 하는 작업 조합은 무엇입니까? (두 가지를 선택하세요.)

1. VPC에 보조 IPv4 CIDR 블록을 연결합니다.
2. 기본 IPv6 CIDR 블록을 VPC에 연결합니다.
3. VP에 대한 새 서브넷을 만듭니다.
4. VPC의 CIDR 블록을 수정합니다.
5. 인스턴스와 연관된 서브넷의 CIDR 블록을 수정합니다.

정답: 
**1. VPC에 보조 IPv4 CIDR 블록을 연결합니다.**  
**4. VPC의 CIDR 블록을 수정합니다.**

### 이유:
1. **보조 IPv4 CIDR 블록 연결**:
   - VPC에 보조 IPv4 CIDR 블록을 추가하면 사용할 수 있는 프라이빗 IPv4 주소의 수를 증가시킬 수 있습니다. 이를 통해 더 많은 EC2 인스턴스를 시작할 수 있습니다.

2. **CIDR 블록 수정**:
   - VPC의 CIDR 블록을 수정하면 기본적으로 사용 가능한 IPv4 주소 범위를 확장할 수 있습니다. 그러나 VPC의 CIDR 블록은 처음 생성할 때 정의되며, 수정 시에는 제한 사항이 있을 수 있지만 필요할 경우 이 방법을 통해도 사용할 수 있는 주소를 늘릴 수 있습니다.

### 다른 옵션들:
- **2. 기본 IPv6 CIDR 블록 연결**: IPv6 CIDR 블록을 추가하면 IPv4 주소에는 영향을 미치지 않으므로, 현재 IPv4 주소 부족 문제를 해결하지 못합니다.

- **3. 새 서브넷 만들기**: 새 서브넷을 생성하더라도 서브넷의 CIDR 블록이 기존 VPC의 CIDR 블록 내에 있어야 하며, 여전히 사용할 수 있는 IPv4 주소가 부족할 수 있습니다.

- **5. 인스턴스와 연관된 서브넷의 CIDR 블록 수정**: 서브넷의 CIDR 블록을 수정할 수는 있지만, 이미 사용 중인 주소 범위가 있을 경우 수정이 불가능하며, 서브넷의 CIDR 블록이 VPC의 CIDR 블록 내에 있어야 하므로 이 방법은 기존 주소 부족 문제를 해결하지 못할 수 있습니다.

## 질문: 128 +

SysOps 관리자가 새 AWS 계정에서 Amazon EC2 Auto Scaling 그룹을 만들고 있습니다. 

인스턴스를 추가한 후 SysOps 관리자는 그룹이 최소 인스턴스 수에 도달하지 못했다는 것을 알게 됩니다. SysOps 관리자는 다음과 같은 오류 메시지를 받습니다.

새 EC2 인스턴스를 시작합니다. 상태 이유: 할당량에 따라 실행 중인 인스턴스가 0개 더 허용됩니다.
최소 1개를 요청했습니다. EC2 인스턴스 시작이 실패했습니다.

어떤 조치로 이 문제를 해결할 수 있습니까?

1. AWS Billing and Cost Management 콘솔에서 Amazon EC2에 대한 계정 지출 한도를 조정합니다.
2. EC2 콘솔의 EC2 설정 섹션에서 해당 AWS 지역의 EC2 할당량을 수정합니다.
3. AWS Management Console에서 Service Quotas를 사용하여 인스턴스 유형 패밀리에 대한 할당량 증가를 요청합니다.
4. AWS Management Console의 자동 크기 조정 그룹에서 재균형 조정 작업을 사용합니다.

정답: **3. AWS Management Console에서 Service Quotas를 사용하여 인스턴스 유형 패밀리에 대한 할당량 증가를 요청합니다.**

### 이유:
AWS 계정은 인스턴스 수에 대한 기본 할당량이 설정되어 있으며, 이 할당량을 초과하여 인스턴스를 시작할 수 없습니다. 오류 메시지에서 "할당량에 따라 실행 중인 인스턴스가 0개 더 허용됩니다."라고 언급된 것은 현재 계정에서 해당 유형의 인스턴스를 시작할 수 있는 최대 수를 초과했음을 의미합니다. 

이 문제를 해결하기 위해서는 **Service Quotas**를 사용하여 인스턴스 유형 패밀리에 대한 할당량 증가를 요청해야 합니다. 이렇게 하면 새로운 EC2 인스턴스를 시작할 수 있는 허용량을 확보할 수 있습니다.

### 다른 옵션들:
1. **AWS Billing and Cost Management 콘솔에서 Amazon EC2에 대한 계정 지출 한도를 조정**: 이는 비용 관리와 관련된 설정이지만, 인스턴스 수에 대한 할당량에는 영향을 미치지 않습니다.
   
2. **EC2 콘솔의 EC2 설정 섹션에서 해당 AWS 지역의 EC2 할당량 수정**: EC2 설정에서 직접 할당량을 수정할 수 없으므로 이 방법은 올바르지 않습니다.
   
4. **AWS Management Console의 자동 크기 조정 그룹에서 재균형 조정 작업을 사용**: 이는 Auto Scaling 그룹의 인스턴스를 조정하는 방법이지만, 현재 할당량 문제를 해결하는 데는 도움이 되지 않습니다.


## 질문: 129 +++

SysOps 관리자가 두 개의 AWS CloudFormation 템플릿을 만들고 있습니다. 

첫 번째 템플릿은 서브넷, 경로 테이블, 인터넷 게이트웨이와 같은 연관된 리소스가 있는 VPC를 만듭니다. 두 번째 템플릿은 첫 번째 템플릿에서 만든 VPC 내에 애플리케이션 리소스를 배포합니다. 두 번째 템플릿은 첫 번째 템플릿에서 만든 리소스를 참조해야 합니다.

이를 최소한의 관리 노력으로 어떻게 달성할 수 있을까요?

1. 첫 번째 템플릿의 출력에 내보내기 필드를 추가하고 두 번째 템플릿에 있는 값을 가져옵니다.
2. 첫 번째 템플릿에서 생성된 스택을 쿼리하고 필요한 값을 검색하는 사용자 지정 리소스를 만듭니다.
3. 두 번째 템플릿에서 참조되는 첫 번째 템플릿에서 매핑을 만듭니다.
4. 첫 번째 템플릿에 리소스 이름을 입력하고 두 번째 템플릿에서 해당 이름을 매개변수로 참조합니다

정답: **1. 첫 번째 템플릿의 출력에 내보내기 필드를 추가하고 두 번째 템플릿에 있는 값을 가져옵니다.**

### 이유:

AWS CloudFormation에서는 여러 템플릿 간에 리소스를 참조할 수 있도록 하기 위해 출력(Output) 섹션을 사용합니다. 첫 번째 템플릿에서 필요한 리소스의 정보를 출력으로 내보내고, 두 번째 템플릿에서는 이 출력을 가져와서 사용할 수 있습니다. 

이 접근 방식은 **최소한의 관리 노력**으로 구현할 수 있으며, 다음과 같은 단계로 진행됩니다:

1. **첫 번째 템플릿에서 리소스의 출력을 정의합니다.**
   - 예를 들어, VPC ID와 같은 리소스 정보를 출력으로 내보냅니다.
   ```yaml
   Outputs:
     VPCId:
       Value: !Ref MyVPC
       Export:
         Name: MyVPCId
   ```

2. **두 번째 템플릿에서 첫 번째 템플릿의 출력을 가져옵니다.**
   - `Fn::ImportValue` 함수를 사용하여 첫 번째 템플릿에서 내보낸 값을 참조합니다.
   ```yaml
   Resources:
     MyApplication:
       Type: AWS::SomeResource
       Properties:
         VpcId: !ImportValue MyVPCId
   ```

### 다른 옵션들:
2. **첫 번째 템플릿에서 생성된 스택을 쿼리하고 필요한 값을 검색하는 사용자 지정 리소스를 만듭니다.**
   - 이 방법은 복잡하고 관리 오버헤드가 더 큽니다. 또한, 직접적인 리소스 참조 대신 API 호출이 필요해 비효율적입니다.

3. **두 번째 템플릿에서 참조되는 첫 번째 템플릿에서 매핑을 만듭니다.**
   - 매핑은 정적 값을 사용하여 리소스를 참조하는 데 적합하지만, 동적으로 생성된 리소스를 참조하는 데는 적합하지 않습니다.

4. **첫 번째 템플릿에 리소스 이름을 입력하고 두 번째 템플릿에서 해당 이름을 매개변수로 참조합니다.**
   - 이 방법은 두 템플릿 간의 직접적인 연결을 생성하지 않으며, 첫 번째 템플릿의 리소스 이름이 변경될 경우 두 번째 템플릿도 수정해야 합니다.
   - 

## 질문: 130 +++++

한 회사가 Application Load Balancer(ALB) 뒤의 세 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 

어떤 솔루션이 이러한 요구 사항을 충족합니까?

1. 원하는 임계값에 도달하면 각 EC2 인스턴스의 크기를 늘리고 애플리케이션 지연 시간을 모니터링하기 위해 Amazon CloudWatch 알람을 생성합니다.
2. 애플리케이션 지연 시간을 모니터링하고 원하는 임계값에 도달하면 ALB에 EC2 인스턴스를 추가하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.
3. 대상 추적 스케일링 정책이 있는 EC2 인스턴스의 자동 스케일링 그룹에 애플리케이션을 배포합니다. ALB를 자동 스케일링 그룹에 연결합니다.
4. 예약된 스케일링 정책이 있는 EC2 인스턴스의 자동 스케일링 그룹에 애플리케이션을 배포합니다. ALB를 자동 스케일링 그룹에 연결합니다.

정답: **3. 대상 추적 스케일링 정책이 있는 EC2 인스턴스의 자동 스케일링 그룹에 애플리케이션을 배포합니다. ALB를 자동 스케일링 그룹에 연결합니다.**

### 이유:
대상 추적 스케일링 정책은 EC2 인스턴스의 자동 스케일링 그룹에서 애플리케이션의 성능을 최적화하는 데 매우 효과적입니다. 이 정책을 사용하면 다음과 같은 장점이 있습니다:

1. **자동화된 확장**: 대상 추적 스케일링 정책은 지정된 메트릭(예: CPU 사용량, 애플리케이션 지연 시간 등)을 기반으로 인스턴스 수를 자동으로 조정합니다. 이로 인해 트래픽이 증가할 때 자동으로 더 많은 인스턴스가 시작됩니다.

2. **ALB와의 통합**: ALB(Application Load Balancer)를 자동 스케일링 그룹에 연결함으로써 인스턴스가 추가되거나 제거될 때 로드 밸런서가 트래픽을 자동으로 분산시킵니다. 이로 인해 애플리케이션의 가용성과 성능이 향상됩니다.

### 다른 옵션들:
1. **각 EC2 인스턴스의 크기를 늘리고 CloudWatch 알람을 생성**: 이는 수동적인 접근 방식으로, 트래픽의 변동에 즉시 대응할 수 없습니다. EC2 인스턴스를 단순히 늘리는 것은 비용이 증가할 수 있으며, 최적의 성능을 보장하지 못할 수 있습니다.

2. **ALB에 EC2 인스턴스를 추가하는 EventBridge 규칙 생성**: 이 방법은 인스턴스를 수동으로 추가해야 하며, 트래픽 급증에 즉시 대응하지 못할 수 있습니다. 자동 스케일링 그룹을 사용하는 것보다 효과적이지 않습니다.

4. **예약된 스케일링 정책**: 이 방법은 특정 시간에만 인스턴스를 추가하는 방식으로, 예상치 못한 트래픽 급증에 즉각적으로 대응할 수 없습니다. 이는 고정된 스케일링이 필요할 때 유용할 수 있지만, 동적인 트래픽에 최적화된 방법이 아닙니다.

## 질문: 131

어떤 회사에 고성능 Windows 워크로드가 있습니다. 

이 워크로드에는 10,000 IOPS의 일관된 성능을 제공하는 스토리지 볼륨이 필요합니다. 이 회사는 이 성능을 달성하기 위해 불필요한 추가 용량에 비용을 지불하고 싶어하지 않습니다.

어떤 솔루션이 가장 적은 비용으로 이러한 요구 사항을 충족할까요?

1. 10,000개의 프로비저닝 IOPS로 구성된 프로비저닝된 IOPS SSD(io1) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.
2. 10,000개의 프로비저닝 IOPS로 구성된 범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.
3. 최대 I/O 모드에서 Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용합니다.
4. 10,000 IOPS로 구성된 Amazon FSx for Windows File Server 파일 시스템을 사용합니다.


정답: **2. 10,000개의 프로비저닝 IOPS로 구성된 범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.**

### 이유:
Amazon EBS의 범용 SSD(gp3) 볼륨은 다음과 같은 이유로 이 요구 사항을 충족하는 가장 비용 효율적인 솔루션입니다:

1. **비용 효율성**: gp3 볼륨은 사용자가 원하는 성능(IOPS 및 처리량)을 기준으로 용량을 설정할 수 있습니다. 기본적으로 gp3는 3,000 IOPS를 제공하지만, 최대 16,000 IOPS까지 확장할 수 있습니다. 따라서 10,000 IOPS를 위해 필요한 용량이 적으며, io1보다 비용이 낮습니다.

2. **최소 용량 요구 사항**: gp3 볼륨은 더 적은 저장 용량으로도 높은 IOPS를 제공할 수 있으며, 불필요한 추가 용량을 피할 수 있습니다. io1 볼륨은 10,000 IOPS를 제공하기 위해 최소 1,000 GiB의 용량이 필요하지만, gp3는 적은 용량으로도 같은 성능을 달성할 수 있습니다.

3. **성능 일관성**: gp3 볼륨은 일관된 성능을 제공하므로, 고성능 워크로드에 적합합니다.

### 다른 옵션들:
1. **io1 볼륨**: 10,000개의 프로비저닝 IOPS로 구성된 io1 볼륨은 고성능이지만, 비용이 더 비쌉니다. 불필요한 용량을 지불해야 할 수 있습니다.

3. **Amazon EFS 파일 시스템**: EFS는 파일 시스템으로 IOPS를 보장하지 않으며, 성능이 가변적일 수 있습니다. 또한, IOPS에 따라 비용이 발생할 수 있습니다.

4. **Amazon FSx for Windows File Server**: 이 서비스는 Windows 기반 파일 스토리지에 최적화되어 있지만, 추가 비용이 발생할 수 있으며, 단일 워크로드에 대한 IOPS 성능을 최적화하기 위해 더 비쌀 수 있습니다. 

따라서, 범용 SSD(gp3) 볼륨이 가장 비용 효율적이고 성능 요구 사항을 충족하는 솔루션입니다.

## 질문: 132

SysOps 관리자는 60분 이상 평균 CPU 사용률이 10% 미만인 모든 Amazon EC2 인스턴스를 자동으로 종료하는 솔루션을 만들어야 합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족할까요?

1. 각 EC2 인스턴스에 60분마다 한 번씩 실행되도록 cron 작업을 구현하고 현재 CPU 사용률을 계산합니다. CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
2. 각 EC2 인스턴스에 대해 Amazon CloudWatch 알람을 구현하여 평균 CPU 사용률을 모니터링합니다. 기간을 1시간으로 설정하고 임계값을 10%로 설정합니다. 알람에서 인스턴스를 중지하기 위한 EC2 작업을 구성합니다.
3. 각 EC2 인스턴스에 통합 Amazon CloudWatch 에이전트를 설치하고 기본 수준 사전 정의된 메트릭 세트를 활성화합니다. 60분마다 CPU 사용률을 기록하고 CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
4. AWS Systems Manager Run Command를 사용하여 60분마다 각 EC2 인스턴스의 CPU 사용률을 가져옵니다. CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
 


정답: **2. 각 EC2 인스턴스에 대해 Amazon CloudWatch 알람을 구현하여 평균 CPU 사용률을 모니터링합니다. 기간을 1시간으로 설정하고 임계값을 10%로 설정합니다. 알람에서 인스턴스를 중지하기 위한 EC2 작업을 구성합니다.**

### 이유:
1. **운영 효율성**: CloudWatch 알람을 사용하면 EC2 인스턴스의 CPU 사용률을 자동으로 모니터링하고, 특정 조건이 충족될 때 인스턴스를 자동으로 중지할 수 있습니다. 이렇게 하면 수동으로 모니터링하거나 스크립트를 실행할 필요가 없으므로 운영 비용과 노력을 줄일 수 있습니다.

2. **자동화**: CloudWatch 알람은 CPU 사용률이 10% 미만인 상태가 60분 이상 지속될 때 자동으로 알림을 트리거하고 인스턴스를 중지하는 작업을 수행할 수 있도록 설정할 수 있습니다. 이는 작업의 자동화를 통해 관리 부담을 최소화합니다.

3. **정확한 모니터링**: CloudWatch는 AWS 리소스에 대한 신뢰할 수 있는 모니터링 솔루션이며, CPU 사용률과 같은 메트릭을 정확하게 수집할 수 있습니다. 

### 다른 옵션들:
1. **cron 작업**: 각 인스턴스에 대해 cron 작업을 설정하는 것은 비효율적이며, 각 인스턴스에서 스크립트를 실행해야 하므로 관리 및 유지보수가 어렵습니다.

3. **CloudWatch 에이전트**: 에이전트를 설치하고 설정하는 데 추가적인 작업이 필요합니다. 또한, 이 방법도 각 인스턴스에서 수동으로 작업을 처리해야 하므로 효율적이지 않습니다.

4. **AWS Systems Manager Run Command**: 이 방법도 EC2 인스턴스에 대해 주기적으로 명령을 실행해야 하며, CloudWatch 알람을 사용하는 것보다 복잡하고 관리가 더 어려울 수 있습니다.

따라서, Amazon CloudWatch 알람을 활용하는 것이 가장 효율적이고 간단한 해결책입니다.

## 질문: 133 +++

SysOps 관리자가 AWS 서비스에 대한 AWS CLI 호출을 인증할 수 없습니다.
다음 중 이 문제의 원인은 무엇입니까?

1. IAM 비밀번호가 올바르지 않습니다.
2. 서버 인증서가 없습니다.
3. SSH 키 쌍이 올바르지 않습니다.
4. 접근 키가 없습니다.


정답: **4. 접근 키가 없습니다.**

### 이유:
AWS CLI를 사용하여 AWS 서비스에 호출을 인증하려면 IAM 사용자에게 할당된 **액세스 키 ID**와 **비밀 액세스 키**가 필요합니다. 이러한 키가 없거나 올바르게 구성되지 않으면 AWS 서비스에 대한 인증이 실패하게 됩니다. 

### 다른 옵션들:
1. **IAM 비밀번호가 올바르지 않습니다**: AWS CLI는 IAM 사용자 비밀번호를 사용하지 않으므로, 비밀번호가 올바르지 않아도 CLI 호출은 영향을 받지 않습니다.

2. **서버 인증서가 없습니다**: AWS CLI 호출은 서버 인증서에 의존하지 않습니다. 이 문제는 주로 HTTPS 통신에서 SSL/TLS 인증서와 관련이 있지만, AWS CLI 인증과는 관련이 없습니다.

3. **SSH 키 쌍이 올바르지 않습니다**: SSH 키 쌍은 EC2 인스턴스에 SSH로 연결할 때 사용되는 것이며, AWS CLI 호출의 인증과는 관련이 없습니다.

따라서, AWS CLI 호출을 인증할 수 없는 주된 원인은 접근 키가 없거나 잘못 구성된 경우입니다.


## 질문: 134 +++

회사에서는 90일 이상 사용되지 않은 모든 IAM 사용자 계정의 액세스 키와 비밀번호를 즉시 비활성화해야 합니다. 

SysOps 관리자는 가장 운영 효율적인 방법을 사용하여 사용되지 않는 키를 비활성화하는 프로세스를 자동화해야 합니다.

SysOps 관리자는 이 솔루션을 어떻게 구현해야 합니까?

1. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Step Functions 워크플로를 만듭니다. 예약된 Amazon EventBridge(Amazon CloudWatch Events) 규칙이 호출되면 AWS Lambda 함수를 실행하여 이러한 IAM 사용자의 AWS 액세스 키와 비밀번호를 자동으로 제거합니다.
2. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Config 규칙을 구성합니다. Amazon EC2 인스턴스에서 자동 주간 일괄 처리 프로세스를 설정하여 이러한 IAM 사용자의 AWS 액세스 키와 비밀번호를 비활성화합니다.
3. Amazon EC2 인스턴스에서 Python 스크립트를 개발하고 실행하여 90일 동안 활성화되지 않은 IAM 사용자를 프로그래밍 방식으로 식별합니다. 이러한 IAM 사용자를 자동으로 삭제합니다.
4. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Config 관리 규칙을 설정합니다. 이러한 IAM 사용자에 대한 AWS 액세스 키를 비활성화하기 위해 AWS Systems Manager 자동화 런북을 설정합니다.

정답: **1. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Step Functions 워크플로를 만듭니다. 예약된 Amazon EventBridge(Amazon CloudWatch Events) 규칙이 호출되면 AWS Lambda 함수를 실행하여 이러한 IAM 사용자의 AWS 액세스 키와 비밀번호를 자동으로 제거합니다.**

### 이유:
이 솔루션은 자동화되고 운영 효율성이 높습니다. 구체적인 이점은 다음과 같습니다:

- **자동화**: AWS Lambda를 사용하여 IAM 사용자의 액세스 키와 비밀번호를 비활성화하는 작업을 자동화함으로써 수동 개입을 줄일 수 있습니다.
  
- **정기적인 실행**: Amazon EventBridge를 사용하여 주기적으로 Lambda 함수를 호출하면, 90일 이상 사용되지 않은 IAM 사용자를 자동으로 식별하고 비활성화할 수 있습니다.

- **확장성**: AWS Step Functions를 사용하면 작업의 흐름을 시각화하고 관리할 수 있으며, 다양한 AWS 서비스를 조합하여 복잡한 워크플로를 구현할 수 있습니다.

### 다른 옵션들:
2. **AWS Config 규칙을 구성**: AWS Config는 IAM 사용자 계정에 대한 변경 사항을 모니터링할 수 있지만, 자동으로 액세스 키와 비밀번호를 비활성화하는 데에는 추가적인 작업이 필요할 수 있습니다.

3. **EC2 인스턴스에서 Python 스크립트 실행**: 이 방법은 관리 효율성이 떨어집니다. EC2 인스턴스를 운영해야 하며, 스크립트를 지속적으로 실행하고 모니터링해야 하므로 운영 비용이 증가할 수 있습니다.

4. **AWS Config 관리 규칙과 Systems Manager 자동화**: 이 접근 방식은 가능하지만, AWS Config 규칙이 IAM 사용자를 식별하고 비활성화하는 과정을 직접 수행하기 어렵습니다. 시스템 구성이나 런북을 관리하는 데 추가적인 복잡성이 있을 수 있습니다.

따라서, 선택지 1이 가장 운영 효율적인 솔루션입니다.


## 질문: 135 +++

한 회사가 AWS CloudFormation 템플릿에서 새로운 Amazon EC2 인스턴스를 시작하여 사용자 지정 AMI 이미지를 만듭니다. 

AWS OpsWorks를 통해 필요한 소프트웨어를 설치하고 구성하고 각 EC2 인스턴스의 이미지를 가져옵니다. 
소프트웨어를 설치하고 구성하는 프로세스는 2~3시간이 걸릴 수 있지만, 때때로 설치 오류로 인해 프로세스가 중단됩니다.

SysOps 관리자는 CloudFormation 템플릿을 수정해야 하므로 프로세스가 중단되면 전체 스택이 실패하고 롤백됩니다.

이러한 요구 사항에 따라 템플릿에 무엇을 추가해야 합니까?

1. 시간 초과가 4시간으로 설정된 조건.
2. CreationPolicy의 시간 제한이 4시간으로 설정되었습니다.
3. DependsOn의 시간제한은 4시간으로 설정되어 있습니다.
4. 시간 제한이 4시간으로 설정된 메타데이터입니다.

정답: **2. CreationPolicy의 시간 제한이 4시간으로 설정되었습니다.**

### 이유:
`CreationPolicy`는 AWS CloudFormation 템플릿에서 리소스의 생성 상태를 제어할 수 있는 기능입니다. `CreationPolicy`를 사용하면 리소스가 성공적으로 생성되기까지의 시간을 지정할 수 있으며, 이 시간을 초과하면 CloudFormation 스택 생성이 실패하고 롤백됩니다. 이 기능은 소프트웨어 설치와 같은 장기 프로세스를 다룰 때 유용합니다.

- **시간 제한 설정**: 4시간의 시간 제한을 설정함으로써, 2~3시간의 소프트웨어 설치 프로세스가 종료되지 않거나 오류가 발생할 경우 CloudFormation이 스택 생성 프로세스를 실패시키고 롤백하도록 할 수 있습니다.

### 다른 옵션들:
1. **시간 초과가 4시간으로 설정된 조건**: 조건은 리소스 생성에 대한 결정적인 논리를 제공하지만, 특정 리소스 생성의 시간을 제어하지 않습니다.

3. **DependsOn의 시간제한은 4시간으로 설정되어 있습니다**: `DependsOn`은 특정 리소스가 다른 리소스의 생성을 완료해야 한다는 것을 지정하는 데 사용되지만, 시간 제한을 설정하는 기능은 없습니다.

4. **시간 제한이 4시간으로 설정된 메타데이터입니다**: 메타데이터는 리소스의 추가 정보를 제공하지만, 시간 제한이나 생성 실패 시의 롤백을 제어하는 데는 사용되지 않습니다.

따라서 `CreationPolicy`를 사용하여 소프트웨어 설치와 구성 프로세스가 중단될 경우 CloudFormation 스택이 실패하고 롤백되도록 설정하는 것이 가장 적합한 방법입니다.


## 질문: 136 +++

한 회사가 AWS 계정에서 eu-west-1 지역의 90개 Amazon EC2 인스턴스에서 워크로드를 실행합니다. 

2개월 후에 회사는 eu-west-1에서 eu-west-3 지역으로 워크로드를 마이그레이션합니다.

회사는 EC2 인스턴스 비용을 줄여야 합니다. 회사는 다음 주에 시작되는 1년 약정을 할 의향이 있습니다. 회사는 1년 기간 동안 지역에 관계없이 90개 EC2 인스턴스에 대한 할인을 제공하는 EC2 인스턴스 구매 옵션을 선택해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. EC2 Standard 예약 인스턴스를 구매하세요.
2. EC2 인스턴스 할인 플랜을 구매하세요.
3. EC2 변환 가능 예약 인스턴스를 구매하세요.
4. 컴퓨팅 절감 플랜을 구매하세요.

정답: **3. EC2 변환 가능 예약 인스턴스를 구매하세요.**

### 이유:
EC2 변환 가능 예약 인스턴스는 특정 지역에 종속되지 않고, 약정 기간 동안 EC2 인스턴스의 유연성을 제공합니다. 이는 사용자가 인스턴스를 다른 지역으로 이동할 수 있는 옵션을 제공하여, 마이그레이션 후에도 같은 약정 혜택을 받을 수 있게 합니다. 

1. **EC2 Standard 예약 인스턴스**: 이 옵션은 특정 지역과 인스턴스 유형에 묶여 있어, 마이그레이션 시 이점을 제공하지 않습니다.

2. **EC2 인스턴스 할인 플랜**: 이 플랜은 인스턴스에 대한 일관된 할인 혜택을 제공하지만, 예약 인스턴스와 같은 약정 기간을 요구하지 않으며, 변환 가능성이나 지역 이동이 포함되지 않습니다.

4. **컴퓨팅 절감 플랜**: 이 옵션은 온디맨드 인스턴스 사용에 대해 할인을 제공하지만, 예약 인스턴스와 같은 장기 약정 기반의 할인은 아닙니다.

따라서, EC2 변환 가능 예약 인스턴스는 마이그레이션을 계획하고 있는 회사의 요구 사항을 충족하는 가장 적합한 옵션입니다.

## 질문: 137

SysOps 관리자가 퍼블릭 서브넷과 프라이빗 서브넷을 포함하는 VPC를 생성했습니다. 

프라이빗 서브넷에서 시작된 Amazon EC2 인스턴스는 인터넷에 액세스할 수 없습니다. 기본 네트워크 ACL은 VPC의 모든 서브넷에서 활성화되어 있으며 모든 보안 그룹은 모든 아웃바운드 트래픽을 허용합니다.

어떤 솔루션이 프라이빗 서브넷의 EC2 인스턴스에 인터넷에 액세스할 수 있게 할까요?

1. 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
2. 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. 퍼블릭 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
3. 프라이빗 서브넷에 NAT 게이트웨이를 만듭니다. 퍼블릭 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
4. 프라이빗 서브넷에 NAT 게이트웨이를 만듭니다. 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.

정답: **1. 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.**

### 이유:
프라이빗 서브넷의 EC2 인스턴스가 인터넷에 액세스할 수 있도록 하려면 NAT(NAT Gateway 또는 NAT Instance) 장치를 사용해야 합니다. NAT 게이트웨이는 퍼블릭 서브넷에 배치되고, 이를 통해 프라이빗 서브넷의 인스턴스가 아웃바운드 트래픽을 인터넷으로 전송할 수 있게 됩니다. 

1. **퍼블릭 서브넷에 NAT 게이트웨이를 만든 후, 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 생성하면** EC2 인스턴스가 NAT 게이트웨이를 통해 인터넷에 액세스할 수 있습니다.

2. **퍼블릭 서브넷에서 NAT 게이트웨이로 가는 경로를 만드는 것은 필요하지 않습니다.** NAT 게이트웨이는 퍼블릭 서브넷에 위치하고, 인터넷에 액세스할 수 있는 IP 주소를 가져야 합니다.

3. **프라이빗 서브넷에 NAT 게이트웨이를 만드는 것은** 올바른 방법이 아닙니다. NAT 게이트웨이는 퍼블릭 서브넷에 있어야 인터넷과 연결될 수 있습니다.

4. **프라이빗 서브넷에 NAT 게이트웨이를 만들고 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만드는 것은** 이론적으로 맞지 않습니다. NAT 게이트웨이는 퍼블릭 서브넷에 있어야 합니다.

따라서, 프라이빗 서브넷의 EC2 인스턴스가 인터넷에 액세스할 수 있도록 하려면 퍼블릭 서브넷에 NAT 게이트웨이를 생성하고 해당 서브넷에서 적절한 경로를 설정하는 것이 필요합니다.


## 질문: 138 +++++
한 회사가 Elastic Load Balancer(ELB) 뒤의 Amazon EC2 인스턴스에서 퍼블릭 웹 애플리케이션을 실행하려고 합니다. 

회사의 보안 팀은 AWS Certificate Manager(ACM) 인증서를 사용하여 웹사이트를 보호하려고 합니다. ELB는 모든 HTTP 요청을 HTTPS로 자동으로 리디렉션해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 포트 80에 HTTPS 리스너가 하나인 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 80에 SSL/TLS 인증서를 연결합니다. HTTP에서 HTTPS로 요청을 리디렉션하는 규칙을 만듭니다.
2. 포트 80에 HTTP 리스너 하나, 포트 443에 HTTPS 프로토콜 리스너 하나가 있는 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.
3. 포트 80과 포트 443에 두 개의 TCP 리스너가 있는 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.
4. 포트 80과 포트 443에 두 개의 TCP 리스너가 있는 네트워크 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.

정답: **2. 포트 80에 HTTP 리스너 하나, 포트 443에 HTTPS 프로토콜 리스너 하나가 있는 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.**

### 이유:
이 솔루션은 보안 팀의 요구 사항과 HTTP 요청을 HTTPS로 리디렉션하는 방법에 적합합니다.

1. **포트 80에 HTTP 리스너**: HTTP 요청을 수신하고, 이후 HTTPS로 리디렉션하는 역할을 합니다.

2. **포트 443에 HTTPS 프로토콜 리스너**: SSL/TLS 인증서를 연결하여 암호화된 연결을 처리합니다.

3. **리디렉션 규칙**: 포트 80에서 수신된 HTTP 요청을 포트 443으로 리디렉션하여 모든 트래픽이 HTTPS로 안전하게 전달되도록 합니다.

### 다른 옵션 분석:
1. **옵션 1**은 포트 80에 HTTPS 리스너를 설정하고 있습니다. HTTPS 요청은 보안 연결이 필요하므로 이 접근법은 부적절합니다.

3. **옵션 3**에서는 TCP 리스너를 사용하고 있으며, HTTP 리디렉션을 설정하기에는 적합하지 않습니다. TCP 리스너는 프로토콜을 명시적으로 처리하지 않기 때문에 리디렉션 규칙을 적용할 수 없습니다.

4. **옵션 4**에서 사용된 네트워크 로드 밸런서는 일반적으로 HTTP/HTTPS 수준에서의 리디렉션을 지원하지 않습니다. 

따라서, **옵션 2**가 요구 사항을 충족하는 가장 적절한 솔루션입니다.


## 질문: 139 +++

한 회사가 AWS Organizations의 조직에 속한 모든 멤버 계정에서 AWS 비용을 추적하려고 합니다. 

멤버 계정 관리자는 매월 예상 비용이 미리 정해진 금액을 초과할 때 알림을 받고 싶어합니다. 관리자는 청구 알람을 구성할 수 없습니다. 모든 사용자의 IAM 권한이 올바릅니다.

이 문제의 원인은 무엇일까요?

1. 관리/지불자 계정에는 청구 알림이 켜져 있지 않습니다.
2. 회사에서는 회원 계정과 관리/지불자 계정 간에 결제 정보를 공유하도록 AWS Resource Access Manager(AWS RAM)를 구성하지 않았습니다.
3. 모든 계정에 대해 Amazon GuardDuty가 켜져 있습니다.
4. 회사에서는 청구를 모니터링하기 위한 AWS Config 규칙을 구성하지 않았습니다.


정답: **1. 관리/지불자 계정에는 청구 알림이 켜져 있지 않습니다.**

### 이유:
AWS Organizations에서는 청구 알림을 설정할 때 관리/지불자 계정에서 알림을 구성해야 합니다. 각 멤버 계정이 독립적으로 청구 알림을 설정할 수는 없으며, 모든 비용은 관리 계정으로 집계되기 때문에 관리 계정에서 청구 알림을 설정해야 합니다.

### 다른 옵션 분석:
2. **AWS Resource Access Manager(AWS RAM)**: 이 옵션은 결제 정보를 공유하는 것과 관련이 있지만, 실제로 청구 알림을 설정하는 데 직접적인 영향을 주지는 않습니다. 청구 알림은 관리 계정에서만 설정해야 합니다.

3. **Amazon GuardDuty**: GuardDuty는 보안 서비스로, 청구 알림과는 관련이 없습니다. 이 서비스의 활성화 여부가 알림 기능에 영향을 주지 않습니다.

4. **AWS Config 규칙**: Config는 리소스 구성을 모니터링하고 규정을 준수하는 데 사용되며, 청구 알림과는 직접적인 연관이 없습니다.

결론적으로, 멤버 계정 관리자가 청구 알림을 받을 수 없는 주된 원인은 **관리/지불자 계정에서 청구 알림이 활성화되지 않았기 때문**입니다.



## 질문: 140 +++

한 회사가 Amazon EC2 인스턴스에서 컨테이너화된 애플리케이션을 실행하기 위해 Amazon Elastic Container Service(Amazon ECS)를 사용하고 있습니다. 

SysOps 관리자는 ECS 작업 간의 트래픽 흐름만 모니터링하면 됩니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. 각 작업의 탄력적 네트워크 인터페이스에 Amazon CloudWatch Logs를 구성합니다.
2. 각 작업의 탄력적 네트워크 인터페이스에서 VPC 흐름 로그를 구성합니다.
3. 작업 정의에서 awsvpc 네트워크 모드를 지정하세요.
4. 작업 정의에서 브리지 네트워크 모드를 지정하세요.
5. 작업 정의에서 호스트 네트워크 모드를 지정하세요.

SysOps 관리자가 ECS 작업 간의 트래픽 흐름만 모니터링하기 위해 선택해야 하는 두 가지 단계는 다음과 같습니다:

2. **각 작업의 탄력적 네트워크 인터페이스에서 VPC 흐름 로그를 구성합니다.**  
   - VPC 흐름 로그를 사용하면 VPC 내에서의 트래픽 흐름을 모니터링할 수 있습니다. 이를 통해 ECS 작업 간의 트래픽을 분석하고, 특정 IP 주소 또는 포트에 대한 데이터 전송을 기록할 수 있습니다.

3. **작업 정의에서 awsvpc 네트워크 모드를 지정하세요.**  
   - `awsvpc` 네트워크 모드를 사용하면 각 ECS 작업이 자체 탄력적 네트워크 인터페이스를 갖게 됩니다. 이를 통해 작업 간의 트래픽을 개별적으로 모니터링하고, VPC 흐름 로그와 결합하여 트래픽 흐름을 보다 정밀하게 분석할 수 있습니다.

### 선택하지 않아야 하는 옵션:
1. **각 작업의 탄력적 네트워크 인터페이스에 Amazon CloudWatch Logs를 구성합니다.**: CloudWatch Logs는 로그 데이터를 수집하는 데 사용되지만, 트래픽 흐름을 모니터링하는 데는 적합하지 않습니다.

4. **작업 정의에서 브리지 네트워크 모드를 지정하세요.**: 브리지 네트워크 모드는 호스트의 Docker 브리지 네트워크를 사용하는 방식으로, 각 작업의 트래픽 흐름을 개별적으로 모니터링하기 어렵습니다.

5.- **작업 정의에서 호스트 네트워크 모드를 지정하세요.**: 호스트 모드는 각 작업이 호스트의 네트워크 스택을 공유하게 하여, IP 주소가 호스트와 동일해집니다. 이 경우에도 트래픽 흐름을 개별적으로 모니터링하기 어렵습니다.

따라서, **VPC 흐름 로그를 구성**하고 **`awsvpc` 네트워크 모드를 지정**하는 것이 최선의 접근 방식입니다.


## 질문: 141 +++

한 회사가 AWS Organizations를 사용하여 여러 AWS 계정을 관리합니다. 

회사의 SysOps 팀은 수동 프로세스를 사용하여 IAM 역할을 만들고 관리해 왔습니다. 
이 팀은 여러 AWS 계정에 필요한 IAM 역할을 만들고 관리하기 위한 자동화된 솔루션이 필요합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. AWS CloudFormation 템플릿을 만듭니다. 템플릿을 재사용하여 각 AWS 계정에서 필요한 IAM 역할을 만듭니다.
2. AWS Directory Service를 AWS Organizations와 함께 사용하면 필요한 IAM 역할을 Microsoft Active Directory 사용자와 자동으로 연결할 수 있습니다.
3. AWS Organizations와 함께 AWS Resource Access Manager를 사용하면 AWS 계정 간에 공유 리소스를 배포하고 관리할 수 있습니다.
4. AWS CloudFormation StackSets를 AWS Organizations와 함께 사용하여 AWS 계정에 대한 IAM 역할을 배포하고 관리합니다.

가장 운영 효율적인 솔루션은 다음과 같습니다:

**4. AWS CloudFormation StackSets를 AWS Organizations와 함께 사용하여 AWS 계정에 대한 IAM 역할을 배포하고 관리합니다.**

### 이유:
- **자동화 및 일관성**: AWS CloudFormation StackSets를 사용하면 하나의 CloudFormation 템플릿을 여러 AWS 계정과 리전에 걸쳐 배포할 수 있습니다. 이를 통해 IAM 역할을 일관되게 생성하고 관리할 수 있습니다.
- **편리한 업데이트**: StackSets를 사용하면 템플릿을 업데이트할 때 모든 관련 계정에서 변경 사항을 쉽게 적용할 수 있습니다.
- **조직 관리**: AWS Organizations와 통합되어, 여러 계정을 효율적으로 관리하고 자동화된 방식으로 IAM 역할을 배포할 수 있습니다.

### 선택하지 않아야 하는 옵션:
1. **AWS CloudFormation 템플릿을 만듭니다. 템플릿을 재사용하여 각 AWS 계정에서 필요한 IAM 역할을 만듭니다.**  
   - 이 방법은 수동으로 각 계정에 템플릿을 배포해야 하므로 자동화된 솔루션이 아닙니다.

2. **AWS Directory Service를 AWS Organizations와 함께 사용하면 필요한 IAM 역할을 Microsoft Active Directory 사용자와 자동으로 연결할 수 있습니다.**  
   - 이 방법은 IAM 역할을 관리하기 위한 것이 아니라 Active Directory와의 통합에 중점을 두고 있습니다.

3. **AWS Organizations와 함께 AWS Resource Access Manager를 사용하면 AWS 계정 간에 공유 리소스를 배포하고 관리할 수 있습니다.**  
   - Resource Access Manager는 리소스를 공유하는 데 사용되며 IAM 역할의 생성 및 관리를 위한 솔루션은 아닙니다.

따라서, **AWS CloudFormation StackSets**를 사용하는 것이 요구 사항을 충족하고 운영 효율성을 극대화하는 가장 적합한 방법입니다.


## 질문: 142

SysOps 관리자는 Amazon RDS 데이터베이스 자격 증명에 대한 자동 로테이션을 구성해야 합니다. 

자격 증명은 30일마다 로테이션해야 합니다. 솔루션은 Amazon RDS와 통합되어야 합니다.

어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할까요?

1. 자격 증명을 AWS Systems Manager Parameter Store에 보안 문자열로 저장합니다. 30일의 로테이션 간격으로 자동 로테이션을 구성합니다.
2. AWS Secrets Manager에 자격 증명을 저장합니다. 30일의 로테이션 간격으로 자동 로테이션을 구성합니다.
3. 자격 증명을 Amazon S3 버킷의 파일에 저장합니다. AWS Lambda 함수를 배포하여 30일마다 자격 증명을 자동으로 회전합니다.
4. AWS Secrets Manager에 자격 증명을 저장합니다. AWS Lambda 함수를 배포하여 30일마다 자격 증명을 자동으로 회전합니다.

가장 적은 운영 오버헤드로 Amazon RDS 데이터베이스 자격 증명을 자동 로테이션하는 솔루션은 다음과 같습니다:

**2. AWS Secrets Manager에 자격 증명을 저장합니다. 30일의 로테이션 간격으로 자동 로테이션을 구성합니다.**

이 옵션은 AWS Secrets Manager가 제공하는 내장된 자동 로테이션 기능을 활용하며, RDS와의 통합이 원활하여 운영 관리를 최소화할 수 있습니다. 

다른 옵션에 비해 추가적인 Lambda 함수를 배포하거나 다른 스토리지 솔루션을 설정할 필요가 없기 때문에 가장 운영적으로 효율적입니다.

## 질문: 143

회사의 SysOps 관리자가 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 복원하려고 시도합니다. 

그러나 다른 시스템 관리자가 실수로 스냅샷을 삭제했기 때문에 스냅샷이 없습니다. 회사는 스냅샷이 삭제된 후 지정된 기간 동안 스냅샷을 복구할 수 있는 기능이 필요합니다.
어떤 솔루션이 이 기능을 제공할까요?

1. 보관해야 하는 개별 EBS 스냅샷에 대해 삭제 보호를 켜세요.
2. 스냅샷 연령에 대한 조건문을 사용하여 EBS 스냅샷 삭제를 거부하는 IAM 정책을 만듭니다. 모든 사용자에게 정책을 적용합니다.
3. 원하는 보관 기간 동안 EBS 스냅샷에 대한 휴지통 보관 규칙을 만듭니다.
4. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 예약하여 EBS 스냅샷을 Amazon S3 Glacier로 복사합니다.
 
스냅샷이 삭제된 후 지정된 기간 동안 복구할 수 있는 기능을 제공하는 가장 적합한 솔루션은 다음과 같습니다:

**3. 원하는 보관 기간 동안 EBS 스냅샷에 대한 휴지통 보관 규칙을 만듭니다.**

이 옵션은 AWS Backup의 기능을 활용하여 삭제된 EBS 스냅샷을 자동으로 보관하고 복구할 수 있게 합니다. 휴지통 보관 규칙을 설정하면 지정된 기간 동안 스냅샷을 복구할 수 있는 기능이 제공됩니다. 

기타 옵션은 스냅샷 보호 또는 삭제 방지와 관련이 있지만, 실제로 삭제된 스냅샷을 복구할 수 있는 기능을 제공하지는 않습니다.



## 질문: 144 +++

SysOps 관리자가 최근 S3 버킷에서 Amazon S3 Cross-Region Replication을 구성했습니다.

이 기능은 기본적으로 대상 S3 버킷에 다음 중 어느 것을 복제합니까?

1. 버킷 소유자에게 권한이 없는 소스 S3 버킷의 개체
2. S3 Glacier에 저장된 객체
3. 복제가 구성되기 전에 존재했던 개체
4. 객체 메타데이터


Amazon S3 Cross-Region Replication(CRR)은 복제가 구성된 이후에 **추가되거나 수정된 객체**만을 복제하며, 복제된 객체는 원본 객체와 동일한 메타데이터를 가집니다. 이를 바탕으로 올바른 답변은 다음과 같습니다:

**4. 객체 메타데이터**  
CRR은 원본 객체와 함께 객체의 메타데이터도 복제합니다.

### 설명:
1. **버킷 소유자에게 권한이 없는 소스 S3 버킷의 객체**: 복제되지 않습니다. 복제하려면 소스 버킷의 객체에 대해 소유자가 적절한 권한을 가지고 있어야 합니다.
2. **S3 Glacier에 저장된 객체**: CRR은 Glacier로 저장된 객체는 복제하지 않습니다.
3. **복제가 구성되기 전에 존재했던 객체**: CRR은 복제 설정 이후에 새로 추가된 객체만 복제합니다.


## 질문: 145 +++

회사에 Amazon CloudWatch Logs로 로그 데이터를 보내는 작업 부하가 있습니다. 

필드 중 하나에 애플리케이션 지연 시간 측정이 포함됩니다. SysOps 관리자는 시간 경과에 따라 이 필드의 p90 통계를 모니터링해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. 로그 데이터에 대한 Amazon CloudWatch Contributor Insights 규칙을 만듭니다.
2. 로그 데이터에 대한 메트릭 필터를 만듭니다.
3. 로그 데이터에 대한 구독 필터를 만듭니다.
4. 워크로드에 대한 Amazon CloudWatch Application Insights 규칙을 만듭니다.

SysOps 관리자가 애플리케이션 지연 시간 측정에 대한 p90 통계를 모니터링해야 하는 경우 가장 적합한 방법은 
**2. 로그 데이터에 대한 메트릭 필터를 만듭니다.**입니다.

### 이유:
- **메트릭 필터**는 CloudWatch Logs에서 특정 패턴을 찾아내어 메트릭을 생성할 수 있는 방법입니다. 이를 통해 애플리케이션의 지연 시간 측정값을 추출하고, p90 같은 통계를 CloudWatch에서 직접 모니터링할 수 있습니다.
- 메트릭 필터를 설정하면 해당 지연 시간 데이터가 CloudWatch에서 메트릭으로 집계되어 그래프화하거나 알림을 설정하는 데 사용할 수 있습니다.

### 다른 옵션들에 대한 설명:
1. **Amazon CloudWatch Contributor Insights 규칙**: 주로 로그의 기여도를 분석하는 데 사용되며, 특정 메트릭(p90 등)을 직접적으로 모니터링하기 위한 것은 아닙니다.
2. **구독 필터**: 로그 데이터를 다른 AWS 서비스로 전송하는 데 사용되며, 메트릭을 수집하거나 통계를 직접적으로 생성하는 데는 적합하지 않습니다.
3. **Amazon CloudWatch Application Insights 규칙**: 애플리케이션 성능 모니터링 및 문제 감지에 유용하지만, 특정 로그 데이터에 대한 메트릭 필터링은 아닙니다.

결론적으로, p90 통계를 효과적으로 모니터링하기 위해서는 **로그 데이터에 대한 메트릭 필터를 만드는 것이 가장 효율적입니다.**



## 질문: 146 ++

어떤 회사가 Amazon S3 Glacier에 민감한 데이터를 보관하려고 합니다. 

회사의 규제 및 규정 준수 요구 사항은 어떤 계정에서도 데이터를 수정하는 것을 허용하지 않습니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

1. 보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 후에 볼트 잠금 정책을 검증합니다.
2. 보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 이내에 볼트 잠금 정책을 검증합니다.
3. 거버넌스 모드에서 S3 객체 잠금을 구성합니다. 24시간 후에 모든 파일을 업로드합니다.
4. 거버넌스 모드에서 S3 객체 잠금을 구성합니다. 모든 파일을 24시간 이내에 업로드합니다.

회사가 Amazon S3 Glacier에 민감한 데이터를 보관하면서 수정하는 것을 허용하지 않으려면, 가장 적합한 솔루션은 
**2. 보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 이내에 볼트 잠금 정책을 검증합니다.**입니다.

### 이유:
- **S3 Glacier 볼트 잠금**은 규제 준수 요구 사항을 충족하기 위해 볼트의 데이터가 변경되거나 삭제되지 않도록 보호하는 기능입니다. 볼트 잠금 정책을 설정하면 볼트를 수정할 수 없게 되며, 이로 인해 데이터 무결성을 유지할 수 있습니다.
- **잠금 ID를 사용하여 24시간 이내에 볼트 잠금 정책을 검증**하는 것은 데이터에 대한 변경이 불가능하도록 보장하며, 즉시 적용될 수 있습니다.

### 다른 옵션들에 대한 설명:
1. **보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 후에 볼트 잠금 정책을 검증합니다.**
   - 이 옵션은 잠금 정책이 적용되기까지의 시간이 지연되므로, 데이터 수정이 허용되는 시간이 생깁니다.

3. **거버넌스 모드에서 S3 객체 잠금을 구성합니다. 24시간 후에 모든 파일을 업로드합니다.**
   - 거버넌스 모드는 특정 사용자에게 객체를 삭제할 수 있는 권한을 부여하는데, 이 옵션은 수정이 허용되는 시점을 만들 수 있습니다.

4. **거버넌스 모드에서 S3 객체 잠금을 구성합니다. 모든 파일을 24시간 이내에 업로드합니다.**
   - 이 옵션도 마찬가지로 수정이 허용되는 시점을 만들 수 있습니다.

결론적으로, S3 Glacier의 **볼트 잠금을 설정하고 24시간 이내에 검증하는** 것이 회사의 규제 및 규정 준수 요구 사항을 가장 효과적으로 충족하는 방법입니다.


## 질문: 147 +++

한 회사가 두 개의 다른 가용성 영역에 걸쳐 분산된 두 개의 초대형 노드가 있는 Amazon ElastiCache for Redis를 사용하는 애플리케이션을 관리합니다. 

회사의 IT 팀은 ElastiCache for Redis 클러스터에 75%의 사용 가능한 메모리가 있다는 것을 발견했습니다. 애플리케이션은 높은 가용성을 유지해야 합니다.

클러스터 크기를 조정하는 가장 비용 효율적인 방법은 무엇입니까?

1. Redis 클러스터용 ElastiCache의 노드 수를 2개에서 1개로 줄입니다.
2. 대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 새 클러스터로 데이터를 마이그레이션합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.
3. 대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 백업을 가져오고 새 클러스터에서 백업을 복원합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.
4. ElastiCache for Redis 클러스터에 대한 온라인 크기 조정을 수행합니다. 노드 유형을 초대형 노드에서 대형 노드로 변경합니다.

Amazon ElastiCache for Redis의 클러스터 크기를 조정하여 비용 효율성을 유지하면서 높은 가용성을 보장하려면 
**4. ElastiCache for Redis 클러스터에 대한 온라인 크기 조정을 수행합니다. 노드 유형을 초대형 노드에서 대형 노드로 변경합니다.**라는 옵션이 가장 적합합니다.

### 이유:
- **온라인 크기 조정**을 통해 애플리케이션의 가용성을 유지하면서 즉시 리소스를 조정할 수 있습니다. 이 과정에서 클러스터가 중단되지 않으므로 애플리케이션이 지속적으로 사용할 수 있습니다.
- **비용 효율성**: 초대형 노드에서 대형 노드로 변경함으로써 메모리 비용을 절감할 수 있습니다. 이는 불필요한 리소스를 줄이는 데 도움이 됩니다.

### 다른 옵션들에 대한 설명:
1. **Redis 클러스터용 ElastiCache의 노드 수를 2개에서 1개로 줄입니다.**
   - 이 옵션은 높은 가용성을 떨어뜨리며, 장애 발생 시 클러스터의 가용성이 크게 저하됩니다.

2. **대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 새 클러스터로 데이터를 마이그레이션합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.**
   - 데이터 마이그레이션은 시간이 걸리며, 이 기간 동안 애플리케이션의 가용성이 영향을 받을 수 있습니다. 이 과정도 비용이 추가될 수 있습니다.

3. **대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 백업을 가져오고 새 클러스터에서 백업을 복원합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.**
   - 이 방법 역시 가용성에 영향을 미칠 수 있으며, 전체적인 프로세스가 복잡하고 시간이 소요될 수 있습니다.

결론적으로, **온라인 크기 조정을 통해 리소스를 조정하는 것이** 높은 가용성을 유지하면서 비용 효율적으로 클러스터를 조정하는 최선의 방법입니다.




## 질문: 148 +++

회사는 애플리케이션을 AWS로 마이그레이션해야 합니다. 

이 회사는 구성 관리를 위해 Chef 레시피를 사용하고 있습니다. 이 회사는 애플리케이션을 AWS로 마이그레이션한 후에도 기존 Chef 레시피를 계속 사용하고 싶어합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. AWS CloudFormation을 사용하여 Amazon EC2 인스턴스를 생성하고, Chef 서버를 설치하고, Chef 레시피를 추가합니다.
2. AWS CloudFormation을 사용하여 스택을 만들고 Chef 레시피에 대한 계층을 추가합니다.
3. Docker 플랫폼과 함께 AWS Elastic Beanstalk를 사용하여 Chef 레시피를 업로드합니다.
4. AWS OpsWorks를 사용하여 스택을 만들고 Chef 레시피로 레이어를 추가합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 
**4. AWS OpsWorks를 사용하여 스택을 만들고 Chef 레시피로 레이어를 추가합니다.** 입니다. 

AWS OpsWorks는 Chef를 지원하며, Chef 레시피를 사용하여 애플리케이션과 인프라를 관리하는 데 최적화되어 있습니다. 이 솔루션은 기존 Chef 레시피를 쉽게 통합하고 관리할 수 있게 해주어 마이그레이션 후에도 효율적으로 구성 관리를 수행할 수 있습니다.



## 질문: 149 +++

한 회사가 AWS Organizations를 사용하여 AWS 계정을 관리합니다. 

SysOps 관리자는 회사의 모든 AWS 계정에서 모든 Amazon EC2 인스턴스에 대한 백업 전략을 만들어야 합니다.

어떤 솔루션이 가장 운영 효율적인 방식으로 이러한 요구 사항을 충족할까요?

1. 각 계정에 AWS Lambda 함수를 배포하여 예약된 기준으로 EC2 인스턴스 스냅샷을 실행합니다.
2. 관리 계정에 AWS CloudFormation 스택 세트를 생성하여 모든 EC2 인스턴스에 AutoBackup=True 태그를 추가합니다.
3. 관리 계정에서 AWS Backup을 사용하여 모든 계정과 리소스에 대한 정책을 배포합니다.
4. SCP(서비스 제어 정책)를 사용하여 각 계정에서 예약된 기준으로 EC2 인스턴스 스냅샷을 실행합니다.

가장 운영 효율적인 방식으로 모든 AWS 계정에서 Amazon EC2 인스턴스에 대한 백업 전략을 만드는 솔루션은 
**3. 관리 계정에서 AWS Backup을 사용하여 모든 계정과 리소스에 대한 정책을 배포합니다.**입니다.

AWS Backup은 여러 AWS 계정과 리전에서 백업 정책을 중앙 집중식으로 관리하고 자동화할 수 있는 기능을 제공합니다. 이를 통해 SysOps 관리자는 효율적으로 모든 EC2 인스턴스의 백업을 관리하고, 일관된 정책을 적용하며, 운영 오버헤드를 최소화할 수 있습니다.



## 질문: 150 +++

SysOps 관리자가 VPC의 연결 문제를 해결하기 위해 VPC Flow Logs를 검토하고 있습니다. 

SysOps 관리자는 로그를 검토하는 동안 거부된 트래픽이 나열되지 않은 것을 알아차렸습니다.

SysOps 관리자는 모든 트래픽이 기록되도록 하기 위해 무엇을 해야 합니까?

1. 모든 트래픽을 캡처하기 위한 필터 설정이 있는 새로운 흐름 로그를 만듭니다.
2. 새 흐름 로그를 만듭니다. 로그 레코드 형식을 사용자 지정 형식으로 설정합니다. 로그에 포함할 적절한 필드를 선택합니다.
3. 기존 흐름 로그를 편집합니다. 모든 트래픽을 캡처하도록 필터 설정을 변경합니다.
4. 기존 흐름 로그를 편집합니다. 로그 레코드 형식을 사용자 지정 형식으로 설정합니다. 로그에 포함할 적절한 필드를 선택합니다.

SysOps 관리자가 VPC Flow Logs에서 모든 트래픽(수락 및 거부된 트래픽)을 기록하도록 하려면 
**3. 기존 흐름 로그를 편집합니다. 모든 트래픽을 캡처하도록 필터 설정을 변경합니다.**를 선택해야 합니다.

이 방법을 통해 기존 흐름 로그의 필터를 수정하여 거부된 트래픽을 포함한 모든 트래픽을 기록할 수 있습니다. 새로운 흐름 로그를 만들 필요 없이 효율적으로 문제를 해결할 수 있는 방법입니다.


## 질문: 151 ++++

한 회사가 포트폴리오 전반에 걸쳐 AWS 서비스 사용을 확대하고 있습니다. 

이 회사는 보안, 규정 준수 및 청구를 위한 비즈니스 프로세스의 분리를 보장하기 위해 각 팀에 AWS 계정을 프로비저닝하려고 합니다. 
계정 생성 및 부트스트래핑은 확장 가능하고 효율적인 방식으로 완료되어야 하며, 정의된 기준선과 거버넌스 가드레일이 있는 새 계정이 생성되어야 합니다. SysOps 관리자는 시간과 리소스를 절약하는 프로비저닝 프로세스를 설계해야 합니다.

이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1. AWS Elastic Beanstalk를 사용하여 AWS 계정을 프로비저닝하고, 인프라를 설정하고, AWS Organizations와 통합하는 작업을 자동화합니다.
2. AWS OpsWorks에서 부트스트래핑 스크립트를 만들고 이를 AWS CloudFormation 템플릿과 결합하여 계정과 인프라를 프로비저닝합니다.
3. AWS Config를 사용하면 AWS Service Catalog를 통해 계정을 프로비저닝하고 인스턴스를 배포할 수 있습니다.
4. AWS Control Tower를 사용하여 Account Factory에서 템플릿을 만들고 해당 템플릿을 사용하여 새로운 계정을 프로비저닝합니다.



이 회사의 요구 사항을 충족하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### **4. AWS Control Tower를 사용하여 Account Factory에서 템플릿을 만들고 해당 템플릿을 사용하여 새로운 계정을 프로비저닝합니다.**

#### 이유:
- **AWS Control Tower**: 이는 여러 AWS 계정을 관리하고 프로비저닝하는 데 특화된 서비스로, 비즈니스 프로세스의 분리를 보장합니다.
- **Account Factory**: Control Tower의 Account Factory를 사용하면 팀이 정의된 기준선과 거버넌스 가드레일을 기반으로 새로운 AWS 계정을 손쉽게 생성하고 관리할 수 있습니다. 이 과정에서 계정은 자동으로 설정되고 필요할 때마다 추가적인 규정을 적용할 수 있습니다.
- **확장성 및 효율성**: Control Tower는 AWS Organizations와 통합되어 계정 생성을 자동화하며, 모든 팀이 동일한 가드레일과 규정을 준수할 수 있도록 합니다. 이로 인해 시간과 리소스를 절약할 수 있습니다.

### 다른 옵션 분석:
1. **AWS Elastic Beanstalk**: 이는 애플리케이션 배포에 초점을 맞춘 서비스이며, AWS 계정 프로비저닝과는 관련이 없습니다.

2. **AWS OpsWorks**: 이는 구성 관리 서비스로, 부트스트래핑 스크립트를 만들 수 있지만 계정 프로비저닝에 대한 직접적인 기능은 없습니다.

3. **AWS Config**: 이는 AWS 리소스의 구성 변경을 기록하고 평가하는 데 사용되지만, 계정 프로비저닝과 인스턴스 배포를 직접적으로 지원하지 않습니다. AWS Service Catalog와 결합하여 사용할 수 있지만, AWS Control Tower만큼의 전문성을 제공하지는 않습니다.

결론적으로, **AWS Control Tower를 사용하는 것이 계정 생성 및 부트스트래핑을 확장 가능하고 효율적으로 완료할 수 있는 가장 적합한 방법입니다.**




## 질문: 152 +++

SysOps 관리자가 Amazon CloudFront 배포판의 캐시 적중률이 10% 미만임을 알아챘습니다.

어떤 구성 변경 모음이 배포판의 캐시 적중률을 증가시킬까요? (두 가지를 선택하세요.)

1. 캐시 동작 설정에서 필요한 쿠키, 쿼리 문자열, 헤더만 전달되는지 확인하세요.
2. HTTPS만 사용하도록 뷰어 프로토콜 정책을 변경합니다.
3. 사전 서명된 쿠키와 URL을 사용하여 배포판에 대한 액세스를 제한하도록 배포판을 구성합니다.
4. 캐시 동작 설정에서 객체의 자동 압축을 활성화합니다.
5. 캐시 동작 설정에서 CloudFront TTL(수명) 설정을 늘립니다.

캐시 적중률을 증가시키기 위해 선택할 수 있는 두 가지 구성 변경은 다음과 같습니다:

1. **캐시 동작 설정에서 필요한 쿠키, 쿼리 문자열, 헤더만 전달되는지 확인하세요.**
   - **이유**: CloudFront는 기본적으로 모든 요청의 모든 쿠키, 쿼리 문자열, 헤더를 전달하면 캐시가 더 많은 변형을 생성합니다. 필요한 것만 전달하도록 설정하면, 더 많은 요청이 캐시된 객체를 반환하게 되어 캐시 적중률이 증가합니다.

5. **캐시 동작 설정에서 CloudFront TTL(수명) 설정을 늘립니다.**
   - **이유**: TTL(시간 제한)은 캐시된 객체가 얼마나 오래 유효한지를 결정합니다. TTL을 늘리면 캐시된 객체가 더 오랫동안 유지되어, 더 많은 요청이 캐시에서 처리되므로 캐시 적중률이 높아질 수 있습니다.

### 다른 옵션들에 대한 설명:

2. **HTTPS만 사용하도록 뷰어 프로토콜 정책을 변경합니다.**
   - **설명**: HTTPS를 사용하는 것은 보안과 관련된 설정이며, 캐시 적중률에는 큰 영향을 미치지 않습니다.

3. **사전 서명된 쿠키와 URL을 사용하여 배포판에 대한 액세스를 제한하도록 배포판을 구성합니다.**
   - **설명**: 사전 서명된 쿠키와 URL은 접근 제어와 관련된 설정으로, 캐시 적중률과는 직접적인 관련이 없습니다.

4. **캐시 동작 설정에서 객체의 자동 압축을 활성화합니다.**
   - **설명**: 자동 압축은 전송 성능을 개선할 수 있지만, 캐시 적중률에 직접적인 영향을 미치지는 않습니다. 오히려 데이터 크기를 줄여 전송 속도를 높이는 데 도움이 됩니다.

결론적으로, 캐시 동작 설정에서 쿠키, 쿼리 문자열, 헤더를 최소한으로 전달하고 TTL을 늘리는 것이 캐시 적중률을 높이는 데 가장 효과적입니다.

## 질문: 153

SysOps 관리자가 인터넷에서 개인 서브넷의 인스턴스로 패치를 다운로드하려고 합니다.

VPC에 대한 인터넷 게이트웨이가 있고 NAT 게이트웨이가 공개 서브넷에 배포되었지만 인스턴스에 인터넷 연결이 없습니다.개인 서브넷에 배포된 리소스는 공개 인터넷에서 직접 액세스할 수 없어야 합니다.

공개 서브넷(10.0.1.0/24) 경로 테이블
대상
10.0.0.0/16 로컬
0.0.0.0/0 IGW

개인 서브넷(10.0.2.0/24) 경로 테이블
대상
10.0.0.0/16 로컬

제공된 정보를 고려할 때, 이 문제를 해결하기 위해 개인 서브넷의 경로 테이블에 무엇을 추가해야 합니까?

1. 0.0.0.0/0 IGW
2. 0.0.0.0/0 NAT
3. 10.0.1.0/24 IGW
4. 10.0.1.0/24 NAT

개인 서브넷의 인스턴스가 인터넷에서 패치를 다운로드할 수 있도록 하려면 NAT 게이트웨이를 통해 인터넷에 액세스할 수 있도록 개인 서브넷의 경로 테이블에 경로를 추가해야 합니다.

### 추가해야 할 경로:

- **대상:** `0.0.0.0/0`
- **대상:** NAT 게이트웨이의 ID (예: `nat-xxxxxxxx`)

### 설명:

1. **0.0.0.0/0 경로**: 이 경로는 모든 외부 IP 주소에 대한 트래픽을 처리하도록 지정합니다. 
2. **NAT 게이트웨이**: 이 경로는 인터넷으로 나가는 트래픽이 NAT 게이트웨이를 통해 처리되도록 합니다. NAT 게이트웨이는 개인 서브넷에서 발생하는 요청을 인터넷으로 라우팅하고, 그 응답을 다시 개인 서브넷으로 전달할 수 있게 합니다.

### 최종적으로 개인 서브넷의 경로 테이블은 다음과 같아야 합니다:

| 대상        | 대상                     |
|------------|------------------------|
| 10.0.0.0/16 | 로컬                   |
| 0.0.0.0/0   | NAT 게이트웨이 ID (nat-xxxxxxxx) |

이렇게 설정하면 개인 서브넷의 인스턴스가 NAT 게이트웨이를 통해 인터넷에 패치를 다운로드할 수 있게 됩니다.



## 질문: 154 +++

한 회사가 AWS에서 전적으로 실행되는 시스템에 대한 외부 감사를 받고 있습니다. 

SysOps 관리자는 AWS에서 관리하는 인프라에 대한 PCI DSS(Payment Card Industry Data Security Standard) 준수에 대한 문서를 제공해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1. AWS Artifact 포털에서 해당 보고서를 다운로드하여 감사자에게 제공합니다.
2. AWS CloudTrail 로그 파일의 전체 사본을 다운로드하여 감사자에게 제공합니다.
3. AWS CloudWatch 로그의 전체 사본을 다운로드하여 감사자에게 제공합니다.
4. 감사자에게 프로덕션 AWS 계정에 대한 관리 액세스 권한을 제공하여 감사자가 규정 준수 여부를 확인할 수 있도록 합니다. 


SysOps 관리자가 PCI DSS 준수에 대한 문서를 제공하기 위해 가장 적절한 조치는 
**1. AWS Artifact 포털에서 해당 보고서를 다운로드하여 감사자에게 제공합니다.**입니다.

### 이유:

1. **AWS Artifact**는 AWS가 특정 보안 및 규정 준수 표준에 대한 준수 보고서 및 인증서를 제공하는 서비스입니다. PCI DSS 보고서와 같은 공식 보고서를 다운로드하여 감사자에게 제공함으로써, AWS에서 관리하는 인프라가 PCI DSS 요구 사항을 충족한다는 것을 입증할 수 있습니다.

2. **기타 옵션들**:
   - **2. AWS CloudTrail 로그 파일의 전체 사본을 다운로드하여 감사자에게 제공합니다.**: CloudTrail 로그는 모든 API 호출을 기록하지만, PCI DSS 준수 여부를 직접적으로 입증하는 데 필요한 문서가 아닙니다.
   - **3. AWS CloudWatch 로그의 전체 사본을 다운로드하여 감사자에게 제공합니다.**: CloudWatch 로그는 모니터링 및 운영 데이터를 포함하지만, PCI DSS 준수를 직접적으로 나타내는 문서가 아닙니다.
   - **4. 감사자에게 프로덕션 AWS 계정에 대한 관리 액세스 권한을 제공하여 감사자가 규정 준수 여부를 확인할 수 있도록 합니다.**: 이는 보안 및 규정 준수 요구 사항을 위험에 빠뜨릴 수 있으며, 감사자에게 직접적인 액세스를 부여하는 것은 일반적으로 권장되지 않습니다.

따라서, AWS Artifact 포털에서 PCI DSS 관련 보고서를 다운로드하여 제공하는 것이 가장 안전하고 적절한 접근 방식입니다.




## 질문: 155

한 회사가 Amazon EC2 및 AWS Lambda와 관련된 비용을 줄이기 위한 이니셔티브를 가지고 있습니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1. Amazon Athena를 사용하여 AWS 비용 및 사용 보고서를 분석하여 비용 절감 방안을 파악합니다.
2. 계정 지출이 예산의 80%에 도달하면 알림을 보내는 AWS Budgets 알림을 만듭니다.
3. Amazon EC2 콘솔을 통해 예약 인스턴스를 구매하세요.
4. AWS Compute Optimizer를 사용하여 제공된 권장 사항에 따라 조치를 취하세요.

SysOps 관리자가 Amazon EC2 및 AWS Lambda와 관련된 비용을 줄이기 위한 가장 적절한 조치는 
**4. AWS Compute Optimizer를 사용하여 제공된 권장 사항에 따라 조치를 취하세요.**입니다.

### 이유:

1. **AWS Compute Optimizer**는 현재 사용 중인 리소스의 사용 패턴을 분석하고, 보다 비용 효율적인 인스턴스 유형이나 크기로의 변경을 권장하여 비용 절감을 도와줍니다. EC2 인스턴스와 Lambda 함수의 사용 패턴을 기반으로 최적의 리소스를 추천받을 수 있습니다.

2. **기타 옵션들**:
   - **1. Amazon Athena를 사용하여 AWS 비용 및 사용 보고서를 분석하여 비용 절감 방안을 파악합니다.**: Athena를 사용하여 데이터를 분석하는 것은 유용하지만, 비용 절감을 위한 직접적인 조치를 제공하지는 않습니다.
   - **2. 계정 지출이 예산의 80%에 도달하면 알림을 보내는 AWS Budgets 알림을 만듭니다.**: 예산 알림은 비용을 모니터링하는 데 유용하지만, 비용 절감 조치를 자동으로 제공하지는 않습니다.
   - **3. Amazon EC2 콘솔을 통해 예약 인스턴스를 구매하세요.**: 예약 인스턴스는 장기적으로 비용 절감을 제공하지만, 사용량을 최적화하는 데 필요한 분석을 제공하지 않으므로, 단기적으로는 더 좋은 선택이 아닐 수 있습니다.

따라서, **AWS Compute Optimizer**를 활용하는 것이 EC2 및 Lambda의 비용을 효과적으로 줄이는 가장 직접적이고 실행 가능한 방법입니다.




## 질문: 156 +++++

어떤 회사는 모든 Amazon EC2 인스턴스에 IPv6만 사용하고 싶어합니다.

EC2 인스턴스는 인터넷에서 액세스할 수 없어야 하지만, EC2 인스턴스는 인터넷에 액세스할 수 있어야 합니다. 
이 회사는 듀얼 스택 VPC와 IPv6 전용 서브넷을 만듭니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 VPC를 어떻게 구성해야 합니까?

1. NAT 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 NAT 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
2. 인터넷 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 인터넷 게이트웨이로 가리키는 엔트리를 포함하는 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
3. Create and attach an egress-only internet gateway. 모든 IPv6 트래픽을 egress-only internet gateway로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
4. 인터넷 게이트웨이와 NAT 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 인터넷 게이트웨이로, 모든 IPv4 트래픽을 NAT 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
 


회사의 요구 사항은 EC2 인스턴스가 **인터넷에서 액세스할 수 없지만**, **인터넷으로 나가는 트래픽은 허용**해야 한다는 것입니다. 이를 충족하기 위해서는 IPv6 전용 환경에서 인터넷으로 나가는 트래픽만 허용하는 **egress-only internet gateway**를 사용하는 것이 적합합니다.

따라서 올바른 구성 방법은 **3번: egress-only internet gateway를 생성하고 연결**하는 것입니다. 
사용자 지정 경로 테이블에 모든 IPv6 트래픽을 egress-only internet gateway로 가리키는 항목을 추가하고, 이 경로 테이블을 IPv6 전용 서브넷에 연결하면 EC2 인스턴스가 인터넷에 나가는 트래픽은 허용되지만, 외부에서 인스턴스로의 트래픽은 차단됩니다.


## 질문: 157 ++

한 회사에는 두 개의 가용성 영역에 걸쳐 애플리케이션 로드 밸런서(ALB) 뒤에 있는 두 개의 Amazon EC2 인스턴스에서 실행되는 기존 웹 애플리케이션이 있습니다. 

이 애플리케이션은 Amazon RDS Multi-AZ DB 인스턴스를 사용합니다. 
Amazon Route 53 레코드 세트는 동적 콘텐츠에 대한 요청을 로드 밸런서로 라우팅하고 정적 콘텐츠에 대한 요청을 Amazon S3 버킷으로 라우팅합니다. 
사이트 방문자는 로딩 시간이 매우 길다고 보고합니다.

웹사이트 성능을 개선하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

1. 정적 콘텐츠에 대한 Amazon CloudFront 캐싱을 추가합니다.
2. 로드 밸런서 리스너를 HTTPS에서 TCP로 변경합니다.
3. Amazon Route 53 지연 기반 라우팅을 활성화합니다.
4. 웹 서버에 Amazon EC2 자동 확장을 구현합니다.
5. 정적 콘텐츠를 Amazon S3에서 웹 서버로 옮깁니다.

웹사이트 성능을 개선하기 위해 선택할 수 있는 두 가지 조치는 다음과 같습니다:

1. **정적 콘텐츠에 대한 Amazon CloudFront 캐싱을 추가합니다.**
   - Amazon CloudFront는 콘텐츠 전송 네트워크(CDN)로, 정적 콘텐츠를 Edge 위치에서 캐싱하여 사용자에게 더 가까운 위치에서 제공할 수 있습니다. 이를 통해 정적 콘텐츠의 로딩 시간을 단축하고 전체 웹사이트 성능을 향상시킬 수 있습니다.

4. **웹 서버에 Amazon EC2 자동 확장을 구현합니다.**
   - EC2 자동 확장은 트래픽 증가에 따라 EC2 인스턴스를 자동으로 추가하거나 제거하여 웹 서버의 용량을 조정할 수 있습니다. 이를 통해 사용자 요청을 보다 효율적으로 처리하고 로딩 시간을 개선할 수 있습니다.

### 기타 옵션들에 대한 설명:

2. **로드 밸런서 리스너를 HTTPS에서 TCP로 변경합니다.**
   - HTTPS를 TCP로 변경하면 보안 연결이 제거되며, 이는 사용자 데이터의 안전성을 저하시킬 수 있습니다. HTTPS를 유지하면서 성능을 개선하는 것이 더 적절합니다.

3. **Amazon Route 53 지연 기반 라우팅을 활성화합니다.**
   - 지연 기반 라우팅은 사용자와 가장 가까운 리전의 리소스를 사용하도록 하지만, 이미 ALB와 RDS를 사용하고 있으므로 이 옵션이 웹사이트의 성능을 크게 개선할 것이라고 보장할 수는 없습니다.

5. **정적 콘텐츠를 Amazon S3에서 웹 서버로 옮깁니다.**
   - 이는 정적 콘텐츠를 S3의 장점을 활용하지 못하게 하며, 오히려 성능을 저하시킬 수 있습니다. S3는 정적 콘텐츠 제공에 최적화되어 있으므로 S3에 두는 것이 더 좋습니다.

결론적으로, **CloudFront를 사용하여 정적 콘텐츠를 캐싱하고, EC2 자동 확장을 통해 트래픽을 처리하는** 것이 웹사이트 성능을 개선하는 가장 효과적인 방법입니다.



## 질문: 158 ++++

한 회사가 온프레미스에서 애플리케이션을 실행하고 있으며 데이터 백업에 AWS를 사용하려고 합니다. 

모든 데이터는 로컬에서 사용할 수 있어야 합니다. 
백업 애플리케이션은 POSIX(Portable Operating System Interface)와 호환되는 블록 기반 스토리지에만 쓸 수 있습니다.

어떤 백업 솔루션이 이러한 요구 사항을 충족할까요?

1. 데이터 백업의 대상으로 Amazon S3를 사용하도록 백업 소프트웨어를 구성합니다.
2. 데이터 백업의 대상으로 Amazon S3 Glacier를 사용하도록 백업 소프트웨어를 구성합니다.
3. AWS Storage Gateway를 사용하고 게이트웨이 캐시 볼륨을 사용하도록 구성합니다.
4. AWS Storage Gateway를 사용하고 게이트웨이에 저장된 볼륨을 사용하도록 구성합니다.

이 회사의 요구 사항을 충족하기 위한 적합한 백업 솔루션은 
**3. AWS Storage Gateway를 사용하고 게이트웨이 캐시 볼륨을 사용하도록 구성합니다.**입니다.

### 이유:
- **AWS Storage Gateway**는 온프레미스 애플리케이션과 AWS 클라우드 간의 매개체 역할을 합니다. 특히 **캐시 볼륨** 모드는 온프레미스에 데이터 캐시를 유지하면서 AWS에 데이터를 백업할 수 있도록 도와줍니다. 이를 통해 데이터는 로컬에서 사용할 수 있고, POSIX 호환 블록 기반 스토리지에 쓸 수 있는 형식으로 제공됩니다.

### 기타 옵션들에 대한 설명:
1. **Amazon S3를 사용하도록 백업 소프트웨어를 구성합니다.**
   - Amazon S3는 객체 스토리지이며 POSIX 호환 블록 기반 스토리지가 아닙니다. 따라서 이 옵션은 요구 사항을 충족하지 않습니다.

2. **Amazon S3 Glacier를 사용하도록 백업 소프트웨어를 구성합니다.**
   - S3 Glacier는 장기 보관 용도로 설계된 스토리지로, 데이터 접근 속도가 느립니다. 또한, POSIX 호환이 아니므로 이 옵션도 요구 사항을 충족하지 않습니다.

4. **AWS Storage Gateway를 사용하고 게이트웨이에 저장된 볼륨을 사용하도록 구성합니다.**
   - 게이트웨이에 저장된 볼륨은 온프레미스에서만 사용할 수 있으며, POSIX 호환 스토리지가 아닌 블록 스토리지로는 사용하기 어렵습니다. 그러나 이 옵션은 원활한 접근성을 보장하지 않기 때문에 적합하지 않습니다.

결론적으로, AWS Storage Gateway의 **캐시 볼륨**을 사용하는 것이 온프레미스 데이터 백업을 AWS에 안전하게 저장하면서도 로컬에서 즉시 접근할 수 있는 최적의 솔루션입니다.




## 질문: 159 +++++

글로벌 기업이 내부 웹 포털을 통해 대량의 개인 식별 정보(PII)를 처리합니다. 

이 회사의 애플리케이션은 AWS Direct Connect 연결을 통해 AWS에 연결된 기업 데이터 센터에서 실행됩니다. 
이 애플리케이션은 PII를 Amazon S3에 저장합니다. 규정 준수 요구 사항에 따라 웹 포털에서 Amazon S3로의 트래픽은 인터넷을 통과해서는 안 됩니다.

SysOps 관리자는 규정 준수 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. Amazon S3에 대한 인터페이스 VPC 엔드포인트를 프로비저닝합니다. 인터페이스 엔드포인트를 사용하도록 애플리케이션을 수정합니다.
2. AWS 네트워크 방화벽을 구성하여 트래픽을 내부 S3 주소로 리디렉션합니다.
3. S3 경로 스타일 엔드포인트를 사용하도록 애플리케이션을 수정합니다.
4. 트래픽을 내부 S3 주소로 리디렉션하기 위해 다양한 VPC 네트워크 ACL을 설정합니다.

이 회사의 요구 사항을 충족하기 위해 SysOps 관리자가 해야 할 조치는 
**1. Amazon S3에 대한 인터페이스 VPC 엔드포인트를 프로비저닝합니다. 인터페이스 엔드포인트를 사용하도록 애플리케이션을 수정합니다.**입니다.

### 이유:
- **Amazon S3에 대한 인터페이스 VPC 엔드포인트**를 사용하면 AWS의 S3 서비스와 안전하게 통신할 수 있으며, 이 트래픽은 인터넷을 통과하지 않고 AWS 네트워크 내에서만 전송됩니다. 이는 PII와 같은 민감한 데이터를 처리하는 애플리케이션에 적합한 방법입니다. 
- 애플리케이션을 수정하여 이 엔드포인트를 사용하면 규정 준수 요구 사항을 완전히 충족하면서 보안이 강화됩니다.

### 기타 옵션들에 대한 설명:
2. **AWS 네트워크 방화벽을 구성하여 트래픽을 내부 S3 주소로 리디렉션합니다.**
   - AWS 네트워크 방화벽은 보안 및 필터링 기능을 제공하지만, 트래픽이 인터넷을 지나가지 않도록 하는 직접적인 해결책이 아닙니다. 이 방법은 요구 사항을 충족하지 못할 수 있습니다.

3. **S3 경로 스타일 엔드포인트를 사용하도록 애플리케이션을 수정합니다.**
   - 경로 스타일 엔드포인트는 S3 버킷에 접근하는 방법을 변경하는 것일 뿐, 인터넷을 통한 트래픽을 차단하는 데는 영향을 주지 않습니다.

4. **트래픽을 내부 S3 주소로 리디렉션하기 위해 다양한 VPC 네트워크 ACL을 설정합니다.**
   - 네트워크 ACL을 설정하는 것은 보안과 관련이 있지만, 이는 복잡하고 관리하기 어렵고, 여전히 인터넷을 통한 트래픽이 발생할 수 있습니다.

결론적으로, **Amazon S3에 대한 인터페이스 VPC 엔드포인트**를 프로비저닝하는 것이 PII를 안전하게 처리하고 인터넷을 통과하지 않도록 하는 가장 효과적인 방법입니다.



## 질문: 160 ++

SysOps 관리자가 Amazon EC2 Auto Scaling 그룹의 확장 이벤트를 알아차렸습니다. 

Amazon CloudWatch는 연관된 Application Load Balancer의 RequestCount 메트릭에서 급증을 보여줍니다. 
관리자는 요청 소스의 IP 주소를 알고 싶어합니다.
관리자는 이 정보를 어디에서 찾을 수 있습니까?

1. 자동 크기 조정 로그
2. AWS CloudTrail 로그
3. EC2 인스턴스 로그
4. Elastic Load Balancer 액세스 로그

관리자가 요청 소스의 IP 주소를 찾기 위해 확인해야 할 것은 **4. Elastic Load Balancer 액세스 로그**입니다.

### 이유:
- **Elastic Load Balancer (ELB) 액세스 로그**는 ALB 또는 NLB를 통해 처리된 모든 요청의 상세 정보를 기록하며, 각 요청에 대한 원본 IP 주소를 포함합니다. 이 로그를 통해 특정 시간대의 요청 소스를 분석하고, 어떤 IP 주소가 요청을 발생시켰는지를 확인할 수 있습니다.

### 기타 옵션들에 대한 설명:
1. **자동 크기 조정 로그**:
   - Auto Scaling 이벤트에 대한 정보는 기록하지만, 요청 소스의 IP 주소와 관련된 정보는 포함되지 않습니다.

2. **AWS CloudTrail 로그**:
   - CloudTrail은 AWS API 호출에 대한 기록을 제공합니다. 이 로그는 EC2 인스턴스의 생성, 종료, 수정과 같은 API 이벤트를 기록하지만, 요청의 원본 IP 주소와는 관련이 없습니다.

3. **EC2 인스턴스 로그**:
   - EC2 인스턴스의 로그는 해당 인스턴스에서 실행 중인 애플리케이션의 로깅에 대한 정보일 수 있지만, ALB에서의 요청 소스 IP 주소를 포함하지 않을 수 있습니다.

결론적으로, 요청 소스의 IP 주소를 확인하기 위해서는 **Elastic Load Balancer 액세스 로그**를 확인하는 것이 가장 적절한 방법입니다.

## 질문: 161

회사의 SysOps 관리자가 회사 웹 애플리케이션 앞에 퍼블릭 네트워크 로드 밸런서(NLB)를 배포합니다. 

웹 애플리케이션은 어떠한 Elastic IP 주소도 사용하지 않습니다. 
사용자는 회사의 도메인 이름을 사용하여 웹 애플리케이션에 액세스해야 합니다. SysOps 관리자는 트래픽을 NLB로 라우팅하도록 Amazon Route 53을 구성해야 합니다.

어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요?

1. NLB에 대한 Route 53 AAAA 레코드를 생성합니다.
2. NL에 대한 Route 53 별칭 레코드를 만듭니다.
3. NLB에 대한 Route 53 CAA 레코드를 생성합니다.
4. NLB에 대한 Route 53 CNAME 레코드를 만듭니다.

SysOps 관리자가 웹 애플리케이션 앞에 퍼블릭 네트워크 로드 밸런서(NLB)를 배포하고, 사용자가 회사의 도메인 이름을 사용하여 해당 애플리케이션에 접근할 수 있도록 트래픽을 NLB로 라우팅하기 위해서는 
**2. NLB에 대한 Route 53 별칭 레코드를 만듭니다**가 가장 비용 효율적이고 적절한 솔루션입니다.

이 회사는 다른 AWS 지역에서 정기 백업을 제공하고자 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. DB 인스턴스를 수정합니다. 지역 간 자동 백업을 활성화합니다.
2. 다른 지역에서 RDS 읽기 복제본을 만듭니다. 읽기 복제본의 스냅샷을 만듭니다.
3. AWS Database Migration Service(AWS DMS)를 사용리 비용이 없고**, Route 53의 내부 DNS 구조에서 최적화된 방식으로 작동하여 트래픽을 더 효율적으로 처리합니다.
- 또한, 별칭 레코드는 **루트 도메인**(예: example.com)에도 사용할 수 있는 반면, CNAME 레코드는 루트 도메인에서 사용할 수 없습니다.

### 다른 옵션들에 대한 설명:
1. **NLB에 대한 Route 53 AAAA 레코드를 생성합니다**:
   - AAAA 레코드는 IPv6 주소를 지정하는 레코드로, NLB에 IPv6 지원을 추가하는 것과는 관련이 없습니다.

3. **NLB에 대한 Route 53 CAA 레코드를 생성합니다**:
   - CAA 레코드는 SSL/TLS 인증서 발급을 허용하는 도메인에 대한 제어를 제공하지만, NLB 트래픽 라우팅에는 직접적인 관련이 없습니다.

4. **NLB에 대한 Route 53 CNAME 레코드를 만듭니다**:
   - CNAME 레코드는 다른 도메인 이름으로 리디렉션하지만, **루트 도메인에서는 사용할 수 없**으며, 별칭 레코드보다는 일반적으로 비효율적입니다.

결론적으로, NLB와 도메인 간의 트래픽 라우팅을 설정하기 위해 Route 53의 별칭 레코드를 사용하는 것이 가장 비용 효율적이고 실용적인 방법입니다.



## 질문: 162 +++++

한 회사가 암호화된 Amazon RDS for Oracle DB 인스턴스를 실행합니다. 

이 회사는 다른 AWS 지역에서 정기 백업을 제공하고자 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. DB 인스턴스를 수정합니다. 지역 간 자동 백업을 활성화합니다.
2. 다른 지역에서 RDS 읽기 복제본을 만듭니다. 읽기 복제본의 스냅샷을 만듭니다.
3. AWS Database Migration Service(AWS DMS)를 사용하여 다른 지역의 DB 인스턴스로 데이터를 복사합니다.
4. DB 인스턴스에서 암호화를 일시적으로 해제합니다. 스냅샷을 찍습니다. 스냅샷을 다른 Region에 복사합니다.

암호화된 Amazon RDS for Oracle DB 인스턴스를 다른 AWS 지역으로 정기 백업하기 위한 가장 운영 효율적인 솔루션은 
**2. 다른 지역에서 RDS 읽기 복제본을 만듭니다. 읽기 복제본의 스냅샷을 만듭니다.**입니다.

### 이유:
- **읽기 복제본 생성**: RDS의 읽기 복제본을 만들면 원본 DB 인스턴스의 데이터가 다른 지역에 실시간으로 복제됩니다. 이는 변경 사항이 발생할 때마다 데이터를 자동으로 업데이트하므로 운영 효율성을 높입니다.
- **스냅샷 생성**: 읽기 복제본의 스냅샷을 만들면 다른 지역에서 데이터의 정기 백업을 생성할 수 있습니다. 이 스냅샷은 백업 및 복구를 위한 안정적인 수단을 제공하며, 필요 시 복원할 수 있습니다.
- **운영 효율성**: 이 방법은 자동화 및 관리가 용이하며, RDS 서비스가 관리하는 인프라로 인해 유지 보수에 대한 부담이 줄어듭니다. 또한, 이 방법은 암호화된 상태를 유지할 수 있습니다.

### 다른 옵션들에 대한 설명:
1. **DB 인스턴스를 수정합니다. 지역 간 자동 백업을 활성화합니다.**: 
   - RDS는 지역 간 자동 백업을 지원하지 않으므로 이 옵션은 유효하지 않습니다.

3. **AWS Database Migration Service(AWS DMS)를 사용하여 다른 지역의 DB 인스턴스로 데이터를 복사합니다.**:
   - DMS를 사용하는 방법은 가능하지만, 설정이 복잡하고 관리 오버헤드가 크며, 지속적인 동기화나 정기적인 백업 솔루션으로는 비효율적일 수 있습니다.

4. **DB 인스턴스에서 암호화를 일시적으로 해제합니다. 스냅샷을 찍습니다. 스냅샷을 다른 Region에 복사합니다.**:
   - 이 방법은 암호화된 DB 인스턴스의 암호화를 해제해야 하므로 보안 위험을 초래할 수 있습니다. 또한, 일시적으로 암호화를 해제하는 것은 비효율적이며 운영 상의 불편함을 초래할 수 있습니다.

결론적으로, 읽기 복제본을 생성하고 그 스냅샷을 사용하는 방법이 암호화를 유지하면서도 정기적으로 데이터를 백업하는 가장 효율적이고 안전한 방법입니다.



## 질문: 163

한 회사가 웹사이트의 새 버전을 출시하고 있습니다. 

경영진은 회사 고객의 20%에 한정된 출시로 새 웹사이트를 배포하려고 합니다. 이 회사는 웹사이트의 DNS 솔루션에 Amazon Route 53을 사용합니다.
어떤 구성이 이러한 요구 사항을 충족할까요?

1. 장애 조치 라우팅 정책을 만듭니다. 정책 내에서 웹사이트 트래픽의 80%를 원래 리소스로 보내도록 구성합니다. 나머지 20%의 트래픽을 새 리소스를 가리키는 장애 조치 레코드로 구성합니다.
2. 다중값 답변 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스의 이름과 IP 주소로 4개의 레코드를 만듭니다. 새 리소스의 이름과 IP 주소로 1개의 레코드를 구성합니다.
3. 지연 기반 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스를 가리키는 레코드를 80의 가중치로 구성합니다. 새 리소스를 가리키는 레코드를 20의 가중치로 구성합니다.
4. 가중치가 적용된 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스를 가리키는 레코드에 대해 가중치 80을 구성합니다. 새 리소스를 가리키는 레코드에 대해 가중치 20을 구성합니다.

경영진이 웹사이트의 새 버전을 고객의 20%에 한정하여 출시하기 위해 필요한 구성은
**4. 가중치가 적용된 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스를 가리키는 레코드에 대해 가중치 80을 구성합니다. 새 리소스를 가리키는 레코드에 대해 가중치 20을 구성합니다.**입니다.

### 이유:
- **가중치 기반 라우팅**: 이 방법은 DNS 쿼리에 대한 응답으로 특정 비율의 트래픽을 두 개의 리소스 간에 분배하는 데 가장 적합합니다. 원래 웹사이트에 대해 80%의 가중치를 설정하고, 새 웹사이트에 대해 20%의 가중치를 설정하면 요청을 비율에 따라 적절히 분배할 수 있습니다.
- **비율 기반 제어**: 이 구성을 통해 웹사이트의 새 버전이 실행되는 동안 원래 리소스의 비율이 높게 유지되며, 고객의 20%만이 새 버전을 사용하도록 할 수 있습니다. 이는 새 버전의 안정성과 성능을 확인하는 데 도움을 줍니다.

### 다른 옵션들에 대한 설명:
1. **장애 조치 라우팅 정책**: 이 정책은 주로 한 리소스가 실패했을 때 다른 리소스로 트래픽을 전환하는 데 사용됩니다. 20%의 트래픽을 새 리소스에 보내기 위한 구성에는 적합하지 않습니다.

2. **다중값 답변 라우팅 정책**: 이 정책은 DNS 응답에 여러 IP 주소를 반환하는 데 사용되지만, 트래픽을 80%와 20%로 세밀하게 조절할 수는 없습니다.

3. **지연 기반 라우팅 정책**: 이 정책은 가장 낮은 지연 시간을 가진 리소스를 선택하는 데 중점을 두므로, 고객의 특정 비율에 대한 트래픽 분배를 지원하지 않습니다.

결론적으로, **가중치가 적용된 라우팅 정책**이 필요에 가장 적합한 해결책입니다.

## 질문: 164

SysOps 관리자가 Amazon EC2 인스턴스, Elastic Load Balancer(ELB) 및 Amazon RDS DB 인스턴스를 프로비저닝하는 AWS CloudFormation 템플릿을 만들었습니다. 

스택 생성 중에 EC2 인스턴스 생성과 ELB 생성이 성공했습니다. 그러나 DB 인스턴스 생성은 실패했습니다.

이 시나리오에서 CloudFormation의 기본 동작은 무엇입니까?

1. CloudFormation은 스택을 롤백하고 삭제합니다.
2. CloudFormation은 스택을 롤백하지만 스택을 삭제하지는 않습니다.
3. CloudFormation은 사용자에게 스택을 롤백할지 아니면 계속할지 묻습니다.
4. CloudFormation은 스택을 성공적으로 완료하지만 DB 인스턴스에 대해 실패 상태를 보고합니다.

CloudFormation에서 스택 생성 중에 리소스 생성이 실패하면 기본 동작은 
**1. CloudFormation은 스택을 롤백하고 삭제합니다.**입니다.

### 이유:
- **스택 롤백**: CloudFormation은 리소스 생성 중 오류가 발생하면 자동으로 이전 상태로 되돌리기 위해 스택을 롤백합니다. 이는 생성된 리소스가 중간 상태에 있을 때, 나중에 발생할 수 있는 문제를 방지하는데 도움을 줍니다.
- **리소스 상태**: EC2 인스턴스와 ELB가 성공적으로 생성된 경우에도 DB 인스턴스의 생성이 실패하면, 전체 스택 생성 프로세스는 실패로 간주되며, 생성된 리소스는 모두 삭제됩니다.

이러한 동작은 AWS CloudFormation의 기본 동작으로, 스택을 안전하게 유지하고 일관성을 보장하기 위해 설계되었습니다.


## 질문: 165

SysOps 관리자는 AWS Lambda 함수의 호출을 자동화해야 합니다. 

Lambda 함수는 Amazon S3 버킷에 저장된 데이터에 대한 보고서를 생성하기 위해 매일 마지막에 실행되어야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. Amazon S3와 Lambda 함수를 대상으로 하는 이벤트 패턴이 있는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
2. 일정과 Lambda 함수를 대상으로 하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
3. S3 버킷에서 객체가 변경될 때마다 Lambda 함수를 호출하는 S3 이벤트 알림을 만듭니다.
4. Cron 작업으로 Amazon EC2 인스턴스를 배포하여 Lambda 함수를 호출합니다.

AWS Lambda 함수를 매일 실행하여 Amazon S3 버킷에 저장된 데이터에 대한 보고서를 생성해야 하는 경우, 가장 운영 효율적인 솔루션은 
**2. 일정과 Lambda 함수를 대상으로 하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.**입니다.

### 이유:
- **스케줄링**: Amazon EventBridge (구 Amazon CloudWatch Events)는 일정에 따라 Lambda 함수를 호출할 수 있는 기능을 제공합니다. 매일 특정 시간에 Lambda 함수를 실행하도록 설정할 수 있어, 자동화된 스케줄링이 가능해집니다.
- **운영 효율성**: Lambda를 직접 호출하기 때문에 추가적인 서버나 관리 리소스가 필요 없으며, AWS 관리 콘솔이나 AWS CLI를 통해 쉽게 설정하고 관리할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
1. **S3와 Lambda 이벤트 패턴**: S3 이벤트는 객체가 생성되거나 수정될 때 호출되므로 매일 특정 시간에 실행하는 데 적합하지 않습니다.
3. **S3 이벤트 알림**: 이 옵션은 S3 버킷의 변경에 따라 Lambda 함수를 호출하지만, 매일 특정 시간에 실행할 수 있는 기능이 없습니다.
4. **EC2 Cron 작업**: EC2 인스턴스를 배포하고 유지 관리하는 것은 운영 효율성에 좋지 않으며, Lambda의 서버리스 특성을 활용하지 못하는 방식입니다. 

따라서 **Amazon EventBridge 규칙을 사용하는 것이 가장 효율적이고 운영적으로 적합한 솔루션**입니다.

## 질문: 166 ++

한 회사가 Amazon S3에 호스팅된 새로운 정적 웹사이트를 출시합니다. 

정적 웹사이트 호스팅 기능이 버킷에서 활성화되었고 콘텐츠가 업로드되었습니다. 하지만 사이트로 이동하면 다음과 같은 오류 메시지가 표시됩니다.

403 Forbidden - Access Denied

이 오류를 해결하려면 어떤 변경을 해야 합니까?

1. 모든 사용자에게 버킷에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가합니다.
2. 모든 사용자에게 버킷 객체에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가합니다.
3. 버킷에 대한 읽기 액세스를 거부하는 기본 버킷 정책을 제거합니다.
4. 버킷에서 CORS(교차 출처 리소스 공유)를 구성합니다.

"403 Forbidden - Access Denied" 오류 메시지가 표시되는 경우, Amazon S3에서 호스팅된 정적 웹사이트에 접근할 수 없다는 것을 의미합니다. 이 문제를 해결하기 위해 가장 적합한 변경 사항은 
**2. 모든 사용자에게 버킷 객체에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가합니다.**입니다.

### 이유:
- **객체 접근 권한**: 정적 웹사이트의 콘텐츠(HTML, CSS, JavaScript 파일 등)는 S3 버킷의 객체로 저장됩니다. 모든 사용자에게 이 객체들에 대한 읽기 액세스를 부여해야만 웹사이트 방문자가 이 콘텐츠를 접근할 수 있습니다.
- **버킷 정책**: 버킷 정책을 사용하여 특정 조건(예: 모든 사용자에 대한 읽기 권한)을 지정하여 S3 객체에 대한 접근을 제어할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
1. **버킷에 대한 읽기 액세스 권한**: 버킷 자체에 대한 권한이 아닌 객체에 대한 권한이 필요합니다. 따라서 "버킷" 자체가 아니라 "버킷 객체"에 대한 읽기 권한을 부여해야 합니다.
3. **기본 버킷 정책 제거**: 기본적으로 S3 버킷은 비공개로 설정되며, 특정 권한을 부여하지 않으면 접근이 차단됩니다. 하지만 기본 정책을 제거하기보다는 필요한 권한을 추가하는 것이 더 좋습니다.
4. **CORS 구성**: CORS는 웹 브라우저의 보안 정책으로, 서로 다른 출처 간의 요청을 허용하는 데 사용됩니다. 하지만 CORS 설정은 이 오류 메시지와는 관련이 없습니다.

결론적으로, **모든 사용자에게 버킷 객체에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가하는 것이 올바른 접근 방법입니다.**


## 질문: 167 +++

한 회사가 AWS Organizations를 사용합니다. 

SysOps 관리자가 관리 계정에서 AWS Compute Optimizer와 AWS 태그 정책을 사용하여 청구 패밀리의 모든 멤버 계정을 관리하려고 합니다. 
SysOps 관리자가 AWS Organizations 콘솔로 이동하지만 관리 계정을 통해 태그 정책을 활성화할 수 없습니다.

이 문제의 원인은 무엇일까요?

1. 조직에서 모든 기능이 활성화되지 않았습니다.
2. 통합 결제가 활성화되지 않았습니다.
3. 회원 계정에는 비용 할당을 위한 태그가 활성화되어 있지 않습니다.
4. 멤버 계정에서 Compute Optimizer에 대한 신뢰할 수 있는 액세스를 수동으로 활성화하지 않았습니다.
 

SysOps 관리자가 AWS Organizations 콘솔에서 태그 정책을 활성화할 수 없는 원인은 
**1. 조직에서 모든 기능이 활성화되지 않았습니다.**입니다.

### 이유:
- **AWS Organizations의 모든 기능 활성화**: 태그 정책과 같은 고급 기능을 사용하려면 조직이 모든 기능 모드로 활성화되어 있어야 합니다. 기본 모드에서는 이러한 기능을 사용할 수 없습니다. 모든 기능 모드로 전환하면 태그 정책, 서비스 제어 정책(SCP) 및 기타 기능을 활용할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 문제가 아닙니다:
2. **통합 결제가 활성화되지 않았습니다**: 통합 결제는 여러 계정의 청구를 하나의 관리 계정으로 통합하는 기능이며, 태그 정책과는 직접적인 연관이 없습니다.
3. **회원 계정에는 비용 할당을 위한 태그가 활성화되어 있지 않습니다**: 비용 할당 태그는 태그 정책이 활성화된 이후에 적용되는 것이므로, 태그 정책을 활성화할 수 없다면 이 문제가 발생하지 않습니다.
4. **회원 계정에서 Compute Optimizer에 대한 신뢰할 수 있는 액세스를 수동으로 활성화하지 않았습니다**: Compute Optimizer의 신뢰할 수 있는 액세스는 태그 정책과는 별개의 설정으로, 태그 정책을 활성화하지 못하는 원인과는 관련이 없습니다.

결론적으로, **조직에서 모든 기능이 활성화되지 않아서 태그 정책을 활성화할 수 없는 것이 문제의 원인입니다.**



## 질문: 168 +++

한 회사가 Amazon S3 버킷에 미디어 콘텐츠를 저장하고 Amazon CloudFront를 사용하여 사용자에게 콘텐츠를 배포합니다. 

라이선스 조건으로 인해 회사는 일부 국가에서 콘텐츠를 배포할 권한이 없습니다. SysOps 관리자는 특정 국가에 대한 액세스를 제한해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. S3:LocationConstraint 조건에 따라 GetObject 작업을 거부하도록 S3 버킷 정책을 구성합니다.
2. 2차 오리진 액세스 ID(OAI)를 만듭니다. S3 버킷 정책을 구성하여 허가되지 않은 국가의 액세스를 방지합니다.
3. CloudFront 배포에서 지역 제한 기능을 활성화하여 허가되지 않은 국가의 액세스를 차단합니다.
4. 승인된 국가의 IP 주소에 대해서만 서명된 CloudFront URL을 생성하도록 애플리케이션을 업데이트합니다.

회사가 Amazon S3 버킷에 저장된 미디어 콘텐츠의 배포를 특정 국가에 대해 제한해야 할 때, 가장 운영 효율적인 솔루션은 
**3. CloudFront 배포에서 지역 제한 기능을 활성화하여 허가되지 않은 국가의 액세스를 차단합니다.**입니다.

### 이유:
- **CloudFront의 지역 제한 기능**: 이 기능을 사용하면 CloudFront 배포에 대한 요청을 특정 국가에서만 허용할 수 있습니다. 이는 간단하고 효율적인 방법으로, 회사가 라이선스 조건을 준수할 수 있도록 보장합니다. CloudFront는 요청의 IP 주소를 기반으로 국가를 식별하고, 허가되지 않은 국가에서의 액세스를 차단할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 덜 효율적입니다:
1. **S3:LocationConstraint 조건**: S3 버킷 정책을 사용하여 객체 접근을 거부하는 것은 특정 국가에 대한 액세스를 제어하는 데 적합하지 않으며, 이 경우에는 CloudFront를 통한 요청을 차단할 수 없습니다.
2. **2차 오리진 액세스 ID(OAI)**: OAI는 S3 버킷에 대한 액세스를 제어하는 방법이지만, 특정 국가의 요청을 차단하는 데는 적합하지 않습니다.
4. **서명된 CloudFront URL 생성**: 서명된 URL을 생성하는 방법도 허가된 국가의 요청을 관리하는 데 도움이 될 수 있지만, 이 방법은 구현이 복잡하고 관리해야 할 추가적인 로직이 필요합니다. 지역 제한 기능을 사용하는 것이 더 간단하고 관리하기 쉽습니다.

결론적으로, **CloudFront의 지역 제한 기능을 활성화하는 것이 가장 운영 효율적인 해결책입니다.**


## 질문: 169 +++

SysOps 관리자가 인터넷에 액세스해야 하는 IPv6 CIDR 블록이 있는 Amazon VPC를 만들었습니다. 

그러나 인터넷에서 VPC로의 액세스는 금지되어 있습니다. VPC에 필요한 구성 요소를 추가하고 구성한 후 관리자는 인터넷에 있는 도메인에 연결할 수 없습니다.

관리자는 경로 테이블에 어떤 추가 경로 대상 규칙을 추가해야 합니까?

1. Route ::/0 트래픽을 NAT 게이트웨이로
2. Route ::/0 인터넷 게이트웨이로의 트래픽
3. 0.0.0.0/0 트래픽을 출구 전용 인터넷 게이트웨이로 경로 지정
4. Route ::/0 트래픽을 이탈 전용 인터넷 게이트웨이로 전송

IPv6 CIDR 블록을 가진 Amazon VPC가 인터넷에 액세스하도록 설정하려면, **2. Route `::/0` 인터넷 게이트웨이로의 트래픽**을 추가해야 합니다.

### 이유:
- **인터넷 게이트웨이**: 인터넷과 VPC 간의 트래픽을 허용하는 역할을 하며, IPv4 및 IPv6 트래픽 모두를 지원합니다. `::/0` 경로를 추가하면 VPC 내의 모든 IPv6 트래픽이 인터넷으로 라우팅되도록 설정됩니다.
- 이 경로를 통해 VPC 내부에서 인터넷으로 나가는 IPv6 트래픽이 올바르게 전달될 수 있습니다.

### 다른 옵션에 대한 설명:
1. **Route `::/0` 트래픽을 NAT 게이트웨이로**: NAT 게이트웨이는 IPv4 트래픽을 인터넷으로 전달하는 데 사용됩니다. IPv6 트래픽에 대해선 NAT 게이트웨이를 사용할 수 없으므로 이 옵션은 적합하지 않습니다.
3. **0.0.0.0/0 트래픽을 출구 전용 인터넷 게이트웨이로 경로 지정**: 0.0.0.0/0는 IPv4 주소에 해당하며, IPv6 주소와는 관련이 없습니다.
4. **Route `::/0` 트래픽을 이탈 전용 인터넷 게이트웨이로 전송**: 이탈 전용 인터넷 게이트웨이는 AWS에서 제공하는 IPv4 전용 옵션으로 IPv6 트래픽에는 적용되지 않습니다.

따라서, 올바른 구성은 **Route `::/0` 인터넷 게이트웨이로의 트래픽**입니다.

## 질문: 170 ++++

한 회사가 여러 쓰기 집약적 애플리케이션을 호스팅합니다. 

이러한 애플리케이션은 단일 Amazon EC2 인스턴스에서 실행되는 MySQL 데이터베이스를 사용합니다. 이 회사는 SysOps 관리자에게 멀티 테넌트 워크로드에 이상적인 고가용성 데이터베이스 솔루션을 구현해 달라고 요청합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 구현해야 합니까?

1. MySQL에 대한 두 번째 EC2 인스턴스를 만듭니다. 두 번째 인스턴스를 읽기 복제본으로 구성합니다.
2. 데이터베이스를 Amazon Aurora DB 클러스터로 마이그레이션합니다. Aurora Replica를 추가합니다.
3. 데이터베이스를 Amazon Aurora 다중 마스터 DB 클러스터로 마이그레이션합니다.
4. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다

멀티 테넌트 워크로드에 이상적인 고가용성 데이터베이스 솔루션을 구현하기 위해 SysOps 관리자가 선택해야 할 솔루션은 
**3. 데이터베이스를 Amazon Aurora 다중 마스터 DB 클러스터로 마이그레이션합니다.**입니다.

### 이유:
- **Amazon Aurora 다중 마스터 DB 클러스터**는 고가용성과 쓰기 집약적인 워크로드에 최적화된 솔루션입니다. 이 구성은 여러 리전에서 동시에 읽기 및 쓰기가 가능하므로, 멀티 테넌트 환경에서의 성능과 가용성을 극대화할 수 있습니다.
- Aurora는 자동 스케일링, 고가용성, 복구 기능을 제공하며, 읽기 및 쓰기 분산이 가능하여 성능 저하를 방지합니다.

### 다른 옵션에 대한 설명:
1. **MySQL에 대한 두 번째 EC2 인스턴스를 만듭니다. 두 번째 인스턴스를 읽기 복제본으로 구성합니다.**: 이 방법은 읽기 전용 복제본을 추가하지만, 쓰기 집약적인 애플리케이션에 대한 고가용성을 제공하지 않습니다.
   
2. **데이터베이스를 Amazon Aurora DB 클러스터로 마이그레이션합니다. Aurora Replica를 추가합니다.**: Aurora 클러스터는 읽기 복제본을 추가할 수 있지만, 쓰기 성능을 고려할 때 다중 마스터 구성이 더 적합합니다.

4. **데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다.**: RDS for MySQL은 관리형 서비스로서 고가용성을 제공하지만, 쓰기 집약적 멀티 테넌트 애플리케이션에 대한 최적의 솔루션은 아닙니다.

결론적으로, **Amazon Aurora 다중 마스터 DB 클러스터**로의 마이그레이션이 가장 적합한 솔루션입니다.


## 질문: 171 +++

한 회사에는 Elastic Load Balancer(ELB) 뒤의 Amazon EC2 인스턴스 플릿에서 실행되는 메모리 집약적 애플리케이션이 있습니다. 

인스턴스는 Auto Scaling 그룹에서 실행됩니다. SysOps 관리자는 애플리케이션에 연결하는 사용자 수에 따라 애플리케이션이 확장될 수 있도록 해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. ELB에서 생성된 ActiveConnectionCount Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.
2. EL에서 생성된 mem_used Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.
3. 추가 연결을 지원하기 위해 자동 크기 조정 그룹의 EC2 인스턴스 수를 늘리려면 예약된 크기 조정 정책을 만듭니다.
4. ELB에 스크립트를 생성하고 배포하여 연결된 사용자 수를 사용자 정의 Amazon CloudWatch 메트릭으로 노출합니다. 메트릭을 사용하는 스케일링 정책을 만듭니다.
 
메모리 집약적 애플리케이션의 사용자 수에 따라 애플리케이션을 자동으로 확장할 수 있도록 하기 위해 SysOps 관리자가 선택해야 할 솔루션은
**1. ELB에서 생성된 ActiveConnectionCount Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.**입니다.

### 이유:
- **ActiveConnectionCount 메트릭**은 ELB가 현재 유지하고 있는 활성 연결 수를 추적합니다. 이는 애플리케이션의 사용량을 직접적으로 나타내며, 사용자 수가 증가함에 따라 연결 수가 늘어나는 것을 반영합니다. 
- 이 메트릭을 기반으로 확장 정책을 설정하면 사용자가 많아질 때 EC2 인스턴스를 자동으로 추가하여 애플리케이션이 원활하게 작동하도록 할 수 있습니다.

### 다른 옵션에 대한 설명:
2. **ELB에서 생성된 mem_used Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.**: 이 메트릭은 메모리 사용량을 나타내지만, 사용자 수와 직접적인 연관성이 낮아 원하는 목표를 달성하기 어려울 수 있습니다.

3. **추가 연결을 지원하기 위해 자동 크기 조정 그룹의 EC2 인스턴스 수를 늘리려면 예약된 크기 조정 정책을 만듭니다.**: 예약된 크기 조정 정책은 특정 시간에 인스턴스 수를 늘리거나 줄이는 데 유용하지만, 실시간 사용자 수 변화에 적응하지 못합니다.

4. **ELB에 스크립트를 생성하고 배포하여 연결된 사용자 수를 사용자 정의 Amazon CloudWatch 메트릭으로 노출합니다. 메트릭을 사용하는 스케일링 정책을 만듭니다.**: 이 접근 방식은 복잡성과 유지 보수 비용이 증가할 수 있으며, 기본 제공 메트릭을 사용하는 것이 더 효율적입니다.

결론적으로, **ActiveConnectionCount**를 사용하는 것이 자동 확장 솔루션으로 가장 효과적입니다.



## 질문: 172 ++

SysOps 관리자가 퍼블릭 서브넷과 프라이빗 서브넷을 포함하는 새 VPC를 만듭니다. 

SysOps 관리자가 프라이빗 서브넷에서 11개의 Amazon EC2 인스턴스를 성공적으로 시작합니다. SysOps 관리자가 동일한 서브넷에서 EC2 인스턴스를 하나 더 시작하려고 시도합니다. 그러나 SysOps 관리자는 사용 가능한 IP 주소가 충분하지 않다는 오류 메시지를 받습니다.

SysOps 관리자가 더 많은 EC2 인스턴스를 배포하려면 무엇을 해야 합니까?

1. CIDR 블록을 /27로 변경하려면 개인 서브넷을 편집합니다.
2. 두 번째 가용성 영역으로 확장하도록 개인 서브넷을 편집합니다.
3. 개인 서브넷에 추가적인 Elastic IP 주소를 할당합니다.
4. 필요한 EC2 인스턴스를 보관할 새로운 개인 서브넷을 만듭니다.

SysOps 관리자가 프라이빗 서브넷에서 더 많은 Amazon EC2 인스턴스를 배포하려면 
**4. 필요한 EC2 인스턴스를 보관할 새로운 개인 서브넷을 만듭니다.**를 선택하는 것이 가장 적합합니다.

### 이유:
- **IP 주소 부족 문제**: 현재 프라이빗 서브넷에 할당된 CIDR 블록이 충분한 IP 주소를 제공하지 않는 경우, 기존 서브넷에서 추가 인스턴스를 시작할 수 없습니다. EC2 인스턴스를 시작할 수 있는 IP 주소의 수는 서브넷의 CIDR 블록에 따라 제한됩니다. 
- **새 서브넷 생성**: 새로운 프라이빗 서브넷을 생성하면 추가 IP 주소를 할당받을 수 있어 더 많은 EC2 인스턴스를 배포할 수 있습니다. 

### 다른 옵션에 대한 설명:
1. **CIDR 블록을 /27로 변경하려면 개인 서브넷을 편집합니다.**: 서브넷의 CIDR 블록을 변경하면 현재 서브넷에 할당된 인스턴스가 영향을 받을 수 있으며, 이미 사용 중인 IP 주소를 해제해야 하므로 직접적으로 해결책이 아닙니다.

2. **두 번째 가용성 영역으로 확장하도록 개인 서브넷을 편집합니다.**: 단순히 가용성 영역을 변경한다고 해서 IP 주소의 수가 늘어나는 것은 아닙니다. 가용성 영역은 리소스를 배포하는 위치를 지정할 뿐입니다.

3. **개인 서브넷에 추가적인 Elastic IP 주소를 할당합니다.**: Elastic IP 주소는 퍼블릭 IP 주소이며, 프라이빗 서브넷 내의 인스턴스에 적용되지 않습니다. 프라이빗 서브넷의 인스턴스는 기본적으로 프라이빗 IP 주소를 사용합니다.

결론적으로, 새로운 개인 서브넷을 만드는 것이 더 많은 EC2 인스턴스를 배포하는 데 효과적인 해결책입니다.


## 질문: 173 +++++

회사는 여러 지리적 위치에서 잠재적인 무단 AWS Management Console 로그인에 대해 AWS 계정을 자동으로 모니터링해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

1. Amazon Cognito를 구성하여 손상된 IAM 자격 증명을 감지합니다.
2. Amazon Inspector를 설정합니다. 승인되지 않은 로그인에 대한 리소스를 스캔하고 모니터링합니다.
3. AWS Config를 설정합니다. 계정에 iam-policy-blacklisted-check 관리 규칙을 추가합니다.
4. Amazon GuardDuty를 구성하여 UnauthorizedAccess:IAMUser/ConsoleLoginSuccess.B 발견 사항을 모니터링합니다.

회사가 여러 지리적 위치에서 잠재적인 무단 AWS Management Console 로그인에 대해 AWS 계정을 자동으로 모니터링해야 하는 경우, 
**4. Amazon GuardDuty를 구성하여 UnauthorizedAccess:IAMUser/ConsoleLoginSuccess.B 발견 사항을 모니터링합니다.**가 가장 적합한 솔루션입니다.

### 이유:
- **Amazon GuardDuty**는 AWS 계정 및 리소스의 보안 위협을 자동으로 모니터링하고 탐지하는 서비스입니다. 
- **UnauthorizedAccess:IAMUser/ConsoleLoginSuccess.B**는 AWS Management Console에 대한 성공적인 로그인 시도를 탐지하는 GuardDuty의 발견 항목으로, 여러 지리적 위치에서의 의심스러운 로그인을 식별하는 데 유용합니다.
- GuardDuty는 지속적으로 로그를 분석하여 이상 징후를 감지하고, 잠재적인 무단 액세스 시도를 알림으로써 보안성을 높일 수 있습니다.

### 다른 옵션에 대한 설명:
1. **Amazon Cognito를 구성하여 손상된 IAM 자격 증명을 감지합니다.**: Amazon Cognito는 주로 인증 및 사용자 관리를 위한 서비스이며, IAM 자격 증명의 손상 여부를 직접적으로 모니터링하지 않습니다.

2. **Amazon Inspector를 설정합니다. 승인되지 않은 로그인에 대한 리소스를 스캔하고 모니터링합니다.**: Amazon Inspector는 애플리케이션 보안 및 취약점 평가 도구로, 로그인 시도를 모니터링하는 데 적합하지 않습니다.

3. **AWS Config를 설정합니다. 계정에 iam-policy-blacklisted-check 관리 규칙을 추가합니다.**: AWS Config는 리소스 구성을 모니터링하지만, 로그인 시도를 모니터링하는 데는 적합하지 않습니다. IAM 정책의 적합성을 평가하는 데는 유용할 수 있으나 로그인 시도 감지에는 한계가 있습니다.

따라서, Amazon GuardDuty를 사용하는 것이 가장 효과적이고 효율적인 방법입니다.

## 질문: 174

한 회사에 Amazon RDS DB 인스턴스가 있습니다. 

이 회사는 고가용성을 유지하면서 캐싱 서비스를 구현하고자 합니다.

어떤 작업 조합이 이러한 요구 사항을 충족할까요? (두 가지를 선택하세요.)

1. 데이터 저장소에 자동 검색을 추가합니다.
2. Memcached용 Amazon ElastiCache 데이터 저장소를 만듭니다.
3. Redis용 Amazon ElastiCache 데이터 저장소를 만듭니다.
4. 데이터 저장소에 대해 다중 AZ를 활성화합니다.
5. 데이터 저장소에 대해 멀티스레딩을 활성화합니다.

고가용성을 유지하면서 캐싱 서비스를 구현하기 위해 가장 적합한 작업 조합은 다음과 같습니다:

### **2. Memcached용 Amazon ElastiCache 데이터 저장소를 만듭니다.**
- **이유**: Memcached는 분산 메모리 객체 캐시 시스템으로, 데이터베이스 쿼리의 성능을 향상시키기 위해 자주 요청되는 데이터를 캐싱하는 데 사용됩니다. 이를 통해 RDS DB 인스턴스에 대한 부하를 줄이고 응답 시간을 개선할 수 있습니다.

### **3. Redis용 Amazon ElastiCache 데이터 저장소를 만듭니다.**
- **이유**: Redis는 인메모리 데이터 구조 저장소로, 캐싱뿐만 아니라 다양한 데이터 구조를 지원합니다. Redis를 사용하면 RDS 인스턴스의 읽기 및 쓰기 성능을 높이는 동시에 데이터의 고가용성을 보장할 수 있습니다. Redis는 복제 및 내결함성 기능을 제공하여 데이터의 가용성을 증가시킵니다.

### 추가 고려 사항:
- **4. 데이터 저장소에 대해 다중 AZ를 활성화합니다.**: 고가용성을 유지하는 데 매우 중요한 설정입니다. 그러나 이 질문의 문맥에서는 캐싱 서비스를 구현하는 방법에 대한 요구 사항이기 때문에, 캐싱 솔루션을 구축하는 데 직접적으로 관련된 항목이 아닙니다.

따라서, 최적의 조합은 **2**와 **3**입니다. 이 조합을 통해 캐싱 서비스를 구현하면서도 고가용성을 유지할 수 있습니다.



## 질문: 175

한 회사가 AWS CloudTrail을 사용하여 계정 활동을 모니터링하고 있으며, 로그가 계정의 Amazon S3 버킷에 전달된 후 일부 로그 파일이 변조되는 것을 우려하고 있습니다.

앞으로 SysOps 관리자는 로그 파일이 S3 버킷에 전달된 후 수정되지 않았는지 어떻게 확인할 수 있습니까?

1. CloudTrail 로그를 Amazon CloudWatch Logs로 스트리밍하여 보조 위치에 로그를 저장합니다.
2. 로그 파일 무결성 검증을 활성화하고 다이제스트 파일을 사용하여 로그 파일의 해시 값을 확인합니다.
3. 여러 지역 간에 S3 로그 버킷을 복제하고 S3 관리 키로 로그 파일을 암호화합니다.
4. 보안 감사를 위해 로그 버킷에 대한 요청을 추적하려면 S3 서버 액세스 로깅을 활성화합니다.

로그 파일이 Amazon S3 버킷에 전달된 후 수정되지 않았는지 확인하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### 정답
2. **로그 파일 무결성 검증을 활성화하고 다이제스트 파일을 사용하여 로그 파일의 해시 값을 확인합니다.**

### 이유
- **로그 파일 무결성 검증**: 로그 파일이 S3 버킷에 저장된 후, 해당 파일이 수정되지 않았음을 확인할 수 있는 가장 확실한 방법은 로그 파일의 해시 값을 계산하고 이를 다이제스트 파일과 비교하는 것입니다. 이 방법은 원본 로그와 수신된 로그의 무결성을 검증할 수 있도록 해주며, 변조가 발생했는지 쉽게 감지할 수 있습니다.

### 다른 선택지 설명
1. **CloudTrail 로그를 Amazon CloudWatch Logs로 스트리밍**: 이 방법은 로그를 모니터링할 수 있지만, 로그 파일의 무결성을 검증하는 기능은 제공하지 않습니다.
   
3. **S3 로그 버킷을 여러 지역 간에 복제하고 S3 관리 키로 로그 파일을 암호화**: 이 방법은 로그 파일의 보안을 강화하지만, 로그 파일이 수정되지 않았는지를 확인하는 데는 직접적인 도움이 되지 않습니다.
   
4. **S3 서버 액세스 로깅을 활성화**: 이 방법은 S3 버킷에 대한 요청을 추적할 수 있지만, 로그 파일의 무결성을 검증하는 데는 직접적인 방법이 아닙니다. 서버 액세스 로그는 액세스 로그를 기록하는 것이며, 로그 파일 자체의 변경 여부를 알 수는 없습니다.

따라서 **로그 파일 무결성 검증을 활성화하고 해시 값을 확인하는 것이** 로그의 변조 여부를 확인하는 데 가장 효과적인 방법입니다.



## 질문: 176

SysOps 관리자가 AWS Trusted Advisor 경고를 검토하고 오픈 액세스 권한이 있는 S3 버킷 정책에 대한 경고를 발견했습니다. 

버킷 소유자와 문제를 논의하는 동안 관리자는 S3 버킷이 Amazon CloudFront 웹 배포의 출처임을 깨달았습니다.

사용자가 CloudFront URL만 사용하여 Amazon S3의 객체에 액세스하도록 하려면 관리자가 어떤 조치를 취해야 합니까?

1. Amazon S3 관리 키(SSE-S3)를 사용한 서버 측 암호화로 S3 버킷 콘텐츠를 암호화합니다.
2. 원본 액세스 ID를 생성하고 S3 버킷의 객체를 읽을 수 있는 권한을 부여합니다.
3. CloudFront 배포에 IAM 사용자를 할당하고 S3 버킷 정책에서 사용자 권한을 부여합니다.
4. CloudFront 배포에 IAM 역할을 할당하고 S3 버킷 정책에서 역할 권한을 부여합니다.

사용자가 CloudFront URL만 사용하여 Amazon S3의 객체에 액세스하도록 하려면 관리자가 취해야 할 조치는 다음과 같습니다:

### 정답
2. **원본 액세스 ID를 생성하고 S3 버킷의 객체를 읽을 수 있는 권한을 부여합니다.**

### 이유
- **원본 액세스 ID (OAI)**: CloudFront는 S3 버킷의 콘텐츠에 액세스할 수 있도록 특정한 ID를 사용합니다. 원본 액세스 ID를 사용하면 CloudFront에서만 S3 버킷의 객체에 대한 액세스가 허용되고, 직접 S3 URL을 통해 접근하는 것을 차단할 수 있습니다. 이를 통해 CloudFront URL을 통해서만 객체에 접근할 수 있도록 보안성을 강화할 수 있습니다.

### 다른 선택지 설명
1. **Amazon S3 관리 키(SSE-S3)를 사용한 서버 측 암호화**: 이 방법은 데이터를 암호화하는 것이지만, S3 버킷에 대한 액세스를 제한하는 데는 직접적인 도움이 되지 않습니다.
   
3. **CloudFront 배포에 IAM 사용자를 할당하고 S3 버킷 정책에서 사용자 권한을 부여**: IAM 사용자를 사용하여 CloudFront와 S3 간의 권한을 관리하는 것은 비효율적이며, OAI를 사용하는 것이 더 간편하고 안전합니다.
   
4. **CloudFront 배포에 IAM 역할을 할당하고 S3 버킷 정책에서 역할 권한을 부여**: IAM 역할을 사용하는 것도 가능하지만, CloudFront와 S3 간의 권한 관리를 더 쉽게 하고 보안을 강화하기 위해 원본 액세스 ID(OAI)를 사용하는 것이 더 적절합니다.

결론적으로, **원본 액세스 ID를 생성하고 S3 버킷의 객체를 읽을 수 있는 권한을 부여하는 것이** 사용자에게 CloudFront URL을 통해서만 객체에 접근할 수 있도록 설정하는 가장 적절한 방법입니다.


## 질문: 177 +

SysOps 관리자가 AWS Trusted Advisor 권장 사항을 검토하고 있습니다. 

SysOps 관리자는 재무 애플리케이션의 모든 애플리케이션 서버가 Low Utilization Amazon EC2 Instances 검사에 나열되어 있음을 알아차렸습니다. 애플리케이션은 3개의 가용성 영역에 걸쳐 3개의 인스턴스에서 실행됩니다. SysOps 관리자는 애플리케이션의 가용성이나 디자인에 영향을 미치지 않으면서 애플리케이션 실행 비용을 줄여야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 애플리케이션 서버의 수를 줄이세요.
2. AWS Cost Explorer에서 적절한 크기 조정 권장 사항을 적용하여 인스턴스 크기를 줄입니다.
3. 인스턴스 앞에 애플리케이션 로드 밸런서를 프로비저닝합니다.
4. 애플리케이션 서버의 인스턴스 크기를 확장합니다

**2. AWS Cost Explorer에서 적절한 크기 조정 권장 사항을 적용하여 인스턴스 크기를 줄입니다.**

### 이유:
AWS Trusted Advisor의 Low Utilization Amazon EC2 Instances 경고는 인스턴스가 과도한 리소스를 사용하고 있지 않다는 것을 나타냅니다. **Cost Explorer**는 해당 인스턴스의 리소스 사용률을 분석하여 적절한 크기로 자동 조정 권장 사항을 제공합니다. 이 방법을 사용하면 애플리케이션의 가용성이나 디자인에 영향을 주지 않으면서 비용을 절감할 수 있습니다.

### 다른 선택지 설명:
1. **애플리케이션 서버의 수를 줄이세요**: 서버 수를 줄이는 것은 애플리케이션의 가용성과 확장성에 영향을 줄 수 있기 때문에 권장되지 않습니다.
   
3. **인스턴스 앞에 애플리케이션 로드 밸런서를 프로비저닝합니다**: 로드 밸런서는 트래픽 분산을 담당하지만, EC2 인스턴스 비용을 줄이는 직접적인 방법이 아닙니다.

4. **애플리케이션 서버의 인스턴스 크기를 확장합니다**: 확장은 비용을 줄이는 것이 아니라 인프라를 확장하는 방법이므로 이 요구 사항에 적합하지 않습니다.

따라서 인스턴스 크기를 줄이는 것이 최적의 솔루션입니다.

## 질문: 178 +

한 회사가 us-east-1 지역에 웹사이트를 호스팅합니다. 

이 회사는 eu-central-1 지역에 웹사이트를 배포할 준비를 하고 있습니다. 유럽에 있는 웹사이트 방문자는 eu-central-1에 호스팅된 웹사이트에 액세스해야 합니다. 다른 모든 방문자는 us-east-1에 호스팅된 웹사이트에 액세스합니다. 이 회사는 Amazon Route 53을 사용하여 웹사이트의 DNS 레코드를 관리합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 Route 53 레코드 세트에 어떤 라우팅 정책을 적용해야 합니까?

1. 지리적 위치 라우팅 정책
2. 지근거리 라우팅 정책
3. 지연 라우팅 정책
4. 다중값 답변 라우팅 정책

회사의 요구 사항을 충족하기 위해 적용해야 할 Amazon Route 53 라우팅 정책은 **1. 지리적 위치 라우팅 정책**입니다.

### 이유:
- **지리적 위치 라우팅 정책**을 사용하면 사용자 위치(대륙, 국가, 또는 주)에 따라 DNS 요청을 특정 리전으로 라우팅할 수 있습니다. 이 경우 유럽에 있는 방문자를 **eu-central-1** 리전에 호스팅된 웹사이트로 라우팅하고, 그 외 지역 방문자는 **us-east-1**에 있는 웹사이트로 라우팅할 수 있습니다. 이는 정확하게 요구 사항에 부합합니다.

### 다른 선택지 설명:
2. **지근거리 라우팅 정책**: 이 정책은 사용자의 물리적 위치와 여러 AWS 리전 간의 네트워크 지연을 기반으로 트래픽을 라우팅합니다. 특정 리전으로의 직접 라우팅을 보장하지 않기 때문에 요구 사항에 적합하지 않습니다.
   
3. **지연 라우팅 정책**: 이 정책은 트래픽을 가장 낮은 네트워크 지연 시간을 기준으로 선택된 리전으로 라우팅합니다. 특정 지역(유럽)에 대한 트래픽 제어를 요구하는 경우보다는 응답 시간에 따라 결정되므로, 요구 사항에 적합하지 않습니다.
   
4. **다중값 답변 라우팅 정책**: 이 정책은 다중 IP 주소를 반환하여 가용성을 높이지만, 특정 위치 기반 라우팅을 제공하지 않기 때문에 요구 사항에 맞지 않습니다.

따라서 **지리적 위치 라우팅 정책**이 유럽 사용자와 나머지 사용자에게 각각 다른 리전으로 트래픽을 라우팅할 수 있는 가장 적절한 방법입니다.

## 질문: 179 +

대규모 IT 부서가 있는 조직에서 AWS로 마이그레이션하기로 결정했습니다.

IT 부서의 직무 기능이 다르기 때문에 모든 사용자에게 모든 AWS 리소스에 대한 액세스 권한을 부여하는 것은 바람직하지 않습니다. 현재 조직은 LDAP 그룹 멤버십을 통해 액세스를 처리합니다.

현재 LDAP 자격 증명을 사용하여 액세스를 허용하는 가장 좋은 방법은 무엇입니까?

1. AWS Directory Service Simple AD를 만듭니다. 온프레미스 LDAP 디렉토리를 Simple AD로 복제합니다.
2. LDAP 그룹을 읽고 IAM 사용자 생성을 자동화하는 Lambda 함수를 만듭니다.
3. AWS CloudFormation을 사용하여 IAM 역할을 만듭니다. Direct Connect를 배포하여 온프레미스 LDAP 서버에 대한 액세스를 허용합니다.
4. SAML을 사용하여 LDAP 디렉토리를 IAM과 페더레이션합니다. 다른 LDAP 그룹에 대응하도록 다른 IAM 역할을 만들어 권한을 제한합니다.


**4. SAML을 사용하여 LDAP 디렉토리를 IAM과 페더레이션합니다. 다른 LDAP 그룹에 대응하도록 다른 IAM 역할을 만들어 권한을 제한합니다.**

### 이유:
LDAP 자격 증명을 활용하여 AWS 리소스에 대한 액세스를 관리하려면 **SAML 기반 SSO(단일 로그인)**을 사용하는 것이 가장 효과적인 방법입니다. 이를 통해 온프레미스 LDAP 디렉토리를 AWS Identity and Access Management(IAM)와 페더레이션하여 LDAP 그룹과 AWS IAM 역할을 연동할 수 있습니다. 각 LDAP 그룹에 맞게 IAM 역할을 설정하여 필요한 리소스에 대한 제한적인 액세스 권한을 부여할 수 있습니다.

### 다른 선택지 설명:
1. **AWS Directory Service Simple AD를 만듭니다. 온프레미스 LDAP 디렉토리를 Simple AD로 복제합니다**: Simple AD는 제한된 기능을 제공하며, 복제 및 동기화 작업을 수행하는 데 어려움이 있을 수 있어 LDAP와의 연동을 처리하기에는 적합하지 않습니다.

2. **LDAP 그룹을 읽고 IAM 사용자 생성을 자동화하는 Lambda 함수를 만듭니다**: 이는 수동으로 IAM 사용자를 생성하는 비효율적인 방법이며, 페더레이션과 비교했을 때 확장성이 떨어집니다.

3. **AWS CloudFormation을 사용하여 IAM 역할을 만듭니다. Direct Connect를 배포하여 온프레미스 LDAP 서버에 대한 액세스를 허용합니다**: Direct Connect는 네트워크 연결을 위한 솔루션으로, SSO와 IAM 페더레이션을 처리하기에는 적합하지 않습니다.

따라서, LDAP 디렉토리와 SAML을 사용한 IAM 페더레이션은 확장성과 관리 효율성을 모두 고려한 최적의 솔루션입니다.

## 질문: 180

SysOps 관리자가 us-east-1 지역에서 AWS CloudFormation 템플릿을 사용하여 Amazon EC2 인스턴스를 생성했습니다. 

관리자는 이 템플릿이 us-west-2 지역에서 EC2 인스턴스를 생성하지 못했다는 것을 알게 되었습니다.

이 실패의 원인 중 하나는 무엇입니까?

1. CloudFormation 템플릿에 정의된 리소스 태그는 us-east-1 지역에만 적용됩니다.
2. CloudFormation 템플릿에서 참조된 Amazon Machine Image(AMI) ID를 us-west-2 지역에서 찾을 수 없습니다.
3. cfn-init 스크립트는 us-west-2 지역에서 리소스 프로비저닝 중에 실행되지 않았습니다.
4. 지정된 지역에 IAM 사용자가 생성되지 않았습니다.

**2. CloudFormation 템플릿에서 참조된 Amazon Machine Image(AMI) ID를 us-west-2 지역에서 찾을 수 없습니다.**

### 이유:
각 AWS 지역은 고유한 Amazon Machine Image(AMI) ID를 가지고 있습니다. CloudFormation 템플릿이 특정 지역에서 AMI ID를 참조할 때, 그 AMI가 해당 지역에 존재하지 않으면 EC2 인스턴스 생성이 실패할 수 있습니다. 이 문제는 동일한 템플릿을 다른 지역에서 사용할 때 발생할 수 있습니다. AMI ID는 지역 간에 다르기 때문에, 템플릿에서 해당 지역의 AMI를 정확하게 참조해야 합니다.

### 다른 선택지 설명:
1. **CloudFormation 템플릿에 정의된 리소스 태그는 us-east-1 지역에만 적용됩니다**: 리소스 태그는 지역에 의존적이지 않으며, 리소스 태그 때문에 EC2 인스턴스 생성이 실패하지는 않습니다.

3. **cfn-init 스크립트는 us-west-2 지역에서 리소스 프로비저닝 중에 실행되지 않았습니다**: `cfn-init` 스크립트가 실행되지 않더라도 EC2 인스턴스가 생성되지만, 인스턴스 내부 설정이 완료되지 않을 수 있습니다. 그러나 인스턴스 생성 실패의 직접적인 원인은 아닙니다.

4. **지정된 지역에 IAM 사용자가 생성되지 않았습니다**: IAM 사용자는 글로벌 서비스로, 특정 지역에 종속되지 않으며 EC2 인스턴스 생성 실패의 원인이 아닙니다.

따라서, 템플릿에서 참조된 AMI ID의 지역 불일치가 실패의 가장 가능성 있는 원인입니다.

## 질문: 181 +++

글로벌 게임 회사가 AWS에서 새로운 게임을 출시할 준비를 하고 있습니다. 

이 게임은 Amazon EC2 인스턴스의 여러 AWS 지역에서 실행됩니다. 인스턴스는 각 지역의 Application Load Balancer(ALB) 뒤에 있는 Auto Scaling 그룹에 있습니다. 이 회사는 DNS 서비스에 Amazon Route 53을 사용할 계획입니다. DNS 구성은 사용자를 가장 가까운 지역으로 안내해야 하며 자동화된 장애 조치를 제공해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Route 53을 구성하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. 각 지역의 ALB 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.
2. 각 지역의 EC2 인스턴스 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.
3. 각 지역의 EC2 인스턴스의 개인 IP 주소를 모니터링하는 상태 검사를 사용하여 Route 53 DNS 장애 조치를 구성합니다.
4. Route 53 지리적 근접 라우팅을 구성합니다. 인프라에 사용되는 지역을 지정합니다.
5. Route 53 단순 라우팅을 구성합니다. 인프라에 사용되는 대륙, 국가, 주 또는 지방을 지정합니다.


**정답:**

1. **각 지역의 ALB 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.**
   - **이유**: ALB는 Auto Scaling 그룹과 연결된 EC2 인스턴스를 대상으로 트래픽을 라우팅합니다. Route 53에서 상태 확인을 사용하여 ALB의 상태를 모니터링하면 특정 지역의 ALB에 장애가 발생할 경우 자동으로 장애 조치를 수행할 수 있습니다.

4. **Route 53 지리적 근접 라우팅을 구성합니다. 인프라에 사용되는 지역을 지정합니다.**
   - **이유**: Route 53의 **지리적 근접 라우팅**은 사용자를 물리적으로 가장 가까운 AWS 지역으로 안내하는 기능을 제공합니다. 게임 플레이어가 자신에게 가장 가까운 서버로 연결되도록 하려면 이 라우팅 정책이 적합합니다. 이는 글로벌 게임에서 지연 시간을 최소화하는 데 중요한 역할을 합니다.

### 선택지 분석:

2. **각 지역의 EC2 인스턴스 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.**
   - ALB 뒤에 있는 EC2 인스턴스는 ALB에서 이미 상태를 모니터링하고 있으므로, ALB 상태를 모니터링하는 것이 더 적합합니다. EC2 인스턴스 자체의 상태를 모니터링하는 대신, ALB 상태 확인을 사용하는 것이 더 효율적입니다.

3. **각 지역의 EC2 인스턴스의 개인 IP 주소를 모니터링하는 상태 검사를 사용하여 Route 53 DNS 장애 조치를 구성합니다.**
   - EC2 인스턴스의 개인 IP 주소는 직접적으로 Route 53 상태 검사에서 모니터링할 필요가 없습니다. 대신 ALB 뒤에 있는 EC2 인스턴스의 상태를 ALB가 모니터링하고 있으므로, ALB 상태를 모니터링하는 것이 더 적합합니다.

5. **Route 53 단순 라우팅을 구성합니다. 인프라에 사용되는 대륙, 국가, 주 또는 지방을 지정합니다.**
   - **단순 라우팅**은 사용자 요청을 고정된 단일 리소스로만 라우팅합니다. 이 게임의 경우 글로벌 사용자에게 근접한 지역으로 트래픽을 라우팅해야 하므로 적합하지 않습니다.
 - 

## 질문: 182 ++

SysOps 관리자가 회사의 웹 애플리케이션의 성능 문제를 조사하고 있습니다. 

이 애플리케이션은 Auto Scaling 그룹에 있는 Amazon EC2 인스턴스에서 실행됩니다. 이 애플리케이션은 하루 종일 무작위로 많은 트래픽이 증가합니다. 트래픽이 빠르게 증가하는 기간 동안 Auto Scaling 그룹은 용량을 충분히 빠르게 추가하지 않습니다. 그 결과 사용자는 성능이 저하됩니다.

이 회사는 웹 트래픽이 빠르게 급증할 때 사용자 경험에 부정적인 영향을 미치지 않으면서 비용을 최소화하고자 합니다. 이 회사는 작은 트래픽 증가보다 큰 트래픽 증가에 대해 Auto Scaling 그룹에 더 많은 용량을 추가하는 솔루션이 필요합니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Auto Scaling 그룹을 어떻게 구성해야 합니까?

1. 시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 간단한 확장 정책을 만듭니다.
2. 시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 단계별 확장 정책을 만듭니다.
3. 시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 대상 추적 확장 정책을 만듭니다.
4. Amazon EC2 Auto Scaling 라이프사이클 후크를 사용합니다. 모든 스케일링 이벤트 후 Auto Scaling 그룹의 최대 인스턴스 수를 조정합니다.

이 회사의 요구 사항을 충족하려면 **2번, 단계별 확장 정책**을 사용하는 것이 좋습니다. 
단계별 확장 정책은 시스템에 과부하가 걸릴 때 더 큰 용량을 추가할 수 있는 설정을 지원하며, 작은 트래픽 증가보다는 큰 트래픽 증가에 대해 더 많은 인스턴스를 빠르게 추가할 수 있게 합니다. 
이를 통해 빠르게 급증하는 트래픽에 대응하면서도 비용을 효율적으로 관리할 수 있습니다.

**3번, 대상 추적 확장 정책**은 CPU 사용률이나 요청 수와 같은 특정 메트릭을 기준으로 확장되지만, 단계별 확장 정책은 트래픽 급증 시 더 유연한 대응을 제공할 수 있습니다.


## 질문: 183 +++

어떤 회사에는 보안 그룹이 SSH 포트를 모든 IP 주소에 개방할 수 없다는 규정 준수 요구 사항이 있습니다. 

SysOps 관리자는 보안 그룹 규칙이 이 요구 사항을 위반할 때 회사의 SysOps 팀에 알리는 솔루션을 구현해야 합니다. 이 솔루션은 또한 보안 그룹 규칙을 자동으로 수정해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 보안 그룹이 변경될 때 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 보안 그룹의 규정 준수 여부를 평가하고, 모든 포트에서 모든 인바운드 보안 그룹 규칙을 제거하고, 보안 그룹이 규정을 준수하지 않는 경우 SysOps 팀에 알립니다.

2. 보안 그룹 변경 사항에 대한 AWS CloudTrail 메트릭 필터를 만듭니다. 메트릭이 0보다 클 때 Amazon Simple Notification Service(Amazon SNS) 토픽을 통해 SysOps 팀에 알리는 Amazon CloudWatch 알람을 만듭니다. AWS Lambda 함수를 SNS 토픽에 구독하여 규칙을 제거하여 보안 그룹 규칙을 수정합니다.

3. AWS Config restricted-ssh 관리 규칙을 활성화합니다. AWS Systems Manager Automation AWS-DisablePublicAccessForSecurityGroup 런북을 사용하여 AWS Config 규칙에 자동 수정을 추가합니다. 규칙이 규정을 준수하지 않을 때 SysOps 팀에 알리기 위해 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.

4. 보안 그룹 변경에 대한 AWS CloudTrail 메트릭 필터를 만듭니다. 메트릭이 0보다 큰 경우 Amazon CloudWatch 알람을 만듭니다. 알람이 ALARM 상태일 때 Systems Manager Automation AWS-DisablePublicAccessForSecurityGroup 런북을 사용하여 보안 그룹을 일시 중단하기 위해 CloudWatch 알람에 AWS Systems Manager 작업을 추가합니다. SysOps 팀에 알리기 위해 두 번째 대상으로 Amazon Simple Notification Service(Amazon SNS) 토픽을 추가합니다.

**3. AWS Config restricted-ssh 관리 규칙을 활성화하고 AWS Systems Manager Automation AWS-DisablePublicAccessForSecurityGroup 런북을 사용하여 자동 수정을 추가하는 솔루션**입니다.

이 솔루션이 적합한 이유는 다음과 같습니다:
- **AWS Config**의 restricted-ssh 규칙은 보안 그룹에서 SSH(포트 22)를 모든 IP 주소에 개방하는 규정을 위반하는지 자동으로 평가합니다.
- **AWS Systems Manager Automation**과 함께 사용하여 규정을 위반한 보안 그룹을 자동으로 수정할 수 있습니다. AWS-DisablePublicAccessForSecurityGroup 런북을 실행하여 해당 규칙을 위반한 인바운드 규칙을 자동으로 제거합니다.
- **Amazon EventBridge**(CloudWatch Events)를 사용하여 위반 사항이 발생할 때 SysOps 팀에 알림을 보냄으로써 규정 준수를 보장할 수 있습니다.

이 솔루션은 규정 위반을 자동으로 감지하고 즉시 수정하며, SysOps 팀에 알림을 제공하는 완전한 자동화된 방식입니다.



## 질문: 184 +++++

한 회사에는 Amazon EC2 Spot Instances에서만 실행되는 애플리케이션이 있습니다. 

인스턴스는 예약된 스케일링 작업이 있는 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 그러나 용량은 항상 예약된 시간에 늘어나지 않으며 인스턴스는 하루에 여러 번 종료됩니다. SysOps 관리자는 인스턴스가 정시에 시작되고 중단이 적도록 해야 합니다.

어떤 작업이 이러한 요구 사항을 충족할까요?

1. Spot Instances에 대한 용량 최적화 할당 전략을 지정합니다. Auto Scaling 그룹에 더 많은 인스턴스 유형을 추가합니다.
2. Spot Instances에 대한 용량 최적화 할당 전략을 지정합니다. Auto Scaling 그룹의 인스턴스 크기를 늘립니다.
3. Spot Instances에 대한 최저 가격 할당 전략을 지정합니다. Auto Scaling 그룹에 더 많은 인스턴스 유형을 추가합니다.
4. Spot Instances에 대한 최저 가격 할당 전략을 지정합니다. Auto Scaling 그룹의 인스턴스 크기를 늘립니다.

정답은 **1. Spot Instances에 대한 용량 최적화 할당 전략을 지정하고 Auto Scaling 그룹에 더 많은 인스턴스 유형을 추가합니다**입니다.

이 선택이 적합한 이유는 다음과 같습니다:

- **용량 최적화 할당 전략**: 이 전략은 Amazon EC2 Spot Instances를 사용하여 인스턴스를 최대한 활용할 수 있는 용량이 높은 인스턴스를 선택합니다. 이로 인해 인스턴스가 종료되는 것을 최소화하고, 정시에 시작될 가능성을 높입니다.
  
- **더 많은 인스턴스 유형 추가**: 다양한 인스턴스 유형을 추가하면 Spot Instances에 대한 가용성을 높이고, 특정 시간에 필요한 용량을 더 잘 충족할 수 있습니다. 다양한 인스턴스 유형을 활용하면 용량이 부족할 때 대체 인스턴스 유형이 자동으로 시작될 수 있습니다.

이 조합은 인스턴스가 정시에 시작되도록 하고 중단을 최소화하는 데 도움이 됩니다.



## 질문: 185 ++

한 회사가 Amazon Aurora MySQL DB 클러스터에 데이터베이스를 배포할 계획입니다. 

데이터베이스는 데모 환경을 위한 데이터를 저장합니다. 데이터는 매일 재설정해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. 데이터가 채워진 후 DB 클러스터의 수동 스냅샷을 만듭니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 스냅샷을 복원한 다음 이전 DB 클러스터를 삭제하도록 함수를 구성합니다.

2. DB 클러스터 생성 중에 Backtrack 기능을 활성화합니다. 48시간의 대상 백트랙 창을 지정합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 백트랙 작업을 수행하도록 함수를 구성합니다.

3. 데이터가 채워진 후 DB 클러스터의 수동 스냅샷을 Amazon S3 버킷으로 내보냅니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. Amazon S3에서 스냅샷을 복원하도록 함수를 구성합니다.

4. DB 클러스터 백업 보존 기간을 2일로 설정합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 함수를 구성하여 DB 클러스터를 특정 시점으로 복원한 다음 이전 DB 클러스터를 삭제합니다.

주어진 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **1. 데이터가 채워진 후 DB 클러스터의 수동 스냅샷을 만듭니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 스냅샷을 복원한 다음 이전 DB 클러스터를 삭제하도록 함수를 구성합니다.**

#### **이유:**
- **운영 효율성**: 수동 스냅샷을 생성하고 이를 통해 매일 데이터를 재설정하는 방식은 관리가 용이하고, 비용 효과적인 솔루션입니다.
- **정확한 복원**: 스냅샷을 사용하면 데이터베이스를 특정 시점으로 쉽게 복원할 수 있습니다.
- **자동화**: AWS Lambda와 Amazon EventBridge를 사용하여 프로세스를 자동화하면 수동 개입 없이도 매일 자동으로 데이터를 재설정할 수 있습니다.

### 다른 옵션에 대한 간단한 분석:
2. **DB 클러스터 생성 중 Backtrack 기능을 활성화**: Backtrack 기능은 데이터베이스를 이전 상태로 되돌리는 데 사용되지만, 하루 단위로 데이터가 재설정되는 데에는 적합하지 않습니다. 주기적으로 데이터를 재설정하려면 수동 스냅샷이 더 효율적입니다.

3. **DB 클러스터의 수동 스냅샷을 Amazon S3 버킷으로 내보냅니다**: 이 옵션은 복잡성을 추가하며, Aurora DB 클러스터의 스냅샷을 직접 S3로 내보낼 수 없습니다. Aurora 스냅샷은 Aurora의 관리 하에 있습니다.

4. **DB 클러스터 백업 보존 기간을 2일로 설정**: 이 방법은 복원하기 위해 특정 시점으로 되돌릴 수는 있지만, 특정 데이터를 매일 재설정하는 데에는 복잡하고 비효율적일 수 있습니다.

따라서 **옵션 1**이 요구 사항을 가장 잘 충족합니다.




## 질문: 186 +++++

SysOps 관리자가 기본 하드웨어 장애 발생 시 Amazon EC2 인스턴스를 복구하기 위한 자동화된 프로세스를 설정하고 있습니다. 

복구된 인스턴스는 원래 인스턴스와 동일한 개인 IP 주소와 동일한 Elastic IP 주소를 가져야 합니다. SysOps 팀은 복구 프로세스가 시작될 때 이메일 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만들고 StatusCheckFailed_Instance 메트릭을 지정합니다. 인스턴스를 복구하기 위한 EC2 작업을 알람에 추가합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하기 위한 알람 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.

2. EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만들고 StatusCheckFailed_System 메트릭을 지정합니다. 인스턴스를 복구하기 위한 EC2 작업을 알람에 추가합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하기 위한 알람 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.

3. 최소, 최대 및 원하는 크기가 1인 동일한 가용성 영역의 세 개의 서로 다른 서브넷에 걸쳐 자동 확장 그룹을 만듭니다. 개인 IP 주소와 탄력적 IP 주소를 지정하는 시작 템플릿을 사용하도록 자동 확장 그룹을 구성합니다. Amazon Simple Email Service(Amazon SES)를 통해 SysOps 팀에 이메일 메시지를 보내도록 자동 확장 그룹에 대한 활동 알림을 추가합니다.

4. 최소, 최대, 원하는 크기가 1인 3개의 가용 영역에 걸쳐 자동 확장 그룹을 만듭니다. 개인 IP 주소와 탄력적 IP 주소를 지정하는 시작 템플릿을 사용하도록 자동 확장 그룹을 구성합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 자동 확장 그룹에 대한 활동 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.
 
주어진 요구 사항을 충족하는 가장 적합한 솔루션은 다음과 같습니다:

### **1. EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만들고 StatusCheckFailed_Instance 메트릭을 지정합니다. 인스턴스를 복구하기 위한 EC2 작업을 알람에 추가합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하기 위한 알람 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.**

#### **이유:**
- **StatusCheckFailed_Instance 메트릭**: 이 메트릭은 인스턴스의 상태 검사가 실패할 때 발생합니다. 하드웨어 장애가 발생했을 때 이 메트릭을 모니터링하여 인스턴스를 자동으로 복구하는 작업을 트리거할 수 있습니다.
- **자동화된 복구**: CloudWatch 알람을 사용하여 EC2 인스턴스를 복구하는 작업을 자동으로 수행할 수 있으며, 이는 원래 인스턴스와 동일한 Elastic IP 주소를 유지하게 할 수 있습니다.
- **이메일 알림**: SNS 토픽을 사용하여 SysOps 팀에게 이메일 알림을 보내는 것은 구현이 간편하고 유용합니다. 

### 다른 옵션에 대한 간단한 분석:
2. **StatusCheckFailed_System 메트릭**: 이 메트릭은 시스템 상태 검사가 실패할 때 발생합니다. 이 경우, 하드웨어 장애가 아닌 다른 시스템 관련 문제를 나타낼 수 있으므로, 인스턴스 복구에 적합하지 않습니다.

3. **자동 확장 그룹을 사용**: 자동 확장 그룹은 인스턴스의 수를 관리하는 데 유용하지만, 기본 하드웨어 장애로 인한 인스턴스 복구와는 관련이 없습니다. 개인 IP 주소와 Elastic IP 주소를 명시적으로 지정하는 것이 어려울 수 있습니다.

4. **가용 영역에 걸쳐 자동 확장 그룹을 만들기**: 이 방법도 기본 하드웨어 장애를 처리하기 위한 최적의 솔루션은 아닙니다. 이는 장애 발생 시 신속한 복구를 위해 설계된 것이 아니라, 전체 인스턴스 수를 조정하는 데 더 적합합니다.

따라서 **옵션 1**이 요구 사항을 가장 잘 충족합니다.


## 질문: 187 ++

한 회사에 최근에 문제가 발생한 공개 웹사이트가 있습니다. 

일부 링크는 누락된 웹페이지로 이어졌고, 다른 링크는 잘못된 웹페이지로 이어졌습니다. 애플리케이션 인프라는 제대로 실행 중이었고, 제공된 모든 리소스는 정상이었습니다. 애플리케이션 로그와 대시보드에는 오류가 표시되지 않았고 모니터링 알람도 발생하지 않았습니다. 시스템 관리자는 최종 사용자가 문제를 보고할 때까지 문제를 알지 못했습니다.

회사는 앞으로 이러한 문제에 대해 웹사이트를 사전에 모니터링해야 하며 가능한 한 빨리 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요?

1. 문제가 발생하면 애플리케이션 로그에 사용자 지정 오류를 표시하도록 애플리케이션을 다시 작성합니다. 오류에 대한 로그를 자동으로 구문 분석합니다. 문제가 감지되면 알림을 제공하는 Amazon CloudWatch 알람을 만듭니다.
2. 웹사이트를 테스트하기 위한 AWS Lambda 함수를 만듭니다. 오류가 감지되면 Amazon CloudWatch 사용자 지정 메트릭을 내보내도록 Lambda 함수를 구성합니다. 문제가 감지되면 알림을 제공하도록 CloudWatch 알람을 구성합니다.
3. Amazon CloudWatch Synthetics 카나리아를 만듭니다. CloudWatch Synthetics Recorder 플러그인을 사용하여 카나리아 실행을 위한 스크립트를 생성합니다. 요구 사항에 따라 카나리아를 구성합니다. 문제가 감지되면 알림을 제공하는 알람을 만듭니다.
4. Amazon CloudWatch 콘솔에서 Application Insights를 켭니다. 문제가 감지되면 알림을 제공하기 위해 CloudWatch 알람을 만듭니다.

회사가 웹사이트의 문제를 사전에 모니터링하고 조기에 감지할 수 있는 솔루션으로 가장 적합한 옵션은 다음과 같습니다:

### **3. Amazon CloudWatch Synthetics 카나리아를 만듭니다. CloudWatch Synthetics Recorder 플러그인을 사용하여 카나리아 실행을 위한 스크립트를 생성합니다. 요구 사항에 따라 카나리아를 구성합니다. 문제가 감지되면 알림을 제공하는 알람을 만듭니다.**

#### **이유:**
- **사전 모니터링**: CloudWatch Synthetics 카나리아는 웹사이트의 가용성과 성능을 모니터링하기 위해 HTTP 요청을 주기적으로 시뮬레이션할 수 있습니다. 이 기능은 웹사이트가 정상적으로 작동하는지 확인하는 데 유용합니다.
- **자동화된 테스트**: 카나리아는 사용자 정의 스크립트를 사용하여 웹사이트의 특정 경로와 페이지를 테스트하므로 누락된 페이지나 잘못된 링크와 같은 문제를 사전에 감지할 수 있습니다.
- **알림**: 문제가 감지되면 CloudWatch 알람을 설정하여 관리 팀에 즉시 알림을 제공할 수 있습니다. 이로 인해 사용자가 문제를 보고하기 전에 사전에 대응할 수 있습니다.

### 다른 옵션에 대한 간단한 분석:
1. **애플리케이션 로그 수정**: 이 방법은 수동으로 문제가 발생할 때까지 기다려야 하며, 로그를 자동으로 구문 분석하는 과정이 추가적인 운영 오버헤드를 유발할 수 있습니다.

2. **AWS Lambda 함수 사용**: Lambda를 사용하여 웹사이트를 테스트할 수 있지만, 이를 구현하기 위해 추가적인 개발과 유지 관리가 필요할 수 있습니다. 이는 운영 오버헤드를 증가시킬 수 있습니다.

4. **Application Insights 활성화**: Application Insights는 유용한 도구이지만, 웹사이트의 특정 링크와 페이지의 상태를 사전에 모니터링하기에는 적합하지 않습니다. 이는 일반적으로 애플리케이션의 성능 및 오류 모니터링에 더 초점을 맞추고 있습니다.

따라서 **옵션 3**인 **Amazon CloudWatch Synthetics 카나리아**가 요구 사항을 가장 효과적으로 충족하며 최소한의 운영 오버헤드로 문제를 사전 모니터링하는 데 적합합니다.



## 질문: 188

SysOps 관리자는 회사의 보안 그룹을 담당합니다. 

회사는 보안 그룹에 대한 모든 변경 사항을 문서화하여 보관하고자 합니다. SysOps 관리자는 보안 그룹이 변경될 때마다 알림을 받아야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. Amazon Detective를 설정하여 보안 그룹 변경 사항을 기록합니다. 구성 기록 로그를 저장할 Amazon CloudWatch Logs 로그 그룹을 지정합니다. 구성 변경에 대한 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 만듭니다. SysOps 관리자의 이메일 주소를 SQS 대기열에 구독합니다.

2. 보안 그룹 변경 사항을 기록하도록 AWS Systems Manager Change Manager를 설정합니다. 구성 기록 로그를 저장할 Amazon CloudWatch Logs 로그 그룹을 지정합니다. 구성 변경 사항에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.

3. 보안 그룹 변경 사항을 기록하도록 AWS Config를 설정합니다. 구성 스냅샷 및 기록 파일의 위치로 Amazon S3 버킷을 지정합니다. 구성 변경 사항에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.

4. Amazon Detective를 설정하여 보안 그룹 변경 사항을 기록합니다. 구성 스냅샷 및 기록 파일의 위치로 Amazon S3 버킷을 지정합니다. 구성 변경에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.
 

SysOps 관리자가 보안 그룹에 대한 모든 변경 사항을 문서화하고 변경될 때마다 알림을 받기 위해 가장 적합한 솔루션은 다음과 같습니다:

### **3. 보안 그룹 변경 사항을 기록하도록 AWS Config를 설정합니다. 구성 스냅샷 및 기록 파일의 위치로 Amazon S3 버킷을 지정합니다. 구성 변경 사항에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.**

#### **이유:**
- **AWS Config**: AWS Config는 AWS 리소스의 구성 변경 사항을 기록하고 이력을 추적하는 데 매우 유용한 서비스입니다. 이를 통해 보안 그룹의 변경 사항을 자동으로 기록하고, 변경 이력을 S3 버킷에 저장하여 문서화할 수 있습니다.
- **SNS 알림**: AWS Config와 SNS를 통합하면 보안 그룹 변경 시 실시간으로 알림을 받을 수 있습니다. SysOps 관리자가 SNS 토픽을 구독함으로써 이메일로 변경 사항에 대한 알림을 받을 수 있습니다.
- **운영 효율성**: 이 접근 방식은 설정이 비교적 간단하며 AWS의 관리형 서비스들을 활용하여 운영 효율성을 높일 수 있습니다.

### 다른 옵션에 대한 간단한 분석:
1. **Amazon Detective**: 이 서비스는 보안 분석 및 조사를 위한 것이며, 보안 그룹 변경 사항을 기록하는 데 최적화되지 않았습니다. 변경 사항에 대한 실시간 알림 기능이 부족합니다.

2. **AWS Systems Manager Change Manager**: 이 서비스는 주로 변경 관리 프로세스를 자동화하는 데 사용되며, AWS Config에 비해 보안 그룹 변경 사항에 대한 이력을 효과적으로 기록하는 데 적합하지 않습니다.

4. **Amazon Detective (2번째 언급)**: 위와 마찬가지로 Detective는 보안 그룹 변경 사항을 기록하는 데 적합하지 않으며, S3 버킷에 기록 파일을 저장하는 방식도 요구 사항에 부합하지 않습니다.

따라서 **옵션 3**인 **AWS Config 설정**이 보안 그룹 변경 사항을 문서화하고 알림을 받는 요구 사항을 가장 잘 충족하는 솔루션입니다.



## 질문: 189 ++

전자상거래 회사가 Amazon Aurora DB 클러스터를 사용하는 웹 애플리케이션을 구축했습니다. 

DB 클러스터에는 작성자 노드와 판독자 노드가 모두 있는 메모리 최적화 인스턴스 유형이 포함됩니다. 트래픽 볼륨은 하루 종일 변합니다. 트래픽이 갑자기 급증하는 동안 DB 클러스터에 대한 Amazon CloudWatch 메트릭은 높은 RAM 소비와 선택 대기 시간 증가를 나타냅니다.

SysOps 관리자는 DB 클러스터의 성능을 개선하기 위해 구성 변경을 구현해야 합니다. 변경은 다운타임을 최소화해야 하며 데이터 손실로 이어져서는 안 됩니다.

어떤 변경이 이러한 요구 사항을 충족할까요?

1. DB 클러스터에 Aurora Replica를 추가합니다.
2. DB 클러스터를 수정하여 DB 클러스터를 멀티 마스터 DB 클러스터로 변환합니다.
3. DB 클러스터의 스냅샷을 찍습니다. 해당 스냅샷에서 더 큰 메모리 최적화 인스턴스를 가진 새 DB 클러스터를 만듭니다.
4. DB 클러스터의 디스크 저장 용량을 기존 디스크 용량의 두 배로 늘립니다.



전자상거래 회사의 Amazon Aurora DB 클러스터의 성능을 개선하기 위해 다운타임을 최소화하고 데이터 손실이 발생하지 않도록 하는 가장 적합한 변경 사항은 다음과 같습니다:

### **1. DB 클러스터에 Aurora Replica를 추가합니다.**

#### **이유:**
- **성능 향상**: Aurora Replica를 추가하면 읽기 작업을 분산시킬 수 있어, 주 노드에 대한 읽기 부하가 줄어들고 성능이 향상됩니다. 이는 특히 트래픽이 급증하는 경우에 유용합니다.
- **다운타임 없음**: Aurora Replica를 추가하는 과정은 다운타임 없이 진행할 수 있습니다. 기존의 DB 클러스터에 새로운 복제본을 추가하는 것이므로, 메인 DB 클러스터는 계속 작동합니다.
- **데이터 손실 방지**: Aurora Replica는 원본 DB 클러스터와 실시간으로 동기화되므로 데이터 손실이 발생하지 않습니다.

### 다른 옵션에 대한 간단한 분석:
2. **DB 클러스터를 수정하여 DB 클러스터를 멀티 마스터 DB 클러스터로 변환합니다**: 멀티 마스터 클러스터는 복잡성을 증가시키고 구현하기 어려울 수 있으며, 추가적인 관리 오버헤드가 발생할 수 있습니다. 또한, 설정 과정에서 잠재적인 데이터 손실 위험이 있습니다.

3. **DB 클러스터의 스냅샷을 찍고 더 큰 인스턴스를 가진 새 DB 클러스터를 만드는 것**: 이 방법은 다운타임을 유발할 수 있으며, 스냅샷 복원 과정에서 데이터 손실이 발생할 수 있습니다.

4. **DB 클러스터의 디스크 저장 용량을 기존 디스크 용량의 두 배로 늘립니다**: 이 방법은 RAM 소비 문제를 해결하지 않으며, 높은 RAM 소비와 선택 대기 시간을 해결하는 데 효과적이지 않습니다. 

따라서 **옵션 1**인 **Aurora Replica 추가**가 성능 향상 및 요구 사항 충족에 가장 적합한 방법입니다.



## 질문: 190 +++

한 회사에는 eu-west-2 지역의 Elastic Load Balancer 뒤에 있는 일련의 Amazon EC2 인스턴스에서 실행되는 간단한 웹 애플리케이션이 있습니다. 

Amazon Route 53은 간단한 라우팅 정책으로 애플리케이션에 대한 DNS 레코드를 보관합니다. 전 세계의 사용자가 웹 브라우저를 통해 애플리케이션에 액세스합니다.

이 회사는 us-east-1 지역과 ap-south-1 지역에 애플리케이션의 추가 사본을 만들어야 합니다. 이 회사는 사용자가 애플리케이션을 로드할 때 가장 빠른 응답 시간을 제공하는 지역으로 사용자를 안내해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. 각각의 새로운 지역에서 새로운 Elastic Load Balancer와 새로운 EC2 인스턴스 세트를 만들어 애플리케이션 사본을 실행합니다. 지리적 위치 라우팅 정책으로 전환합니다.
2. 각 새 지역에서 새 EC2 인스턴스에 애플리케이션 사본을 만듭니다. 이 새 EC2 인스턴스를 eu-west-2의 Elastic Load Balancer에 추가합니다. 대기 시간 라우팅 정책으로 전환합니다.
3. 각 새 지역에서 새 EC2 인스턴스에 애플리케이션 사본을 만듭니다. 이 새 EC2 인스턴스를 eu-west-2의 Elastic Load Balancer에 추가합니다. 다중값 라우팅 정책으로 전환합니다.
4. 각각의 새로운 지역에서 새로운 Elastic Load Balancer와 새로운 EC2 인스턴스 세트를 만들어 애플리케이션 사본을 실행합니다. 대기 시간 라우팅 정책으로 전환합니다.



회사가 **eu-west-2** 지역에 있는 Elastic Load Balancer 뒤에 있는 웹 애플리케이션의 추가 사본을 **us-east-1**과 **ap-south-1** 지역에 만들고, 사용자가 가장 빠른 응답 시간을 제공하는 지역으로 안내하도록 하려면 다음 옵션이 가장 적합합니다:

**4. 각각의 새로운 지역에서 새로운 Elastic Load Balancer와 새로운 EC2 인스턴스 세트를 만들어 애플리케이션 사본을 실행합니다. 대기 시간 라우팅 정책으로 전환합니다.**

#### **이유:**
- **새로운 Elastic Load Balancer와 EC2 인스턴스 세트**: 각 지역에 애플리케이션의 복제본을 생성하여 사용자가 지리적으로 가까운 리소스를 사용할 수 있도록 합니다. 이는 각 지역의 사용자에게 빠른 응답 시간을 보장합니다.
- **대기 시간 라우팅 정책**: Amazon Route 53의 대기 시간 라우팅 정책은 사용자의 요청을 가장 낮은 대기 시간을 가진 리전으로 라우팅합니다. 이렇게 하면 사용자는 애플리케이션을 가장 빠르게 로드할 수 있는 지역으로 안내받습니다.

### 다른 옵션에 대한 간단한 분석:
1. **지리적 위치 라우팅 정책으로 전환**: 지리적 위치 라우팅은 사용자의 위치에 따라 트래픽을 라우팅하지만, 응답 시간이 가장 빠른 리전으로 자동으로 라우팅하지는 않습니다.

2. **eu-west-2의 Elastic Load Balancer에 새 EC2 인스턴스를 추가**: 이 방법은 여러 지역에 대한 독립적인 복제본을 만들지 않으며, 지역 간 로드 분산을 제대로 수행하지 않습니다.

3. **다중값 라우팅 정책으로 전환**: 다중값 라우팅 정책은 여러 리소스의 IP 주소를 반환하지만, 대기 시간 기반 라우팅보다 응답 시간 최적화에서 효과적이지 않을 수 있습니다.

따라서 **옵션 4**가 요구 사항을 충족하는 가장 적절한 솔루션입니다.



## 질문: 191 +++++

회사가 AWS Organizations를 사용하여 새 멤버 계정을 만듭니다. 

SysOps 관리자는 새 계정에 AWS Business Support를 추가해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. IAM 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다.
2. 루트 사용자 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다.
3. AWS Support API를 사용하여 지원 플랜을 변경하세요.
4. 루트 사용자 계정의 비밀번호를 재설정합니다.
5. 새 계정에서 관리자 권한이 있는 IAM 사용자를 만듭니다.

SysOps 관리자가 새 멤버 계정에 AWS Business Support를 추가하기 위한 올바른 단계는 다음과 같습니다.

### **정답:**
**2. 루트 사용자 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다.**  
**5. 새 계정에서 관리자 권한이 있는 IAM 사용자를 만듭니다.**

### **이유:**

1. **루트 사용자 자격 증명을 사용하여 새 계정에 로그인하고 지원 계획을 변경하는 이유**는, AWS에서 지원 플랜(예: Business Support)을 변경하는 작업은 루트 사용자 권한을 필요로 하기 때문입니다. 루트 사용자만이 AWS Support Plan을 변경할 수 있습니다.

2. **관리자 권한이 있는 IAM 사용자 생성**은, 루트 사용자 계정을 사용하는 것은 보안상의 위험이 있기 때문에, 이후 새 계정에서 IAM 사용자를 만들어 해당 계정의 일상적 관리 작업을 맡기게 됩니다. 관리자 권한이 있는 IAM 사용자는 대부분의 운영을 수행할 수 있습니다.

### **잘못된 선택:**

- **1. IAM 자격 증명을 사용하여 지원 계획을 변경하는 것은 불가능**합니다. 지원 계획은 루트 사용자만이 변경할 수 있습니다.
  
- **3. AWS Support API를 사용하여 지원 플랜을 변경하는 방법은 AWS에서 제공하지 않습니다.** AWS Support API는 Business 또는 Enterprise Support 플랜이 활성화된 상태에서만 사용할 수 있으며, 플랜 자체를 변경하는 데 사용되지 않습니다.

- **4. 루트 사용자 계정의 비밀번호를 재설정할 필요는 없습니다**. 계정 접근에 문제가 있는 경우에만 비밀번호 재설정이 필요합니다.


## 질문: 192

SysOps 관리자가 회사의 AWS 계정에 두 개의 VPC(VPC1 및 VPC2)를 만듭니다. 

SysOps 관리자가 VPC1에 Linux Amazon EC2 인스턴스를 배포하고 VPC2에 Amazon RDS for MySQL DB 인스턴스를 배포합니다. DB 인스턴스는 프라이빗 서브넷에 배포됩니다. EC2 인스턴스에서 실행되는 애플리케이션은 데이터베이스에 연결해야 합니다.

SysOps 관리자는 EC2 인스턴스가 데이터베이스에 연결할 수 있도록 하기 위해 무엇을 해야 합니까?

1. DB 인스턴스 연결 문자열을 VPC1 경로 테이블에 입력합니다.
2. 두 VPC 간에 VPC 피어링을 구성합니다.
3. 두 VPC에 동일한 IPv4 CIDR 범위를 추가합니다.
4. DB 인스턴스의 공용 IP 주소를 사용하여 DB 인스턴스에 연결합니다.


SysOps 관리자가 **VPC1**에 있는 Amazon EC2 인스턴스가 **VPC2**에 있는 Amazon RDS for MySQL DB 인스턴스에 연결할 수 있도록 하기 위해 가장 적절한 방법은 다음과 같습니다:
**2. 두 VPC 간에 VPC 피어링을 구성합니다.**

#### **이유:**
- **VPC 피어링**을 설정하면 서로 다른 VPC 간에 안전하게 연결할 수 있습니다. EC2 인스턴스가 VPC1에 있고 RDS DB 인스턴스가 VPC2에 있는 경우, VPC 피어링을 통해 두 VPC 간의 트래픽을 전송하고, 애플리케이션이 데이터베이스에 연결할 수 있게 됩니다.
- VPC 피어링을 구성한 후, EC2 인스턴스에서 RDS DB 인스턴스의 프라이빗 IP 주소를 사용하여 연결할 수 있습니다. 이를 통해 애플리케이션이 안전하게 데이터베이스에 접근할 수 있습니다.

### 다른 옵션에 대한 간단한 분석:
1. **DB 인스턴스 연결 문자열을 VPC1 경로 테이블에 입력합니다**: 이는 VPC 간의 직접 연결을 제공하지 않으며, 경로 테이블에 경로를 추가하는 것만으로는 연결을 설정할 수 없습니다.

3. **두 VPC에 동일한 IPv4 CIDR 범위를 추가합니다**: 동일한 CIDR 범위를 사용할 수는 없습니다. 각 VPC는 서로 다른 CIDR 범위를 가져야 합니다.

4. **DB 인스턴스의 공용 IP 주소를 사용하여 DB 인스턴스에 연결합니다**: RDS 인스턴스가 프라이빗 서브넷에 배포된 경우 공용 IP 주소가 없거나 접근이 불가능할 수 있습니다. 또한, 공용 IP 주소를 사용하면 보안 위험이 증가할 수 있습니다.

따라서 **옵션 2**가 요구 사항을 충족하는 최선의 솔루션입니다.


## 질문: 193 ++

한 회사가 Amazon S3 버킷을 사용하여 데이터 파일을 저장합니다. 

S3 버킷에는 수백 개의 객체가 들어 있습니다. 이 회사는 S3 버킷의 모든 객체에 있는 태그를 다른 태그로 교체해야 합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

1. S3 배치 작업을 사용합니다. 모든 객체 태그를 대체할 작업을 지정합니다.
2. AWS CLI를 사용하여 각 객체의 태그를 가져옵니다. 태그를 목록에 저장합니다. S3 Batch Operations를 사용합니다. 모든 객체 태그를 삭제하는 작업을 지정합니다. AWS CLI와 목록을 사용하여 객체에 태그를 다시 지정합니다.
3. AWS CLI를 사용하여 각 객체의 태그를 가져옵니다. 태그를 목록에 저장합니다. AWS CLI와 목록을 사용하여 객체 태그를 제거합니다. AWS CLI와 목록을 사용하여 객체에 태그를 다시 지정합니다.
4. AWS CLI를 사용하여 객체를 다른 S3 버킷으로 복사합니다. 복사된 객체에 새 태그를 추가합니다. 원래 객체를 삭제합니다.


S3 버킷의 모든 객체 태그를 다른 태그로 교체하는 가장 운영 효율적인 방법은 **1. S3 배치 작업을 사용하는 것**입니다.

### **정답:**
**1. S3 배치 작업을 사용합니다. 모든 객체 태그를 대체할 작업을 지정합니다.**

### **이유:**
S3 Batch Operations는 여러 객체에 대해 대규모 작업을 자동으로 처리할 수 있는 기능을 제공합니다. 객체의 태그를 일괄적으로 업데이트하는 작업을 효율적으로 처리할 수 있으며, 이를 통해 수백 개의 객체에 대해 태그 교체 작업을 손쉽게 수행할 수 있습니다. **S3 Batch Operations**는 지정한 작업을 모든 객체에 대해 자동으로 실행하므로, 수동으로 각 객체를 업데이트하는 것보다 훨씬 더 빠르고 운영적으로 효율적입니다.

### **다른 선택지:**

- **2. AWS CLI와 S3 Batch Operations로 태그를 삭제한 후 다시 지정하는 방식**은 불필요하게 복잡하며, 모든 태그를 제거한 뒤 다시 추가하는 과정에서 실수할 가능성이 커집니다.
  
- **3. AWS CLI로 태그를 수동으로 제거하고 다시 지정하는 방식**은 비효율적이며, 객체가 많을수록 시간이 오래 걸립니다.

- **4. AWS CLI로 객체를 복사하고 새 태그를 추가한 뒤 원래 객체를 삭제하는 방식**은 매우 비효율적입니다. 특히 데이터가 많은 경우, 복사와 삭제 작업은 비용이 많이 들고 시간이 오래 걸립니다.

따라서 S3 Batch Operations를 사용하는 것이 가장 간단하고 효율적인 방법입니다.


## 질문: 194 +++

회사에서 여러 Amazon EC2 인스턴스에서 실행 중인 애플리케이션의 인벤토리를 작성해야 합니다. 

회사에서는 AWS Systems Manager에 대한 적절한 권한이 있는 사용자와 역할을 구성했습니다. Systems Manager Agent의 업데이트된 버전이 설치되어 모든 인스턴스에서 실행 중입니다. 인벤토리 컬렉션을 구성하는 동안 SysOps 관리자는 단일 서브넷의 모든 인스턴스가 Systems Manager에서 관리되지 않는다는 사실을 발견했습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1. 모든 EC2 인스턴스에 Systems Manager 액세스에 대한 올바른 태그가 있는지 확인하세요.
2. AWS Identity and Access Management Access Analyzer를 구성하여 문제를 파악하고 자동으로 해결합니다.
3. 모든 EC2 인스턴스에 Systems Manager 액세스 권한이 있는 인스턴스 프로필이 있는지 확인하세요.
4. Systems Manager를 구성하여 인터페이스 VPC 엔드포인트를 사용합니다.

단일 서브넷의 모든 인스턴스가 AWS Systems Manager에서 관리되지 않는 문제를 해결하기 위해 SysOps 관리자가 가장 먼저 해야 할 일은 
**4. Systems Manager를 구성하여 인터페이스 VPC 엔드포인트를 사용하는 것**입니다.

### **정답:**
**4. Systems Manager를 구성하여 인터페이스 VPC 엔드포인트를 사용합니다.**

### **이유:**
Systems Manager는 관리형 인스턴스와 통신하기 위해 네트워크 연결이 필요합니다. 만약 인스턴스가 퍼블릭 서브넷에 있지 않거나 인터넷 게이트웨이를 통해 Systems Manager와 통신할 수 없는 경우, VPC 엔드포인트를 구성해야 합니다. **인터페이스 VPC 엔드포인트**는 AWS Systems Manager가 인터넷 없이도 VPC 내의 인스턴스와 통신할 수 있도록 합니다. 이것이 구성되지 않으면 Systems Manager는 해당 인스턴스를 관리할 수 없습니다.

### **다른 선택지:**

- **1. 모든 EC2 인스턴스에 Systems Manager 액세스에 대한 올바른 태그가 있는지 확인하세요**는 태그가 필수 요건은 아니므로 문제 해결에 적합하지 않습니다.

- **2. AWS Identity and Access Management Access Analyzer를 구성하여 문제를 파악하고 자동으로 해결합니다**는 IAM 관련 문제를 해결하는 도구로, 현재 문제와는 직접적인 관련이 없습니다.

- **3. 모든 EC2 인스턴스에 Systems Manager 액세스 권한이 있는 인스턴스 프로필이 있는지 확인하세요**는 인스턴스에 적절한 IAM 역할이 없는 경우에 해결책이 될 수 있습니다. 하지만 SysOps 관리자가 이미 권한을 설정했다고 언급했으므로 현재 문제의 원인은 아닐 가능성이 큽니다.

따라서 Systems Manager와 통신할 수 있도록 **VPC 엔드포인트를 구성**하는 것이 올바른 해결책입니다.

## 질문: 195 +

한 회사가 Amazon S3 버킷에 민감한 데이터를 저장합니다. 

회사는 S3 버킷에 대한 모든 액세스 시도를 기록해야 합니다. 회사의 위험 팀은 모든 삭제 이벤트에 대한 즉각적인 알림을 받아야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 감사 로그에 대한 S3 서버 액세스 로깅을 활성화합니다. S3 버킷에 대한 Amazon Simple Notification Service(Amazon SNS) 알림을 설정합니다. 알림 시스템의 이벤트 유형에 대해 DeleteObject를 선택합니다.

2. 감사 로그에 대한 S3 서버 액세스 로깅을 활성화합니다. 알림 시스템에 대한 Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스에서 cron 작업을 실행하여 매일 액세스 로그를 다운로드하고 DeleteObject 이벤트를 스캔합니다.

3. 감사 로그에는 Amazon CloudWatch Logs를 사용합니다. 알림 시스템에는 Amazon Simple Notification Service(Amazon SNS) 알림과 함께 Amazon CloudWatch 알람을 사용합니다.

4. 감사 로그에는 Amazon CloudWatch Logs를 사용합니다. 알림 시스템에 Amazon EC2 인스턴스를 시작합니다. 매일 EC2 인스턴스에서 cron 작업을 실행하여 항목 목록을 전날 목록과 비교합니다. 항목이 누락된 경우 알림을 보내도록 cron 작업을 구성합니다.

회사가 Amazon S3 버킷에 대한 모든 액세스 시도를 기록하고, 삭제 이벤트에 대해 즉각적인 알림을 받아야 할 때 가장 적절한 솔루션은 
**3. 감사 로그에는 Amazon CloudWatch Logs를 사용합니다. 알림 시스템에는 Amazon Simple Notification Service(Amazon SNS) 알림과 함께 Amazon CloudWatch 알람을 사용합니다.**입니다.

### **이유:**
1. **Amazon S3 서버 액세스 로깅** 또는 **CloudTrail**을 사용하여 S3 버킷에 대한 모든 액세스를 기록할 수 있습니다.
2. **Amazon CloudTrail**은 S3 삭제 이벤트를 포함한 모든 이벤트를 추적할 수 있으며, 이 로그 데이터를 **Amazon CloudWatch Logs**로 보낼 수 있습니다.
3. **CloudWatch Logs**는 특정 이벤트(예: `DeleteObject`)를 모니터링하고, 이 이벤트가 발생하면 **CloudWatch 알람**을 트리거할 수 있습니다.
4. **CloudWatch 알람**은 **SNS 알림**을 통해 즉시 위험 팀에게 경고를 보낼 수 있습니다.

이 방식은 자동화된 방식으로 실시간에 가까운 알림을 제공하며, EC2 인스턴스나 수동 작업을 필요로 하지 않아 운영 효율성이 높습니다.

### **다른 선택지:**

- **1. 감사 로그에 대한 S3 서버 액세스 로깅을 활성화하고 SNS 알림을 설정하는 것**은 로그 수집은 가능하지만, 실시간 알림이 제공되지 않고 삭제 이벤트에 대한 모니터링도 불완전할 수 있습니다.
  
- **2. Amazon EC2 인스턴스를 사용하여 cron 작업을 실행하는 방식**은 실시간 알림이 제공되지 않으며, 수동 처리와 유사하여 운영 효율성이 낮습니다.

- **4. 항목을 비교하는 방식**은 삭제 이벤트를 탐지하기에 적절하지 않으며, EC2 인스턴스를 활용한 수동 작업이므로 자동화 측면에서 비효율적입니다.

따라서 **CloudWatch Logs 및 알람과 SNS 알림**을 결합하는 방식이 가장 적합한 솔루션입니다.


## 질문: 196

SysOps 관리자가 Amazon GuardDuty로부터 Amazon EC2 인스턴스에서 의심스러운 네트워크 활동에 대한 알림을 받습니다. 

GuardDuty 발견 사항은 트래픽 대상으로 새 외부 IP 주소를 나열합니다. SysOps 관리자는 외부 IP 주소를 인식하지 못합니다. SysOps 관리자는 GuardDuty가 식별한 외부 IP 주소로의 트래픽을 차단해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

1. 외부 IP 주소로의 트래픽을 차단하기 위해 새 보안 그룹을 만듭니다. 새 보안 그룹을 EC2 인스턴스에 할당합니다.
2. Amazon Athena에서 VPC 흐름 로그를 사용하여 외부 IP 주소로의 트래픽을 차단합니다.
3. 네트워크 ACL을 만듭니다. 외부 IP 주소로의 트래픽에 대한 아웃바운드 거부 규칙을 추가합니다.
4. 외부 IP 주소로의 트래픽을 차단하기 위해 새 보안 그룹을 만듭니다. 새 보안 그룹을 전체 VPC에 할당합니다.
 
Amazon GuardDuty에서 식별한 외부 IP 주소로의 트래픽을 차단하는 가장 적절한 솔루션은 
**3. 네트워크 ACL을 만듭니다. 외부 IP 주소로의 트래픽에 대한 아웃바운드 거부 규칙을 추가합니다.**입니다.

### **이유:**
- **네트워크 ACL(Network Access Control List)**은 VPC 내에서 서브넷 단위로 트래픽을 제어할 수 있는 보안 계층으로, 인바운드 및 아웃바운드 트래픽을 허용 또는 거부할 수 있습니다. 네트워크 ACL을 사용하면 GuardDuty가 식별한 외부 IP 주소로의 트래픽을 특정 서브넷 전체에 대해 쉽게 차단할 수 있습니다.
- **보안 그룹**은 상태 기반이며 주로 인스턴스 단위로 작동합니다. 보안 그룹을 사용하여 IP 주소를 차단할 수는 있지만, 네트워크 ACL은 VPC 레벨에서 더 광범위하게 트래픽을 제어하는 데 적합합니다.

### **다른 선택지:**
- **1. 새 보안 그룹을 만들어 EC2 인스턴스에 할당하는 것**은 특정 인스턴스에만 적용되므로, 모든 트래픽을 제어하기에 적절하지 않으며 VPC 전체에 대한 트래픽을 관리하는 데 효율적이지 않습니다.
  
- **2. Amazon Athena에서 VPC 흐름 로그를 사용**하는 것은 트래픽을 분석하는 데는 유용하지만, 실제로 트래픽을 차단하지는 않습니다.

- **4. 보안 그룹을 전체 VPC에 할당하는 것**은 가능하지 않습니다. 보안 그룹은 특정 인스턴스나 리소스에만 적용할 수 있으며, VPC 전체를 대상으로 적용할 수 없습니다.

따라서 **네트워크 ACL을 사용하여 외부 IP 주소로의 트래픽을 아웃바운드에서 거부**하는 것이 가장 적합한 솔루션입니다.

## 질문: 197 +

15분이 걸리던 회사의 보고 작업이 이제 1시간이 걸립니다. 애플리케이션이 보고서를 생성합니다. 

이 애플리케이션은 Amazon EC2 인스턴스에서 실행되고 Amazon RDS for MySQL 데이터베이스에서 데이터를 추출합니다.

SysOps 관리자가 RDS 인스턴스의 Amazon CloudWatch 대시보드를 확인하고 보고서가 실행되지 않을 때에도 Read IOPS 메트릭이 높다는 것을 알아챘습니다. SysOps 관리자는 RDS 인스턴스의 성능과 가용성을 개선해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. RDS 인스턴스 앞에 Amazon ElastiCache 클러스터를 구성합니다. ElastiCache 클러스터를 쿼리하도록 보고 작업을 업데이트합니다.
2. RDS 읽기 복제본을 배포합니다. 보고 작업을 업데이트하여 리더 엔드포인트를 쿼리합니다.
3. Amazon CloudFront 배포를 만듭니다. RDS 인스턴스를 원본으로 설정합니다. CloudFront 배포를 쿼리하도록 보고 작업을 업데이트합니다.
4. RDS 인스턴스의 크기를 늘립니다.
 

보고 작업이 15분에서 1시간으로 늘어났고, Amazon RDS for MySQL의 Read IOPS 메트릭이 높다는 것은 데이터베이스의 성능 문제를 나타냅니다. SysOps 관리자는 RDS 인스턴스의 성능과 가용성을 개선하기 위해 다음과 같은 솔루션을 고려할 수 있습니다.

### 정답
**2. RDS 읽기 복제본을 배포합니다. 보고 작업을 업데이트하여 리더 엔드포인트를 쿼리합니다.**

### 이유
- **읽기 복제본 사용**: RDS 읽기 복제본은 데이터베이스의 읽기 전용 복사본을 생성하여 읽기 작업의 부하를 분산시킬 수 있습니다. 보고 작업이 RDS 인스턴스에서 데이터를 읽는 경우, 읽기 복제본을 사용하면 원본 RDS 인스턴스의 부하를 줄이고 성능을 개선할 수 있습니다. 따라서 RDS 인스턴스가 더 나은 성능을 제공할 수 있도록 할 수 있습니다.



## 질문: 198 ++

회사의 SysOps 관리자는 회사의 각 계정에서 AWS Personal Health Dashboard를 정기적으로 확인합니다. 

계정은 AWS Organizations의 조직에 속합니다. 
회사는 최근 조직에 10개의 계정을 추가했습니다. SysOps 관리자는 각 계정의 Personal Health Dashboard에서 알림을 통합해야 합니다.

어떤 솔루션이 최소한의 노력으로 이 요구 사항을 충족할까요?

1. AWS Health에서 조직 보기를 활성화합니다.
2. 각 계정의 개인 건강 대시보드를 구성하여 이벤트를 중앙 AWS CloudTrail 로그로 전달합니다.
3. AWS Health API를 쿼리하고 모든 이벤트를 Amazon DynamoDB 테이블에 기록하는 AWS Lambda 함수를 생성합니다.
4. AWS Health API를 사용하여 Amazon DynamoDB 테이블에 이벤트를 기록합니다.

AWS Personal Health Dashboard의 알림을 통합하기 위해 SysOps 관리자가 선택할 수 있는 최적의 솔루션은 다음과 같습니다.

### 정답
**1. AWS Health에서 조직 보기를 활성화합니다.**

### 이유
- **조직 보기를 활성화하면**: AWS Organizations의 모든 계정에서 발생하는 개인 건강 이벤트를 중앙에서 모니터링할 수 있습니다. 이를 통해 각 계정에서 별도로 Personal Health Dashboard를 확인할 필요 없이 한 곳에서 모든 알림을 통합하여 쉽게 관리할 수 있습니다.




## 질문: 199 +

한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

EC2 인스턴스는 자동 확장 그룹에 있으며 애플리케이션 로드 밸런서(ALB) 뒤에서 실행됩니다. 
총 요청이 초당 100건을 초과하면 애플리케이션에 오류가 발생합니다. SysOps 관리자는 요청이 이 임계값을 초과한 시점을 확인하기 위해 2주 기간 동안의 총 요청에 대한 정보를 수집해야 합니다.

SysOps 관리자는 이 데이터를 수집하기 위해 무엇을 해야 합니까?

1. ALB의 RequestCount 메트릭을 사용합니다. 2주와 1분의 기간을 구성합니다. 차트를 검토하여 최대 트래픽 시간과 볼륨을 확인합니다.
2. Amazon CloudWatch 메트릭 수학을 사용하여 2주 기간 동안 모든 EC2 인스턴스에 대한 요청 수의 합계를 생성합니다. 1분 간격으로 정렬합니다.
3. EC2 시작 구성 템플릿에서 Amazon CloudWatch 사용자 지정 메트릭을 만들어 모든 EC2 인스턴스에서 집계된 요청 메트릭을 생성합니다.
4. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. EC2 요청을 기반으로 하는 메트릭을 만드는 EC2 이벤트 매칭 패턴을 구성합니다. 그래프에 데이터를 표시합니다.
 
요청이 초당 100건을 초과한 시점을 확인하기 위해 2주 기간 동안의 총 요청 정보를 수집하려면 가장 적절한 솔루션은 다음과 같습니다:

**1. ALB의 RequestCount 메트릭을 사용합니다. 2주와 1분의 기간을 구성합니다. 차트를 검토하여 최대 트래픽 시간과 볼륨을 확인합니다.**

이 방법은 ALB에서 제공하는 `RequestCount` 메트릭을 사용하여 요청 수를 직접 모니터링하고, 2주 동안의 데이터를 수집하여 트래픽이 특정 임계값을 초과한 시점을 분석하는 데 가장 효과적입니다. CloudWatch 대시보드를 통해 시각적으로 최대 트래픽 시간과 볼륨을 쉽게 확인할 수 있습니다.




## 질문: 200 ++

한 회사가 최근 AWS의 VPC로 애플리케이션을 마이그레이션했습니다. 

AWS Site-to-Site VPN 연결은 회사의 온프레미스 네트워크를 VPC에 연결합니다. 애플리케이션은 온프레미스에 있는 다른 시스템에서 고객 데이터를 검색합니다. 애플리케이션은 온프레미스 DNS 서버를 사용하여 도메인 레코드를 확인합니다. 마이그레이션 후 애플리케이션은 이름 확인 오류로 인해 고객 데이터에 연결할 수 없습니다.

어떤 솔루션이 애플리케이션에 내부 도메인 이름을 확인할 수 있는 기능을 제공할까요?

1. VPC에서 EC2 인스턴스를 시작합니다. EC2 인스턴스에서 모든 DNS 요청을 온프레미스 DNS 서버로 전달하는 사용자 지정 DNS 포워더를 배포합니다. 이름 서버에 EC2 인스턴스를 사용하는 Amazon Route 53 프라이빗 호스팅 영역을 만듭니다.
2. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 온프레미스 도메인에 대한 DNS 쿼리를 온프레미스 DNS 서버로 전달하도록 아웃바운드 엔드포인트를 구성합니다.
3. AWS 환경과 온프레미스 네트워크 간에 두 개의 AWS Direct Connect 연결을 설정합니다. 두 연결을 포함하는 링크 집계 그룹(LAG)을 설정합니다. 온프레미스 DNS 서버를 가리키도록 VPC 리졸버 주소를 변경합니다.
4. 온프레미스 도메인에 대한 Amazon Route 53 퍼블릭 호스팅 존을 만듭니다. 온프레미스 도메인에 대한 DNS 요청을 Route 53 퍼블릭 호스팅 존으로 전달하도록 네트워크 ACL을 구성합니다.


애플리케이션이 내부 도메인 이름을 확인할 수 있는 기능을 제공하기 위해 가장 적절한 솔루션은 다음과 같습니다:

**2. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 온프레미스 도메인에 대한 DNS 쿼리를 온프레미스 DNS 서버로 전달하도록 아웃바운드 엔드포인트를 구성합니다.**

이 솔루션은 AWS VPC와 온프레미스 네트워크 간의 DNS 쿼리를 효과적으로 처리할 수 있도록 합니다. Route 53 Resolver 아웃바운드 엔드포인트를 통해 VPC 내의 DNS 쿼리가 온프레미스 DNS 서버로 전달되어 이름 확인 오류를 해결할 수 있습니다. 이렇게 하면 애플리케이션이 온프레미스 시스템에서 고객 데이터를 검색하는 데 필요한 내부 도메인 이름을 올바르게 확인할 수 있게 됩니다.



## 질문: 201 +++++

회사의 웹 애플리케이션은 Amazon CloudFront 배포를 통해 사용할 수 있으며 인터넷 연결 Application Load Balancer(ALB)를 통해 직접 사용할 수 있습니다. 

SysOps 관리자는 CloudFront 배포를 통해서만 애플리케이션에 액세스할 수 있도록 해야 하며 ALB를 통해 직접 액세스할 수 있도록 해서는 안 됩니다. SysOps 관리자는 애플리케이션 코드를 변경하지 않고 이 변경을 해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. ALB 유형을 내부로 수정합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다.
2. Lambda@Edge 함수를 만듭니다. 요청의 사용자 지정 헤더 값을 저장된 비밀번호와 비교하고 일치하는 경우 요청을 원본으로 전달하도록 함수를 구성합니다. 함수를 배포와 연결합니다.
3. ALB를 새 내부 ALB로 교체합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다. 배포의 원점 설정에 사용자 지정 HTTP 헤더를 추가합니다. ALB 리스너에서 일치하는 사용자 지정 헤더와 헤더의 값을 포함하는 요청을 전달하는 규칙을 추가합니다. 고정된 응답 코드 403을 반환하는 기본 규칙을 추가합니다.
4. 배포를 위한 원본 설정에 사용자 지정 HTTP 헤더를 추가합니다. ALB 리스너에서 일치하는 사용자 지정 헤더와 헤더의 값을 포함하는 요청을 전달하는 규칙을 추가합니다. 고정된 응답 코드 403을 반환하는 기본 규칙을 추가합니다.

회사의 웹 애플리케이션에 대한 요구 사항을 충족하기 위해서 **"ALB 유형을 내부로 수정합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다."**가 가장 적합한 솔루션입니다.

### 정답:
**1. ALB 유형을 내부로 수정합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다.**

#### 이유:
- **직접 액세스 차단**: ALB를 내부로 설정하면 ALB에 대한 외부 액세스가 차단됩니다. 따라서 사용자는 CloudFront 배포를 통해서만 애플리케이션에 액세스할 수 있습니다.
- **애플리케이션 코드 변경 없음**: 이 방법은 애플리케이션 코드나 아키텍처를 변경하지 않고, ALB의 유형만 변경하는 방식이기 때문에 요구 사항을 충족할 수 있습니다.

### 대안 설명:
2. **Lambda@Edge 함수를 만듭니다.**
   - Lambda@Edge를 사용하여 요청의 헤더를 검사하고 조건에 따라 요청을 처리할 수 있지만, 이 방식은 다소 복잡하고 성능에 영향을 미칠 수 있습니다. 또한, 코드의 변경 없이 요구 사항을 충족하기 어렵습니다.

3. **ALB를 새 내부 ALB로 교체합니다.**
   - 이 방법도 효과적일 수 있지만, ALB를 교체하는 것은 불필요한 작업을 추가하고, 내부 ALB를 추가로 설정하는 것보다 기존 ALB를 내부로 변경하는 것이 더 간단합니다.

4. **배포를 위한 원본 설정에 사용자 지정 HTTP 헤더를 추가합니다.**
   - 사용자 지정 HTTP 헤더를 추가하는 것은 요청을 검증하는 데 유용할 수 있지만, ALB에 대한 직접 액세스를 차단하는 데는 효과적이지 않습니다. 요청이 ALB로 직접 전달될 수 있으므로, 이 방법은 요구 사항을 완전히 충족하지 않습니다.

따라서, **ALB 유형을 내부로 수정하고 배포의 원점을 내부 ALB로 설정하는 것이 가장 효율적이며 요구 사항을 충족하는 방법입니다.**

## 질문: 202 +

한 회사가 AWS에서 여러 워크로드를 실행합니다. 

이 회사는 특정 AWS 지역에서 모니터링할 5개의 AWS Trusted Advisor 서비스 할당량 지표를 식별합니다. 이 회사는 리소스 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 받고 싶어합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.

2. 각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.

3. AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 지표를 모니터링합니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.

4. AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 메트릭을 모니터링합니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
 

회사가 AWS에서 Trusted Advisor 서비스 할당량 지표를 모니터링하고 이메일 알림을 받고자 할 때 가장 적합한 솔루션은 
**"각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다."**입니다.

### 정답:
**1. 각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.**

#### 이유:
- **세부 모니터링**: CloudWatch 알람을 사용하여 각 서비스 할당량 메트릭을 개별적으로 모니터링할 수 있습니다. 이는 특정 리소스의 사용량이 임계값을 초과했을 때 신속하게 대응할 수 있게 해줍니다.
- **알림의 유연성**: Amazon SNS를 사용하면 이메일 알림을 쉽게 설정할 수 있으며, 사용자가 선택한 구독자에게 알림을 보낼 수 있습니다.
- **효율성**: 각 메트릭에 대해 개별적으로 알람을 설정하면, 각 서비스 할당량의 상태를 효과적으로 관리할 수 있습니다.

### 대안 설명:
2. **각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.**
   - SQS는 메시지를 큐에 저장하는 데 유용하지만, 이메일 알림을 직접 제공하지 않으므로 SNS가 더 적합합니다.

3. **AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 지표를 모니터링합니다.**
   - Service Health Dashboard는 서비스의 상태를 모니터링하는 데 사용되지만, 특정 리소스 사용량을 측정하거나 알림을 설정하는 데는 적합하지 않습니다.

4. **AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 메트릭을 모니터링합니다.**
   - 이 방법은 위와 동일한 이유로 적합하지 않으며, CloudWatch 알람을 설정하는 것이 훨씬 효율적입니다.

따라서, **각 Trusted Advisor 서비스 할당량 메트릭에 대해 Amazon CloudWatch 알람을 만들고, SNS를 통해 이메일 알림을 설정하는 방법이 가장 효과적입니다.**


## 질문: 203 +++

회사에서 온프레미스 사용자를 위한 Windows 파일 공유를 호스팅하기 위해 관리형 파일 시스템을 구현해야 합니다. 

AWS 클라우드의 리소스도 이러한 파일 공유의 데이터에 액세스할 수 있어야 합니다. SysOps 관리자는 온프레미스에서 사용자 파일 공유를 제공하고 최소 지연 시간으로 사용자 파일 공유를 AWS에서 사용할 수 있도록 해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. Amazon S3 파일 게이트웨이를 설정합니다.
2. AWS Direct Connect 연결을 설정합니다.
3. AWS DataSync를 사용하여 기존 파일 서버와 AWS 간의 데이터 전송을 자동화합니다.
4. Amazon FSx 파일 게이트웨이를 설정합니다.

이러한 요구 사항을 충족하기 위해 가장 적합한 솔루션은 **"AWS Direct Connect 연결을 설정합니다."**입니다.

### 정답:
**2. AWS Direct Connect 연결을 설정합니다.**

#### 이유:
- **지연 시간 최소화**: AWS Direct Connect는 온프레미스 데이터 센터와 AWS 간의 전용 네트워크 연결을 제공합니다. 이는 인터넷을 통한 연결보다 더 낮은 지연 시간과 더 안정적인 성능을 제공합니다.
- **온프레미스와 AWS 통합**: 이 연결을 통해 온프레미스 파일 공유와 AWS 리소스 간의 데이터 전송을 원활하게 할 수 있습니다. 사용자는 로컬 네트워크와 유사한 방식으로 AWS 리소스에 액세스할 수 있습니다.
- **안정성 및 보안**: Direct Connect는 데이터가 전송되는 동안 더 높은 보안성과 신뢰성을 제공하므로, 파일 공유에 적합합니다.

### 대안 설명:
1. **Amazon S3 파일 게이트웨이를 설정합니다.**
   - S3 파일 게이트웨이는 온프레미스 애플리케이션이 S3에 파일을 저장하고 가져올 수 있도록 하는 서비스입니다. 그러나 이 옵션은 지연 시간에 영향을 줄 수 있으며, 파일 공유를 위한 완전한 솔루션은 아닙니다.

3. **AWS DataSync를 사용하여 기존 파일 서버와 AWS 간의 데이터 전송을 자동화합니다.**
   - DataSync는 데이터를 자동으로 이동하는 데 유용하지만, 실시간 액세스가 필요한 파일 공유에는 적합하지 않습니다. 이 옵션은 주기적인 데이터 전송에는 유용하지만, 파일 공유에 대한 즉각적인 액세스를 보장하지는 않습니다.

4. **Amazon FSx 파일 게이트웨이를 설정합니다.**
   - FSx 파일 게이트웨이는 Amazon FSx 스토리지를 온프레미스 환경에서 사용할 수 있도록 지원하지만, 최적의 지연 시간을 제공하기 위해서는 Direct Connect와 함께 사용하는 것이 더 좋습니다. FSx는 주로 AWS 내에서 파일 시스템을 제공하는 데 사용됩니다.

결론적으로, **AWS Direct Connect 연결을 설정하여 온프레미스와 AWS 간의 파일 공유를 위한 안정적이고 낮은 지연 시간의 연결을 구현하는 것이 가장 효과적입니다.**

## 질문: 204 +++

한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 

이 회사는 Amazon RDS for PostgreSQL DB 인스턴스에서 데이터베이스를 호스팅하고 있습니다. 이 회사는 DB 인스턴스에 대한 모든 연결을 암호화하도록 요구합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자는 무엇을 해야 합니까?

1. 인바운드 보안 그룹 규칙을 사용하여 데이터베이스에 대한 SSL 연결을 허용합니다.
2. AWS Key Management Service(AWS KMS) 암호화 키를 사용하여 데이터베이스를 암호화합니다.
3. 사용자 정의 매개변수 그룹을 사용하여 데이터베이스에 대한 SSL 연결을 적용합니다.
4. 사용자 정의 PostgreSQL 확장 기능을 사용하여 데이터베이스에 SSL/TLS 패치를 적용합니다.

Amazon RDS for PostgreSQL DB 인스턴스에 대한 모든 연결을 암호화하도록 요구하기 위해 SysOps 관리자가 취해야 할 가장 적절한 조치는 **"인바운드 보안 그룹 규칙을 사용하여 데이터베이스에 대한 SSL 연결을 허용합니다."**입니다.

### 정답:
**1. 인바운드 보안 그룹 규칙을 사용하여 데이터베이스에 대한 SSL 연결을 허용합니다.**

#### 이유:
- **SSL/TLS 사용**: PostgreSQL은 SSL/TLS를 통해 연결을 암호화할 수 있습니다. DB 인스턴스에 대한 연결을 암호화하기 위해서는 클라이언트가 SSL을 통해 연결할 수 있도록 해야 합니다.
- **보안 그룹 설정**: 인바운드 보안 그룹 규칙을 통해 SSL 연결이 허용되도록 설정함으로써, 안전하게 암호화된 연결이 가능하게 됩니다.

### 대안 설명:
2. **AWS Key Management Service(AWS KMS) 암호화 키를 사용하여 데이터베이스를 암호화합니다.**
   - AWS KMS는 데이터 저장을 위한 암호화를 제공하지만, DB 인스턴스와의 연결을 암호화하는 것과는 다릅니다. KMS는 데이터베이스 내에서 저장된 데이터를 암호화하는 데 사용됩니다.

3. **사용자 정의 매개변수 그룹을 사용하여 데이터베이스에 대한 SSL 연결을 적용합니다.**
   - 사용자 정의 매개변수 그룹을 사용하여 SSL 연결을 적용할 수 있지만, 인바운드 보안 그룹을 설정하지 않으면 클라이언트가 SSL로 연결할 수 없습니다. 따라서 보안 그룹 규칙이 먼저 적용되어야 합니다.

4. **사용자 정의 PostgreSQL 확장 기능을 사용하여 데이터베이스에 SSL/TLS 패치를 적용합니다.**
   - PostgreSQL 자체의 SSL/TLS 패치를 적용하는 것은 일반적인 요구 사항이 아니며, RDS에서는 관리형 서비스이므로 사용자가 직접 패치를 적용하는 것은 불가능합니다.

결론적으로, DB 인스턴스에 대한 모든 연결을 암호화하기 위해서는 인바운드 보안 그룹 규칙을 사용하여 SSL 연결을 허용하는 것이 가장 효과적입니다.


## 질문: 205

한 회사가 최근에 Savings Plans를 구매했습니다. 

이 회사는 회사의 활용도가 특정 날짜에 90% 미만으로 떨어지면 이메일 알림을 받고 싶어합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

1. AWS Trusted Advisor에서 Savings Plan 체크를 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 특정 날짜에 사용률이 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.
2. CloudWatch의 AWS/SavingsPlans 네임스페이스에서 SavingsPlansUtilization 메트릭을 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 특정 날짜에 사용률이 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.
3. Savings Plans 알림을 만들어 Savings Plans의 일일 사용률을 모니터링합니다. 사용률이 주어진 날의 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
4. AWS Budgets를 사용하여 Savings Plans 예산을 생성하여 Savings Plans의 일일 사용률을 추적합니다. 사용률이 주어진 날의 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
 

회사가 Savings Plans의 활용도가 특정 날짜에 90% 미만으로 떨어지면 이메일 알림을 받고 싶어하는 요구 사항을 충족하기 위한 가장 적절한 솔루션은 **"AWS Budgets를 사용하여 Savings Plans 예산을 생성하여 Savings Plans의 일일 사용률을 추적합니다."**입니다.

### 정답:
**4. AWS Budgets를 사용하여 Savings Plans 예산을 생성하여 Savings Plans의 일일 사용률을 추적합니다. 사용률이 주어진 날의 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.**

#### 이유:
- **예산 관리**: AWS Budgets를 사용하면 리소스의 사용률을 기반으로 예산을 설정할 수 있습니다. Savings Plans 활용도에 대한 예산을 설정하고, 특정 임계값(예: 90% 미만)에 도달할 때 알림을 받을 수 있습니다.
- **이메일 알림**: Budgets를 통해 SNS 토픽에 알림을 설정하여, 활용도가 특정 기준에 미치지 않을 때 이메일로 알림을 받을 수 있습니다.

### 대안 설명:
1. **AWS Trusted Advisor에서 Savings Plan 체크를 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다.**
   - AWS Trusted Advisor는 Savings Plans 활용도에 대한 정보를 제공하지만, 직접적인 알림 기능이 부족하므로 이 방법은 적합하지 않습니다.

2. **CloudWatch의 AWS/SavingsPlans 네임스페이스에서 SavingsPlansUtilization 메트릭을 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다.**
   - CloudWatch에서 메트릭을 모니터링할 수는 있지만, 알림을 설정하는 데 필요한 정책을 구성하는 데 한계가 있습니다. 또한, Savings Plans 활용도에 대한 알림이 SNS와 결합되지 않으면 실질적인 이메일 알림을 제공하기 어렵습니다.

3. **Savings Plans 알림을 만들어 Savings Plans의 일일 사용률을 모니터링합니다.**
   - Savings Plans 알림은 있지만, AWS Budgets를 사용하는 것이 더 나은 방법입니다. Budgets는 더 유연하게 예산을 관리하고 알림을 설정할 수 있도록 돕기 때문입니다.

따라서, **AWS Budgets를 사용하여 Savings Plans의 일일 사용률을 추적하고 특정 기준에 따라 이메일 알림을 받는 것이 가장 효과적인 솔루션입니다.**


## 질문: 206

한 회사가 애플리케이션에서 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 사용합니다. 
애플리케이션은 고유한 메시지 본문이 있는 메시지를 대기열로 보냅니다. 회사는 SQS FIFO 대기열로 전환하기로 결정했습니다.

회사는 SQS FIFO 대기열로 마이그레이션하기 위해 무엇을 해야 합니까?

1. 새 SQS FIFO 대기열을 만듭니다. 새 FIFO 대기열에서 콘텐츠 기반 중복 제거를 켭니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다.
2. 새 SQS FIFO 대기열을 만듭니다. DelaySeconds 매개변수를 메시지에 포함하도록 애플리케이션을 업데이트합니다.
3. 대기열 유형을 SQS 표준에서 SQS FIFO로 수정합니다. 대기열에서 콘텐츠 기반 중복 제거를 끕니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다.
4. SQS 표준에서 SQS FIFO로 큐 유형을 수정합니다. 동일한 메시지 본문으로 메시지를 보내고 메시지에 DelaySeconds 매개변수를 포함하도록 애플리케이션을 업데이트합니다.

회사가 Amazon SQS 표준 대기열에서 FIFO 대기열로 마이그레이션하기 위해 필요한 조치는 
**"새 SQS FIFO 대기열을 만듭니다. 새 FIFO 대기열에서 콘텐츠 기반 중복 제거를 켭니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다."**입니다.

### 정답:
**1. 새 SQS FIFO 대기열을 만듭니다. 새 FIFO 대기열에서 콘텐츠 기반 중복 제거를 켭니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다.**

#### 이유:
- **새 대기열 생성**: SQS의 대기열 유형을 변경할 수 없기 때문에 새로운 FIFO 대기열을 만들어야 합니다.
- **메시지 그룹 ID**: FIFO 대기열에서는 메시지가 순서대로 처리되고 중복이 방지되도록 메시지 그룹 ID를 사용해야 합니다. 애플리케이션에서 메시지 그룹 ID를 포함하도록 업데이트해야 합니다.
- **중복 제거**: FIFO 대기열에서는 콘텐츠 기반 중복 제거를 사용할 수 있으며, 이를 통해 동일한 메시지가 중복되어 처리되는 것을 방지할 수 있습니다.

### 대안 설명:
2. **새 SQS FIFO 대기열을 만듭니다. DelaySeconds 매개변수를 메시지에 포함하도록 애플리케이션을 업데이트합니다.**
   - DelaySeconds 매개변수는 메시지의 지연 전송에 관한 것이며 FIFO 대기열로의 전환에는 필요하지 않습니다.

3. **대기열 유형을 SQS 표준에서 SQS FIFO로 수정합니다.**
   - 대기열 유형을 직접 수정하는 것은 불가능합니다. 반드시 새 FIFO 대기열을 생성해야 합니다.

4. **SQS 표준에서 SQS FIFO로 큐 유형을 수정합니다.**
   - 마찬가지로 대기열 유형을 수정하는 것은 불가능하며, 같은 이유로 새로운 FIFO 대기열을 만들어야 합니다.

따라서, **새 SQS FIFO 대기열을 생성하고, 메시지 그룹 ID를 포함하도록 애플리케이션을 업데이트하는 것이 FIFO 대기열로의 마이그레이션을 위한 올바른 접근 방식입니다.**


## 질문: 207 +++++

회사의 SysOps 관리자는 AWS 계정에서 시작된 모든 Amazon EC2 Windows 인스턴스에 타사 에이전트가 설치되어 있는지 확인해야 합니다. 

타사 에이전트에는 .msi 패키지가 있습니다. 회사는 패치를 위해 AWS Systems Manager를 사용하고 Windows 인스턴스에 적절한 태그가 지정됩니다. 타사 에이전트는 새 버전이 출시됨에 따라 주기적 업데이트가 필요합니다. SysOps 관리자는 이러한 업데이트를 자동으로 배포해야 합니다.

어떤 단계 조합이 최소한의 운영 노력으로 이러한 요구 사항을 충족할 수 있을까요? (두 가지를 선택하세요.)

1. 타사 에이전트에 대한 Systems Manager Distributor 패키지를 만듭니다.
2. Systems Manager Inventory가 구성되어 있는지 확인하세요. Systems Manager Inventory가 구성되어 있지 않으면 Windows에 적합한 태그 값을 기반으로 인스턴스에 대한 새 인벤토리를 설정하세요.
3. AWS-RunRemoteScript 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.
4. AWS-ConfigureAWSPackage 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.
5. Windows에 대한 태그 값으로 Systems Manager OpsItem을 만듭니다. Systems Manager Distributor 패키지를 OpsItem에 연결합니다. 패키지 배포에 특정한 유지 관리 기간을 만듭니다. 유지 관리 기간을 하루 24시간으로 구성합니다.

SysOps 관리자가 요구 사항을 충족하기 위해 최소한의 운영 노력으로 선택할 수 있는 두 가지 단계는 다음과 같습니다:

1. **타사 에이전트에 대한 Systems Manager Distributor 패키지를 만듭니다.**
   - 이 단계는 타사 에이전트를 자동으로 배포하기 위해 필요한 패키지를 생성하는 것입니다. 이를 통해 향후 업데이트를 쉽게 관리할 수 있습니다.

4. **AWS-ConfigureAWSPackage 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.**
   - 이 단계는 정의된 일정에 따라 타사 에이전트를 자동으로 업데이트하고 설치하는 데 필요한 프로세스를 설정합니다. 태그를 기반으로 인스턴스를 필터링하여 특정 인스턴스에만 업데이트를 적용할 수 있습니다.

### 이유:
- **운영 효율성**: 이 두 가지 조합을 통해 패키지 관리와 인스턴스 업데이트를 자동화하여 운영 부담을 줄일 수 있습니다.
- **자동화된 업데이트**: Systems Manager의 기능을 활용하여 패치 및 업데이트를 정기적으로 자동으로 수행할 수 있습니다.

### 대안 설명:
2. **Systems Manager Inventory가 구성되어 있는지 확인하세요. Systems Manager Inventory가 구성되어 있지 않으면 Windows에 적합한 태그 값을 기반으로 인스턴스에 대한 새 인벤토리를 설정하세요.**
   - 인벤토리 구성은 중요하지만, 타사 에이전트를 업데이트하는 직접적인 방법은 아닙니다.

3. **AWS-RunRemoteScript 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.**
   - 이 옵션은 스크립트를 실행하는 방법으로 업데이트를 수행할 수 있지만, 패키지 관리가 아닌 원격 스크립트 실행에 의존하므로 좀 더 복잡할 수 있습니다.

5. **Windows에 대한 태그 값으로 Systems Manager OpsItem을 만듭니다. Systems Manager Distributor 패키지를 OpsItem에 연결합니다. 패키지 배포에 특정한 유지 관리 기간을 만듭니다. 유지 관리 기간을 하루 24시간으로 구성합니다.**
   - OpsItem을 설정하는 것은 유용하지만, 타사 에이전트 업데이트 자동화의 핵심 단계는 아닙니다.

따라서, 선택된 두 단계가 가장 적합합니다.



## 질문: 208

한 회사가 단일 AWS 리전에서 수백 개의 Amazon EC2 인스턴스를 실행합니다. 

각 EC2 인스턴스에는 연결된 1GiB General Purpose SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨이 두 개 있습니다. 중요한 워크로드는 EBS 볼륨에서 사용 가능한 모든 IOPS 용량을 사용하는 것입니다.

회사 정책에 따라 회사는 회사의 애플리케이션이 제대로 작동하는지 확인하기 위한 긴 수락 테스트를 완료하지 않고는 인스턴스 유형이나 EBS 볼륨 유형을 변경할 수 없습니다. SysOps 관리자는 가능한 한 빨리 EBS 볼륨의 I/O 성능을 높여야 합니다. SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1. 1GiB EBS 볼륨의 크기를 늘립니다.
2. 각 EC2 인스턴스에 두 개의 추가 탄력적 네트워크 인터페이스를 추가합니다.
3. 해당 지역의 EBS 볼륨에서 전송 가속을 켭니다.
4. 모든 EC2 인스턴스를 클러스터 배치 그룹에 추가합니다.

EBS 볼륨의 I/O 성능을 즉시 높이기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### **1. 1GiB EBS 볼륨의 크기를 늘립니다.**

#### 이유:
- **IOPS 성능 증가**: Amazon EBS의 gp2 볼륨은 볼륨 크기에 따라 IOPS 성능이 결정됩니다. 구체적으로, gp2 볼륨은 각 GiB에 대해 3 IOPS를 제공합니다. 따라서 볼륨의 크기를 늘리면 더 많은 IOPS를 제공받을 수 있습니다. 예를 들어, 1GiB에서 100GiB로 늘리면 IOPS는 300으로 증가합니다.
- **빠른 적용**: EBS 볼륨 크기 변경은 최소한의 다운타임으로 수행할 수 있으며, 이미 설정된 정책이나 수락 테스트 없이도 즉시 성능을 향상시킬 수 있는 가장 빠른 방법입니다.

### **대안 설명:**
2. **각 EC2 인스턴스에 두 개의 추가 탄력적 네트워크 인터페이스를 추가합니다.**
   - 이 방법은 네트워크 성능을 향상시킬 수 있지만, EBS 볼륨의 IOPS와는 관련이 없습니다.

3. **해당 지역의 EBS 볼륨에서 전송 가속을 켭니다.**
   - EBS 볼륨에서 전송 가속은 지원되지 않으며, EBS 볼륨의 성능을 직접적으로 향상시키지 않습니다.

4. **모든 EC2 인스턴스를 클러스터 배치 그룹에 추가합니다.**
   - 클러스터 배치 그룹은 네트워크 대역폭 및 지연 시간 측면에서 성능을 향상시킬 수 있지만, EBS 볼륨의 IOPS 성능에는 직접적인 영향을 미치지 않습니다.

결론적으로, **EBS 볼륨의 크기를 늘리는 것이 I/O 성능을 높이는 가장 효과적이고 빠른 방법입니다.**



## 질문: 209 +

회사에서 AWS에 새로운 워크로드를 배포해야 합니다. 

회사는 모든 저장 데이터를 암호화하고 매년 한 번씩 암호화 키를 순환해야 합니다. 워크로드는 데이터 저장을 위해 Amazon RDS for MySQL Multi-AZ 데이터베이스를 사용합니다.
어떤 구성 방식이 이러한 요구 사항을 충족할까요?

1. MySQL 구성 파일에서 Transparent Data Encryption(TDE)을 활성화합니다. 12개월마다 수동으로 키를 회전합니다.
2. Amazon RDS에 대한 AWS 관리 키를 사용하여 데이터베이스 생성 시 RDS 암호화를 활성화합니다.
3. 새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. KMS 키를 사용하여 생성 시 데이터베이스에서 RDS 암호화를 활성화합니다.
4. 새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. RDS DB 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에서 암호화를 활성화합니다.

회사의 요구 사항에 맞게 AWS에서 새로운 워크로드를 배포하기 위한 최적의 구성 방식은 다음과 같습니다:

### **3. 새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. KMS 키를 사용하여 생성 시 데이터베이스에서 RDS 암호화를 활성화합니다.**

#### 이유:
- **데이터 암호화**: AWS KMS를 사용하여 RDS 데이터베이스를 암호화할 수 있으며, 데이터베이스가 생성될 때 KMS 키를 사용하여 데이터를 보호합니다.
- **자동 키 로테이션**: KMS는 고객 관리 키에 대해 자동 키 로테이션을 지원하므로, 매년 키를 수동으로 순환할 필요 없이 1년에 한 번 자동으로 키를 교체할 수 있습니다. 이를 통해 보안성을 높이고 관리의 편의성을 제공합니다.

### **대안 설명:**

1. **MySQL 구성 파일에서 Transparent Data Encryption(TDE)을 활성화합니다. 12개월마다 수동으로 키를 회전합니다.**
   - MySQL TDE는 RDS에서 지원되지 않으며, RDS for MySQL의 경우 AWS KMS를 사용한 암호화가 필요합니다. 수동으로 키를 회전하는 것은 비효율적입니다.

2. **Amazon RDS에 대한 AWS 관리 키를 사용하여 데이터베이스 생성 시 RDS 암호화를 활성화합니다.**
   - AWS 관리 키는 AWS에 의해 관리되지만, 회사가 매년 키를 순환해야 하는 요구 사항을 충족하지 않습니다. 키 관리에 대한 제어력이 떨어집니다.

4. **새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. RDS DB 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에서 암호화를 활성화합니다.**
   - EBS 볼륨의 암호화는 RDS의 데이터베이스 자체와는 관계가 없습니다. RDS 데이터베이스의 암호화를 위해서는 KMS 키를 사용하여 RDS에서 직접 암호화를 활성화해야 합니다.

결론적으로, **AWS KMS를 사용하여 고객 관리 키를 생성하고 자동 키 로테이션을 활성화하는 것이 요구 사항을 충족하는 가장 효과적인 방법입니다.**

## 질문: 210 +++

한 회사에 액티브-패시브 구성으로 두 개의 AWS 리전에 배포된 애플리케이션이 있습니다. 

이 애플리케이션은 각 리전의 애플리케이션 로드 밸런서(ALB) 뒤에 있는 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 각 리전의 Amazon EC2 자동 확장 그룹에 있습니다. 이 애플리케이션은 DNS에 Amazon Route 53 호스팅 영역을 사용합니다. SysOps 관리자는 보조 리전으로 자동 장애 조치를 구성해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. 각 ALB를 가리키는 Route 53 별칭 레코드를 구성합니다. 장애 조치 라우팅 정책을 선택합니다. Evaluate Target Health를 Yes로 설정합니다.
2. 각 AL을 가리키는 CNAME 레코드 구성 장애 조치 라우팅 정책 선택. 대상 상태 평가를 예로 설정.
3. Auto Scaling 그룹에 대한 Elastic Load Balancing(ELB) 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.
4. 자동 확장 그룹에 대한 EC2 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.

SysOps 관리자가 액티브-패시브 구성으로 두 개의 AWS 리전에 배포된 애플리케이션에 대해 자동 장애 조치를 구성하기 위한 최적의 솔루션은 다음과 같습니다:

**1. 각 ALB를 가리키는 Route 53 별칭 레코드를 구성합니다. 장애 조치 라우팅 정책을 선택합니다. Evaluate Target Health를 Yes로 설정합니다.**

#### 이유:
- **Route 53 별칭 레코드**: Amazon Route 53의 별칭 레코드를 사용하면 ALB에 대한 직접적인 DNS 레코드를 생성할 수 있습니다. 이 방식은 ELB와 같은 AWS 리소스를 직접적으로 참조할 수 있는 장점이 있습니다.
- **장애 조치 라우팅 정책**: 장애 조치 라우팅 정책을 선택함으로써, 기본 리전의 ALB가 비정상일 경우 Route 53이 보조 리전으로 자동으로 트래픽을 전환할 수 있습니다.
- **Evaluate Target Health**: 이 설정을 `Yes`로 설정하면 Route 53이 ALB의 상태를 모니터링하여, ALB가 비정상일 경우 장애 조치를 수행할 수 있습니다.

### **대안 설명:**

2. **각 ALB를 가리키는 CNAME 레코드 구성 장애 조치 라우팅 정책 선택. 대상 상태 평가를 예로 설정.**
   - CNAME 레코드는 AWS 리소스를 직접 참조할 수 없으며, 별칭 레코드를 사용해야 합니다. 또한, `Evaluate Target Health`가 CNAME 레코드에서는 적용되지 않습니다.

3. **Auto Scaling 그룹에 대한 Elastic Load Balancing(ELB) 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.**
   - 이 방법은 ALB의 상태 검사와 관련이 있지만, Route 53의 DNS 장애 조치 기능을 사용하지 않으므로, 트래픽을 자동으로 전환하는 방식에 대한 해결책이 아닙니다.

4. **자동 확장 그룹에 대한 EC2 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.**
   - EC2 상태 검사는 EC2 인스턴스의 상태를 모니터링하지만, Route 53을 통해 DNS 수준에서 자동으로 장애 조치를 수행하는 방법이 아닙니다.

결론적으로, **Route 53 별칭 레코드와 장애 조치 라우팅 정책을 사용하는 것이 이 시나리오에서 자동 장애 조치를 효과적으로 구현하는 방법입니다.**


## 질문: 211 +++++

한 회사가 머신 러닝을 기반으로 하는 모니터링 솔루션을 구현하고 있습니다. 

모니터링 솔루션은 Amazon EC2 Auto Scaling에서 생성된 Amazon EventBridge(Amazon CloudWatch Events) 이벤트를 사용합니다. 모니터링 솔루션은 예상치 못한 확장 이벤트와 같은 비정상적인 동작을 감지하며 EventBridge(CloudWatch Events) API 대상으로 구성됩니다.

초기 테스트 중에 회사는 모니터링 솔루션이 이벤트를 수신하지 않는다는 것을 알게 됩니다. 그러나 Amazon CloudWatch는 EventBridge(CloudWatch Events) 규칙이 호출되고 있음을 보여줍니다. SysOps 관리자는 이 문제를 해결하기 위해 클라이언트 오류 세부 정보를 검색하는 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 노력으로 이러한 요구 사항을 충족할까요?

1. 이벤트 패턴에 대한 EventBridge(CloudWatch Events) 아카이브를 만들어 이벤트를 재생합니다. 모니터링 솔루션에서 로깅을 늘립니다. replay를 사용하여 모니터링 솔루션을 호출합니다. 오류 세부 정보를 검토합니다.
2. 대상의 배달 못한 편지 대기열로 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 추가합니다. 배달 못한 편지 대기열의 메시지를 처리하여 오류 세부 정보를 검색합니다.
3. AWS Lambda 함수를 대상으로 동일한 이벤트 패턴에 대한 두 번째 EventBridge(CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 모니터링 솔루션을 호출하고 Amazon CloudWatch Logs에 결과를 기록합니다. 로그에서 오류를 검사합니다.
4. Amazon Simple Notification Service(Amazon SNS) 주제에 오류 메시지를 보내도록 EventBridge(CloudWatch Events) 규칙을 구성합니다.
 
이 문제를 해결하기 위한 최소한의 운영 노력으로 요구 사항을 충족할 수 있는 솔루션은 다음과 같습니다:

**1. 이벤트 패턴에 대한 EventBridge(CloudWatch Events) 아카이브를 만들어 이벤트를 재생합니다. 모니터링 솔루션에서 로깅을 늘립니다. replay를 사용하여 모니터링 솔루션을 호출합니다. 오류 세부 정보를 검토합니다.**

#### 이유:
- **이벤트 아카이브**: EventBridge에서는 이벤트 아카이브를 생성하여 과거의 이벤트를 저장하고 필요 시 재생할 수 있습니다. 이는 이벤트가 정상적으로 수신되지 않는 이유를 진단하는 데 유용합니다.
- **이벤트 재생**: 아카이브에서 이벤트를 재생하여 모니터링 솔루션이 해당 이벤트를 제대로 처리하는지 확인할 수 있습니다. 이를 통해 모니터링 솔루션에서 오류가 발생하는지 또는 이벤트 처리에 문제가 있는지 검토할 수 있습니다.
- **로깅 증가**: 모니터링 솔루션에서 로깅을 늘리면 발생한 오류의 세부 사항을 더 잘 파악할 수 있어 문제 해결에 도움이 됩니다.

### **대안 설명:**

2. **대상의 배달 못한 편지 대기열로 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 추가합니다. 배달 못한 편지 대기열의 메시지를 처리하여 오류 세부 정보를 검색합니다.**
   - 이 방법은 추가적인 복잡성을 도입하며, 문제를 진단하기 위한 정보 제공 측면에서 덜 효율적일 수 있습니다. 특히 클라이언트 오류가 발생하는 경우를 완전히 감지하지 못할 수 있습니다.

3. **AWS Lambda 함수를 대상으로 동일한 이벤트 패턴에 대한 두 번째 EventBridge(CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 모니터링 솔루션을 호출하고 Amazon CloudWatch Logs에 결과를 기록합니다. 로그에서 오류를 검사합니다.**
   - 이 방법은 효과적일 수 있지만, 추가적인 Lambda 함수를 설정해야 하고 이를 통해 발생할 수 있는 복잡성을 감안하면 초기 테스트의 간단한 문제를 해결하기에는 과한 솔루션입니다.

4. **Amazon Simple Notification Service(Amazon SNS) 주제에 오류 메시지를 보내도록 EventBridge(CloudWatch Events) 규칙을 구성합니다.**
   - SNS를 통한 오류 메시지 전송은 모니터링 솔루션이 실패할 경우 알림을 받을 수 있지만, 세부적인 오류 정보를 수집하는 데는 한계가 있을 수 있습니다. 클라이언트 오류 세부 정보를 얻기 위한 방법으로는 덜 효과적입니다.

결론적으로, **이벤트 아카이브를 사용하고 이벤트를 재생하여 로깅을 통해 오류 세부 정보를 확인하는 방법이 가장 효과적이며 운영 노력도 최소화할 수 있습니다.**



## 질문: 212 +++

한 회사가 Amazon S3 버킷에 백업을 저장하고 있습니다. 

백업은 백업이 생성된 후 최소 3개월 동안 삭제되어서는 안 됩니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. 모든 사용자에 대해 s3:DeleteObject 작업을 거부하는 IAM 정책을 구성합니다. 객체가 작성된 후 3개월이 지나면 정책을 제거합니다.
2. 규정 준수 모드에서 새 S3 버킷에 S3 개체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관 기간 3개월로 저장합니다.
3. 기존 S3 버킷에서 S3 버전 관리를 활성화합니다. 백업을 보호하기 위해 S3 라이프사이클 규칙을 구성합니다.
4. 거버넌스 모드에서 새 S3 버킷에 S3 객체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관하고 보관 기간은 3개월입니다.
 

이 요구 사항을 충족하기 위한 가장 적절한 솔루션은 다음과 같습니다:

### **2. 규정 준수 모드에서 새 S3 버킷에 S3 개체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관 기간 3개월로 저장합니다.**

#### 이유:
- **S3 개체 잠금**: S3 개체 잠금을 사용하면 객체가 잠금 상태로 유지되어 지정된 기간 동안 삭제할 수 없게 됩니다. 이 기능은 데이터의 무결성을 보장하고 요구 사항에 맞게 데이터를 보호하는 데 적합합니다.
- **규정 준수 모드**: 규정 준수 모드를 선택하면 모든 객체가 설정된 보관 기간 동안 삭제되지 않도록 보장할 수 있으며, 이 모드에서는 객체의 삭제가 허용되지 않습니다.
- **3개월 보관**: 이 요구 사항은 3개월 동안 객체를 삭제할 수 없도록 하기 때문에 S3 개체 잠금이 가장 적합한 옵션입니다.

### **대안 설명:**

1. **모든 사용자에 대해 s3:DeleteObject 작업을 거부하는 IAM 정책을 구성합니다. 객체가 작성된 후 3개월이 지나면 정책을 제거합니다.**
   - 이 방법은 객체를 보호하는 데 효과적이지 않습니다. IAM 정책을 수동으로 제거해야 하므로 실수나 관리 작업으로 인해 오류가 발생할 수 있습니다.

3. **기존 S3 버킷에서 S3 버전 관리를 활성화합니다. 백업을 보호하기 위해 S3 라이프사이클 규칙을 구성합니다.**
   - S3 버전 관리는 객체의 이전 버전을 보관하는 데 유용하지만, 이 옵션은 특정 기간 동안 객체를 삭제할 수 없도록 보장하지 않으므로 요구 사항을 완전히 충족하지 않습니다.

4. **거버넌스 모드에서 새 S3 버킷에 S3 객체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관하고 보관 기간은 3개월입니다.**
   - 거버넌스 모드는 삭제 권한이 있는 사용자에게 객체를 삭제할 수 있는 권한을 남겨두지만, 요구 사항에서는 3개월 동안 삭제가 불가능해야 하므로 적절하지 않습니다.

결론적으로, **S3 개체 잠금을 규정 준수 모드로 활성화하여 백업이 3개월 동안 삭제되지 않도록 하는 방법이 가장 효과적이며 요구 사항을 충족하는 방법입니다.**




## 질문: 213 +

SysOps 관리자는 AWS 리전 간 데이터 전송 비용을 추적해야 합니다. 

SysOps 관리자는 전송 비용이 특정 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내는 솔루션을 구현해야 합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. AWS 비용 및 사용 보고서를 만듭니다. Amazon Athena에서 결과를 분석합니다. 비용이 임계값의 75%에 도달하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.
2. 비용이 임계값의 75%에 도달하면 감지하도록 Amazon CloudWatch 청구 알람을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.
3. AWS Budgets를 사용하여 데이터 전송 비용에 대한 비용 예산을 만듭니다. 예산 금액의 75%에 알림을 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 예산을 구성합니다.
4. VPC 흐름 로그를 설정합니다. 데이터 전송을 분석하기 위해 AWS Lambda 함수에 구독 필터를 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 Lambda 함수를 구성합니다.

이 요구 사항을 충족하기 위한 가장 적절한 솔루션은 다음과 같습니다:

### **3. AWS Budgets를 사용하여 데이터 전송 비용에 대한 비용 예산을 만듭니다. 예산 금액의 75%에 알림을 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 예산을 구성합니다.**

#### 이유:
- **AWS Budgets**: 이 서비스는 사용자가 설정한 예산 기준에 따라 비용 및 사용량을 추적할 수 있게 해줍니다. 데이터 전송 비용에 대해 특정 임계값을 설정하고, 해당 임계값의 75%에 도달했을 때 알림을 보낼 수 있습니다.
- **이메일 알림**: AWS Budgets에서는 비용이 임계값에 도달했을 때 Amazon Simple Notification Service(Amazon SNS)를 통해 이메일 알림을 보낼 수 있습니다. 이를 통해 필요한 이메일 배포 목록에 직접 알림을 보낼 수 있습니다.

### **대안 설명:**

1. **AWS 비용 및 사용 보고서를 만듭니다. Amazon Athena에서 결과를 분석합니다. 비용이 임계값의 75%에 도달하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.**
   - 이 방법은 유용하지만 설정과 관리가 복잡합니다. Athena를 사용해 분석해야 하므로 추가적인 작업이 필요합니다.

2. **비용이 임계값의 75%에 도달하면 감지하도록 Amazon CloudWatch 청구 알람을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.**
   - CloudWatch 청구 알람은 특정 비용을 감지하는 데 유용하지만, 예산을 설정하고 관리하는 것보다 덜 유연합니다. AWS Budgets가 더 적합한 선택입니다.

4. **VPC 흐름 로그를 설정합니다. 데이터 전송을 분석하기 위해 AWS Lambda 함수에 구독 필터를 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 Lambda 함수를 구성합니다.**
   - VPC 흐름 로그 및 Lambda를 사용하여 데이터 전송을 추적하는 것은 가능하지만, 비용 전송과 직접적인 관련이 없고 설정이 복잡하므로 최적의 솔루션이 아닙니다.

결론적으로, **AWS Budgets를 사용하여 데이터 전송 비용에 대한 예산을 설정하고 알림을 구성하는 방법이 가장 효과적이며 요구 사항을 충족하는 방법입니다.**


## 질문: 214

회사는 모든 감사 로그를 10년 동안 보관해야 합니다. 회사는 로그를 향후 편집으로부터 보호해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. AWS Key Management Service(AWS KMS) 암호화를 구성합니다.
2. Amazon S3 Glacier 볼트에 데이터를 저장합니다. WORM(write-once, read-many) 액세스에 대한 볼트 잠금 정책을 구성합니다.
3. Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 서버 측 암호화를 구성합니다.
4. Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 다중 요소 인증(MFA)을 구성합니다.
 
회사가 모든 감사 로그를 10년 동안 보관하고, 로그를 향후 편집으로부터 보호해야 하는 요구 사항을 충족하기 위한 가장 적절한 솔루션은 다음과 같습니다:

**2. Amazon S3 Glacier 볼트에 데이터를 저장합니다. WORM(write-once, read-many) 액세스에 대한 볼트 잠금 정책을 구성합니다.**

#### 이유:
- **Amazon S3 Glacier**: 이 서비스는 장기 보관 및 저비용 저장에 적합하며, 10년 동안 데이터를 안전하게 보관하는 데 유용합니다.
- **WORM 볼트 잠금 정책**: WORM 정책을 사용하면 데이터가 작성된 후 변경할 수 없도록 보호되며, 이는 로그 데이터의 무결성을 보장하는 데 매우 중요합니다. 볼트 잠금을 통해 데이터는 설정된 기간 동안 삭제되거나 수정될 수 없습니다.

### **대안 설명:**

1. **Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. AWS Key Management Service(AWS KMS) 암호화를 구성합니다.**
   - EBS는 일반적으로 블록 저장소이며, 장기 보관 및 WORM 보호에는 적합하지 않습니다. 로그 데이터의 무결성을 보장하기 어려울 수 있습니다.

3. **Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 서버 측 암호화를 구성합니다.**
   - S3 Standard-IA는 적당한 비용으로 데이터에 액세스할 수 있지만, WORM 보호 기능이 없어 로그의 편집 및 삭제로부터 보호할 수 없습니다.

4. **Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 다중 요소 인증(MFA)을 구성합니다.**
   - MFA는 추가적인 보안 계층을 제공하지만, WORM 보호 기능이 없으므로 로그의 변경을 방지하는 데 적합하지 않습니다.

결론적으로, **Amazon S3 Glacier와 WORM 볼트 잠금 정책을 사용하는 것이 10년 동안 로그를 보관하고 편집으로부터 보호하는 데 가장 효과적인 방법입니다.**



## 질문: 215

회사의 AWS Lambda 함수에서 성능 문제가 발생하고 있습니다. 

Lambda 함수는 많은 CPU 집약적 작업을 수행합니다. Lambda 함수가 충분히 빠르게 실행되지 않아 시스템에 병목 현상이 발생합니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1. Lambda 함수의 CPU 시작 옵션에서 하이퍼스레딩을 활성화합니다.
2. AWS 관리 암호화를 끕니다.
3. Lambda 함수의 메모리 양을 늘립니다.
4. 필요한 코드를 사용자 정의 레이어에 로드합니다.

AWS Lambda 함수에서 CPU 집약적 작업으로 인해 성능 문제가 발생하는 경우, 이를 해결하기 위해 가장 적절한 조치는 다음과 같습니다:

### **3. Lambda 함수의 메모리 양을 늘립니다.**

#### 이유:
- AWS Lambda는 메모리 할당량에 따라 CPU 성능을 자동으로 조정합니다. 즉, 더 많은 메모리를 할당하면 Lambda 함수에 할당되는 CPU 용량도 증가합니다. 따라서 Lambda 함수의 메모리를 늘리면 CPU 성능이 향상되어 성능 병목 현상이 완화될 수 있습니다.

### **대안 설명:**

1. **Lambda 함수의 CPU 시작 옵션에서 하이퍼스레딩을 활성화합니다.**
   - AWS Lambda에서는 하이퍼스레딩을 수동으로 활성화할 수 없으며, CPU는 메모리와 함께 자동으로 할당됩니다. 따라서 이 옵션은 사용할 수 없습니다.

2. **AWS 관리 암호화를 끕니다.**
   - 암호화는 성능에 큰 영향을 미치지 않으며, 보안과 관련된 중요한 요소이기 때문에 단순히 끄는 것은 권장되지 않습니다.

4. **필요한 코드를 사용자 정의 레이어에 로드합니다.**
   - 사용자 정의 레이어는 코드 재사용 및 관리에 유용하지만, CPU 성능 문제를 직접 해결하지는 않습니다. 성능을 개선하려면 메모리를 늘리는 것이 더 효과적입니다.

결론적으로, Lambda 함수의 성능을 개선하기 위해 **메모리 양을 늘리는 것이 가장 효과적인 방법**입니다.

## 질문: 216 ++

한 회사가 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다.

웹 서버 로그는 Amazon CloudWatch Logs에 게시됩니다. 로그 이벤트는 동일한 구조를 가지고 있으며 사용자 요청과 관련된 HTTP 응답 코드를 포함합니다. 이 회사는 웹 서버가 HTTP 404 응답을 반환하는 횟수를 모니터링해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. 웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 메트릭 필터를 만듭니다.
2. 웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 구독 필터를 만듭니다.
3. 지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 AWS Lambda 함수를 만듭니다.
4. 지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 스크립트를 만듭니다.
 
HTTP 404 응답을 모니터링하기 위한 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **1. 웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 메트릭 필터를 만듭니다.**

#### 이유:
- **메트릭 필터**를 사용하면 CloudWatch Logs에서 특정 로그 이벤트(이 경우 HTTP 404 응답)를 자동으로 수집하고 이를 기반으로 메트릭을 생성할 수 있습니다. 이 방법은 실시간으로 모니터링할 수 있으며, 다른 설정이나 추가 작업 없이도 특정 이벤트의 수를 쉽게 추적할 수 있습니다.
- 메트릭 필터를 설정하면 CloudWatch 대시보드에서 이를 시각화하거나 알람을 설정하는 것도 간단합니다.

### **대안 설명:**

2. **웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 구독 필터를 만듭니다.**
   - 구독 필터는 실시간 데이터 흐름을 위해 주로 사용됩니다. HTTP 404 응답을 모니터링하는 데 유용할 수 있지만, 메트릭을 수집하고 모니터링하는 효율성 측면에서는 메트릭 필터보다 덜 효율적입니다.

3. **지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 AWS Lambda 함수를 만듭니다.**
   - 이 방법은 수동적이며, Lambda 함수를 호출해야 하므로 운영적으로 덜 효율적입니다. 쿼리를 정기적으로 실행해야 하므로 자동화 측면에서도 추가적인 관리가 필요합니다.

4. **지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 스크립트를 만듭니다.**
   - 스크립트를 주기적으로 실행해야 하며, 추가적인 유지 관리가 필요하므로 운영 효율성 측면에서는 비효율적입니다.

결론적으로, **CloudWatch Logs 메트릭 필터**를 설정하는 것이 HTTP 404 응답을 모니터링하는 데 있어 가장 운영 효율적인 솔루션입니다.



## 질문: 217 +

한 회사가 AWS 클라우드에서 비용을 관리하려고 합니다. 

SysOps 관리자는 청구 보고서에 표시될 리소스에 할당된 특정 회사 정의 태그가 필요합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. AWS에서 생성한 비용 할당 태그로 태그를 활성화합니다.
2. 태그를 사용자 정의 비용 배분 태그로 활성화합니다.
3. 새로운 비용 범주를 만듭니다. 계정 청구 차원을 선택합니다.
4. 새로운 AWS 비용 및 사용 보고서를 만듭니다. 리소스 ID를 포함합니다.

AWS에서 비용 관리 요구 사항을 충족하기 위해 SysOps 관리자가 해야 할 조치는 다음과 같습니다:

### **2. 태그를 사용자 정의 비용 배분 태그로 활성화합니다.**

#### 이유:
- **사용자 정의 비용 배분 태그**를 활성화하면 AWS 청구 및 비용 관리 대시보드에서 특정 태그를 사용하여 리소스 비용을 추적하고 보고할 수 있습니다. 이렇게 하면 각 리소스에 대한 비용을 분석하고 회사의 요구에 따라 리소스를 할당할 수 있습니다.
- 이 태그는 청구 보고서에 포함되어 특정 태그가 할당된 리소스의 비용을 정확하게 파악할 수 있도록 도와줍니다.

### **대안 설명:**

1. **AWS에서 생성한 비용 할당 태그로 태그를 활성화합니다.**
   - AWS에서 자동으로 생성한 태그는 일반적으로 기본 제공되는 태그이며, 특정 회사 정의 태그를 포함하지 않을 수 있습니다.

3. **새로운 비용 범주를 만듭니다. 계정 청구 차원을 선택합니다.**
   - 비용 범주는 비용을 그룹화하는 데 사용되지만, 특정 리소스에 대한 태그를 활성화하는 것과는 다릅니다. 특정 태그에 대한 비용을 관리하기 위해서는 비용 배분 태그가 필요합니다.

4. **새로운 AWS 비용 및 사용 보고서를 만듭니다. 리소스 ID를 포함합니다.**
   - 비용 및 사용 보고서는 정보를 집계할 수 있지만, 특정 태그를 활성화하지 않으면 원하는 리소스에 대한 세부 비용을 추적할 수 없습니다.

결론적으로, **사용자 정의 비용 배분 태그를 활성화하는 것**이 회사 정의 태그가 청구 보고서에 표시될 수 있도록 하는 가장 효과적인 방법입니다.


## 질문: 218 +++

한 회사가 전 세계적으로 확장 중이며 Amazon Elastic Block Store(Amazon EBS) 볼륨의 데이터를 다른 AWS 리전으로 백업해야 합니다. 

데이터를 저장하는 대부분의 EBS 볼륨은 암호화되어 있지만 일부 EBS 볼륨은 암호화되지 않았습니다. 이 회사는 모든 EBS 볼륨의 백업 데이터를 암호화해야 합니다.
어떤 솔루션이 가장 적은 관리 오버헤드로 이러한 요구 사항을 충족할까요?

1. Amazon Data Lifecycle Manager(Amazon DLM)에서 수명 주기 정책을 구성하여 크로스 리전 백업이 활성화된 EBS 볼륨 스냅샷을 만듭니다. AWS Key Management Service(AWS KMS)를 사용하여 스냅샷 사본을 암호화합니다.
2. EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷 상태가 COMPLETED이면 스냅샷을 다른 Region으로 복사하고 Encrypted 매개변수를 False로 설정합니다.
3. EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷을 서버 측 암호화를 사용하는 Amazon S3 버킷에 복사합니다. S3 버킷에서 S3 Cross-Region Replication을 켭니다.
4.  Python 런타임으로 AWS Lambda 함수를 예약합니다. Lambda 함수를 구성하여 EBS 볼륨 스냅샷을 만들고, 암호화되지 않은 스냅샷을 암호화하고, 스냅샷을 다른 리전으로 복사합니다.

주어진 요구 사항을 충족하는 가장 관리 오버헤드가 적은 솔루션은 다음과 같습니다:

### **1. Amazon Data Lifecycle Manager(Amazon DLM)에서 수명 주기 정책을 구성하여 크로스 리전 백업이 활성화된 EBS 볼륨 스냅샷을 만듭니다. AWS Key Management Service(AWS KMS)를 사용하여 스냅샷 사본을 암호화합니다.**

#### 이유:
- **Amazon Data Lifecycle Manager (DLM)**를 사용하면 EBS 볼륨의 스냅샷을 자동으로 생성하고 관리할 수 있으며, 정책에 따라 주기적으로 실행됩니다. 이로 인해 수동으로 스냅샷을 만들 필요가 없어 관리 오버헤드가 줄어듭니다.
- **크로스 리전 백업**을 활성화하면 스냅샷이 다른 AWS 리전으로 자동으로 복사되므로 추가적인 작업이 필요 없습니다.
- **AWS KMS를 사용한 암호화**는 자동으로 모든 스냅샷에 적용되므로, 암호화되지 않은 볼륨도 안전하게 보호할 수 있습니다.

### **대안 설명:**

2. **EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷 상태가 COMPLETED이면 스냅샷을 다른 Region으로 복사하고 Encrypted 매개변수를 False로 설정합니다.**
   - 이 방법은 수동 작업이 필요하며 관리 오버헤드가 더 많습니다. 각 스냅샷을 수동으로 확인하고 복사해야 하므로 비효율적입니다.

3. **EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷을 서버 측 암호화를 사용하는 Amazon S3 버킷에 복사합니다. S3 버킷에서 S3 Cross-Region Replication을 켭니다.**
   - 이 방법은 EBS 스냅샷을 S3에 복사하는 복잡한 절차를 요구하며, EBS 볼륨의 데이터를 S3로 복사하는 것은 일반적으로 권장되지 않습니다.

4. **Python 런타임으로 AWS Lambda 함수를 예약합니다. Lambda 함수를 구성하여 EBS 볼륨 스냅샷을 만들고, 암호화되지 않은 스냅샷을 암호화하고, 스냅샷을 다른 리전으로 복사합니다.**
   - Lambda 함수를 사용하는 방법은 관리 오버헤드가 크고 유지보수해야 할 코드가 필요합니다. 이는 자동화의 이점을 줄입니다.

결론적으로, **Amazon Data Lifecycle Manager를 사용하는 방법**이 가장 효율적이며 관리 오버헤드가 적어 요구 사항을 충족할 수 있습니다.

## 질문: 219

SysOps 관리자가 AWS Fargate를 사용하는 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터를 만듭니다. 

클러스터가 성공적으로 배포되었습니다. SysOps 관리자는 kubectl 명령줄 도구를 사용하여 클러스터를 관리해야 합니다.
kubectl이 클러스터 API 서버와 통신할 수 있도록 SysOps 관리자의 머신에서 다음 중 어떤 것을 구성해야 합니까?

1. kubeconfig 파일
2. kube-proxy Amazon EKS 추가 기능
3. Fargate 프로필
4. eks-connector.yaml 파일

SysOps 관리자가 AWS Fargate를 사용하는 Amazon Elastic Kubernetes Service (EKS) 클러스터에서 `kubectl` 명령줄 도구를 사용하여 클러스터를 관리하기 위해 구성해야 하는 것은 다음과 같습니다:

### **1. kubeconfig 파일**

#### 이유:
- **kubeconfig 파일**은 `kubectl`이 Kubernetes API 서버와 통신하기 위해 필요한 클러스터 정보, 사용자 인증 정보 및 네임스페이스 설정을 포함합니다.
- EKS 클러스터를 배포하면 AWS CLI 또는 AWS Management Console을 통해 `kubeconfig` 파일을 생성하고 구성할 수 있습니다. 이 파일을 사용하여 `kubectl` 명령어로 EKS 클러스터에 접근하고 관리할 수 있습니다.

### **다른 옵션 설명:**

2. **kube-proxy Amazon EKS 추가 기능**:
   - `kube-proxy`는 Kubernetes 클러스터 내에서 네트워크 트래픽을 관리하는 구성 요소입니다. 이 기능은 클러스터 내부에서 동작하며 `kubectl`과의 통신을 설정하는 데 필요하지 않습니다.

3. **Fargate 프로필**:
   - Fargate 프로필은 EKS에서 작업을 실행할 Fargate 작업을 정의하는 데 사용되며, `kubectl`의 통신 설정과는 관련이 없습니다.

4. **eks-connector.yaml 파일**:
   - `eks-connector.yaml`은 일반적으로 EKS 클러스터와 AWS 리소스를 연결하는 구성 파일이지만, `kubectl`을 사용하여 클러스터를 관리하는 데는 필요하지 않습니다.

따라서, **kubeconfig 파일**을 설정하는 것이 `kubectl`이 클러스터 API 서버와 통신할 수 있도록 하는 올바른 방법입니다.


## 질문: 220 +++

한 회사가 분석에 사용할 애플리케이션에서 데이터를 수집하려고 합니다. 

처음 90일 동안은 데이터에 자주 액세스하지 않지만 가용성은 높게 유지해야 합니다. 이 기간 동안 회사의 분석 팀은 밀리초 단위로 데이터에 액세스해야 합니다. 그러나 90일 후에는 회사에서 더 낮은 비용으로 장기간 데이터를 보관해야 합니다. 90일 후 검색 시간은 5시간 미만이어야 합니다.

이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

1.처음 90일 동안 S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 90일 후 S3 Glacier Flexible Retrieval로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
2.처음 90일 동안 S3 One Zone-Infrequent Access(S3 One Zone-IA)에 데이터를 저장합니다. 90일 후에 S3 Glacier Deep Archive로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
3.처음 90일 동안 S3 Standard에 데이터를 저장합니다. 90일 후 S3 Glacier Flexible Retrieval로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
4.처음 90일 동안 S3 Standard에 데이터를 저장합니다. 90일 후 S3 Glacier Deep Archive로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.

이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 다음과 같습니다:

### **3. 처음 90일 동안 S3 Standard에 데이터를 저장합니다. 90일 후 S3 Glacier Flexible Retrieval로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.**

#### 이유:
1. **초기 90일 동안 S3 Standard 사용**:
   - **S3 Standard** 스토리지 클래스는 고가용성을 제공하며, 밀리초 단위로 데이터에 액세스할 수 있는 속도를 지원합니다. 처음 90일 동안 자주 액세스할 데이터에 적합합니다.

2. **90일 후 S3 Glacier Flexible Retrieval로 이동**:
   - **S3 Glacier Flexible Retrieval**는 장기 저장을 위해 비용 효율적이며, 검색 시간은 5시간 이내로 설정할 수 있습니다. 따라서 초기 요구 사항이 완료된 후 데이터를 안전하게 저장할 수 있습니다.

### **다른 옵션 설명:**

1. **S3 Standard-IA**:
   - 처음 90일 동안 사용할 수 있지만, 이 스토리지 클래스는 저비용의 비정기적인 액세스를 위한 것이므로 데이터에 자주 액세스해야 하는 경우 적합하지 않습니다.

2. **S3 One Zone-IA**:
   - 저렴한 비용으로 제공되지만, 데이터 내구성과 가용성이 떨어집니다. 따라서 높은 가용성이 필요한 데이터에는 적합하지 않습니다.

3. **S3 Glacier Deep Archive**:
   - 가장 저렴한 스토리지 옵션이지만, 검색 시간이 12시간 이상 걸리므로 90일 후에도 5시간 이내로 검색해야 하는 요구 사항에 부합하지 않습니다.

따라서, **처음 90일 동안 S3 Standard에 데이터를 저장하고 90일 후에 S3 Glacier Flexible Retrieval로 이동하는 방법이 가장 적합합니다.**

## 질문: 221 +++++

회사의 애플리케이션은 현재 모든 AWS 서비스에 대한 모든 액세스를 허용하는 IAM 역할을 사용합니다. 

SysOps 관리자는 회사의 IAM 정책이 애플리케이션에 필요한 권한만 허용하는지 확인해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하는 정책을 어떻게 만들 수 있습니까?

1.AWS CloudTrail을 켭니다. AWS Security Hub를 사용하여 정책을 생성합니다.
2.Amazon EventBridge(Amazon CloudWatch Events)를 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.
3.AWS CLI를 사용하여 AWS Identity and Access Management Access Analyzer에서 get-generated-policy 명령을 실행합니다.
4.AWS CloudTrail을 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.
 

SysOps 관리자가 회사의 IAM 정책이 애플리케이션에 필요한 권한만 허용하는지 확인하기 위해 가장 적합한 방법은 다음과 같습니다:
**3. AWS CLI를 사용하여 AWS Identity and Access Management Access Analyzer에서 get-generated-policy 명령을 실행합니다.**

#### 이유:
- **AWS IAM Access Analyzer**는 기존 리소스의 액세스 로그를 분석하여 IAM 역할 또는 정책에 필요한 최소 권한을 생성하는 데 도움을 줍니다.
- `get-generated-policy` 명령은 특정 역할에 대한 사용 기록을 기반으로 권한을 자동으로 생성합니다. 이를 통해 현재 IAM 역할이 실제로 사용하는 권한만 포함된 정책을 얻을 수 있습니다.

### **다른 옵션 설명:**

1. **AWS CloudTrail을 켭니다. AWS Security Hub를 사용하여 정책을 생성합니다.**
   - CloudTrail은 API 호출을 기록하지만, Security Hub는 보안 관련 데이터를 집계하는 도구로 IAM 정책을 직접 생성하는 데는 사용되지 않습니다.

2. **Amazon EventBridge(Amazon CloudWatch Events)를 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.**
   - EventBridge는 이벤트 기반 서비스이며, Access Analyzer와 함께 사용할 수 있지만, 정책 생성을 위한 직접적인 방법은 아닙니다.

4. **AWS CloudTrail을 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.**
   - CloudTrail을 활성화하는 것은 좋지만, 직접적인 정책 생성 기능은 Access Analyzer의 기능이므로, 이 방법은 완전한 솔루션이 아닙니다.

따라서, **AWS CLI를 사용하여 AWS Identity and Access Management Access Analyzer에서 get-generated-policy 명령을 실행하는 것이 가장 적합한 방법입니다.**




## 질문: 222 ++++

한 회사에서 Amazon EC2 Amazon Machine Image(AMI)로 제공되는 타사 단위 테스트 솔루션을 배포하고 있습니다. 

모든 시스템 구성 데이터는 Amazon DynamoDB에 저장됩니다. 테스트 결과는 Amazon S3에 저장됩니다.

제품을 작동하려면 최소 3개의 EC2 인스턴스가 필요합니다. 회사의 테스트 팀은 Spot Instance 가격이 특정 임계값에 도달하면 추가로 3개의 EC2 인스턴스를 사용하려고 합니다. SysOps 관리자는 이 기능을 제공하는 고가용성 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요?

1.시작 구성을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 구성에서 제공된 AMI를 사용합니다. 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성합니다. 시작 구성에서 최대 스팟 인스턴스 가격을 구성합니다.
2.시작 템플릿을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 템플릿에서 제공된 AMI를 사용합니다. 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성합니다. 시작 템플릿에서 최대 스팟 인스턴스 가격을 구성합니다.
3.시작 구성을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 구성에서 제공된 AMI를 사용합니다. 한 자동 확장 그룹에 대해 세 개의 온디맨드 인스턴스를 구성합니다. 다른 자동 확장 그룹에 대해 세 개의 스팟 인스턴스를 구성합니다. 스팟 인스턴스가 있는 자동 확장 그룹에 대해 시작 구성에서 최대 스팟 인스턴스 가격을 구성합니다.
4.시작 템플릿을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 템플릿에서 제공하는 AMI를 사용합니다. 한 자동 확장 그룹에 대해 세 개의 온디맨드 인스턴스를 구성합니다. 다른 자동 확장 그룹에 대해 세 개의 스팟 인스턴스를 구성합니다. 스팟 인스턴스가 있는 자동 확장 그룹에 대해 시작 템플릿에서 최대 스팟 인스턴스 가격을 구성합니다.

고가용성 솔루션을 구현하고, 스팟 인스턴스 가격이 특정 임계값에 도달했을 때 추가로 EC2 인스턴스를 사용하도록 하는 최소한의 운영 오버헤드 솔루션은 다음과 같습니다:

**2. 시작 템플릿을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 템플릿에서 제공된 AMI를 사용합니다. 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성합니다. 시작 템플릿에서 최대 스팟 인스턴스 가격을 구성합니다.**

#### 이유:
- **시작 템플릿**은 시작 구성에 비해 유연성과 기능이 더 많습니다. 예를 들어, 버전 관리와 변경 관리가 용이하며, 태그 및 다른 기능을 더 잘 지원합니다.
- **자동 확장 그룹**을 사용하면 EC2 인스턴스의 수를 동적으로 조정할 수 있습니다. 이는 고가용성을 유지하는 데 중요한 역할을 합니다.
- 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성하여, 스팟 인스턴스 가격이 임계값에 도달했을 때 자동으로 인스턴스를 추가할 수 있습니다.

### **다른 옵션 설명:**

1. **시작 구성을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다.**
   - 시작 구성은 더 이상 권장되지 않으며, 기능이 제한적입니다.

3. **시작 구성을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다.**
   - 이 방법은 관리 오버헤드가 증가할 수 있으며, 시작 구성은 권장되지 않습니다.

4. **시작 템플릿을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다.**
   - 이 방법도 가능하지만, 단일 자동 확장 그룹에서 온디맨드와 스팟 인스턴스를 조합하여 관리하는 것이 더 효율적입니다.

따라서 **시작 템플릿을 사용하여 단일 자동 확장 그룹을 정의하고, 온디맨드와 스팟 인스턴스를 조합하여 구성하는 것이 가장 적합한 방법입니다.**


## 질문: 223 ++++

SysOps 관리자는 여러 AWS 리전에 배포할 수 있는 애플리케이션 스택을 정의하기 위해 AWS CloudFormation 템플릿을 만듭니다. 

SysOps 관리자는 또한 AWS Management Console을 사용하여 Amazon CloudWatch 대시보드를 만듭니다. 애플리케이션의 각 배포에는 고유한 CloudWatch 대시보드가 ​​필요합니다.

SysOps 관리자는 애플리케이션이 배포될 때마다 CloudWatch 대시보드 생성을 어떻게 자동화할 수 있습니까?

1.AWS CLI를 사용하여 대시보드 이름으로 aws cloudformation put-dashboard 명령을 실행하기 위해 스크립트를 만듭니다. 새 CloudFormation 스택이 생성될 때마다 명령을 실행합니다.
2.기존 CloudWatch 대시보드를 JSON으로 내보냅니다. CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. 내보낸 JSON을 리소스의 DashboardBody 속성에 포함합니다.
3.CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. Intrinsic Ref 함수를 사용하여 기존 CloudWatch 대시보드의 ID를 참조합니다.
4.CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. DashboardName 속성에 기존 대시보드의 이름을 지정합니다.


AWS CloudFormation 템플릿을 사용하여 애플리케이션 배포 시 Amazon CloudWatch 대시보드 생성을 자동화하기 위한 가장 효율적인 솔루션은 다음과 같습니다:

### **2. 기존 CloudWatch 대시보드를 JSON으로 내보냅니다. CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. 내보낸 JSON을 리소스의 DashboardBody 속성에 포함합니다.**

#### 이유:
- **CloudFormation 리소스 정의**: AWS::CloudWatch::Dashboard 리소스를 정의하면 CloudFormation 스택이 생성될 때 자동으로 대시보드를 생성할 수 있습니다.
- **JSON 내보내기**: 기존 대시보드를 JSON으로 내보내면, 대시보드의 현재 구성과 모니터링할 지표를 그대로 가져올 수 있어 재사용이 가능합니다.
- **자동화**: 새로운 애플리케이션 배포마다 CloudFormation 스택을 실행하면 대시보드도 자동으로 생성되므로 운영 오버헤드가 줄어듭니다.

### **다른 옵션 설명:**

1. **AWS CLI를 사용하여 대시보드 이름으로 aws cloudformation put-dashboard 명령을 실행하기 위해 스크립트를 만듭니다.**
   - 이 방법은 CLI를 통한 수동 작업이 필요하고, CloudFormation과의 통합이 없어 자동화가 부족합니다.

3. **CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. Intrinsic Ref 함수를 사용하여 기존 CloudWatch 대시보드의 ID를 참조합니다.**
   - 기존 대시보드의 ID를 참조하는 것은 새로운 대시보드를 자동으로 생성하는 데 적합하지 않으며, 대시보드가 이미 존재하는 경우에만 유용합니다.

4. **CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. DashboardName 속성에 기존 대시보드의 이름을 지정합니다.**
   - 이 방법도 기존 대시보드를 참조하는 것이며, 새로운 대시보드를 생성하는 데는 적합하지 않습니다.

따라서 **기존 대시보드를 JSON으로 내보내고, CloudFormation 템플릿에 포함하여 대시보드를 자동으로 생성하는 것이 가장 효과적인 방법입니다.**


## 질문: 224

한 회사가 규제된 워크로드에 대한 클라우드 호스팅 준비를 명확히 하기 위해 보안 정책을 업데이트했습니다. 
민감한 것으로 식별된 워크로드는 회사 내의 다른 고객이나 다른 AWS 계정과 공유되지 않는 하드웨어에서 실행되어야 합니다.

어떤 솔루션이 이 정책을 준수하도록 보장할까요?

1.전용 호스트에만 워크로드를 배포합니다.
2.전용 인스턴스에만 워크로드를 배포합니다.
3.예약 인스턴스에만 워크로드를 배포합니다.
4.모든 인스턴스를 전용 배치 그룹에 배치합니다.

회사의 보안 정책에 따라 민감한 워크로드가 다른 고객이나 AWS 계정과 공유되지 않는 하드웨어에서 실행되어야 한다면, 가장 적합한 솔루션은 **"전용 호스트에만 워크로드를 배포합니다."**입니다.

### 정답:
**1. 전용 호스트에만 워크로드를 배포합니다.**

#### 이유:
- **물리적 격리**: 전용 호스트는 단일 고객을 위해 물리적으로 전용된 EC2 호스트입니다. 이는 해당 호스트에서 실행되는 모든 인스턴스가 고객의 것만으로 구성되며, 다른 고객과 자원을 공유하지 않습니다. 이러한 방식은 규제된 워크로드에 대해 높은 수준의 보안을 제공합니다.
- **규제 준수**: 전용 호스트를 사용하면 민감한 데이터가 다른 고객과 격리된 환경에서 처리되므로 규제 요구 사항을 준수하는 데 적합합니다.

### 대안 설명:
2. **전용 인스턴스에만 워크로드를 배포합니다.**
   - 전용 인스턴스는 특정 하드웨어에서 실행되지만, 해당 인스턴스는 여전히 다른 AWS 계정과 같은 물리적 호스트를 공유할 수 있습니다. 따라서 완전한 격리를 보장하지는 않습니다.

3. **예약 인스턴스에만 워크로드를 배포합니다.**
   - 예약 인스턴스는 인스턴스에 대한 결제 모델로, 물리적 호스트에 대한 격리를 제공하지 않습니다. 예약 인스턴스는 다른 고객과 호스트를 공유할 수 있습니다.

4. **모든 인스턴스를 전용 배치 그룹에 배치합니다.**
   - 전용 배치 그룹은 인스턴스가 특정 하드웨어에 배치되도록 하지만, 여전히 다른 고객과 같은 물리적 호스트를 공유할 수 있으므로 완전한 격리를 제공하지는 않습니다.

따라서, **전용 호스트에 워크로드를 배포하는 것이 보안 정책을 준수하는 가장 적합한 솔루션입니다.**


## 질문: 225 +++++

한 회사가 호주 시드니에서 웹사이트를 운영합니다. 

미국과 유럽의 사용자들은 이미지와 비디오가 로드되는 데 시간이 오래 걸린다고 보고하고 있습니다. 
그러나 호주에서 실시한 로컬 테스트에서는 성능 문제가 나타나지 않았습니다. 웹사이트에는 Amazon S3에 저장된 이미지와 비디오 형태의 정적 콘텐츠가 대량으로 있습니다.
미국과 유럽 사용자의 사용자 경험을 가장 크게 개선할 수 있는 솔루션은 무엇일까요?

1.Amazon S3에 대한 AWS PrivateLink를 구성합니다.
2.S3 전송 가속을 구성합니다.
3.Amazon CloudFront 배포를 만듭니다. 정적 콘텐츠를 CloudFront 엣지 위치에 배포합니다.
4.각 AWS 리전에서 Amazon API Gateway API를 만듭니다. 로컬에서 콘텐츠를 캐시합니다.

미국과 유럽 사용자들의 이미지와 비디오 로딩 시간을 개선하기 위해 가장 효과적인 솔루션은 **"Amazon CloudFront 배포를 만듭니다. 정적 콘텐츠를 CloudFront 엣지 위치에 배포합니다."**입니다.

### 정답:
**3. Amazon CloudFront 배포를 만듭니다. 정적 콘텐츠를 CloudFront 엣지 위치에 배포합니다.**

#### 이유:
- **전 세계적인 엣지 위치**: Amazon CloudFront는 전 세계에 분산된 엣지 로케이션을 제공하여 사용자의 위치와 가까운 서버에서 콘텐츠를 제공함으로써 지연 시간을 줄입니다. 이는 미국과 유럽 사용자에게 더 빠른 로딩 시간을 제공합니다.
- **정적 콘텐츠 캐싱**: CloudFront는 정적 콘텐츠를 캐싱하여 이후 요청 시 서버에 대한 부하를 줄이고 사용자에게 더 빠르게 데이터를 제공합니다.

### 대안 설명:
1. **Amazon S3에 대한 AWS PrivateLink를 구성합니다.**
   - AWS PrivateLink는 보안 통신을 제공하지만, 사용자 경험을 개선하는 데 도움이 되지 않으며, 특히 정적 콘텐츠의 지연 시간 문제를 해결할 수 없습니다.

2. **S3 전송 가속을 구성합니다.**
   - S3 전송 가속은 업로드 성능을 향상시키지만, 정적 콘텐츠의 배포 속도에는 직접적인 영향을 미치지 않습니다. 이 솔루션은 다운로드 속도를 개선하는 데 제한적입니다.

4. **각 AWS 리전에서 Amazon API Gateway API를 만듭니다. 로컬에서 콘텐츠를 캐시합니다.**
   - API Gateway는 RESTful API를 생성하는 데 유용하지만, 정적 콘텐츠의 전송을 위해 사용하기에는 비효율적이며, CloudFront와 같은 콘텐츠 전송 네트워크(CDN) 솔루션보다 성능 개선 효과가 적습니다.

따라서 **CloudFront를 사용하여 정적 콘텐츠를 전 세계에 효율적으로 배포하는 것이 가장 좋은 해결책입니다.**


## 질문: 226 +

SysOps 관리자가 Amazon Elastic Block Store(Amazon EBS) 볼륨이 연결된 Amazon EC2 인스턴스 세트에서 사용 가능한 디스크 공간을 모니터링하려고 합니다. 

SysOps 관리자는 EBS 볼륨의 사용된 디스크 공간이 임계값을 초과할 때 알림을 받고 싶지만 DiskReadOps 메트릭도 임계값을 초과할 때만 알림을 받고 싶어합니다. SysOps 관리자가 Amazon Simple Notification Service(Amazon SNS) 토픽을 설정했습니다. SysOps 관리자가 두 메트릭이 모두 임계값을 초과할 때만 알림을 받을 수 있는 방법은 무엇입니까?

1.EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
2.EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 각 알람을 구성하여 SNS 토픽에 알림을 게시합니다.
3.EBSByteBalance% 메트릭에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
4.EC2 인스턴스에 대한 자세한 모니터링을 구성합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
 

SysOps 관리자가 Amazon EBS 볼륨의 사용된 디스크 공간과 DiskReadOps 메트릭이 모두 임계값을 초과할 때만 알림을 받기 위해 가장 적절한 방법은 **"EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만들고, 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다."**입니다.

### 정답:
**1. EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.**

#### 이유:
- **복합 알람 기능**: CloudWatch에서 복합 알람을 사용하면 여러 메트릭이 모두 특정 조건을 만족할 때만 알림을 받을 수 있습니다. 이 기능을 사용하면 두 메트릭이 동시에 임계값을 초과할 때만 SNS 알림을 받을 수 있습니다.
- **CloudWatch 에이전트**: EBS의 디스크 사용량을 모니터링하려면 EC2 인스턴스에 CloudWatch 에이전트를 설치해야 합니다. 이 에이전트는 인스턴스의 디스크 사용량에 대한 세부 메트릭을 수집할 수 있습니다.

### 대안 설명:
2. **각 알람을 구성하여 SNS 토픽에 알림을 게시합니다.**
   - 이 방법은 각 메트릭에 대해 별도의 알람을 설정하므로, 두 메트릭이 모두 임계값을 초과할 때 알림을 받지 않게 됩니다. 각 메트릭의 임계값 초과에 대한 개별 알림이 전송됩니다.

3. **EBSByteBalance% 메트릭에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다.**
   - EBSByteBalance% 메트릭은 EBS 용량의 가용성에 대한 정보를 제공하지만, 사용된 디스크 공간을 모니터링하는 데 필요한 메트릭이 아닙니다. 디스크 공간의 사용량을 정확히 측정하려면 CloudWatch 에이전트를 통해 수집된 메트릭을 사용하는 것이 좋습니다.

4. **자세한 모니터링을 구성합니다.**
   - 자세한 모니터링을 구성하는 것은 유용하지만, 복합 알람을 사용하여 두 개의 메트릭을 결합하지 않으면 여전히 개별 알람이 생성되어 두 메트릭이 모두 임계값을 초과할 때만 알림을 받는 목표를 달성할 수 없습니다.

따라서 **첫 번째 옵션이 가장 적절한 해결책입니다.**


## 질문: 227 +

회사가 회사 계정의 Amazon S3 버킷에 있는 모든 데이터의 공개 노출을 금지하기 위해 보안 정책을 업데이트했습니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1.계정 수준에서 S3 공개 액세스 차단을 켭니다.
2.모든 S3 객체가 비공개로 유지되도록 Amazon Event Bridge(Amazon CloudWatch Events) 규칙을 만듭니다.
3.Amazon Inspector를 사용하여 S3 버킷을 검색하고 공개 S3 버킷이 발견되면 S3 ACL을 자동으로 재설정합니다.
4.S3 객체 람다를 사용하여 S3 ACL을 조사하고 모든 공개 S3 ACL을 비공개로 변경합니다.

회사가 Amazon S3 버킷에 있는 모든 데이터의 공개 노출을 금지하기 위해 가장 적절한 조치는 **"계정 수준에서 S3 공개 액세스 차단을 켭니다."**입니다.

### 정답:
**1. 계정 수준에서 S3 공개 액세스 차단을 켭니다.**

#### 이유:
- **전체적인 보안 강화**: S3 공개 액세스 차단 기능을 활성화하면 모든 S3 버킷 및 객체에 대해 공용 액세스를 기본적으로 차단할 수 있습니다. 이는 의도치 않게 데이터가 공개되는 것을 방지하고, 전체 계정의 보안을 강화하는 데 매우 효과적입니다.
- **정책 적용의 용이성**: S3 공개 액세스 차단은 단일 설정으로 모든 S3 버킷에 적용되므로, 개별 버킷에 대한 추가적인 설정을 필요로 하지 않습니다.

### 대안 설명:
2. **모든 S3 객체가 비공개로 유지되도록 Amazon Event Bridge(Amazon CloudWatch Events) 규칙을 만듭니다.**
   - 이 방법은 비공식적인 방법으로, S3 객체의 상태를 모니터링하고 자동으로 조치를 취하는 데는 유용하지만, 모든 버킷과 객체에 대한 보안을 보장하는 것에는 한계가 있습니다.

3. **Amazon Inspector를 사용하여 S3 버킷을 검색하고 공개 S3 버킷이 발견되면 S3 ACL을 자동으로 재설정합니다.**
   - Amazon Inspector는 보안 취약점을 분석하는 도구이지만, S3 ACL을 자동으로 조정하는 기능은 제공하지 않습니다. 이 접근 방식은 주기적인 검사를 통해 문제를 발견할 수는 있지만, 실시간으로 문제를 해결하는 데는 한계가 있습니다.

4. **S3 객체 람다를 사용하여 S3 ACL을 조사하고 모든 공개 S3 ACL을 비공개로 변경합니다.**
   - 이 방법은 리소스를 검사하고 변경하는 데 사용할 수 있지만, S3 공개 액세스 차단 기능을 통해 사전 예방적으로 모든 공개 액세스를 차단하는 것이 더 효과적입니다. 추가적인 유지 관리 작업이 필요하며, 모든 상황에 적합하지 않을 수 있습니다.

따라서, **계정 수준에서 S3 공개 액세스 차단을 활성화하는 것이 가장 안전하고 효과적인 방법입니다.**


## 질문: 228 ++

회사의 SysOps 관리자가 회사의 AWS 계정 중 하나에 대한 AWS 지원 플랜을 변경해야 합니다. 

계정에는 다중 요소 인증(MFA)이 활성화되어 있고 MFA 장치가 분실되었습니다.
SysOps 관리자는 로그인하기 위해 무엇을 해야 합니까?

1.이메일 및 전화 인증을 사용하여 루트 사용자로 로그인합니다. 새 MFA 장치를 설정합니다. 루트 사용자 비밀번호를 변경합니다.
2.관리자 권한이 있는 IAM 사용자로 로그인합니다. IAM 콘솔을 사용하여 MFA 토큰을 다시 동기화합니다.
3.관리자 권한이 있는 IAM 사용자로 로그인합니다. 새 장치를 추가하여 루트 사용자에 대한 MFA 장치를 재설정합니다.
4.비밀번호 분실 절차를 사용하여 이메일 주소를 확인하세요. 새 비밀번호와 MFA 장치를 설정하세요.

MFA 장치가 분실된 경우 SysOps 관리자가 AWS 계정에 로그인하기 위한 적절한 접근 방식은 

**"관리자 권한이 있는 IAM 사용자로 로그인합니다. IAM 콘솔을 사용하여 MFA 토큰을 다시 동기화합니다."**입니다.

### 정답:
**2. 관리자 권한이 있는 IAM 사용자로 로그인합니다. IAM 콘솔을 사용하여 MFA 토큰을 다시 동기화합니다.**

#### 이유:
- **IAM 사용자 접근**: 관리자가 IAM 사용자 계정을 가지고 있다면, 해당 계정으로 로그인하여 MFA 토큰을 다시 동기화하거나, 새로운 MFA 장치를 추가할 수 있습니다. 
- **MFA 재동기화**: AWS에서는 MFA 장치가 분실된 경우, IAM 콘솔을 통해 MFA 장치를 재동기화하는 옵션이 제공됩니다. 이를 통해 계정에 대한 접근 권한을 복구할 수 있습니다.

### 대안 설명:
1. **이메일 및 전화 인증을 사용하여 루트 사용자로 로그인합니다. 새 MFA 장치를 설정합니다. 루트 사용자 비밀번호를 변경합니다.**
   - 이 방법은 MFA 장치를 잃어버린 상태에서는 사용할 수 없습니다. 루트 사용자 계정에 대한 MFA를 우회할 수 있는 방법이 없기 때문입니다.

3. **관리자 권한이 있는 IAM 사용자로 로그인합니다. 새 장치를 추가하여 루트 사용자에 대한 MFA 장치를 재설정합니다.**
   - IAM 사용자는 루트 사용자 계정의 MFA를 직접 재설정할 수 없습니다. 루트 사용자의 MFA는 루트 사용자 계정에 속해 있으며, IAM 사용자는 이 작업을 수행할 권한이 없습니다.

4. **비밀번호 분실 절차를 사용하여 이메일 주소를 확인하세요. 새 비밀번호와 MFA 장치를 설정하세요.**
   - 비밀번호 분실 절차는 일반적으로 루트 사용자 계정에 대한 접근을 위한 방법으로, MFA 장치가 활성화된 경우에는 접근할 수 없습니다.

따라서, **관리자 권한이 있는 IAM 사용자로 로그인하여 MFA 토큰을 다시 동기화하는 것이 가장 적절한 접근 방법입니다.**

## 질문: 229 ++

회사에서 새로운 다중 계정 아키텍처를 만들고 있습니다. 

SysOps 관리자는 모든 AWS 계정에서 사용자 액세스 및 권한을 중앙에서 관리하는 로그인 솔루션을 구현해야 합니다. 
이 솔루션은 AWS Organizations와 통합되어야 하며 타사 Security Assertion Markup Language(SAML) 2.0 ID 공급자(IdP)에 연결되어야 합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1.Amazon Cognito 사용자 풀을 구성합니다. 사용자 풀을 타사 IdP와 통합합니다.
2.타사 IdP로 AWS Single Sign-On을 활성화하고 구성합니다.
3.조직의 각 AWS 계정에 대해 타사 IdP를 AWS Identity and Access Management(IAM)와 연합합니다.
4.타사 IdP를 AWS Organizations와 직접 통합합니다.

이러한 요구 사항을 충족하기 위해 가장 적합한 솔루션은 **"타사 IdP로 AWS Single Sign-On을 활성화하고 구성합니다."**입니다.

### 정답:
**2. 타사 IdP로 AWS Single Sign-On을 활성화하고 구성합니다.**

#### 이유:
- **중앙 관리**: AWS Single Sign-On(SSO)을 사용하면 모든 AWS 계정에 대한 사용자 액세스를 중앙에서 관리할 수 있습니다. 이를 통해 사용자는 단일 자격 증명으로 여러 AWS 계정에 안전하게 액세스할 수 있습니다.
- **SAML 2.0 지원**: AWS SSO는 SAML 2.0을 지원하므로, 타사 IdP와 통합하여 사용자 인증을 처리할 수 있습니다. 이 통합을 통해 기업은 기존의 IdP를 활용하여 AWS 계정에 대한 액세스를 관리할 수 있습니다.
- **AWS Organizations와 통합**: AWS SSO는 AWS Organizations와 잘 통합되어 있어 여러 계정에서 일관된 사용자 권한 관리를 쉽게 구현할 수 있습니다.

### 대안 설명:
1. **Amazon Cognito 사용자 풀을 구성합니다. 사용자 풀을 타사 IdP와 통합합니다.**
   - Amazon Cognito는 주로 모바일 및 웹 애플리케이션에서 사용자 인증을 처리하는 데 사용됩니다. 이는 여러 AWS 계정에 대한 중앙 관리 솔루션으로는 적합하지 않습니다.

3. **조직의 각 AWS 계정에 대해 타사 IdP를 AWS Identity and Access Management(IAM)와 연합합니다.**
   - IAM을 통해 각 계정에 대해 연합을 설정할 수 있지만, 이는 중앙에서 관리하는 접근 방식을 제공하지 않으며, 각 계정에서 별도로 설정해야 하므로 비효율적입니다.

4. **타사 IdP를 AWS Organizations와 직접 통합합니다.**
   - AWS Organizations는 타사 IdP와 직접 통합되는 기능을 제공하지 않습니다. 대신 AWS SSO를 통해 IdP와 통합해야 하며, SSO는 여러 계정의 관리에 더 적합합니다.

따라서, **타사 IdP로 AWS Single Sign-On을 활성화하고 구성하는 것이 가장 적합한 솔루션입니다.**



## 질문: 230 +++++

한 회사가 AWS Organizations에서 단일 조직을 사용하여 여러 계정을 관리하고 있습니다. 

조직은 모든 ​​기능을 활성화했습니다. 회사는 조직의 모든 계정과 모든 AWS 지역에서 AWS Config를 켜고 싶어합니다.
SysOps 관리자는 이러한 요구 사항을 가장 운영적으로 효율적인 방식으로 충족하기 위해 무엇을 해야 합니까?

1.AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 켜는 스택 인스턴스를 배포할 수 있습니다.
2.AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 활성화하는 스택 정책을 배포할 수 있습니다.
3.SCP(서비스 제어 정책)를 사용하여 모든 계정과 모든 지역에서 AWS Config를 구성합니다.
4.조직의 모든 계정에서 AWS Config를 켜기 위해 AWS CLI를 사용하는 스크립트를 만듭니다. 조직의 관리 계정에서 스크립트를 실행합니다.

AWS Organizations에서 여러 계정을 효율적으로 관리하고 AWS Config를 모든 계정과 모든 리전에서 활성화하기 위한 가장 적합한 방법은 
**"AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 켜는 스택 인스턴스를 배포할 수 있습니다."**입니다.

### 정답:
**1. AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 켜는 스택 인스턴스를 배포할 수 있습니다.**

#### 이유:
- **운영 효율성:** AWS CloudFormation Stack Sets를 사용하면 관리 계정에서 단일 스택 템플릿을 정의하여 여러 계정과 리전에서 AWS Config를 활성화할 수 있습니다. 이는 반복적인 작업을 줄이고, 모든 계정에서 일관된 구성을 보장하는 데 효과적입니다.
- **자동화:** Stack Sets는 AWS Config를 활성화하는 데 필요한 리소스를 자동으로 생성하고 관리하여 관리 작업의 수고를 덜어줍니다.

### 대안 설명:
2. **AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 활성화하는 스택 정책을 배포할 수 있습니다.**
   - 스택 정책은 스택 인스턴스에 대한 권한을 설정하는 것이며, AWS Config를 활성화하는 데 직접적으로 사용되지 않습니다. 따라서 이 방법은 요구 사항을 충족하지 못합니다.

3. **SCP(서비스 제어 정책)를 사용하여 모든 계정과 모든 지역에서 AWS Config를 구성합니다.**
   - SCP는 특정 서비스에 대한 액세스를 제어하는 데 사용되며, AWS Config를 활성화하는 데 필요한 작업이 아닙니다. SCP는 AWS Config의 활성화와는 관련이 없습니다.

4. **조직의 모든 계정에서 AWS Config를 켜기 위해 AWS CLI를 사용하는 스크립트를 만듭니다. 조직의 관리 계정에서 스크립트를 실행합니다.**
   - 이 방법은 수동 작업을 포함하며, 수많은 계정과 리전에서 AWS Config를 활성화하는 데 비효율적입니다. Stack Sets를 사용하면 자동화되고 일관된 방식으로 작업을 수행할 수 있습니다.

따라서, **AWS CloudFormation Stack Sets를 사용하여 모든 계정과 모든 리전에서 AWS Config를 활성화하는 것이 가장 운영 효율적인 방법입니다.**


## 질문: 231 ++++

SysOps 관리자가 더 이상 사용하지 않는 AWS CloudFormation 스택을 삭제해야 합니다. 

CloudFormation 스택이 DELETE_FAILED 상태입니다. SysOps 관리자가 CloudFormation 스택을 삭제하는 데 필요한 권한을 검증했습니다.

다음 중 DELETE_FAILED 상태의 가능한 원인은 무엇입니까? (두 가지를 선택하십시오.)

1.스택을 삭제하기 위해 구성된 시간 제한이 너무 짧아 삭제 작업을 완료할 수 없습니다.
2.스택에는 중첩된 스택이 포함되어 있으므로 이를 먼저 수동으로 삭제해야 합니다.
3.스택은 --disable-rollback 옵션으로 배포되었습니다.
4.스택의 보안 그룹과 연관된 추가 리소스가 있습니다.
5.스택에 객체가 여전히 들어 있는 Amazon S3 버킷이 있습니다.
 

DELETE_FAILED 상태의 AWS CloudFormation 스택이 발생하는 가능한 원인으로는 다음 두 가지를 선택할 수 있습니다:

### 정답:
1. **스택을 삭제하기 위해 구성된 시간 제한이 너무 짧아 삭제 작업을 완료할 수 없습니다.**
   - 스택 삭제 시 리소스를 정리하는 데 필요한 시간보다 짧은 시간 제한이 설정된 경우, 작업이 완료되지 않아 DELETE_FAILED 상태로 전환될 수 있습니다.

2. **스택에는 중첩된 스택이 포함되어 있으므로 이를 먼저 수동으로 삭제해야 합니다.**
   - 중첩된 스택이 존재할 경우, 외부에서 이 스택을 삭제하기 전에 먼저 중첩된 스택을 수동으로 삭제해야 합니다. 이 과정이 누락되면 DELETE_FAILED 상태가 발생할 수 있습니다.

### 대안 설명:
3. **스택은 --disable-rollback 옵션으로 배포되었습니다.**
   - --disable-rollback 옵션은 스택 생성을 실패할 경우 롤백을 비활성화하는 옵션으로, 삭제와는 관련이 없습니다. 이 옵션은 스택이 실패했을 때 삭제 작업에는 영향을 미치지 않습니다.

4. **스택의 보안 그룹과 연관된 추가 리소스가 있습니다.**
   - 일반적으로 보안 그룹은 삭제가 완료되지 않으면 리소스가 있더라도 삭제될 수 있습니다. 이 경우에는 DELETE_FAILED 상태가 발생하지 않습니다.

5. **스택에 객체가 여전히 들어 있는 Amazon S3 버킷이 있습니다.**
   - CloudFormation 스택의 삭제는 S3 버킷 내의 객체와는 관련이 없습니다. 버킷 자체가 스택의 일부가 아닌 한, 객체가 남아 있다고 해서 DELETE_FAILED 상태가 발생하지 않습니다.

따라서, **시간 제한 문제와 중첩 스택의 존재가 DELETE_FAILED 상태의 원인이 될 수 있습니다.**


## 질문: 232

SysOps 관리자는 Amazon CloudFront를 통해 승인된 사용자 집합에 디지털 콘텐츠를 제공하는 솔루션을 구성해야 합니다. 

승인되지 않은 사용자는 액세스가 제한되어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

1.퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. 서명된 URL을 사용하여 CloudFront를 통해 S3 버킷에 액세스합니다.
2.퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(원본 액세스 ID)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. CloudFront에서 서명된 URL로 S3 버킷 액세스를 제한합니다.
3.퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(Origin Access Identity)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. 필드 수준 암호화를 활성화합니다.
4.디지털 콘텐츠를 퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 저장합니다. CloudFront를 통한 콘텐츠의 제한된 전달을 위해 서명된 쿠키를 사용합니다.

Amazon CloudFront를 통해 승인된 사용자 집합에 디지털 콘텐츠를 제공하고, 승인되지 않은 사용자는 액세스가 제한되도록 하는 최적의 솔루션은 
**"퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(원본 액세스 ID)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. CloudFront에서 서명된 URL로 S3 버킷 액세스를 제한합니다."**입니다.

### 정답:
**2. 퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(원본 액세스 ID)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. CloudFront에서 서명된 URL로 S3 버킷 액세스를 제한합니다.**

#### 이유:
- **퍼블릭 액세스 차단:** Amazon S3 버킷의 퍼블릭 액세스를 차단하면 승인되지 않은 사용자가 직접 S3 버킷에 접근할 수 없습니다.
- **OAI 사용:** CloudFront의 원본 액세스 ID(OAI)를 사용하면 CloudFront가 S3 버킷의 콘텐츠에 접근할 수 있게 하면서, 직접적인 S3 URL 접근을 차단할 수 있습니다. 이렇게 하면 CloudFront를 통해서만 콘텐츠를 안전하게 제공할 수 있습니다.
- **서명된 URL 사용:** 서명된 URL을 사용하면 특정 사용자에게만 콘텐츠에 대한 액세스를 허용할 수 있습니다. URL에 만료 시간을 설정하여 일정 기간 동안만 액세스할 수 있도록 하여 보안을 강화합니다.

### 대안 설명:
1. **퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. 서명된 URL을 사용하여 CloudFront를 통해 S3 버킷에 액세스합니다.**
   - 퍼블릭 액세스가 차단되지 않은 경우, 승인되지 않은 사용자가 콘텐츠에 직접 접근할 수 있으므로 요구 사항을 충족하지 않습니다.

3. **퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(Origin Access Identity)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. 필드 수준 암호화를 활성화합니다.**
   - 필드 수준 암호화는 보안에 도움이 되지만, 주된 요구 사항인 승인된 사용자 집합에 대한 액세스 제한을 직접 해결하지 않습니다.

4. **디지털 콘텐츠를 퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 저장합니다. CloudFront를 통한 콘텐츠의 제한된 전달을 위해 서명된 쿠키를 사용합니다.**
   - 퍼블릭 액세스가 차단되지 않은 경우, 승인되지 않은 사용자가 S3 버킷에 접근할 수 있는 문제가 발생하므로 요구 사항을 충족하지 않습니다. 서명된 쿠키는 추가적인 보안을 제공하지만, 여전히 S3 버킷의 퍼블릭 액세스 문제가 해결되지 않습니다.

따라서, **퍼블릭 액세스가 차단된 S3 버킷과 OAI를 사용하여 CloudFront를 통한 안전한 콘텐츠 제공이 가장 적절한 해결책입니다.**

## 질문: 233 +++++

SysOps 관리자는 회사의 Amazon EC2 인스턴스가 예상대로 자동 확장되도록 해야 합니다. 

SysOps 관리자는 Amazon EC2 자동 확장 수명 주기 후크를 구성하여 Amazon EventBridge(Amazon CloudWatch Events)로 이벤트를 전송한 다음 AWS Lambda 함수를 호출하여 EC2 인스턴스를 구성합니다.
구성이 완료되면 Lambda 함수가 complete-lifecycle-action 이벤트를 호출하여 EC2 인스턴스를 서비스에 넣습니다. 
테스트에서 SysOps 관리자는 EC2 인스턴스가 자동 확장될 때 Lambda 함수가 호출되지 않는다는 것을 발견했습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1.Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 합니다.
2.라이프사이클 후크에 오류나 시간 초과가 발생하는 경우 라이프사이클 후크 작업을 CONTINUE로 변경합니다.
3.EventBridge(CloudWatch Events) 규칙에서 재시도 정책을 구성하여 실패 시 Lambda 함수 호출을 다시 시도합니다.
4.Lambda 함수 실행 역할을 업데이트하여 complete-lifecycle-action 이벤트를 호출할 수 있는 권한을 부여합니다.
 

SysOps 관리자가 Amazon EC2 인스턴스의 자동 확장이 예상대로 작동하도록 하기 위해 Lambda 함수가 호출되지 않는 문제를 해결하려면 
**"Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 합니다."**가 올바른 선택입니다.

### 정답:
**1. Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 합니다.**

#### 이유:
- Lambda 함수가 EventBridge (이전의 CloudWatch Events)에서 호출되기 위해서는 해당 이벤트 소스가 Lambda 함수를 호출할 수 있는 권한이 필요합니다. 이 권한은 IAM 역할 정책을 통해 설정해야 합니다. 권한이 없으면 Lambda 함수가 호출되지 않으므로, 이 문제를 해결하기 위해 Lambda 함수에 EventBridge에서 호출할 수 있도록 필요한 권한을 추가해야 합니다.

### 대안 설명:
2. **라이프사이클 후크에 오류나 시간 초과가 발생하는 경우 라이프사이클 후크 작업을 CONTINUE로 변경합니다.**
   - 이 설정은 후크가 실패했을 때의 동작을 변경하는 것이지만, Lambda 함수가 호출되지 않는 근본 원인을 해결하지 않습니다.

3. **EventBridge(CloudWatch Events) 규칙에서 재시도 정책을 구성하여 실패 시 Lambda 함수 호출을 다시 시도합니다.**
   - 재시도 정책을 설정하는 것은 유용할 수 있지만, Lambda 함수가 호출되지 않는 문제를 해결하지 않습니다. 권한이 부족한 경우에는 재시도해도 호출되지 않습니다.

4. **Lambda 함수 실행 역할을 업데이트하여 complete-lifecycle-action 이벤트를 호출할 수 있는 권한을 부여합니다.**
   - 이는 Lambda 함수가 EC2 인스턴스의 상태를 업데이트할 수 있도록 하는 것이며, Lambda 함수가 호출되지 않는 문제와는 관련이 없습니다. 이 작업은 Lambda 함수가 호출된 후에 필요한 조치입니다.

따라서, **Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 하는 것이 이 문제를 해결하는 올바른 방법입니다.**


## 질문: 234 ++++

한 회사에서는 모든 IAM 사용자에게 다중 인증(MFA)을 사용하도록 의무화했으며, 사용자는 CLI를 사용하여 모든 API 호출을 해야 합니다. 

그러나 사용자는 MFA 토큰을 입력하라는 메시지를 받지 않으며, MFA 없이도 CLI 명령을 실행할 수 있습니다. 
이 회사는 MFA를 시행하기 위해 MFA로 인증되지 않은 API 호출을 거부하는 IAM 정책을 모든 사용자에게 첨부했습니다.

API 호출이 MFA를 사용하여 인증되도록 하려면 어떤 추가 단계를 거쳐야 합니까?

1.IAM 역할에서 MFA를 활성화하고 IAM 사용자에게 역할 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.
2.CLI를 사용하여 API 호출을 하기 전에 IAM 사용자에게 MFA를 사용하여 AWS 관리 콘솔에 로그인하도록 요청합니다.
3.MFA는 CLI 사용에 지원되지 않으므로 IAM 사용자는 콘솔 사용으로 제한합니다.
4.사용자에게 get-session token 명령에서 임시 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.

이 시나리오에서 모든 IAM 사용자가 다중 인증(MFA)을 사용하여 AWS CLI에서 API 호출을 해야 하는 상황에서, 추가적인 단계로 
**"사용자에게 get-session-token 명령에서 임시 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다."**가 올바른 선택입니다.

### 정답:
**4. 사용자에게 get-session-token 명령에서 임시 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.**

#### 이유:
- MFA를 사용하여 AWS CLI에서 API 호출을 수행하려면, 사용자가 먼저 `get-session-token` 명령을 통해 임시 자격 증명을 요청해야 합니다. 이 명령은 MFA 토큰을 입력하도록 요구하며, 인증이 완료되면 임시 자격 증명(Access Key, Secret Access Key, Session Token)을 제공합니다. 사용자는 이 임시 자격 증명을 사용하여 CLI에서 API 호출을 수행할 수 있습니다. 

### 대안 설명:
1. **IAM 역할에서 MFA를 활성화하고 IAM 사용자에게 역할 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.**
   - IAM 역할을 사용하여 MFA를 활성화할 수 있지만, 이 접근 방식은 사용자가 CLI에서 API 호출을 하도록 요구하는 것과는 관련이 없습니다. 사용자는 여전히 임시 자격 증명을 얻어야 합니다.

2. **CLI를 사용하여 API 호출을 하기 전에 IAM 사용자에게 MFA를 사용하여 AWS 관리 콘솔에 로그인하도록 요청합니다.**
   - 관리 콘솔에서 MFA를 사용하여 로그인하는 것은 유용하지만, CLI에서 API 호출을 하려면 임시 자격 증명을 필요로 하므로 이 방법은 요구 사항을 충족하지 않습니다.

3. **MFA는 CLI 사용에 지원되지 않으므로 IAM 사용자는 콘솔 사용으로 제한합니다.**
   - 이는 잘못된 정보입니다. MFA는 CLI 사용에도 지원되며, 이를 사용하여 API 호출을 수행할 수 있습니다. 사용자를 콘솔 사용으로 제한하는 것은 최선의 해결책이 아닙니다.

따라서, **사용자가 `get-session-token` 명령을 통해 MFA를 활용하여 임시 자격 증명을 얻고 이를 사용하여 API 호출을 수행하는 것이 MFA를 적용하는 올바른 방법입니다.**


## 질문: 235 ++

SysOps 관리자가 모든 회사 Amazon S3 버킷에 대한 퍼블릭 액세스를 차단했습니다. 

SysOps 관리자는 S3 버킷이 미래에 공개적으로 읽을 수 있게 되면 알림을 받고 싶어합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

1.각 S3 버킷의 퍼블릭 액세스 설정을 주기적으로 확인하는 AWS Lambda 함수를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.
2.S3 API를 사용하여 각 S3 버킷의 퍼블릭 액세스 설정을 확인하는 cron 스크립트를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.
3.각 S3 버킷에 대해 S3 이벤트 알림을 활성화합니다. Amazon Simple Notification Service(Amazon SNS) 주제에 S3 이벤트 알림을 구독합니다.
4.AWS Config에서 s3-bucket-public-read-prohibited 관리형 규칙을 활성화합니다. AWS Config 규칙을 Amazon Simple Notification Service(Amazon SNS) 토픽에 구독합니다.
 

SysOps 관리자가 모든 Amazon S3 버킷에 대한 퍼블릭 액세스를 차단하고, 미래에 S3 버킷이 공개적으로 읽을 수 있게 될 경우 알림을 받으려면 
**"AWS Config에서 s3-bucket-public-read-prohibited 관리형 규칙을 활성화합니다. AWS Config 규칙을 Amazon Simple Notification Service(Amazon SNS) 토픽에 구독합니다."**가 가장 운영 효율적인 방법입니다.

### 정답:
**4. AWS Config에서 s3-bucket-public-read-prohibited 관리형 규칙을 활성화합니다. AWS Config 규칙을 Amazon Simple Notification Service(Amazon SNS) 토픽에 구독합니다.**

#### 이유:
- **AWS Config**는 AWS 리소스의 구성 및 변경 사항을 추적하는 서비스로, S3 버킷의 퍼블릭 액세스 설정과 같은 규정을 모니터링하는 데 매우 유용합니다. `s3-bucket-public-read-prohibited` 관리형 규칙은 S3 버킷이 퍼블릭 읽기 권한을 갖고 있는지를 자동으로 검사하고, 위반 시 AWS Config에서 이벤트를 생성합니다.
- 이를 Amazon SNS와 통합하면, 규칙 위반 시 자동으로 알림을 받을 수 있어 운영 효율성이 높아집니다. 관리형 규칙을 사용하면 매번 Lambda 함수를 설정하거나 스크립트를 실행할 필요가 없어 관리가 간편합니다.

### 대안 설명:
1. **각 S3 버킷의 퍼블릭 액세스 설정을 주기적으로 확인하는 AWS Lambda 함수를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.**
   - Lambda 함수를 사용하여 버킷 설정을 주기적으로 확인하는 것은 가능하지만, AWS Config를 사용하는 것보다 관리가 더 복잡하고 지속적인 유지 보수가 필요합니다.

2. **S3 API를 사용하여 각 S3 버킷의 퍼블릭 액세스 설정을 확인하는 cron 스크립트를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.**
   - cron 스크립트는 관리와 유지 보수가 필요하며, AWS 환경 내에서 S3 버킷의 상태를 실시간으로 모니터링하기에는 비효율적입니다.

3. **각 S3 버킷에 대해 S3 이벤트 알림을 활성화합니다. Amazon Simple Notification Service(Amazon SNS) 주제에 S3 이벤트 알림을 구독합니다.**
   - S3 이벤트 알림은 객체 생성, 삭제 등의 이벤트에 대한 알림을 제공하지만, 퍼블릭 액세스 설정의 변경 사항에 대한 알림을 제공하지 않으므로 이 요구 사항에 부합하지 않습니다.

따라서, **AWS Config에서 관리형 규칙을 활성화하고 SNS와 통합하는 것이 S3 버킷의 퍼블릭 액세스 설정 변경을 효과적으로 모니터링하는 가장 효율적인 방법입니다.**



## 질문: 236 ++++

한 회사가 Amazon S3를 사용하여 도메인 example.com과 하위 도메인 www.example.com에서 정적 웹사이트를 출시할 계획입니다.

SysOps 관리자는 이 요구 사항을 어떻게 충족해야 합니까?

1. 도메인과 하위 도메인 모두에 대해 example.com이라는 이름의 S3 버킷을 하나 만듭니다.
2. 도메인과 하위 도메인 모두에 *.example.com이라는 와일드카드를 사용하여 하나의 S3 버킷을 생성합니다.
3. example.com과 www.example.com이라는 이름의 두 개의 S3 버킷을 만듭니다. 하위 도메인 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.
4. http://example.com과 http://*.example.com이라는 이름의 두 개의 S3 버킷을 만듭니다. 와일드카드(*) 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.
 

정적 웹사이트를 Amazon S3에서 호스팅하려면 SysOps 관리자는 다음과 같은 방법으로 요구 사항을 충족할 수 있습니다:

**3. `example.com`과 `www.example.com`이라는 이름의 두 개의 S3 버킷을 만듭니다. 하위 도메인 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.**

이유:
- **S3 버킷 네이밍 규칙**: Amazon S3에서 정적 웹사이트 호스팅 시 버킷 이름은 DNS 호환 도메인 이름이어야 합니다. 따라서 `example.com`과 `www.example.com`이라는 두 개의 S3 버킷이 필요합니다.
- **리디렉션 설정**: 일반적으로 `www.example.com`으로 들어오는 트래픽을 `example.com`으로 리디렉션합니다. 이를 위해 `www.example.com` S3 버킷을 리디렉션 버킷으로 설정하고, 실제 웹 콘텐츠는 `example.com` 버킷에서 호스팅합니다.
- **와일드카드 버킷 지원 없음**: Amazon S3는 와일드카드(*) 버킷을 지원하지 않으므로, 옵션 2나 4는 불가능합니다.

이 방법으로 도메인과 하위 도메인 모두에서 정적 웹사이트를 성공적으로 호스팅할 수 있습니다.

## 질문: 237 +++++

SysOps 관리자가 AWS Client VPN을 구성하여 기업 네트워크의 사용자를 VPC에서 실행 중인 AWS 리소스에 연결하고 있습니다. 

규정 준수 요구 사항에 따라 VPC로 향하는 트래픽만 VPN 터널을 통과할 수 있습니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Client VPN을 어떻게 구성해야 합니까?

1.NAT 게이트웨이를 통한 인터넷 경로가 있는 개인 서브넷과 클라이언트 VPN 엔드포인트를 연결합니다.
2.클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켭니다.
3.클라이언트 VPN 엔드포인트에서 DNS 서버 IP 주소를 지정합니다.
4.VPN 클라이언트의 신원 인증서로 사용할 개인 인증서를 선택하세요.

AWS Client VPN을 구성하여 규정 준수 요구 사항에 따라 VPC로 향하는 트래픽만 VPN 터널을 통과할 수 있도록 하려면 
**"클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켭니다."**가 올바른 선택입니다.

### 정답: 
**2. 클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켭니다.**

#### 이유:
- **분할 터널**은 클라이언트 VPN 엔드포인트에서 설정할 수 있는 옵션으로, 이를 활성화하면 VPN을 통해 특정 트래픽만 VPC로 전송되고 나머지 트래픽(예: 인터넷으로 향하는 트래픽)은 로컬 네트워크를 통해 직접 전송됩니다. 따라서 VPC로 향하는 트래픽만 터널을 통해 전송되어 규정 준수 요구 사항을 충족할 수 있습니다.

### 대안 설명:
1. **NAT 게이트웨이를 통한 인터넷 경로가 있는 개인 서브넷과 클라이언트 VPN 엔드포인트를 연결합니다.**
   - NAT 게이트웨이는 인터넷으로의 아웃바운드 트래픽을 지원하지만, 이 설정은 분할 터널링과는 직접적인 관련이 없습니다. NAT 게이트웨이를 사용하는 것은 일반적으로 VPC 내에서 인터넷에 접근하기 위한 것이며, 규정 준수 요구 사항에 맞지 않습니다.

3. **클라이언트 VPN 엔드포인트에서 DNS 서버 IP 주소를 지정합니다.**
   - DNS 서버 IP 주소를 지정하는 것은 클라이언트가 도메인 이름을 해결하는 데 필요할 수 있지만, 규정 준수 요구 사항을 충족하는 데는 직접적인 관련이 없습니다.

4. **VPN 클라이언트의 신원 인증서로 사용할 개인 인증서를 선택하세요.**
   - 개인 인증서를 선택하는 것은 클라이언트의 인증을 설정하는 것이며, 이는 보안 설정과 관련이 있지만 VPN 트래픽의 흐름을 규제하는 데는 도움이 되지 않습니다.

따라서, **클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켜는 것이 VPC로 향하는 트래픽만 VPN 터널을 통과하도록 설정하는 올바른 방법입니다.**



## 질문: 238 +

SysOps 관리자가 5개의 Amazon EC2 인스턴스에 호스팅된 애플리케이션을 테스트하고 있습니다. 

인스턴스는 Application Load Balancer(ALB) 뒤의 Auto Scaling 그룹에서 실행됩니다. 
부하 테스트 중 CPU 사용률이 높아 Auto Scaling 그룹이 확장되고 있습니다. SysOps 관리자는 Auto Scaling 그룹이 확장되기 전에 CPU 사용률이 높은 근본 원인을 찾기 위해 문제를 해결해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1.인스턴스 확장 보호를 활성화합니다.
2.인스턴스를 대기 상태로 전환합니다.
3.ALB에서 리스너를 제거합니다.
4.실행 및 종료 프로세스 유형을 일시 중단합니다


이 시나리오에서 SysOps 관리자가 Auto Scaling 그룹의 확장을 방지하고 CPU 사용률이 높은 근본 원인을 조사하기 위해 취해야 할 적절한 조치는 
**"인스턴스 확장 보호를 활성화합니다."**입니다.

### 정답: 
**1. 인스턴스 확장 보호를 활성화합니다.**

#### 이유:
- 인스턴스 확장 보호를 활성화하면 Auto Scaling 그룹이 CPU 사용률이 높아질 때 인스턴스를 자동으로 종료하거나 축소하지 않도록 보호할 수 있습니다. 이로 인해 관리자는 인스턴스가 계속 실행되고 있는 동안 문제를 진단하고 해결할 수 있습니다.

### 대안 설명:
2. **인스턴스를 대기 상태로 전환합니다.**
   - 대기 상태로 전환하면 인스턴스가 요청을 처리하지 않지만, Auto Scaling 그룹의 확장을 방지하는 데는 도움이 되지 않습니다. 오히려 사용자의 요청이 해당 인스턴스로 라우팅되지 않게 되므로 문제가 악화될 수 있습니다.

3. **ALB에서 리스너를 제거합니다.**
   - ALB에서 리스너를 제거하면 인스턴스에 대한 모든 트래픽이 차단됩니다. 이는 테스트 중에 의도한 대로 트래픽을 차단할 수 있지만, CPU 사용률이 높은 원인을 조사하는 데 도움이 되지 않습니다.

4. **실행 및 종료 프로세스 유형을 일시 중단합니다.**
   - 실행 및 종료 프로세스를 일시 중단하면 Auto Scaling 그룹의 활동을 중단하지만, CPU 사용률이 높은 근본 원인을 찾는 데 실질적인 도움이 되지 않습니다. 이는 기본적으로 Auto Scaling의 기능을 중단하는 것이므로 긴급한 경우가 아닌 이상 권장되지 않습니다.

따라서, **인스턴스 확장 보호를 활성화하는 것이 CPU 사용률 문제를 조사하는 가장 적절한 접근법입니다.**


## 질문: 239 +++

웹 애플리케이션은 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 

인스턴스는 여러 가용성 영역에 걸쳐 Auto Scaling 그룹에서 실행됩니다. 
SysOps 관리자는 이러한 EC2 인스턴스 중 일부가 Auto Scaling 그룹에서는 정상으로 표시되지만 ALB 대상 그룹에서는 비정상으로 표시된다는 것을 알아챘습니다.

이 문제의 가능한 이유는 무엇입니까?

1.보안 그룹은 ALB와 오류가 발생한 EC2 인스턴스 간의 트래픽을 허용하지 않습니다.
2.자동 크기 조정 그룹 상태 검사는 EC2 상태 검사를 위해 구성되었습니다.
3.EC2 인스턴스를 시작할 수 없고 EC2 상태 확인에도 실패합니다.
4.대상 그룹 상태 검사가 잘못된 포트 또는 경로로 구성되었습니다.

EC2 인스턴스가 Auto Scaling 그룹에서는 정상으로 표시되지만, ALB 대상 그룹에서는 비정상으로 표시되는 이유 중 가장 가능성이 높은 것은
**4. 대상 그룹 상태 검사가 잘못된 포트 또는 경로로 구성되었습니다.**

### 이유:
- ALB는 대상 그룹의 EC2 인스턴스에 대해 **상태 검사(health check)**를 수행하며, 특정 경로 또는 포트를 통해 상태를 확인합니다. 만약 상태 검사 경로 또는 포트가 잘못 설정되어 있거나, 애플리케이션이 그 경로에서 정상적으로 응답하지 않는 경우, ALB는 인스턴스를 **비정상**으로 판단할 수 있습니다.
- 반면, Auto Scaling 그룹은 **EC2 인스턴스의 상태**(예: 인스턴스 자체가 실행 중인지)를 기준으로 하므로, 인스턴스가 정상으로 표시될 수 있습니다.

### 선택하지 않은 다른 옵션 검토:
1. **보안 그룹은 ALB와 오류가 발생한 EC2 인스턴스 간의 트래픽을 허용하지 않습니다.**
   - 만약 보안 그룹이 트래픽을 허용하지 않는다면, EC2 인스턴스에 대한 연결 자체가 이루어지지 않기 때문에, 비정상으로 표시될 가능성이 있지만, 이 경우 트래픽 문제는 상태 검사 경로 설정보다는 연결 문제에서 발생합니다.

2. **자동 크기 조정 그룹 상태 검사는 EC2 상태 검사를 위해 구성되었습니다.**
   - Auto Scaling 그룹은 EC2 인스턴스의 **시스템 및 네트워크 상태**에 따라 상태를 결정하며, 상태가 "정상"으로 표시되지만, 이는 ALB 상태 검사와는 다르기 때문에 ALB의 상태 검사와 직접적인 연관이 없습니다.

3. **EC2 인스턴스를 시작할 수 없고 EC2 상태 확인에도 실패합니다.**
   - 만약 EC2 인스턴스 자체가 실패했다면, Auto Scaling 그룹에서 해당 인스턴스는 **정상으로 표시되지** 않으며, 문제가 더 광범위할 것입니다.

따라서 가장 가능성이 높은 원인은 **대상 그룹의 상태 검사 설정 오류(경로 또는 포트 설정 오류)**입니다.



## 질문: 240 +

SysOps 관리자가 Amazon EC2 Auto Scaling 그룹의 확장 이벤트를 알아차렸습니다. 

Amazon CloudWatch는 연관된 Application Load Balancer의 RequestCount 메트릭에서 급증을 보여줍니다. 관리자는 요청 소스의 IP 주소를 알고 싶어합니다.

관리자는 이 정보를 어디에서 찾을 수 있습니까?

1.자동 크기 조정 로그
2.AWS CloudTrail 로그
3.EC2 인스턴스 로그
4.Elastic Load Balancer 액세스 로그

관리자가 요청 소스의 IP 주소를 확인하려면 다음 옵션이 가장 적절합니다.

### 정답:
**4. Elastic Load Balancer 액세스 로그**

### 이유:
- **Elastic Load Balancer 액세스 로그**는 Application Load Balancer(ALB)에 도달하는 모든 요청에 대한 세부 정보를 제공합니다. 여기에는 **요청을 보낸 클라이언트의 IP 주소**를 비롯한 여러 중요한 정보가 포함됩니다. 액세스 로그는 S3 버킷에 저장되며, 이를 통해 특정 시간대의 요청 소스 IP를 확인할 수 있습니다.
  
### 선택하지 않은 옵션 검토:
1. **자동 크기 조정 로그**
   - 자동 크기 조정 로그에는 인스턴스의 크기 조정과 관련된 이벤트가 기록되지만, 클라이언트의 IP 주소와 같은 세부 요청 정보를 제공하지 않습니다.

2. **AWS CloudTrail 로그**
   - AWS CloudTrail은 AWS API 호출을 기록하며, ELB와 관련된 호출을 추적할 수 있지만, 개별 요청에 대한 IP 주소 정보는 제공하지 않습니다.

3. **EC2 인스턴스 로그**
   - EC2 인스턴스 로그는 해당 인스턴스에서 실행되는 애플리케이션의 로그일 수 있으나, ELB를 경유한 모든 클라이언트 IP 주소 정보를 제공하는 데는 적합하지 않습니다.



## 질문: 241

한 회사가 여러 개의 고성능 컴퓨팅(HPC) 가상 머신(VM)을 AWS의 Amazon EC2 인스턴스로 마이그레이션할 계획입니다. 

SysOps 관리자는 이 배포를 위한 배치 그룹을 식별해야 합니다. 이 전략은 네트워크 지연을 최소화하고 HPC VM 간의 네트워크 처리량을 최대화해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 전략을 선택해야 합니까?

1.하나의 가용성 영역에 있는 클러스터 배치 그룹에 인스턴스를 배포합니다.
2.두 개의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.
3.하나의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.
4.2개의 가용성 영역에 분산된 배치 그룹에 인스턴스를 배포합니다.

SysOps 관리자가 네트워크 지연을 최소화하고 HPC(고성능 컴퓨팅) VM 간의 네트워크 처리량을 최대화하기 위해 선택해야 할 전략은 
**1. 하나의 가용성 영역에 있는 클러스터 배치 그룹에 인스턴스를 배포합니다.**입니다.

### 이유:
- **클러스터 배치 그룹**은 동일한 가용성 영역(AZ) 내에서 EC2 인스턴스가 물리적으로 가까운 하드웨어에 배치되도록 보장합니다. 이 방식은 높은 네트워크 처리량과 낮은 지연 시간을 요구하는 HPC 작업에 매우 적합합니다.
- **네트워크 지연을 최소화하고 처리량을 최대화**하기 위한 최고의 선택입니다.

### 선택하지 않은 옵션 검토:
2. **두 개의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.**
   - 두 개의 AZ에 분산하면 네트워크 지연이 증가할 수 있으며, HPC의 성능 요구사항에 적합하지 않습니다.

3. **하나의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.**
   - 파티션 배치 그룹은 인스턴스가 서로 다른 하드웨어에 분리되어 배치되도록 보장하여 장애 도메인 격리를 제공합니다. 이는 내결함성에 좋지만, 지연 시간과 처리량 최적화에는 클러스터 배치 그룹이 더 유리합니다.

4. **2개의 가용성 영역에 분산된 배치 그룹에 인스턴스를 배포합니다.**
   - 가용성 영역 간의 통신은 높은 네트워크 지연 시간을 발생시킬 수 있으므로, HPC 워크로드에는 적합하지 않습니다.

따라서 네트워크 성능을 극대화하기 위해 **클러스터 배치 그룹**을 사용하는 것이 가장 적합한 전략입니다.


## 질문: 242 +++

오류 프로세스는 전체 프로세서를 사용하고 100%로 실행되는 것으로 알려져 있습니다. 

SysOps 관리자는 문제가 2분 이상 발생할 때 Amazon EC2 인스턴스를 자동으로 다시 시작하려고 합니다.
어떻게 이를 달성할 수 있을까요?

1.기본 모니터링을 사용하여 EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만듭니다. 인스턴스를 다시 시작하는 작업을 추가합니다.
2.EC2 인스턴스에 대한 Amazon CloudWatch 알람을 자세한 모니터링과 함께 생성합니다. 인스턴스를 다시 시작하는 작업을 추가합니다.
3.2분마다 예약된 시간에 호출되는 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.
4.EC2 상태 확인을 통해 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.
 
이 요구 사항을 가장 효율적으로 달성하려면 
**2. EC2 인스턴스에 대한 Amazon CloudWatch 알람을 자세한 모니터링과 함께 생성합니다. 인스턴스를 다시 시작하는 작업을 추가합니다.**가 가장 적합한 솔루션입니다.

### 이유:
- **자세한 모니터링(Enhanced Monitoring)**은 1분 간격의 더 정밀한 모니터링을 제공합니다. 이를 통해 CPU 사용량이 100%에 도달했을 때 신속하게 알람을 설정할 수 있습니다.
- CloudWatch 알람을 생성하여 CPU 사용량이 2분 동안 100% 이상일 때 트리거되도록 설정하고, 그에 따라 인스턴스를 자동으로 다시 시작하는 작업을 추가할 수 있습니다.
  
### 선택하지 않은 옵션 검토:
1. **기본 모니터링을 사용하여 EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만듭니다.**
   - 기본 모니터링은 5분 간격으로 데이터를 수집하므로, 2분 이상 100% CPU 사용 시 문제를 확인하기에는 적합하지 않습니다.

3. **2분마다 예약된 시간에 호출되는 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.**
   - 이는 너무 자주 호출되어 불필요하게 인스턴스를 다시 시작할 수 있으며, CPU 사용량과 같은 성능 지표에 기반한 조건을 설정할 수 없습니다.

4. **EC2 상태 확인을 통해 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.**
   - EC2 상태 확인은 주로 인스턴스의 하드웨어 문제를 감지합니다. CPU 사용량 100%와 같은 문제를 해결하는 데는 적합하지 않습니다.

따라서 **자세한 모니터링과 CloudWatch 알람을 사용하는 방법**이 문제를 해결하는 데 가장 적합한 솔루션입니다. 


## 질문: 243

한 회사가 Amazon S3 버킷에 많은 양의 민감한 데이터를 보관합니다.

회사의 보안팀은 SysOps 관리자에게 S3 버킷의 모든 현재 객체가 암호화되었는지 확인하도록 요청합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1.S3 버킷에 대해 실행되고 각 객체의 상태를 출력하는 스크립트를 만듭니다.
2.S3 버킷에서 S3 인벤토리 구성을 만듭니다. 적절한 상태 필드를 포함합니다.
3.보안 팀에 S3 버킷에 대한 읽기 액세스 권한이 있는 IAM 사용자를 제공합니다.
4.AWS CLI를 사용하여 S3 버킷에 있는 모든 객체 목록을 출력합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 
**2. S3 버킷에서 S3 인벤토리 구성을 만듭니다. 적절한 상태 필드를 포함합니다.**

### 이유:
- **S3 인벤토리**는 S3 버킷 내의 모든 객체에 대한 메타데이터를 자동으로 제공하는 서비스입니다. 인벤토리 보고서는 암호화 상태, 크기, 태그 등 다양한 객체 속성을 포함할 수 있으며, 대규모 데이터 집합에서도 효율적으로 사용됩니다.
- 이를 통해 관리자는 객체 암호화 상태를 확인하고, 필요한 조치를 쉽게 취할 수 있습니다. 또한 인벤토리 보고서는 정기적으로 생성되어 자동으로 최신 정보를 제공하므로 수동 작업을 줄일 수 있습니다.

### 선택하지 않은 옵션 검토:
1. **S3 버킷에 대해 실행되고 각 객체의 상태를 출력하는 스크립트를 만듭니다.**
   - 스크립트를 만드는 방법은 가능하지만, 수동 관리가 필요하고 큰 S3 버킷의 경우 시간이 오래 걸리며 비효율적입니다.

3. **보안 팀에 S3 버킷에 대한 읽기 액세스 권한이 있는 IAM 사용자를 제공합니다.**
   - 보안 팀이 객체의 암호화 상태를 직접 확인할 수 있게 하지만, 암호화 상태를 수동으로 검토해야 하므로 비효율적입니다.

4. **AWS CLI를 사용하여 S3 버킷에 있는 모든 객체 목록을 출력합니다.**
   - AWS CLI를 통해 객체 목록을 출력할 수는 있지만, 객체 암호화 상태를 직접적으로 출력하지 않으므로 추가적인 작업이 필요합니다.

따라서 **S3 인벤토리**를 설정하여 자동으로 객체의 암호화 상태를 추적하는 것이 가장 효율적인 솔루션입니다.

## 질문: 244 +

사용자는 관계형 데이터베이스에서 주기적으로 느린 응답 시간을 경험하고 있습니다. 

데이터베이스는 350GB General Purpose SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨이 있는 버스트 가능한 Amazon EC2 인스턴스에서 실행됩니다. 
SysOps 관리자는 Amazon CloudWatch에서 EC2 인스턴스를 모니터링하고 느린 응답 기간 동안 VolumeReadOps 메트릭이 최고 값의 10% 미만으로 떨어지는 것을 관찰합니다.
SysOps 관리자는 지속적으로 높은 성능을 보장하기 위해 무엇을 해야 합니까?

1.gp2 볼륨을 일반 용도 SSD(gp3) EBS 볼륨으로 변환합니다.
2.gp2 볼륨을 Cold HDD(sc1) EBS 볼륨으로 변환합니다.
3.EC2 인스턴스를 메모리 최적화된 인스턴스 유형으로 변환합니다.
4.EC2 인스턴스에서 무제한 모드를 활성화합니다.

지속적으로 높은 성능을 보장하기 위한 최선의 선택은 
**1. gp2 볼륨을 일반 용도 SSD(gp3) EBS 볼륨으로 변환합니다.**

### 이유:
- **gp2 볼륨**은 용량에 따라 IOPS 성능이 결정되며, 일정 기간에 걸쳐 IOPS 버스트가 가능하지만, 버스트 크레딧이 소진되면 성능이 저하됩니다. VolumeReadOps 메트릭이 낮다는 것은 IOPS 제한에 도달했음을 나타낼 수 있습니다.
- **gp3 볼륨**은 용량과 성능이 분리되어 있으며, 기본적으로 더 높은 IOPS를 제공하고 필요에 따라 성능을 조정할 수 있어 일관된 성능을 보장합니다. 따라서 **gp3 볼륨**으로 전환하면 더 안정적인 IOPS를 제공할 수 있습니다.

### 선택하지 않은 옵션 검토:
2. **gp2 볼륨을 Cold HDD(sc1) EBS 볼륨으로 변환합니다.**
   - **sc1 볼륨**은 주로 대용량, 저성능 워크로드에 적합하며, 랜덤 읽기 및 쓰기 성능이 낮기 때문에 관계형 데이터베이스 성능을 개선하지 못합니다.

3. **EC2 인스턴스를 메모리 최적화된 인스턴스 유형으로 변환합니다.**
   - 메모리 최적화된 인스턴스는 메모리 집약적인 워크로드에 적합하지만, 문제의 원인은 EBS IOPS와 관련이 있으므로 이 옵션이 적합하지 않습니다.

4. **EC2 인스턴스에서 무제한 모드를 활성화합니다.**
   - 무제한 모드는 CPU 크레딧과 관련이 있으며, 현재 문제는 CPU 성능과 관련이 없으므로 이 옵션이 적절하지 않습니다.

따라서 **gp3 볼륨**으로 변환하는 것이 성능 문제를 해결하는 가장 적절한 솔루션입니다.


## 질문 #245 +

SysOps 관리자가 워크로드 비용을 최적화하고 있습니다. 

워크로드는 여러 AWS 지역에서 실행 중이며 컴퓨터에 Amazon EC2 On-Demand 인스턴스와 함께 AWS Lambda를 사용하고 있습니다. 
전체 사용량은 예측 가능합니다. 각 지역에서 사용되는 컴퓨터 양은 사용자의 위치에 따라 다릅니다.

SysOps 관리자는 이 워크로드를 최적화하기 위해 어떤 접근 방식을 사용해야 합니까?

A. 지난 30일간의 사용량을 기준으로 컴퓨터 절약 플랜을 구매하세요.
B. 사용량 기준을 계산하여 변환 가능 예약 인스턴스를 구매합니다.
C. 지난 30일간의 사용량을 기준으로 EC2 인스턴스 절감 플랜을 구매하세요.
D. 사용 기준을 계산하여 표준 예약 인스턴스를 구매합니다.

SysOps 관리자가 여러 AWS 지역에서 실행 중인 워크로드를 최적화하려면 
**A. 지난 30일간의 사용량을 기준으로 컴퓨터 절약 플랜을 구매하세요**가 가장 적합한 접근 방식입니다.

#### **이유:**
- **컴퓨팅 절약 플랜**은 EC2 인스턴스와 AWS Lambda 등 다양한 컴퓨팅 서비스에 대한 사용량을 최적화할 수 있습니다. 절약 플랜은 사용량 패턴을 기준으로 전체 컴퓨팅 비용을 절감할 수 있는 방법을 제공합니다.
- 여러 지역에서 워크로드가 실행되기 때문에, 컴퓨팅 절약 플랜은 **모든 지역**에서 적용되며, 워크로드가 EC2와 Lambda를 포함하기 때문에 **다양한 컴퓨팅 서비스**에 대해 비용을 절감할 수 있습니다.
- 이 절약 플랜은 예측 가능한 사용량 패턴을 기반으로 하여 최적의 비용 절감을 제공합니다.

AWS는 할인형 옵션으로 예약 인스턴스(RI, Reserved Instance)를 운영하고 있습니다.
2019년 새로운 할인 혜택을 제공하는 Saving Plan을 출시하였습니다.
고객들은 해당 할인형 옵션을 통해 일정 컴퓨팅 사용을 약정 하여 할인 받을 수 있게 되었습니다.
기존 RI의 단점으로는 인스턴스 자체를 빌리는 옵션이었기에 약정 진행 중 인스턴스 크기, 타입 등을 변경할 수 없었습니다.
그에 비해 SP는 컴퓨팅 성능에 대해서 약정하기 때문에, 보다 유연하게 할인을 적용받아 인프라를 운영할 수 있는 장점이 있습니다.


#### 다른 옵션 분석:
- **B. 변환 가능 예약 인스턴스**: 이는 EC2 인스턴스에만 적용되며, Lambda와 같은 다른 서비스에는 적용되지 않습니다.
- **C. EC2 인스턴스 절감 플랜**: 이는 EC2에만 국한되므로 Lambda 사용량까지 최적화할 수 없습니다.
- **D. 표준 예약 인스턴스**: 이것도 EC2에만 적용되며, 지역 간에 유연하게 사용되지 않습니다.

따라서 다양한 지역에서 EC2와 Lambda를 사용하는 예측 가능한 워크로드에 대해 **컴퓨팅 절약 플랜**이 가장 적합한 선택입니다.

## 질문 #246 ++

소프트웨어 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 워크로드를 실행합니다. 
SysOps 관리자는 EC2 인스턴스에 대한 사용자 지정 상태 검사를 정의해야 합니다.

가장 운영 효율적인 솔루션은 무엇입니까?

A. 각 EC2 인스턴스를 설정하여 ALB가 읽을 수 있도록 공유 Amazon S3 버킷에 정상/비정상 상태를 기록하도록 합니다.
B. ALB에서 상태 검사를 구성하고 상태 검사 경로 설정이 올바른지 확인합니다.
C. EC2 인스턴스의 확장 및 축소를 추적하도록 Amazon ElastiCache를 설정합니다.
D. 모든 EC2 인스턴스에 대한 사용자 정의 검사를 보장하기 위해 Amazon API Gateway 상태 검사를 구성합니다.

가장 운영 효율적인 솔루션은 
**B. ALB에서 상태 검사를 구성하고 상태 검사 경로 설정이 올바른지 확인합니다**입니다.

#### 이유:
- **ALB의 기본 제공 상태 검사**는 각 EC2 인스턴스의 상태를 주기적으로 확인하여 인스턴스가 정상인지 비정상인지 판단합니다.
- 상태 검사 경로는 각 EC2 인스턴스의 특정 엔드포인트(예: `/health` 경로)를 검사하도록 설정할 수 있습니다. 이를 통해 ALB는 트래픽을 정상 인스턴스로만 라우팅하여 가용성을 보장합니다.
- 이 방법은 AWS에서 제공하는 **내장된 기능**을 사용하는 것이므로 추가 인프라를 설정하거나 복잡성을 도입할 필요가 없으며 운영 효율성이 뛰어납니다.

#### 다른 옵션 분석:
- **A. S3 버킷에 상태를 기록**: 불필요하게 복잡하고, 상태 기록 후 이를 ALB가 참조하는 작업을 구현하는 것은 추가 관리 작업을 요구할 뿐만 아니라 비효율적입니다.
- **C. Amazon ElastiCache 설정**: 상태 검사를 위해 ElastiCache를 사용하는 것은 관련이 없으며, 확장/축소와 상태 검사는 별개의 문제입니다.
- **D. API Gateway 상태 검사**: API Gateway는 상태 검사를 위한 서비스가 아니며, 이 방법은 과도하게 복잡합니다. ALB의 상태 검사 기능을 대신 사용하는 것이 훨씬 효율적입니다.

따라서 **B. ALB에서 상태 검사를 구성**하는 것이 운영 효율성과 간결성 측면에서 가장 적합한 솔루션입니다.



## 질문 #247

SysOps 관리자는 회사 계정 내의 Microsoft Windows 기반 Amazon EC2 인스턴스에 연결된 Amazon EBS 볼륨의 여유 공간을 모니터링해야 합니다. 관리자는 잠재적인 문제에 대해 경고를 받아야 합니다.

낮은 저장 공간이 EC2 인스턴스 성능에 영향을 미치기 전에 이메일 알림을 받으려면 관리자가 무엇을 해야 합니까?
A. 기본 제공되는 Amazon CloudWatch 메트릭을 사용하고 이메일 알림을 위한 CloudWatch 알람과 Amazon SNS 주제를 구성합니다.
B. AWS CloudTrail 로그를 사용하여 Amazon SNS 주제에 알림을 보내도록 트레일을 구성합니다.
C. Amazon CloudWatch 에이전트를 사용하여 디스크 공간 메트릭을 보낸 다음 Amazon SNS 주제를 사용하여 CloudWatch 경보를 설정합니다.
가장 많이 투표된
D. AWS Trusted Advisor를 사용하여 EC2 디스크 공간에 대한 이메일 알림을 활성화합니다.





## 질문 #248 ++

한 회사가 회사의 AWS 워크로드와 관련된 리소스에 사용자 정의 태그를 적용합니다. 

태그를 적용한 지 20일 후에 회사는 AWS Cost Explorer 콘솔에서 태그를 사용하여 뷰를 필터링할 수 없다는 것을 알게 됩니다.

이 문제의 이유는 무엇입니까?

A. Cost Explorer에서 태그를 사용하여 뷰를 필터링하려면 최소 30일이 걸립니다.
B. 회사에서 비용 할당을 위한 사용자 정의 태그를 활성화하지 않았습니다.
가장 많이 투표된
C. 해당 회사는 AWS 비용 및 사용 보고서를 작성하지 않았습니다.
D. 회사에서는 AWS Budgets에 사용 예산을 생성하지 않았습니다.

이 문제의 이유는 
**B. 회사에서 비용 할당을 위한 사용자 정의 태그를 활성화하지 않았습니다**입니다.

#### 이유:
- **AWS Cost Explorer**에서 태그를 사용하여 비용과 사용량을 필터링하려면 **사용자 정의 태그를 비용 할당 태그로 활성화**해야 합니다.
- 태그를 생성한 후, **AWS 태그 편집기**나 **Cost Allocation Tags 설정**에서 해당 태그를 비용 할당 태그로 활성화하지 않으면 Cost Explorer에서 태그를 기준으로 뷰를 필터링할 수 없습니다.
- 비용 할당 태그를 활성화한 이후부터만 해당 태그가 비용 보고서와 연결되기 때문에, 태그 적용 후에도 비용 분석에 사용할 수 없습니다.

#### 다른 옵션 분석:
- **A. 최소 30일이 걸린다**: 태그가 활성화되면 24시간 이내에 Cost Explorer에서 사용 가능해야 합니다. 30일의 시간 제한은 존재하지 않습니다.
- **C. AWS 비용 및 사용 보고서를 작성하지 않음**: 이 보고서는 비용 분석의 또 다른 도구이며, 태그 필터링과 직접적인 관계는 없습니다.
- **D. 예산을 생성하지 않음**: 예산 생성은 비용 추적이나 태그 사용과는 별개의 기능입니다.

따라서 회사는 **비용 할당 태그**로 사용자 정의 태그를 활성화해야 이 문제를 해결할 수 있습니다.


## 질문 #249 +++

한 회사에 여러 AWS Lambda 함수를 사용하는 중요한 서버리스 애플리케이션이 있습니다. 

각 Lambda 함수는 자체 Amazon CloudWatch Logs 로그 그룹에서 매일 1GB의 로그 데이터를 생성합니다. 회사의 보안 팀은 모든 로그 그룹에서 유형별로 그룹화된 애플리케이션 오류 수를 요청합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. stats 명령과 count 함수를 사용하여 CloudWatch Logs Insights 쿼리를 수행합니다.
B. groupby 키워드와 count 함수를 사용하여 CloudWatch Logs 검색을 수행합니다.
C. SELECT 및 GROUP BY 키워드를 사용하는 Amazon Athena 쿼리를 수행합니다.
D. SELECT 및 GROUP BY 키워드를 사용하는 Amazon RDS 쿼리를 수행합니다.


이 요구 사항을 충족하기 위한 가장 적합한 솔루션은 
**A. stats 명령과 count 함수를 사용하여 CloudWatch Logs Insights 쿼리를 수행합니다**입니다.

#### 이유:
- **Amazon CloudWatch Logs Insights**는 CloudWatch Logs에서 데이터를 쿼리하고 분석할 수 있는 강력한 도구입니다. 이를 통해 로그 데이터를 필터링하고, 집계하며, 실시간으로 분석할 수 있습니다.
- **`stats` 명령과 `count` 함수**를 사용하면 로그 데이터를 유형별로 그룹화하고, 각 그룹 내에서 발생한 오류 수를 쉽게 집계할 수 있습니다. 이를 통해 보안 팀의 요구 사항을 충족할 수 있습니다.

#### 다른 옵션 분석:
- **B. groupby 키워드와 count 함수**: CloudWatch Logs Insights에서는 `groupby` 키워드를 사용하지 않으며, 올바른 구문이 아닙니다. 대신 `stats`와 `count` 함수를 사용해야 합니다.
- **C. Amazon Athena 쿼리**: Athena는 S3에 저장된 데이터에 대해 SQL 쿼리를 실행하는 서비스입니다. 그러나 이 경우에는 CloudWatch Logs에 저장된 로그 데이터를 분석해야 하므로 적절하지 않습니다.
- **D. Amazon RDS 쿼리**: RDS는 관계형 데이터베이스 서비스로, 로그 분석을 위한 도구가 아닙니다. 로그 데이터를 직접 쿼리하는 데 사용되지 않습니다.

따라서 **CloudWatch Logs Insights**에서 **`stats`와 `count`**를 사용하는 것이 최적의 솔루션입니다.

## 질문 #250 n

여러 AWS 계정이 있는 회사는 AWS Lambda 함수에 대한 권장 사항을 얻고 각 Lambda 함수에 대한 최적의 리소스 구성을 식별해야 합니다.

SysOps 관리자는 이러한 권장 사항을 어떻게 제공해야 합니까?

A. AWS Serverless Application Repository를 만들고 Lambda 함수 권장 사항을 내보냅니다.
B. AWS Compute Optimizer를 활성화하고 Lambda 함수 권장 사항을 내보냅니다.
C. AWS Organizations의 모든 기능을 활성화하고 AWS CloudTrail Insights에서 권장 사항을 내보냅니다.
D. AWS Trusted Advisor를 실행하고 Lambda 함수 권장 사항을 내보냅니다.


이 요구 사항을 충족하기 위한 최적의 솔루션은 

**B. AWS Compute Optimizer를 활성화하고 Lambda 함수 권장 사항을 내보냅니다**입니다.

#### 이유:
- **AWS Compute Optimizer**는 AWS 리소스에 대한 최적의 구성을 추천하는 서비스로, **Lambda 함수**의 메모리 및 CPU 설정을 최적화할 수 있는 권장 사항을 제공합니다. Compute Optimizer는 Lambda 함수의 리소스 사용량과 성능 메트릭을 분석하고, 비용 절감과 성능 향상을 위한 권장 사항을 제공합니다.

#### 다른 옵션 분석:
- **A. AWS Serverless Application Repository**는 Lambda 함수 권장 사항을 제공하지 않고, 서버리스 애플리케이션을 공유 및 배포할 수 있는 플랫폼입니다.
- **C. AWS CloudTrail Insights**는 계정 내에서 발생하는 비정상적인 API 호출을 분석하는 데 사용되며, Lambda 함수의 리소스 최적화를 위한 권장 사항을 제공하지 않습니다.
- **D. AWS Trusted Advisor**는 비용 절감, 성능 개선, 보안 강화 등을 위한 권장 사항을 제공하지만, 구체적으로 Lambda 함수에 대한 최적화 권장 사항을 제공하지 않습니다.

따라서 **AWS Compute Optimizer**를 사용하는 것이 가장 적합한 솔루션입니다.



## 질문 #251 ++

한 회사에서 AWS CloudFormation 템플릿을 사용하여 클라우드 인프라를 배포합니다. 

회사의 모든 템플릿을 분석한 결과, 회사에서 여러 템플릿에 동일한 구성 요소를 선언한 것으로 나타났습니다. SysOps 관리자는 이러한 공통 구성 요소에 대한 자체 매개변수와 조건이 있는 전용 템플릿을 만들어야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

A. CloudFormation 변경 세트를 개발합니다.
B. CloudFormation 매크로를 개발합니다.
C. CloudFormation 중첩 스택을 개발합니다.
D. CloudFormation 스택 세트를 개발합니다.

이 요구 사항을 충족하는 최적의 솔루션은

**C. CloudFormation 중첩 스택을 개발합니다**입니다.

#### 이유:
- **CloudFormation 중첩 스택**은 여러 스택에서 반복적으로 사용하는 공통 구성 요소를 별도의 템플릿으로 분리하여 재사용할 수 있게 해줍니다. 이를 통해 공통된 리소스를 한 곳에서 정의하고 여러 템플릿에서 참조할 수 있으며, 관리가 용이해집니다. 또한 각 중첩된 스택은 고유한 매개변수와 조건을 가질 수 있어 다양한 시나리오에 맞게 설정할 수 있습니다.

#### 다른 옵션 분석:
- **A. CloudFormation 변경 세트**는 스택을 업데이트하기 전에 변경 사항을 미리 검토하는 기능으로, 템플릿 내 공통 구성 요소를 처리하는 것과는 관련이 없습니다.
- **B. CloudFormation 매크로**는 템플릿 내에서 사용자 지정 로직을 실행하거나 템플릿을 변환하는 기능이지만, 공통 구성 요소를 재사용하는 목적으로 중첩 스택이 더 적합합니다.
- **D. CloudFormation 스택 세트**는 여러 AWS 계정 또는 지역에 걸쳐 동일한 스택을 배포할 때 사용되며, 공통된 구성 요소를 처리하기 위한 솔루션이 아닙니다.

따라서 **CloudFormation 중첩 스택**을 개발하여 공통 구성 요소를 재사용하는 것이 이 요구 사항에 가장 적합한 솔루션입니다.

## 질문 #252 +

SysOps 관리자가 같은 회사 내의 다른 사업부와 연관된 다른 계정 간에 Amazon RDS 데이터베이스 스냅샷을 공유하는 프로세스를 구축하고 있습니다. 모든 데이터는 저장 시 암호화되어야 합니다.

관리자는 이 프로세스를 어떻게 구현해야 합니까?

A. 암호화된 스냅샷을 다운로드하고 스냅샷을 암호화하는 데 사용된 AWS KMS 암호화 키를 사용하여 암호를 해독한 다음 각 계정에 새 볼륨을 생성하는 스크립트를 작성합니다.

B. 스냅샷을 암호화하는 데 사용되는 AWS KMS 암호화 키에 모든 관련 계정에 대한 권한을 부여하도록 키 정책을 업데이트한 다음, 해당 계정과 스냅샷을 공유합니다.

C. 스냅샷을 기반으로 Amazon EC2 인스턴스를 만든 다음 인스턴스의 Amazon EBS 볼륨을 스냅샷으로 저장하고 다른 계정과 공유합니다. 각 계정 소유자가 해당 스냅샷에서 새 볼륨을 만들고 암호화하도록 요구합니다.

D. 암호화된 스냅샷에서 암호화되지 않은 새 RDS 인스턴스를 만들고 SSH/RDP를 사용하여 인스턴스에 연결한 다음 데이터베이스 내용을 파일로 내보낸 다음 이 파일을 다른 계정과 공유합니다.


이 요구 사항을 충족하는 최적의 솔루션은 

**B. 스냅샷을 암호화하는 데 사용되는 AWS KMS 암호화 키에 모든 관련 계정에 대한 권한을 부여하도록 키 정책을 업데이트한 다음, 해당 계정과 스냅샷을 공유합니다**입니다.

#### 이유:
- Amazon RDS 스냅샷이 **암호화**된 경우, 이를 다른 계정과 공유하려면 해당 스냅샷을 암호화하는 데 사용된 **AWS KMS (Key Management Service)** 키에 대해 다른 계정이 해당 키에 접근할 수 있도록 권한을 부여해야 합니다. 이 방법은 저장된 데이터를 안전하게 유지하면서도 다른 계정에서 스냅샷을 사용할 수 있게 해줍니다.
- **KMS 키 정책**을 업데이트하여 관련 계정에 권한을 부여하면, 해당 계정에서 암호화된 스냅샷을 액세스하고 사용할 수 있습니다. 이 방법은 데이터가 암호화된 상태로 유지되므로 보안 요구 사항도 충족됩니다.

#### 다른 옵션 분석:
- **A. 암호화된 스냅샷을 다운로드하고 KMS 키로 암호를 해독한 후 각 계정에 새 볼륨 생성**: 스냅샷 데이터에 직접 접근하거나 암호를 해독하는 것은 AWS에서 지원하지 않는 복잡하고 비효율적인 방법입니다.
- **C. Amazon EC2 인스턴스를 통해 EBS 볼륨으로 스냅샷을 공유**: 이 방법은 불필요하게 복잡하고, RDS 데이터베이스 스냅샷을 공유하는 기본적인 AWS 방법에 적합하지 않습니다.
- **D. 암호화된 스냅샷에서 암호화되지 않은 RDS 인스턴스를 만들고 파일로 내보내기**: 이 방법은 데이터 보안 측면에서 적절하지 않으며, 암호화를 유지하지 않기 때문에 요구 사항을 충족하지 못합니다.

따라서 **KMS 키 정책을 업데이트**하여 다른 계정이 스냅샷을 액세스할 수 있도록 하는 방법이 가장 안전하고 효율적인 솔루션입니다.

## 질문 #253 +

SysOps 관리자가 VPC에서 Amazon S3 게이트웨이 엔드포인트를 구성합니다. 

VPC 내부의 프라이빗 서브넷에는 아웃바운드 인터넷 액세스가 없습니다. 사용자는 프라이빗 서브넷 중 하나에 있는 Amazon EC2 인스턴스에 로그인하고 동일한 AWS 리전의 Amazon S3 버킷에 파일을 업로드할 수 없습니다.

어떤 솔루션이 이 문제를 해결할까요?


A. EC2 인스턴스 역할 정책을 업데이트하여 대상 S3 버킷에 대한 s3:PutObject 액세스를 포함합니다.
B. EC2 보안 그룹을 업데이트하여 포트 80에 대해 0.0.0.0/0으로의 아웃바운드 트래픽을 허용합니다.
C. S3 게이트웨이 엔드포인트에 대한 S3 접두사 목록 대상 경로를 포함하도록 EC2 서브넷 경로 테이블을 업데이트합니다.
D. S3 버킷 정책을 업데이트하여 개인 서브넷 CIDR 블록에서 s3:PutObject 액세스를 허용합니다.

이 문제를 해결하는 최적의 솔루션은 
**C. S3 게이트웨이 엔드포인트에 대한 S3 접두사 목록 대상 경로를 포함하도록 EC2 서브넷 경로 테이블을 업데이트합니다**입니다.

#### 이유:
- Amazon S3에 액세스하기 위해 VPC 내에서 **S3 게이트웨이 엔드포인트**를 사용하는 경우, 해당 엔드포인트에 대한 경로가 **서브넷의 경로 테이블**에 설정되어 있어야 합니다. 이 경로를 설정하지 않으면 VPC 내부의 EC2 인스턴스가 S3 버킷에 접근할 수 없습니다.
- 서브넷 경로 테이블에 S3 접두사 목록을 사용한 엔드포인트 경로를 추가함으로써, 인터넷 액세스 없이도 VPC 내에서 S3에 대한 안전한 연결이 가능해집니다.

#### 다른 옵션 분석:
- **A. EC2 인스턴스 역할 정책을 업데이트**: EC2 인스턴스가 S3에 액세스할 수 있도록 권한을 추가하는 것은 중요하지만, 이 문제는 권한 부족이 아니라 네트워크 경로 설정과 관련이 있습니다.
- **B. EC2 보안 그룹을 업데이트**: S3에 대한 접근은 HTTP/HTTPS(포트 80/443)를 통해 이루어지지만, 게이트웨이 엔드포인트를 사용 중인 경우 EC2 보안 그룹이 아니라 경로 테이블 설정이 문제의 핵심입니다.
- **D. S3 버킷 정책을 업데이트**: 버킷 정책을 통해 CIDR 블록에서의 접근을 허용하는 것은 S3 권한을 설정하는 방법일 수 있지만, 이 문제는 S3 버킷 정책과는 무관하며 경로 테이블의 설정이 필요합니다.

따라서 **서브넷 경로 테이블을 업데이트**하는 것이 이 문제를 해결하는 적절한 방법입니다.

## 질문 #254 +

한 회사가 Amazon S3를 사용하여 미국 전역의 다양한 미디어 팀에서 원시 비디오 영상을 수집합니다. 이 회사는 최근 유럽과 호주의 새로운 지역으로 확장했습니다. 유럽과 호주에 있는 기술 팀은 미국에서 대상 S3 버킷에 대용량 비디오 파일을 업로드할 때 지연이 발생한다고 보고했습니다. S3 버킷으로의 업로드 속도를 높이는 가장 비용 효율적인 방법은 무엇입니까? (두 가지를 선택하세요.)


A. 유럽과 호주에 있는 AWS와 지사 간에 여러 개의 AWS Direct Connect 연결을 생성하여 대상 S3 버킷에 파일을 업로드합니다.
B. 유럽과 호주에 있는 AWS와 지사 간에 여러 개의 AWS 사이트 간 VPN 연결을 생성하여 대상 S3 버킷에 파일을 업로드합니다.
C. 대상 S3 버킷에 파일을 업로드하려면 Amazon S3 Transfer Acceleration을 사용하세요.
D. 유럽과 호주 지사에서 대상 S3 버킷으로 파일을 업로드하려면 AWS Global Accelerator를 사용하세요.
E. 유럽과 호주 지사에서 대상 S3 버킷으로 파일을 업로드하려면 다중 파트 업로드를 사용합니다.

이 문제를 해결하는 가장 비용 효율적인 방법은 
**C. Amazon S3 Transfer Acceleration을 사용**하고 
**E. 다중 파트 업로드를 사용**하는 것입니다.

#### 이유:

1. **C. Amazon S3 Transfer Acceleration 사용**:
   - S3 Transfer Acceleration은 **전 세계적으로 분산된 엣지 로케이션**을 사용하여 S3 버킷으로의 업로드 속도를 크게 향상시킵니다. 특히 **장거리 대용량 파일 전송** 시 효과적이며, **비용 효율적**입니다. 유럽과 호주에서 미국의 S3 버킷으로 대용량 비디오 파일을 업로드할 때 전송 지연을 줄일 수 있습니다.
   
2. **E. 다중 파트 업로드 사용**:
   - 다중 파트 업로드는 **대용량 파일을 작은 청크로 분할**하여 동시에 업로드할 수 있게 해줍니다. 이렇게 하면 **전송이 더 빠르고 안정적**이며, 특히 대용량 비디오 파일의 업로드 속도를 높일 수 있습니다. 중간에 실패한 부분만 재전송하면 되기 때문에, 장거리 업로드 시에 유리합니다.

#### 다른 옵션 분석:
- **A. AWS Direct Connect 연결을 생성**: Direct Connect는 고속 전용 네트워크 연결을 제공하지만, 이는 **비용이 많이 드는** 솔루션입니다. 미디어 업로드와 같은 경우에는 비용 효율성이 떨어집니다.
- **B. AWS 사이트 간 VPN 연결을 생성**: VPN은 보안적인 이점이 있지만, S3 Transfer Acceleration이나 다중 파트 업로드만큼 **성능 향상**에 기여하지 않으며, 비용 측면에서도 효율적이지 않습니다.
- **D. AWS Global Accelerator 사용**: Global Accelerator는 주로 **애플리케이션 성능 최적화**를 위해 사용되며, **S3 버킷에 대한 파일 업로드를 가속화**하는 데는 사용되지 않습니다.

따라서, **S3 Transfer Acceleration**과 **다중 파트 업로드**가 가장 적합한 솔루션입니다.

## 질문 #255

SysOps 관리자가 개발팀이 AWS에 애플리케이션을 배포하도록 돕고 있습니다. 

AWS CloudFormation 템플릿에는 Amazon Linux EC2 인스턴스, Amazon Aurora DB 클러스터, 90일마다 순환해야 하는 하드코딩된 데이터베이스 비밀번호가 포함되어 있습니다.

데이터베이스 비밀번호를 관리하는 가장 안전한 방법은 무엇입니까?

A. AWS::SecretsManager::Secret 리소스를 GenerateSecretString 속성과 함께 사용하여 비밀번호를 자동으로 생성합니다. AWS::SecretsManager::RotationSchedule 리소스를 사용하여 비밀번호의 로테이션 일정을 정의합니다. AWS Secrets Manager에서 비밀을 검색하여 데이터베이스에 액세스하도록 애플리케이션을 구성합니다.

B. SecretString 속성이 있는 AWS::SecretsManager::Secret 리소스를 사용합니다. CloudFormation 매개변수로 비밀번호를 허용합니다. CloudFormation 매개변수의 AllowedPattern 속성을 사용하여 최소 길이, 대문자와 소문자, 특수 문자를 요구합니다. AWS Secrets Manager에서 비밀을 검색하여 데이터베이스에 액세스하도록 애플리케이션을 구성합니다.

C. AWS::SSM::Parameter 리소스를 사용합니다. CloudFormation 매개변수로 입력을 수락하여 매개변수를 보안 문자열로 저장합니다. AWS Systems Manager Parameter Store에서 매개변수를 검색하여 데이터베이스에 액세스하도록 애플리케이션을 구성합니다.

D. AWS::SSM::Parameter 리소스를 사용합니다. CloudFormation 매개변수로 입력을 수락하여 매개변수를 문자열로 저장합니다. AWS Systems Manager Parameter Store에서 매개변수를 검색하여 데이터베이스에 액세스하도록 애플리케이션을 구성합니다.

데이터베이스 비밀번호를 관리하는 가장 안전한 방법은 
**A. AWS::SecretsManager::Secret 리소스를 GenerateSecretString 속성과 함께 사용하여 비밀번호를 자동으로 생성하고, AWS::SecretsManager::RotationSchedule 리소스를 사용하여 비밀번호의 로테이션 일정을 정의한 후, AWS Secrets Manager에서 비밀을 검색하여 데이터베이스에 액세스하도록 애플리케이션을 구성**하는 것입니다.

#### 이유:

1. **자동 생성 및 로테이션**:
   - **AWS Secrets Manager**를 사용하면 비밀번호를 자동으로 생성하고 정기적으로 로테이션할 수 있습니다. 이는 비밀번호의 보안을 크게 향상시키고, 수동으로 비밀번호를 관리하는 번거로움을 줄여줍니다. 비밀번호가 주기적으로 변경되면 보안 위협을 최소화할 수 있습니다.

2. **애플리케이션 통합**:
   - AWS Secrets Manager에서 비밀을 검색하여 애플리케이션에서 쉽게 사용할 수 있도록 통합할 수 있습니다. 이는 비밀번호 관리의 편리함을 증가시키고, 애플리케이션이 보안 비밀을 안전하게 저장하고 사용할 수 있게 해줍니다.

#### 다른 옵션 분석:
- **B. SecretString 속성이 있는 AWS::SecretsManager::Secret 리소스를 사용**: 비밀번호를 CloudFormation 매개변수로 허용하는 것은 보안상 취약할 수 있으며, 매개변수의 내용을 저장하는 과정에서 비밀번호가 노출될 수 있습니다.
  
- **C. AWS::SSM::Parameter 리소스를 사용하여 매개변수를 보안 문자열로 저장**: Systems Manager Parameter Store도 비밀번호를 저장할 수 있지만, 자동 비밀번호 로테이션 기능이 제공되지 않습니다. 비밀번호를 주기적으로 변경해야 하는 경우, 수동으로 관리해야 하므로 안전성이 떨어집니다.

- **D. AWS::SSM::Parameter 리소스를 사용하여 문자열로 저장**: 문자열로 저장하는 경우 비밀번호의 보안이 떨어지며, 비밀번호 관리의 편의성과 안전성이 모두 부족합니다.

따라서, **AWS Secrets Manager**를 활용하여 비밀번호를 자동 생성하고 로테이션하는 방법이 가장 안전하고 효율적인 솔루션입니다.

## 질문 #256 +++++

애플리케이션 A는 네트워크 로드 밸런서(NLB) 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 

EC2 인스턴스는 자동 확장 그룹에 있으며 NLB와 연결된 동일한 서브넷에 있습니다. 온프레미스 환경의 다른 애플리케이션은 포트 8080에서 애플리케이션 A와 통신할 수 없습니다.

문제를 해결하기 위해 SysOps 관리자가 흐름 로그를 분석합니다. 흐름 로그에는 다음 레코드가 포함됩니다.

2 11112222333 eni-<###> 192.168.0.13  172.31.16.139 59003 8080 1 4 336 1432917027 14322917142  ACCEPT OK
2 11112222333 eni-<###> 172.31.16.139 192.168.0.13  8080  59003 1 4 336 1432917027 14322917142  REJECT OK

거부된 트래픽의 이유는 무엇입니까?

A. EC2 인스턴스의 보안 그룹에는 NLB의 트래픽에 대한 허용 규칙이 없습니다.
B. NLB의 보안 그룹에는 온-프레미스 환경의 트래픽에 대한 허용 규칙이 없습니다.
C. 온프레미스 환경의 ACL은 AWS 환경으로의 트래픽을 허용하지 않습니다.
D. 서브넷과 연결된 네트워크 ACL은 임시 포트 범위에 대한 아웃바운드 트래픽을 허용하지 않습니다.

주어진 흐름 로그를 분석하여 거부된 트래픽의 이유를 확인해 보겠습니다. 흐름 로그의 두 레코드는 다음과 같습니다:

1. **허용된 트래픽:**
   - **Source:** 192.168.0.13 (온프레미스)
   - **Destination:** 172.31.16.139 (NLB)
   - **Source Port:** 59003
   - **Destination Port:** 8080
   - **Action:** ACCEPT

2. **거부된 트래픽:**
   - **Source:** 172.31.16.139 (NLB)
   - **Destination:** 192.168.0.13 (온프레미스)
   - **Source Port:** 8080
   - **Destination Port:** 59003
   - **Action:** REJECT

### **거부된 트래픽의 이유 분석:**

- **허용된 트래픽:** 온프레미스 환경(192.168.0.13)에서 NLB(172.31.16.139)로의 트래픽은 성공적으로 허용되었습니다. 이는 온프레미스 환경에서 NLB로의 요청이 통신이 가능하다는 것을 의미합니다.

- **거부된 트래픽:** 그러나 NLB가 EC2 인스턴스에 대한 응답(172.31.16.139에서 192.168.0.13으로의 트래픽)을 보내려 할 때, 이 트래픽이 거부되었습니다. 이는 NLB에서 EC2 인스턴스로의 트래픽이 수신되지 않았음을 나타냅니다.

### **결론:**
거부된 트래픽의 이유는 다음과 같습니다.

**B. NLB의 보안 그룹에는 온-프레미스 환경의 트래픽에 대한 허용 규칙이 없습니다.**

이 이유는 NLB가 EC2 인스턴스에 연결된 보안 그룹에서 포트 8080에 대한 인바운드 규칙이 없기 때문에 발생한 것으로 보입니다. NLB가 EC2 인스턴스로 응답을 보내기 위해서는 해당 포트에 대한 허용 규칙이 필요합니다. 

다른 옵션들에 대한 설명은 다음과 같습니다:

- **A. EC2 인스턴스의 보안 그룹에는 NLB의 트래픽에 대한 허용 규칙이 없습니다.**
  - 이 옵션은 주로 NLB가 EC2 인스턴스에 트래픽을 보내기 위한 규칙을 의미하지만, 흐름 로그에 따르면 NLB에서 EC2 인스턴스로의 트래픽이 문제가 발생하고 있습니다.

- **C. 온프레미스 환경의 ACL은 AWS 환경으로의 트래픽을 허용하지 않습니다.**
  - 이 경우, 온프레미스에서 AWS로의 트래픽은 허용된 것으로 보이며, 흐름 로그에서 이미 수신된 요청이 ACCEPT로 표시됩니다.

- **D. 서브넷과 연결된 네트워크 ACL은 임시 포트 범위에 대한 아웃바운드 트래픽을 허용하지 않습니다.**
  - 이 옵션은 아웃바운드 트래픽에 대한 문제를 다루지만, 흐름 로그에서는 인바운드 트래픽 거부가 발생하고 있습니다.

따라서 **B**가 정답입니다.

## 질문 #257 ++++

회사의 SysOps 관리자가 고가용성 환경을 유지 관리합니다. 

이 환경에는 Amazon EC2 인스턴스와 Amazon RDS Multi-AZ 데이터베이스가 포함됩니다. EC2 인스턴스는 Application Load Balancer 뒤의 Auto Scaling 그룹에 있습니다.

최근 회사에서 장애 조치 테스트를 수행했습니다. SysOps 관리자는 RDS 데이터베이스의 장애 조치 시간을 최소 10% 줄여야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?


A. RDS 인스턴스 크기를 늘리세요.
B. RDS 클러스터를 단일 가용성 영역에서 실행하도록 수정합니다.
C. 다른 AWS 리전에서 읽기 복제본을 만듭니다. 실패 시 읽기 복제본을 승격합니다.
D. RDS 프록시를 만듭니다. 애플리케이션을 프록시 엔드포인트로 가리킵니다.

RDS 데이터베이스의 장애 조치 시간을 최소 10% 줄이기 위해 적합한 솔루션은 다음과 같습니다:

### **정답: D. RDS 프록시를 만듭니다. 애플리케이션을 프록시 엔드포인트로 가리킵니다.**

### 이유:
- **RDS 프록시:** RDS 프록시는 데이터베이스에 대한 연결 관리와 장애 조치를 개선하는 데 도움을 줍니다. 데이터베이스 연결을 풀링하여 애플리케이션과 데이터베이스 간의 연결 시간을 줄이고, 장애 발생 시 더 빠르게 새로운 연결을 수립할 수 있도록 하여 전체 장애 조치 시간을 단축시킵니다.

### 다른 옵션에 대한 설명:
- **A. RDS 인스턴스 크기를 늘리세요.**
  - 인스턴스 크기를 늘리면 성능이 향상될 수 있지만, 장애 조치 시간 자체를 줄이는 데 직접적인 영향을 미치지는 않습니다.

- **B. RDS 클러스터를 단일 가용성 영역에서 실행하도록 수정합니다.**
  - 단일 AZ로 변경하면 가용성을 낮출 수 있으며, 장애 조치 시간을 줄이기 위해서는 도움이 되지 않습니다. Multi-AZ 구성은 장애 조치 시 더 빠른 복구를 제공합니다.

- **C. 다른 AWS 리전에서 읽기 복제본을 만듭니다. 실패 시 읽기 복제본을 승격합니다.**
  - 읽기 복제본을 다른 리전에서 만드는 것은 재해 복구 측면에서 도움이 될 수 있지만, 리전 간의 전환은 더 긴 지연 시간을 초래할 수 있으며, 장애 조치 시간을 줄이는 데 적합하지 않습니다.

결론적으로, **D** 옵션이 RDS 데이터베이스의 장애 조치 시간을 최소화하는 데 가장 효과적인 솔루션입니다.

## 질문 #258 ++++

회사의 VPC는 ​​AWS Site-to-Site VPN을 통해 온프레미스 데이터 센터에 연결됩니다. 

회사는 VPC에 Amazon EC2 인스턴스가 있어야 example.com에 대한 DNS 쿼리를 데이터 센터의 DNS 서버로 보낼 수 있습니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?


A. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 온프레미스 DNS 서버에서 example.com에 대한 DNS 요청을 인바운드 엔드포인트로 전달하는 조건부 전달 규칙을 만듭니다.
B. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. example.com에 대한 모든 쿼리를 온프레미스 DNS 서버로 보내는 Resolver에 전달 규칙을 만듭니다. 이 규칙을 VPC와 연결합니다.
C. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 온프레미스 DNS 서버에서 example.com에 대한 DNS 요청을 아웃바운드 엔드포인트로 전달하는 조건부 전달 규칙을 만듭니다.
D. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. example.com에 대한 모든 쿼리를 온프레미스 DNS 서버로 보내는 Resolver에 전달 규칙을 만듭니다. 이 규칙을 VPC와 연결합니다.

회사의 VPC가 온프레미스 데이터 센터에 연결되어 있고, EC2 인스턴스가 example.com에 대한 DNS 쿼리를 데이터 센터의 DNS 서버로 보낼 수 있어야 합니다. 이를 위해 필요한 구성은 다음과 같습니다:

### **정답: D. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. example.com에 대한 모든 쿼리를 온프레미스 DNS 서버로 보내는 Resolver에 전달 규칙을 만듭니다. 이 규칙을 VPC와 연결합니다.**

### 이유:
- **아웃바운드 엔드포인트:** VPC 내의 Amazon EC2 인스턴스가 DNS 요청을 외부로 보내기 위해서는 아웃바운드 엔드포인트가 필요합니다.
- **전달 규칙:** example.com에 대한 모든 DNS 쿼리를 온프레미스 DNS 서버로 전달하도록 규칙을 설정하면, EC2 인스턴스가 DNS 요청을 해당 서버로 올바르게 전송할 수 있습니다.

### 다른 옵션에 대한 설명:
- **A. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 온프레미스 DNS 서버에서 example.com에 대한 DNS 요청을 인바운드 엔드포인트로 전달하는 조건부 전달 규칙을 만듭니다.**
  - 인바운드 엔드포인트는 외부에서 VPC로 들어오는 DNS 요청을 처리하는 데 사용되므로 이 시나리오에 적합하지 않습니다.

- **B. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. example.com에 대한 모든 쿼리를 온프레미스 DNS 서버로 보내는 Resolver에 전달 규칙을 만듭니다. 이 규칙을 VPC와 연결합니다.**
  - 이 옵션도 인바운드 엔드포인트를 사용하고 있으므로 적합하지 않습니다.

- **C. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 온프레미스 DNS 서버에서 example.com에 대한 DNS 요청을 아웃바운드 엔드포인트로 전달하는 조건부 전달 규칙을 만듭니다.**
  - 이 옵션은 아웃바운드 엔드포인트를 사용하지만, 온프레미스 DNS 서버가 아닌 VPC의 EC2 인스턴스에서 요청이 발생해야 하므로 적합하지 않습니다.

따라서 **D**가 가장 적합한 솔루션입니다.

## 질문 #259

SysOps 관리자는 데이터베이스 성능을 분석하는 업무를 맡았습니다. 

데이터베이스는 단일 Amazon RDS DB 인스턴스에서 실행됩니다. SysOps 관리자는 트래픽이 가장 많은 시간에 읽기 트래픽 양으로 인해 데이터베이스의 리소스가 과도하게 사용된다는 것을 알게 되었습니다.

SysOps 관리자는 RDS 성능을 개선하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)


A. 읽기 복제본 추가
B. Memcached에 Amazon ElastiCache를 사용하도록 애플리케이션을 수정합니다.
C. RDS에서 Amazon DynamoDB로 데이터베이스를 마이그레이션합니다.
D. 향상된 네트워킹을 활성화하여 데이터베이스를 Amazon EC2로 마이그레이션합니다.
E. 데이터베이스를 다중 AZ 배포로 업그레이드합니다.

데이터베이스 성능을 개선하기 위해 SysOps 관리자가 선택할 수 있는 두 가지 조치는 다음과 같습니다:

### 1. **A. 읽기 복제본 추가**
- **이유:** 읽기 복제본을 추가하면 읽기 요청을 분산시켜 데이터베이스 인스턴스의 부하를 줄일 수 있습니다. 특히 읽기 트래픽이 많은 경우 읽기 복제본을 사용하면 기본 데이터베이스에 대한 부담을 줄이고 성능을 향상시킬 수 있습니다.

### 2. **B. Memcached에 Amazon ElastiCache를 사용하도록 애플리케이션을 수정합니다.**
- **이유:** ElastiCache를 사용하면 자주 조회되는 데이터를 메모리에 캐시하여 데이터베이스에 대한 직접적인 읽기 요청 수를 줄일 수 있습니다. 이는 데이터베이스의 리소스 사용을 줄이고, 애플리케이션의 응답 속도를 개선하는 데 도움이 됩니다.

### 다른 옵션에 대한 설명:
- **C. RDS에서 Amazon DynamoDB로 데이터베이스를 마이그레이션합니다.**
  - 이 옵션은 RDS의 성능 문제를 해결하는 직접적인 방법이 아닙니다. DynamoDB는 다른 유형의 데이터베이스이며, 마이그레이션은 복잡성을 증가시킬 수 있습니다.

- **D. 향상된 네트워킹을 활성화하여 데이터베이스를 Amazon EC2로 마이그레이션합니다.**
  - RDS는 관리형 서비스이며, EC2로 마이그레이션하는 것은 관리 오버헤드를 증가시킬 수 있습니다. 향상된 네트워킹은 RDS에서 사용할 수 없습니다.

- **E. 데이터베이스를 다중 AZ 배포로 업그레이드합니다.**
  - 다중 AZ 배포는 고가용성을 제공하지만 읽기 성능 향상에는 직접적인 도움이 되지 않습니다. 이는 장애 조치와 가용성 향상에 초점을 맞추기 때문에 성능 문제를 해결하는 데에는 적합하지 않습니다.

따라서 **A**와 **B**가 성능을 개선하기 위한 최적의 선택입니다.


## 질문 #260 +++++

회사의 SysOps 관리자가 여러 AWS 계정에서 모든 새 EC2 인스턴스의 템플릿으로 사용될 사용자 지정 소프트웨어가 있는 Amazon EC2 인스턴스를 만들었습니다.

 EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨은 AWS 관리 키로 암호화됩니다.

SysOps 관리자는 사용자 지정 EC2 인스턴스의 Amazon Machine Image(AMI)를 만들고 AMI를 회사의 다른 AWS 계정과 공유할 계획입니다. 회사에서는 모든 AMI가 AWS Key Management Service(AWS KMS) 키로 암호화되어야 하며 권한이 있는 AWS 계정만 공유 AMI에 액세스할 수 있어야 합니다.

어떤 솔루션이 다른 AWS 계정과 AMI를 안전하게 공유할까요?


A. AMI가 생성된 계정에서 고객 관리 KMS 키를 만듭니다. 키 정책을 수정하여 AMI가 공유될 AWS 계정에 kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant 및 kms:Decrypt 권한을 제공합니다. AMI 권한을 수정하여 AMI가 공유될 AWS 계정 번호를 지정합니다.

B. AMI가 생성된 계정에서 고객 관리 KMS 키를 만듭니다. 키 정책을 수정하여 AMI가 공유될 AWS 계정에 kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant 및 kms:Decrypt 권한을 제공합니다. AMI의 복사본을 만들고 KMS 키를 지정합니다. 복사된 AMI의 권한을 수정하여 AMI가 공유될 AWS 계정 번호를 지정합니다.

C. AMI가 생성된 계정에서 고객 관리 KMS 키를 만듭니다. 키 정책을 수정하여 AMI가 공유될 AWS 계정에 kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant 및 kms:Decrypt 권한을 제공합니다. AMI의 복사본을 만들고 KMS 키를 지정합니다. 복사된 AMI의 권한을 수정하여 공개합니다.

D. AMI가 생성된 계정에서 AWS 관리 키의 키 정책을 수정하여 AMI가 공유될 AWS 계정에 kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant 및 kms:Decrypt 권한을 제공합니다. AMI 권한을 수정하여 AMI가 공유될 AWS 계정 번호를 지정합니다.


AWS에서 AMI를 안전하게 공유하기 위해 SysOps 관리자가 수행해야 할 작업은 다음과 같습니다:

### 최적의 선택:
**B. AMI가 생성된 계정에서 고객 관리 KMS 키를 만듭니다. 키 정책을 수정하여 AMI가 공유될 AWS 계정에 kms:DescribeKey, kms:ReEncrypt*, kms:CreateGrant 및 kms:Decrypt 권한을 제공합니다. AMI의 복사본을 만들고 KMS 키를 지정합니다. 복사된 AMI의 권한을 수정하여 AMI가 공유될 AWS 계정 번호를 지정합니다.**

### 이유:
1. **고객 관리 KMS 키:** AWS 관리 키는 특정 계정 내에서만 사용되므로, 고객 관리 KMS 키를 생성하여 보다 유연한 권한 관리와 함께 키 정책을 설정할 수 있습니다.
2. **키 정책 수정:** AMI를 공유할 AWS 계정에 필요한 KMS 권한을 제공하여 해당 계정이 AMI를 사용할 수 있도록 합니다.
3. **AMI 복사:** 복사본을 만들면 원래 AMI와는 별개의 AMI가 생성되므로, 복사된 AMI에 대한 접근 권한을 세밀하게 조정할 수 있습니다. 이는 보안 및 권한 관리를 더 쉽게 만듭니다.
4. **AMI 권한 수정:** 복사된 AMI의 권한을 수정하여 특정 AWS 계정만 액세스할 수 있도록 합니다.

### 다른 선택지에 대한 설명:
- **A.** 키 정책 수정 후 AMI를 직접 공유하는 방법은 KMS 권한을 효과적으로 관리할 수 없으므로 보안에 취약할 수 있습니다.
  
- **C.** 복사된 AMI를 공개하는 것은 요구 사항에 위배되며, AMI가 공유될 AWS 계정에만 권한을 부여해야 합니다.

- **D.** AWS 관리 키는 특정 계정에서만 사용되므로, 다른 AWS 계정과 안전하게 공유하기 위해서는 고객 관리 KMS 키를 사용하는 것이 좋습니다.

따라서 **B**가 AMI를 안전하게 공유하기 위한 가장 적절한 솔루션입니다.

## 질문 #261

한 회사가 프로덕션 파일 서버를 AWS로 마이그레이션하고 있습니다. 

파일 서버에 저장된 모든 데이터는 가용성 영역을 사용할 수 없게 되거나 시스템 유지 관리가 수행될 때에도 액세스 가능해야 합니다. 사용자는 SMB 프로토콜을 통해 파일 서버와 상호 작용할 수 있어야 합니다. 또한 사용자는 Windows ACL을 사용하여 파일 권한을 관리할 수 있어야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 단일 AWS Storage Gateway 파일 게이트웨이를 생성합니다.
B. Windows 파일 서버용 Amazon FSx 다중 AZ 파일 시스템을 만듭니다.
C. 두 개의 가용성 영역에 두 개의 AWS Storage Gateway 파일 게이트웨이를 배포합니다. 파일 게이트웨이 앞에 애플리케이션 로드 밸런서를 구성합니다.
D. 두 개의 Amazon FSx for Windows File Server Single-AZ 2 파일 시스템을 배포합니다. Microsoft Distributed File System Replication(DFSR)을 구성합니다.

회사의 요구 사항을 충족하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### 최적의 선택:
**B. Windows 파일 서버용 Amazon FSx 다중 AZ 파일 시스템을 만듭니다.**

### 이유:
- **가용성 영역의 이중성:** Amazon FSx for Windows File Server를 다중 AZ로 구성하면 데이터가 두 개의 가용성 영역에 걸쳐 복제되어 가용성 영역이 사용할 수 없게 되거나 시스템 유지 관리가 수행되는 경우에도 계속 액세스할 수 있습니다.
- **SMB 프로토콜 지원:** Amazon FSx는 SMB 프로토콜을 지원하여 사용자가 파일 서버와 상호 작용할 수 있게 합니다.
- **Windows ACL 지원:** FSx는 Windows ACL(액세스 제어 목록)을 사용하여 파일 권한을 관리할 수 있도록 해 주므로, 사용자가 Windows 환경에서 익숙한 방식으로 파일 접근 권한을 설정할 수 있습니다.

### 다른 선택지에 대한 설명:
- **A. 단일 AWS Storage Gateway 파일 게이트웨이를 생성합니다.**
  - 파일 게이트웨이는 데이터를 S3에 저장하는 데 유용하지만, 가용성 영역 장애 조치나 SMB 지원에 대한 요구 사항을 충족하지 않습니다.

- **C. 두 개의 가용성 영역에 두 개의 AWS Storage Gateway 파일 게이트웨이를 배포합니다. 파일 게이트웨이 앞에 애플리케이션 로드 밸런서를 구성합니다.**
  - 이 방법은 고가용성을 제공하지 않으며, Storage Gateway는 SMB 및 ACL을 지원하더라도 다중 AZ 구성을 고려할 때 복잡성이 증가합니다.

- **D. 두 개의 Amazon FSx for Windows File Server Single-AZ 2 파일 시스템을 배포합니다. Microsoft Distributed File System Replication(DFSR)을 구성합니다.**
  - 이 구성은 복잡하고 관리가 어렵습니다. 또한, Single-AZ 배포는 장애 조치 시 가용성을 보장하지 않습니다.

따라서 **B**가 가장 비용 효율적이며 요구 사항을 충족하는 솔루션입니다.

## 질문 #262 +++

SysOps 관리자는 Amazon EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨의 읽기 및 쓰기 메트릭을 기반으로 하는 알림을 만들어야 합니다. 

SysOps 관리자는 DiskReadBytes 메트릭과 DiskWriteBytes 메트릭에 대한 Amazon CloudWatch 알람을 만들고 활성화합니다.

동일한 알람 구성으로 EC2 인스턴스에 설치된 사용자 지정 모니터링 도구는 볼륨 메트릭이 임계값을 초과했음을 나타냅니다. 그러나 CloudWatch 알람은 ALARM 상태가 아니었습니다.

어떤 작업을 수행하면 CloudWatch 알람이 올바르게 작동합니까?

A. 원하는 지표를 캡처하기 위해 EC2 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다.
B. 원하는 지표를 캡처하기 위해 EC2 인스턴스에 AWS Systems Manager Agent를 설치하고 구성합니다.
C. EBS 볼륨에 대해 VolumeReadBytes 메트릭과 VolumeWriteBytes 메트릭을 사용하도록 CloudWatch 알람을 재구성합니다.
D. EC2 인스턴스에 대해 VolumeReadBytes 메트릭과 VolumeWriteBytes 메트릭을 사용하도록 CloudWatch 알람을 재구성합니다.

CloudWatch 알람이 올바르게 작동하도록 하려면 다음 단계를 수행해야 합니다:

### 최적의 선택:
**C. EBS 볼륨에 대해 VolumeReadBytes 메트릭과 VolumeWriteBytes 메트릭을 사용하도록 CloudWatch 알람을 재구성합니다.**

### 이유:
- **DiskReadBytes** 및 **DiskWriteBytes** 메트릭은 EC2 인스턴스의 스토리지 사용량을 나타내는 메트릭입니다. 그러나 EBS 볼륨에 대한 모니터링을 하려면 **VolumeReadBytes** 및 **VolumeWriteBytes** 메트릭을 사용해야 합니다.
- 이 두 메트릭은 EBS 볼륨 수준에서 읽기 및 쓰기 작업의 총 바이트 수를 모니터링하므로, CloudWatch 알람이 올바르게 작동하도록 하려면 EBS 볼륨에 대해 이러한 메트릭을 사용해야 합니다.

### 다른 선택지에 대한 설명:
- **A. 원하는 지표를 캡처하기 위해 EC2 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다.**
  - CloudWatch 에이전트를 설치하는 것은 사용자 지정 메트릭을 수집하는 데 유용하지만, 기본적으로 EBS 메트릭은 CloudWatch에 자동으로 제공됩니다. 이 경우 EBS 메트릭을 올바르게 설정하는 것이 우선입니다.

- **B. 원하는 지표를 캡처하기 위해 EC2 인스턴스에 AWS Systems Manager Agent를 설치하고 구성합니다.**
  - AWS Systems Manager Agent는 관리 작업에 유용하지만, 메트릭 수집과는 관련이 없습니다. EBS 메트릭을 수집하려면 CloudWatch 알람 구성을 변경해야 합니다.

- **D. EC2 인스턴스에 대해 VolumeReadBytes 메트릭과 VolumeWriteBytes 메트릭을 사용하도록 CloudWatch 알람을 재구성합니다.**
  - EC2 인스턴스에는 **VolumeReadBytes** 및 **VolumeWriteBytes** 메트릭이 아닌 **DiskReadBytes** 및 **DiskWriteBytes** 메트릭이 있습니다. EBS 볼륨에 대해 메트릭을 구성해야 하므로 이 선택은 올바르지 않습니다.

따라서 **C**가 올바른 선택입니다. EBS 볼륨 메트릭을 사용하도록 알람을 재구성하면 CloudWatch 알람이 제대로 작동할 것입니다.

## 질문 #263 +

한 회사가 최근 서버 인프라를 Amazon EC2 인스턴스로 이전했습니다. 

이 회사는 Amazon CloudWatch 메트릭을 사용하여 인스턴스 메모리 사용률과 사용 가능한 디스크 공간을 추적하려고 합니다.

이러한 요구 사항을 충족하기 위해 SysOps 관리자는 무엇을 해야 합니까?

A. CloudWatch에서 모니터링이 필요한 모든 인스턴스에 대해 AWS Management Console에서 CloudWatch를 구성합니다. AWS는 지정된 인스턴스에 대한 에이전트를 자동으로 설치하고 구성합니다.
B. 모든 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 IAM 역할을 연결합니다.
C. 모든 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 IAM 사용자를 연결합니다.
D. 모든 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 필요한 보안 그룹을 연결합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자는 **B. 모든 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 IAM 역할을 연결합니다.**를 선택해야 합니다.

#### 이유:
1. **CloudWatch 에이전트 설치**: CloudWatch 에이전트를 설치하면 EC2 인스턴스의 메모리 사용률, 사용 가능한 디스크 공간, 프로세스, 사용자 정의 메트릭 등을 모니터링할 수 있습니다. 기본적으로 CloudWatch는 CPU 사용률과 같은 기본 메트릭만 제공하므로, 메모리와 디스크 공간과 같은 추가 메트릭을 추적하기 위해 에이전트 설치가 필요합니다.

2. **IAM 역할 사용**: EC2 인스턴스에 IAM 역할을 연결하면 인스턴스가 AWS 리소스에 안전하게 액세스할 수 있도록 권한을 부여합니다. IAM 사용자를 연결하는 것은 인스턴스와 로그 기록과 같은 AWS 리소스 간의 인증을 다루는 데 적합하지 않으며, 보안 위험을 초래할 수 있습니다.

#### 다른 옵션 분석:
- **A. AWS Management Console에서 CloudWatch를 구성**: AWS는 자동으로 에이전트를 설치하지 않습니다. 따라서 수동으로 설치하고 구성해야 합니다.

- **C. IAM 사용자를 연결**: IAM 사용자를 사용하는 것은 보안상 적절하지 않습니다. EC2 인스턴스는 IAM 역할을 사용하여 AWS 리소스에 안전하게 액세스해야 합니다.

- **D. 필요한 보안 그룹을 연결**: 보안 그룹은 네트워크 접근 제어에 사용되며, CloudWatch에 로그를 쓸 수 있도록 하는 것과는 관련이 없습니다.

결론적으로, **모든 인스턴스에 CloudWatch 에이전트를 설치하고 IAM 역할을 연결하여 메모리 사용률과 디스크 공간을 모니터링하는 방법**이 가장 적합한 솔루션입니다.


## 질문 #264 ++

한 회사가 최근 기본 부팅 볼륨이 있는 Amazon EC2 인스턴스에 MySQL을 배포했습니다. 이 회사는 1.75TB 데이터베이스를 복원하려고 합니다. 

SysOps 관리자는 올바른 Amazon Elastic Block Store(Amazon EBS) 볼륨을 프로비저닝해야 합니다. 이 데이터베이스는 최대 10,000 IOPS의 읽기 성능이 필요하며 크기가 증가하지 않을 것으로 예상됩니다.

어떤 솔루션이 가장 낮은 비용으로 필요한 성능을 제공할까요?


A. 2TB Cold HDD(sc1) 볼륨을 배포합니다.
B. 2TB 처리량 최적화된 HDD(st1) 볼륨을 배포합니다.
C. 2TB General Purpose SSD(gp3) 볼륨을 배포합니다. IOPS를 10,000으로 설정합니다.
D. 2TB Provisioned IOPS SSD(io2) 볼륨을 배포합니다. IOPS를 10,000으로 설정합니다.

주어진 요구 사항을 충족하는 가장 비용 효율적인 Amazon EBS 볼륨 솔루션은 다음과 같습니다:

### 최적의 선택:
**C. 2TB General Purpose SSD(gp3) 볼륨을 배포합니다. IOPS를 10,000으로 설정합니다.**

### 이유:
- **General Purpose SSD (gp3)**는 비용 효율성이 높으면서도 높은 성능을 제공합니다. `gp3` 볼륨은 최대 16,000 IOPS와 1,000 MB/s의 처리량을 지원합니다. 따라서 10,000 IOPS의 요구 사항을 충분히 초과하여 충족할 수 있습니다.
- `gp3` 볼륨은 사용량에 따라 비용이 측정되므로, 높은 IOPS를 프로비저닝하는 것이 `io2`에 비해 더 경제적입니다.

### 다른 선택지에 대한 설명:
- **A. 2TB Cold HDD(sc1) 볼륨을 배포합니다.**
  - `sc1` 볼륨은 저비용 스토리지 옵션이지만, IOPS 성능이 낮고 일반적으로 읽기 및 쓰기 성능이 높지 않기 때문에 10,000 IOPS를 제공하지 않습니다.

- **B. 2TB 처리량 최적화된 HDD(st1) 볼륨을 배포합니다.**
  - `st1` 볼륨은 처리량 최적화된 HDD이지만, IOPS 성능이 낮아서 10,000 IOPS 요구 사항을 충족하지 않습니다. 이 볼륨은 주로 대규모 데이터 집합을 처리하는 데 적합합니다.

- **D. 2TB Provisioned IOPS SSD(io2) 볼륨을 배포합니다. IOPS를 10,000으로 설정합니다.**
  - `io2`는 높은 성능을 제공하지만, 비용이 비쌉니다. 특정 IOPS를 프로비저닝하는 데 높은 비용이 들어가므로, 이 경우 `gp3`가 더 나은 비용 대비 성능을 제공합니다.

따라서 **C**는 필요한 성능을 제공하면서도 가장 낮은 비용을 유지할 수 있는 선택입니다.

## 질문 #265

SysOps 관리자가 애플리케이션의 자동 확장 그룹에 Amazon EC2 인스턴스 플릿을 설정하고 있습니다. 

플릿은 트래픽 버스트를 수용하기 위해 항상 50%의 CPU를 사용할 수 있어야 합니다. 부하는 주 7일, 오전 9시부터 오후 5시 사이에 상당히 증가합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 EC2 인스턴스의 확장을 어떻게 구성해야 합니까?


A. CPU 사용률이 90% 이상일 때 실행되는 대상 추적 확장 정책을 만듭니다.
B. CPU 사용률이 50%를 넘을 때 실행되는 대상 추적 확장 정책을 만듭니다. 09:00에 플릿을 사용할 수 있도록 하는 예약된 확장 정책을 만듭니다. 17:00에 플릿을 확장하는 두 번째 예약된 확장 정책을 만듭니다.
C. 원하는 인스턴스, 최대 인스턴스, 최소 인스턴스를 2로 설정하여 자동 확장 그룹을 2개의 인스턴스로 시작하도록 설정합니다. 09:00에 플릿을 사용할 수 있도록 하는 예약된 확장 정책을 만듭니다.
D. 09:00에 함대를 사용할 수 있도록 하는 예약된 스케일링 정책을 만듭니다. 17:00에 함대를 스케일링하는 두 번째 예약된 스케일링 정책을 만듭니다.

주어진 요구 사항을 충족하기 위해 EC2 인스턴스의 확장을 어떻게 구성해야 하는지에 대한 최적의 선택은 다음과 같습니다:

### 최적의 선택:
**B. CPU 사용률이 50%를 넘을 때 실행되는 대상 추적 확장 정책을 만듭니다. 09:00에 플릿을 사용할 수 있도록 하는 예약된 확장 정책을 만듭니다. 17:00에 플릿을 확장하는 두 번째 예약된 확장 정책을 만듭니다.**

### 이유:
- **대상 추적 확장 정책**: CPU 사용률이 50%를 넘으면 자동으로 인스턴스를 확장하도록 설정하면, 애플리케이션이 항상 요구하는 최소 50%의 CPU 사용량을 유지할 수 있습니다. 이는 트래픽 버스트를 처리하는 데 유용합니다.
- **예약된 확장 정책**: 오전 9시와 오후 5시에 각각 인스턴스를 확장하거나 축소하는 예약된 확장 정책을 추가하면, 비즈니스 시간 동안 증가하는 부하를 효과적으로 관리할 수 있습니다. 이로 인해 필요할 때 인스턴스를 미리 준비하고, 부하가 줄어들 때 인스턴스를 축소하여 비용을 절감할 수 있습니다.

### 다른 선택지에 대한 설명:
- **A. CPU 사용률이 90% 이상일 때 실행되는 대상 추적 확장 정책을 만듭니다.**
  - 이 옵션은 CPU 사용률이 너무 높은 경우에만 확장하므로, 50% CPU 사용률을 항상 유지해야 하는 요구 사항을 충족하지 못합니다.

- **C. 원하는 인스턴스, 최대 인스턴스, 최소 인스턴스를 2로 설정하여 자동 확장 그룹을 2개의 인스턴스로 시작하도록 설정합니다. 09:00에 플릿을 사용할 수 있도록 하는 예약된 확장 정책을 만듭니다.**
  - 이 옵션은 기본 인스턴스 수를 설정하지만, 50% CPU 사용량 요구 사항을 관리할 수 없으며, 부하가 발생하는 동안 추가 인스턴스를 동적으로 생성하지 않습니다.

- **D. 09:00에 함대를 사용할 수 있도록 하는 예약된 스케일링 정책을 만듭니다. 17:00에 함대를 스케일링하는 두 번째 예약된 스케일링 정책을 만듭니다.**
  - 이 옵션은 예약된 정책만 설정하고 CPU 사용률에 대한 동적 확장을 고려하지 않으므로, 애플리케이션의 CPU 사용량이 50%를 초과할 때 자동으로 확장되지 않습니다.

따라서 **B**가 요구 사항을 충족하는 가장 효율적인 방법입니다.

## 질문 #266 ++

한 회사가 모든 기존 Amazon S3 버킷에 대한 서버 액세스 로깅을 켰습니다. 
이 회사는 새 S3 버킷과 기존 S3 버킷의 로깅 설정을 모니터링하는 솔루션을 구현하려고 합니다. 이 솔루션은 로깅이 켜지지 않은 모든 S3 버킷을 수정해야 합니다.

SysOps 관리자는 이러한 요구 사항을 가장 운영적으로 효율적인 방식으로 충족하기 위해 무엇을 해야 합니까?

A. AWS CloudTrail을 사용하여 로깅 정보를 추적합니다. 수정을 위해 AWS Lambda 함수를 시작합니다.
B. s3-bucket-logging-enabled 규칙을 사용하여 AWS Config에서 자동 수정을 구성합니다.
C. AWS Trusted Advisor를 구성하여 로깅 구성을 모니터링하고 필요한 경우 액세스 로깅을 켭니다.
D. Amazon CloudWatch 메트릭을 사용하여 로깅 정보를 추적합니다. 수정을 위해 AWS Lambda 함수를 시작합니다.

주어진 요구 사항을 가장 운영적으로 효율적으로 충족하기 위한 방법은 다음과 같습니다:

### 최적의 선택:
**B. s3-bucket-logging-enabled 규칙을 사용하여 AWS Config에서 자동 수정을 구성합니다.**

### 이유:
- **AWS Config**: AWS Config는 AWS 리소스의 구성 변경을 모니터링하고 기록하는 서비스로, `s3-bucket-logging-enabled` 규칙을 사용하면 S3 버킷의 로깅 설정을 평가하고 자동으로 로깅을 활성화할 수 있습니다.
- **자동 수정**: AWS Config에서 자동 수정을 설정하면 로깅이 비활성화된 버킷을 찾아 자동으로 수정할 수 있어 운영 오버헤드가 크게 줄어듭니다. 이를 통해 모든 버킷에 대해 지속적으로 로깅이 활성화되도록 보장할 수 있습니다.

### 다른 선택지에 대한 설명:
- **A. AWS CloudTrail을 사용하여 로깅 정보를 추적합니다. 수정을 위해 AWS Lambda 함수를 시작합니다.**
  - CloudTrail은 API 호출을 기록하지만, 특정 S3 버킷의 로깅 설정을 자동으로 관리하는 기능이 없습니다. 이 방법은 수동 개입이 필요할 수 있습니다.

- **C. AWS Trusted Advisor를 구성하여 로깅 구성을 모니터링하고 필요한 경우 액세스 로깅을 켭니다.**
  - Trusted Advisor는 일부 AWS 모범 사례에 대한 권장 사항을 제공하지만, 자동으로 로깅을 켜는 기능은 없습니다.

- **D. Amazon CloudWatch 메트릭을 사용하여 로깅 정보를 추적합니다. 수정을 위해 AWS Lambda 함수를 시작합니다.**
  - CloudWatch는 메트릭을 추적할 수 있지만, S3 버킷의 로깅 설정을 자동으로 수정하는 기능은 없습니다. 이 또한 수동 개입이 필요할 수 있습니다.

따라서 **B**가 가장 운영적으로 효율적인 선택입니다.


## 질문 #267

한 회사가 Auto Scaling 그룹에서 Amazon EC2 On-Demand 인스턴스를 실행하고 있습니다. 

인스턴스는 Amazon Simple Queue Service(Amazon SQS) 대기열의 메시지를 처리합니다. Auto Scaling 그룹은 대기열의 메시지 수에 따라 확장되도록 설정되어 있습니다. 메시지를 완전히 처리하는 데 최대 12시간이 걸릴 수 있습니다. SysOps 관리자는 메시지 처리 중에 인스턴스가 중단되지 않도록 해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 메시지 처리 시작 시 처리 스크립트에서 Amazon EC2 Auto Scaling API를 호출하여 Auto Scaling 그룹의 특정 인스턴스에 대한 인스턴스 축소 보호를 활성화합니다. 메시지 처리가 완료된 후 처리 스크립트에서 Amazon EC2 Auto Scaling API를 호출하여 인스턴스 축소 보호를 비활성화합니다.
B. 자동 크기 조정 그룹의 종료 정책을 OldestInstance로 설정합니다.
C. 자동 크기 조정 그룹의 종료 정책을 OldestLaunchConfiguration으로 설정합니다.
D. 메시지 처리 시작 시 처리 스크립트에서 Amazon EC2 Auto Scaling API를 호출하여 Auto Scaling 그룹의 특정 인스턴스에 대한 Launch 및 Terminate 스케일링 프로세스를 일시 중단합니다. 메시지 처리가 완료된 후 처리 스크립트에서 Amazon EC2 Auto Scaling API를 호출하여 스케일링 프로세스를 재개합니다.

메시지를 처리하는 동안 Amazon EC2 인스턴스가 중단되지 않도록 하는 가장 적절한 방법은 다음과 같습니다:

### 최적의 선택:
**A. 메시지 처리 시작 시 처리 스크립트에서 Amazon EC2 Auto Scaling API를 호출하여 Auto Scaling 그룹의 특정 인스턴스에 대한 인스턴스 축소 보호를 활성화합니다. 메시지 처리가 완료된 후 처리 스크립트에서 Amazon EC2 Auto Scaling API를 호출하여 인스턴스 축소 보호를 비활성화합니다.**

### 이유:
- **인스턴스 축소 보호**: 인스턴스 축소 보호를 활성화하면 Auto Scaling 그룹의 인스턴스가 수요에 따라 종료되는 것을 방지할 수 있습니다. 메시지 처리 중에는 해당 인스턴스가 종료되지 않도록 보장하는 것이 중요합니다.
- **유연성**: 메시지 처리 완료 후 축소 보호를 비활성화할 수 있어, Auto Scaling 그룹이 정상적으로 조정되도록 할 수 있습니다. 

### 다른 옵션 분석:
- **B. 자동 크기 조정 그룹의 종료 정책을 OldestInstance로 설정합니다.**
  - 이 정책은 인스턴스가 종료될 때 가장 오래된 인스턴스를 종료하도록 설정하지만, 처리 중인 인스턴스가 종료될 수 있으므로 요구 사항을 충족하지 않습니다.

- **C. 자동 크기 조정 그룹의 종료 정책을 OldestLaunchConfiguration으로 설정합니다.**
  - 이 정책도 OldestInstance와 유사하며, 처리 중인 인스턴스가 종료될 위험이 있습니다. 이 옵션 역시 요구 사항을 충족하지 않습니다.

- **D. 메시지 처리 시작 시 처리 스크립트에서 Amazon EC2 Auto Scaling API를 호출하여 Auto Scaling 그룹의 특정 인스턴스에 대한 Launch 및 Terminate 스케일링 프로세스를 일시 중단합니다. 메시지 처리가 완료된 후 처리 스크립트에서 Amazon EC2 Auto Scaling API를 호출하여 스케일링 프로세스를 재개합니다.**
  - 이 접근법은 인스턴스가 스케일링 프로세스에서 제외되지만, Auto Scaling 그룹의 다른 인스턴스에서 수요에 따라 확장하지 못하게 되어 비효율적일 수 있습니다. 이로 인해 인프라의 유연성이 줄어들 수 있습니다.

### 결론:
따라서 **A** 옵션이 가장 적절하며, 인스턴스 축소 보호를 활성화하여 메시지 처리 중에 인스턴스가 중단되지 않도록 보장하는 방법입니다.


## 질문 #268 +++++

한 회사가 AWS Organizations를 사용하여 AWS에서 계정 집합을 관리합니다. 

회사의 보안 팀은 네이티브 AWS 서비스를 사용하여 Center for Internet Security(CIS) AWS Foundations Benchmark에 따라 모든 AWS 계정을 정기적으로 검사하려고 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?


A. 중앙 보안 계정을 AWS Security Hub 관리자 계정으로 지정합니다. Security Hub 관리자 계정에서 초대장을 보내고 멤버 계정에서 초대장을 수락하는 스크립트를 만듭니다. 새 계정이 생성될 때마다 스크립트를 실행합니다. Security Hub를 구성하여 CIS AWS Foundations Benchmark 스캔을 실행합니다.

B. Amazon Inspector를 사용하여 모든 계정에서 CIS AWS Foundations 벤치마크를 실행합니다.

C. 중앙 보안 계정을 Amazon GuardDuty 관리자 계정으로 지정합니다. GuardDuty 관리자 계정에서 초대장을 보내고 멤버 계정에서 초대장을 수락하는 스크립트를 만듭니다. 새 계정이 생성될 때마다 스크립트를 실행합니다. GuardDuty를 구성하여 CIS AWS Foundations Benchmark 스캔을 실행합니다.

D. AWS Security Hub 관리자 계정을 지정합니다. 조직에서 새 계정을 구성하여 자동으로 멤버 계정이 되도록 합니다. CIS AWS Foundations Benchmark 스캔을 활성화합니다.

AWS Organizations를 사용하여 여러 AWS 계정을 관리하고 있으며, 모든 계정을 정기적으로 검사하여 Center for Internet Security (CIS) AWS Foundations Benchmark에 따라 보안을 유지하려는 경우, 가장 운영 효율적인 방법은 다음과 같습니다:

### 최적의 선택:
**D. AWS Security Hub 관리자 계정을 지정합니다. 조직에서 새 계정을 구성하여 자동으로 멤버 계정이 되도록 합니다. CIS AWS Foundations Benchmark 스캔을 활성화합니다.**

### 이유:
- **자동화 및 운영 효율성**: 이 접근 방식은 새로운 계정을 만들 때마다 수동으로 스크립트를 실행할 필요 없이, 계정이 자동으로 멤버 계정으로 추가되도록 설정할 수 있습니다. 이는 운영 오버헤드를 줄여줍니다.
- **AWS Security Hub**: Security Hub는 여러 AWS 계정에서 보안 데이터를 중앙에서 수집하고 관리할 수 있도록 도와주는 서비스입니다. CIS AWS Foundations Benchmark를 지원하므로, 이 요구 사항에 부합합니다.
- **지속적인 모니터링**: Security Hub를 통해 지속적으로 보안 상태를 모니터링하고 경고를 받을 수 있습니다.

### 다른 옵션 분석:
- **A. 중앙 보안 계정을 AWS Security Hub 관리자 계정으로 지정합니다. Security Hub 관리자 계정에서 초대장을 보내고 멤버 계정에서 초대장을 수락하는 스크립트를 만듭니다. 새 계정이 생성될 때마다 스크립트를 실행합니다. Security Hub를 구성하여 CIS AWS Foundations Benchmark 스캔을 실행합니다.**
  - 이 옵션은 수동 작업이 필요하여 운영 효율성이 떨어집니다. 각 계정마다 스크립트를 실행해야 하므로 관리 오버헤드가 증가합니다.

- **B. Amazon Inspector를 사용하여 모든 계정에서 CIS AWS Foundations 벤치마크를 실행합니다.**
  - Amazon Inspector는 주로 EC2 인스턴스에 대한 취약성 평가를 수행하는 서비스로, CIS 벤치마크 스캔을 지원하지 않습니다. 따라서 이 옵션은 부적절합니다.

- **C. 중앙 보안 계정을 Amazon GuardDuty 관리자 계정으로 지정합니다. GuardDuty 관리자 계정에서 초대장을 보내고 멤버 계정에서 초대장을 수락하는 스크립트를 만듭니다. 새 계정이 생성될 때마다 스크립트를 실행합니다. GuardDuty를 구성하여 CIS AWS Foundations Benchmark 스캔을 실행합니다.**
  - GuardDuty는 네트워크 이상 징후를 탐지하는 서비스이지, CIS 벤치마크에 대한 직접적인 스캔 기능은 없습니다. 따라서 이 옵션도 적절하지 않습니다.

### 결론:
따라서 **D** 옵션이 가장 효율적이며, AWS Security Hub를 통해 모든 AWS 계정을 정기적으로 검사하는 데 적합한 방법입니다.


## 질문 #269 +++

한 회사가 현재 단일 가용성 영역의 VPC 내에서 인프라를 운영하고 있습니다. 

VPC는 ​​가상 사설 게이트웨이에 연결된 AWS 사이트 간 VPN 연결을 통해 회사의 온프레미스 데이터 센터에 연결됩니다. 온프레미스 경로 테이블은 모든 VPC 네트워크를 VPN 연결로 라우팅합니다. 두 환경 간의 통신이 올바르게 작동합니다. SysOps 관리자가 새 가용성 영역 내에 새 VPC 서브넷을 만들고 서브넷 내에 새 리소스를 배포했습니다. 그러나 새 리소스와 온프레미스 환경 간에 통신을 설정할 수 없습니다.

SysOps 관리자는 문제를 해결하기 위해 어떤 단계를 거쳐야 합니까?
A. 온프레미스 트래픽을 가상 사설 게이트웨이로 전송하는 새 서브넷의 경로 테이블에 경로를 추가합니다.
B. AWS 지원팀에 티켓을 생성하여 사이트 간 VPN 경로 구성에 가용성 영역을 추가해 달라고 요청하세요.
C. 새로운 가용성 영역에 연결된 가상 사설 게이트웨이와 온프레미스 데이터 센터 간에 새로운 사이트 간 VPN 연결을 설정합니다.
D. 사이트 간 VPN 연결을 AWS Direct Connect 연결로 바꿉니다.

새 가용성 영역 내에 새 VPC 서브넷을 만들고 그 서브넷 내에 새 리소스를 배포했지만, 새 리소스와 온프레미스 환경 간에 통신이 이루어지지 않는 문제를 해결하기 위해 SysOps 관리자가 따라야 할 단계는 다음과 같습니다:

### 최적의 선택:
**A. 온프레미스 트래픽을 가상 사설 게이트웨이로 전송하는 새 서브넷의 경로 테이블에 경로를 추가합니다.**

### 이유:
- 새 VPC 서브넷의 경로 테이블에 온프레미스 데이터 센터와의 통신을 위한 올바른 경로가 설정되어 있어야 합니다. 현재 경로 테이블에 이 경로가 없기 때문에, 새 서브넷 내의 리소스가 온프레미스 환경으로 트래픽을 전달할 수 없습니다.
- 경로 테이블에 온프레미스 환경으로의 경로를 추가함으로써, 새 서브넷의 리소스가 VPN을 통해 온프레미스 환경과 통신할 수 있게 됩니다.

### 다른 옵션 분석:
- **B. AWS 지원팀에 티켓을 생성하여 사이트 간 VPN 경로 구성에 가용성 영역을 추가해 달라고 요청하세요.**
  - 경로 구성은 고객이 관리하는 것이므로, AWS 지원팀에 요청할 필요는 없습니다. 경로 테이블을 수동으로 구성하는 것이 필요합니다.

- **C. 새로운 가용성 영역에 연결된 가상 사설 게이트웨이와 온프레미스 데이터 센터 간에 새로운 사이트 간 VPN 연결을 설정합니다.**
  - 새로운 VPN 연결을 설정할 필요는 없습니다. 이미 기존의 가상 사설 게이트웨이를 사용하여 연결되어 있으며, 올바른 경로를 추가하면 문제가 해결됩니다.

- **D. 사이트 간 VPN 연결을 AWS Direct Connect 연결로 바꿉니다.**
  - Direct Connect는 대체 연결 방법일 수 있지만, 현재 문제를 해결하는 데에는 필요하지 않습니다. VPN이 이미 설정되어 있으므로, 경로 문제를 해결하는 것이 우선입니다.

### 결론:
따라서 **A** 옵션을 선택하여 새 서브넷의 경로 테이블에 온프레미스 트래픽을 가상 사설 게이트웨이로 전송하는 경로를 추가해야 합니다. 이를 통해 새 리소스와 온프레미스 환경 간의 통신이 가능해집니다.

## 질문 #270 ++++

SysOps 관리자는 Ubuntu를 실행하는 수백 개의 Amazon EC2 인스턴스에 배포된 사용자 지정 애플리케이션에서 로그 파일의 내용을 수집해야 합니다. 

로그 파일은 Amazon CloudWatch Logs에 저장해야 합니다.

SysOps 관리자는 운영 오버헤드가 가장 낮은 애플리케이션 로그 파일을 어떻게 수집해야 합니까?


A. 각 EC2 인스턴스에서 syslogd 서비스를 구성하여 애플리케이션 로그 파일을 수집하여 CloudWatch Logs로 전송합니다.
B. 각 EC2 인스턴스에서 Amazon Linux 패키지 관리자를 사용하여 CloudWatch 에이전트를 설치합니다. 각 에이전트를 구성하여 애플리케이션 로그 파일을 수집합니다.
C. AWS Systems Manager를 사용하여 각 EC2 인스턴스에 CloudWatch 에이전트를 설치합니다. CloudWatch 구성 마법사를 사용하여 각 인스턴스에 에이전트 구성을 만듭니다. 각 에이전트를 구성하여 애플리케이션 로그 파일을 수집합니다.
D. AWS Systems Manager Parameter Store에 CloudWatch 에이전트 구성을 저장합니다. Systems Manager를 사용하여 각 EC2 인스턴스에 CloudWatch 에이전트를 설치합니다. 각 에이전트를 구성하여 애플리케이션 로그 파일을 수집합니다.

운영 오버헤드를 최소화하면서 Ubuntu에서 실행되는 여러 Amazon EC2 인스턴스의 애플리케이션 로그 파일을 Amazon CloudWatch Logs로 수집하는 가장 효율적인 방법은 다음과 같습니다:

### 최적의 선택:
**C. AWS Systems Manager를 사용하여 각 EC2 인스턴스에 CloudWatch 에이전트를 설치합니다. CloudWatch 구성 마법사를 사용하여 각 인스턴스에 에이전트 구성을 만듭니다. 각 에이전트를 구성하여 애플리케이션 로그 파일을 수집합니다.**

### 이유:
- **AWS Systems Manager**를 사용하면 여러 인스턴스에 에이전트를 설치하고 구성하는 프로세스를 중앙 집중화할 수 있습니다. 이를 통해 수백 개의 인스턴스에 대해 일관된 구성을 쉽게 적용할 수 있습니다.
- **CloudWatch 구성 마법사**를 사용하면 에이전트 구성을 직관적으로 만들 수 있으며, 이를 통해 로그 파일 수집을 쉽게 관리할 수 있습니다.
- 이 접근 방식은 운영 오버헤드를 줄이고, 필요할 경우 구성 변경을 쉽게 적용할 수 있는 유연성을 제공합니다.

### 다른 옵션 분석:
- **A. 각 EC2 인스턴스에서 syslogd 서비스를 구성하여 애플리케이션 로그 파일을 수집하여 CloudWatch Logs로 전송합니다.**
  - syslogd를 사용하는 것은 가능하지만, 로그 파일을 CloudWatch Logs에 통합하는 추가 설정과 관리가 필요할 수 있어 운영 오버헤드가 증가합니다.

- **B. 각 EC2 인스턴스에서 Amazon Linux 패키지 관리자를 사용하여 CloudWatch 에이전트를 설치합니다. 각 에이전트를 구성하여 애플리케이션 로그 파일을 수집합니다.**
  - 이 방법은 가능하지만, 수백 개의 인스턴스에 대해 개별적으로 설치 및 구성을 진행해야 하므로 관리 오버헤드가 더 클 수 있습니다.

- **D. AWS Systems Manager Parameter Store에 CloudWatch 에이전트 구성을 저장합니다. Systems Manager를 사용하여 각 EC2 인스턴스에 CloudWatch 에이전트를 설치합니다. 각 에이전트를 구성하여 애플리케이션 로그 파일을 수집합니다.**
  - 이 옵션은 Parameter Store를 사용하여 구성 정보를 저장하는 방법이지만, C 옵션이 더 간편하고 직관적이며, 설치 및 구성을 위한 추가적인 작업을 필요로 하지 않습니다.

### 결론:
따라서 **C** 옵션이 운영 오버헤드를 최소화하면서 로그 파일을 수집하는 가장 효율적인 방법입니다.


## 질문 #271 +++

SysOps 관리자는 AWS에서 애플리케이션에 대한 재해 복구(DR) 계획을 설계해야 합니다. 

애플리케이션은 애플리케이션 로드 밸런서(ALB) 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 자동 확장 그룹에 있습니다. 애플리케이션은 Amazon Aurora PostgreSQL 데이터베이스를 사용합니다. 복구 시간 목표(RTO)와 복구 지점 목표(RPO)는 각각 15분입니다.

SysOps 관리자는 이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)


A. DR 지역으로 내보내도록 Aurora 백업을 구성합니다.
B. Aurora 글로벌 데이터베이스 옵션을 사용하여 DR 지역에 데이터를 복제하도록 Aurora 클러스터를 구성합니다.
C. ALB와 자동 확장 그룹으로 DR 지역을 구성합니다. 기본 지역과 동일한 구성을 사용합니다.
D. DR Region을 ALB와 Auto Scaling 그룹으로 구성합니다. Auto Scaling 그룹의 최소 용량, 최대 용량, 원하는 용량을 1로 설정합니다.
E. 장애 조치 활동 중에 AWS CloudFormation을 사용하여 새 ALB와 새 자동 확장 그룹을 수동으로 시작합니다.

RTO와 RPO를 각각 15분으로 설정한 재해 복구(DR) 계획을 설계할 때 가장 비용 효율적인 솔루션을 선택하는 것이 중요합니다. 주어진 요구 사항을 충족하기 위해 선택할 수 있는 단계 조합은 다음과 같습니다:

### 선택할 단계:
1. **B. Aurora 글로벌 데이터베이스 옵션을 사용하여 DR 지역에 데이터를 복제하도록 Aurora 클러스터를 구성합니다.**
   - **이유:** Aurora 글로벌 데이터베이스는 DR 환경에 대한 데이터 복제를 지원하며, 데이터가 거의 실시간으로 복제됩니다. 이로 인해 RPO를 충족할 수 있으며, 데이터베이스 장애 조치 시 빠른 복구를 보장합니다.

2. **C. ALB와 자동 확장 그룹으로 DR 지역을 구성합니다. 기본 지역과 동일한 구성을 사용합니다.**
   - **이유:** DR 지역에서 애플리케이션 로드 밸런서(ALB)와 자동 확장 그룹을 동일한 구성으로 설정하면, 장애 조치 시 애플리케이션을 즉시 사용할 수 있습니다. 이 구성이 RTO를 충족하는 데 필요한 자동화된 트래픽 분산과 인스턴스 관리를 제공합니다.

### 다른 옵션 분석:
- **A. DR 지역으로 내보내도록 Aurora 백업을 구성합니다.**
   - 이 옵션은 데이터를 백업하지만, RPO 15분을 충족하지 못할 수 있습니다. 백업은 일반적으로 리커버리 지점이 비교적 길어지므로 즉각적인 DR 솔루션으로는 적합하지 않습니다.

- **D. DR Region을 ALB와 Auto Scaling 그룹으로 구성합니다. Auto Scaling 그룹의 최소 용량, 최대 용량, 원하는 용량을 1로 설정합니다.**
   - 이 옵션은 자동 확장 그룹이 항상 인스턴스를 유지하도록 설정하는 것입니다. 그러나 DR 환경에서 즉각적으로 트래픽을 처리할 수 있는 용량이 충분하지 않아 RTO를 충족하기 어려울 수 있습니다.

- **E. 장애 조치 활동 중에 AWS CloudFormation을 사용하여 새 ALB와 새 자동 확장 그룹을 수동으로 시작합니다.**
   - 이 접근 방식은 수동 프로세스를 포함하며, RTO와 RPO 요구 사항을 충족하는 데 시간 소모적입니다. 자동화가 부족해 신속한 복구를 어렵게 만듭니다.

### 결론:
따라서 **B**와 **C**를 선택하는 것이 이러한 요구 사항을 가장 비용 효율적으로 충족하는 방법입니다.


## 질문 #272

SysOps 관리자가 Amazon EC2에서 실행되는 간단한 공개 웹사이트를 만들고 있습니다. 

SysOps 관리자는 기존 퍼블릭 서브넷에 EC2 인스턴스를 만들고 인스턴스에 Elastic IP 주소를 할당했습니다. 그런 다음 SysOps 관리자는 인스턴스에 새 보안 그룹을 만들어 적용하여 0.0.0.0/0에서 들어오는 HTTP 트래픽을 허용했습니다. 마지막으로 SysOps 관리자는 새 네트워크 ACL을 만들어 서브넷에 적용하여 0.0.0.0/0에서 들어오는 HTTP 트래픽을 허용했습니다. 하지만 인터넷에서 웹사이트에 접근할 수 없습니다.

이 문제의 원인은 무엇입니까?

A. SysOps 관리자가 새 네트워크 ACL에서 임시 포트 반환 트래픽을 허용하는 아웃바운드 규칙을 만들지 않았습니다.
B. SysOps 관리자가 보안 그룹에 포트 80에서 HTTP 트래픽을 허용하는 아웃바운드 규칙을 만들지 않았습니다.
C. EC2 인스턴스에 할당된 Elastic IP 주소가 변경되었습니다.
D. 포트 80에서 들어오는 HTTP 트래픽을 거부하는 규칙을 포함하는 서브넷과 연관된 추가 네트워크 ACL이 있습니다.

문제의 원인은 다음과 같습니다:

**A. SysOps 관리자가 새 네트워크 ACL에서 임시 포트 반환 트래픽을 허용하는 아웃바운드 규칙을 만들지 않았습니다.**

### 설명:
- **네트워크 ACL 규칙:** AWS의 네트워크 ACL(Access Control List)은 인바운드 및 아웃바운드 트래픽에 대한 규칙을 설정할 수 있습니다. 사용자가 웹사이트에 접속하면 HTTP 요청이 인바운드로 들어오고, 이에 대한 응답은 아웃바운드로 나갑니다. 따라서 인바운드 규칙을 설정하는 것뿐만 아니라 아웃바운드 규칙도 설정해야 합니다.
  
- **HTTP 트래픽 흐름:** 사용자가 웹사이트에 접근할 때, HTTP 요청은 포트 80에서 들어오고(인바운드), 그에 대한 응답은 임시 포트(예: 1024 이상)에서 나갑니다. 만약 아웃바운드 규칙에서 이러한 임시 포트의 반환 트래픽을 허용하지 않으면, 응답이 차단되어 사용자는 웹사이트에 접근할 수 없습니다.

### 다른 옵션 분석:
- **B.** 보안 그룹의 아웃바운드 규칙에 대한 언급은 있지만, 기본적으로 보안 그룹은 모든 아웃바운드 트래픽을 허용하므로 보안 그룹에서 포트 80에 대한 아웃바운드 규칙이 필요하지 않습니다.
  
- **C.** Elastic IP 주소가 변경되었다면, 사용자가 연결할 수 없을 것입니다. 그러나 문제에서 언급한 내용에 대한 정보가 없기 때문에 이 경우는 고려하지 않아도 됩니다.
  
- **D.** 추가적인 네트워크 ACL이 있는 경우, 이는 가능성이 있지만, 주어진 문제에서 주된 문제는 아웃바운드 트래픽 허용 여부이므로 이 옵션은 불필요하게 복잡한 요소입니다.

따라서, **A**가 문제의 주요 원인입니다.


## 질문 #273 +++

한 회사에 Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용하는 애플리케이션이 있습니다. 

애플리케이션 로직 오류와 관련된 최근 사고로 여러 파일이 손상되었습니다. 이 회사는 EFS 파일 시스템을 백업하고 복구하는 기능을 개선하고자 합니다. 이 회사는 개별 파일을 빠르게 복구할 수 있어야 합니다.

이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. Amazon Data Lifecycle Manager(Amazon DLM)를 구성하여 데이터 사본을 Amazon S3 Glacier 볼트에 보관합니다. S3 Glacier 검색 요청을 사용하여 개별 파일을 검색합니다.
B. 다른 AWS 리전에 두 번째 EFS 파일 시스템을 만듭니다. AWS DataSync를 구성하여 데이터를 백업 파일 시스템에 복사합니다. 백업 EFS 파일 시스템에서 복사하여 파일을 복구합니다.
C. Amazon EFS에서 AWS Backup을 활성화하여 파일 시스템을 Amazon S3 Glacier 볼트에 백업합니다. S3 Glacier 검색 요청을 사용하여 개별 파일을 검색합니다.
D. Amazon EFS에서 AWS Backup을 활성화하여 파일 시스템을 백업 볼트에 백업합니다. 부분 복원 작업을 사용하여 개별 파일을 검색합니다.

회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에서 손상된 여러 파일을 빠르게 복구할 수 있도록 하려면, 가장 비용 효율적이면서도 요구 사항을 충족하는 솔루션은 다음과 같습니다:

**D. Amazon EFS에서 AWS Backup을 활성화하여 파일 시스템을 백업 볼트에 백업합니다. 부분 복원 작업을 사용하여 개별 파일을 검색합니다.**

### 이유:
- **AWS Backup 사용:** AWS Backup을 사용하면 EFS 파일 시스템을 효율적으로 백업할 수 있으며, 복원 시에 파일 시스템의 특정 파일이나 디렉터리만 선택적으로 복원할 수 있는 기능을 제공합니다.
- **부분 복원:** 이 방법을 사용하면 필요할 때 손상된 개별 파일만 선택적으로 복원할 수 있어 빠른 복구가 가능합니다. 

### 다른 옵션 분석:
- **A.** Amazon DLM을 사용하여 S3 Glacier로 데이터 사본을 보관하는 것은 비용은 절감할 수 있지만, Glacier에서 파일을 복구하는 데 시간이 걸리고 복원 작업이 복잡합니다. 이는 개별 파일을 빠르게 복구해야 하는 요구 사항에 적합하지 않습니다.
  
- **B.** 다른 AWS 리전에 두 번째 EFS 파일 시스템을 생성하고 AWS DataSync를 사용하여 데이터를 복사하는 것은 추가 비용과 복잡성을 초래합니다. 또한, 복구 프로세스가 비효율적일 수 있습니다.
  
- **C.** AWS Backup을 사용하여 S3 Glacier에 백업하는 것도 시간이 걸리는 복구 과정이 필요합니다. S3 Glacier에서 개별 파일을 복원하는 데 필요한 시간과 비용이 더 발생할 수 있습니다.

따라서, **D**가 요구 사항을 가장 효율적으로 충족하는 선택입니다.

## 질문 #274  ++

한 회사가 write-once, ready-many(WORM) 드라이브를 거버넌스 모드에서 S3 Object Lock이 구성된 Amazon S3 버킷으로 마이그레이션합니다. 

마이그레이션하는 동안 회사는 불필요한 데이터를 S3 버킷에 복사합니다.

SysOps 관리자가 AWS CLI를 사용하여 S3 버킷에서 불필요한 데이터를 삭제하려고 시도합니다. 그러나 SysOps 관리자는 오류를 수신합니다. SysOps 관리자는 불필요한 데이터를 성공적으로 삭제하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. 보관 기한을 늘립니다.
B. s3:BypassLegalRetention 권한이 있는 역할을 가정합니다.
C. s3:BypassGovernanceRetention 권한이 있는 역할을 가정합니다.
D. 삭제 명령을 실행할 때 요청에 x-amz-bypass-governance-retention:true 헤더를 포함합니다.
E. 삭제 명령을 실행할 때 요청에 x-amz-bypass-legal-retention:true 헤더를 포함합니다.

SysOps 관리자가 WORM(Write-Once, Read-Many) 드라이브를 거버넌스 모드에서 S3 Object Lock이 구성된 Amazon S3 버킷에서 불필요한 데이터를 삭제하기 위해 취해야 할 단계는 다음과 같습니다:

**C. s3:BypassGovernanceRetention 권한이 있는 역할을 가정합니다.**  
**D. 삭제 명령을 실행할 때 요청에 x-amz-bypass-governance-retention:true 헤더를 포함합니다.**

### 이유:
- **C.** `s3:BypassGovernanceRetention` 권한을 가진 역할을 가정하면, 관리자는 거버넌스 모드에서 설정된 데이터 보존 정책을 우회하여 해당 데이터를 삭제할 수 있습니다. 이 권한은 거버넌스 모드에서 Object Lock이 활성화된 경우에 필요합니다.

- **D.** 삭제 명령을 실행할 때 `x-amz-bypass-governance-retention:true` 헤더를 포함하면, 삭제 요청이 거버넌스 보존 정책을 우회하도록 설정됩니다. 이를 통해 불필요한 데이터를 삭제할 수 있습니다.

### 선택하지 않은 옵션들:
- **A.** 보관 기한을 늘리는 것은 불필요한 데이터를 삭제하는 데 도움이 되지 않습니다. 이는 데이터 보존 기간을 연장하는 조치입니다.
- **B.** `s3:BypassLegalRetention` 권한은 법적 보존 모드와 관련이 있으며, 현재의 요구 사항에 직접적으로 필요하지 않습니다.
- **E.** `x-amz-bypass-legal-retention:true` 헤더는 법적 보존을 우회하기 위해 사용되며, 이 경우에는 필요하지 않습니다.

따라서 SysOps 관리자는 **C**와 **D**를 선택해야 합니다.


## 질문 #275 +

회사에서는 포트 3389에서 인터넷에 열려 있는 보안 그룹 목록을 확인해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. Amazon GuardDuty를 구성하여 보안 그룹을 스캔하고 포트 3389에서 제한 없는 액세스를 보고합니다.
B. 포트 3389에서 제한 없는 액세스를 허용하는 보안 그룹을 식별하기 위해 서비스 제어 정책(SCP)을 구성합니다.
C. AWS Identity and Access Management Access Analyzer를 사용하여 포트 3389에서 제한 없는 액세스 권한이 있는 인스턴스를 찾습니다.
D. AWS Trusted Advisor를 사용하여 포트 3389에서 무제한 액세스를 허용하는 보안 그룹을 찾으세요.

회사가 포트 3389에서 인터넷에 열려 있는 보안 그룹 목록을 확인하기 위해 SysOps 관리자가 해야 할 작업은 다음과 같습니다:

**D. AWS Trusted Advisor를 사용하여 포트 3389에서 무제한 액세스를 허용하는 보안 그룹을 찾으세요.**

### 이유:
- **AWS Trusted Advisor**는 보안 권장 사항을 제공하며, 특히 보안 그룹 설정을 포함하여 특정 포트에 대해 제한 없는 액세스가 있는 보안 그룹을 찾는 데 유용합니다. Trusted Advisor의 보안 검사 기능을 통해 포트 3389(RDP)에 대해 인터넷에서 접근 가능한 보안 그룹을 쉽게 식별할 수 있습니다.

### 다른 옵션들:
- **A**: Amazon GuardDuty는 보안 위협을 탐지하는 서비스이지 보안 그룹 구성을 스캔하여 특정 포트에 대한 액세스를 보고하지 않습니다.
- **B**: 서비스 제어 정책(SCP)은 조직의 계정에 대한 액세스를 관리하는 데 사용되며, 특정 보안 그룹을 식별하는 데는 적합하지 않습니다.
- **C**: AWS Identity and Access Management Access Analyzer는 IAM 정책을 분석하여 권한이 있는 리소스를 확인하는 데 사용되며, 보안 그룹의 포트 액세스를 찾는 데는 사용되지 않습니다.

따라서 **D**가 가장 적절한 답변입니다.

## 질문 #276 ++++

회사 웹사이트에는 AWS의 웹 계층과 데이터베이스 계층이 있습니다.

 웹 계층은 두 개의 가용 영역에 걸쳐 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스로 구성됩니다. 데이터베이스 계층은 Amazon RDS for MySQL Multi-AZ DB 인스턴스에서 실행됩니다. 데이터베이스 서브넷 네트워크 ACL은 데이터베이스에 액세스해야 하는 웹 서브넷으로만 제한됩니다. 웹 서브넷은 기본 규칙이 있는 기본 네트워크 ACL을 사용합니다.

회사의 운영 팀은 Auto Scaling 그룹 구성에 세 번째 서브넷을 추가했습니다. Auto Scaling 이벤트가 발생한 후 일부 사용자는 간헐적으로 오류 메시지를 받는다고 보고합니다. 오류 메시지는 서버가 데이터베이스에 연결할 수 없다는 것을 나타냅니다. 운영 팀은 경로 테이블이 올바르고 모든 보안 그룹에서 필요한 포트가 열려 있는지 확인했습니다.

SysOps 관리자는 웹 서버가 DB 인스턴스와 통신할 수 있도록 어떤 작업 조합을 취해야 합니까? (두 가지를 선택하십시오.)


A. 기본 ACL에서 임시 포트 범위와 소스를 데이터베이스 서브넷으로 지정하여 TCP 유형의 인바운드 허용 규칙을 만듭니다.
B. 기본 ACL에서 MySQL/Aurora(3306) 유형의 아웃바운드 허용 규칙을 만듭니다. 대상을 데이터베이스 서브넷으로 지정합니다.
C. 데이터베이스 서브넷의 네트워크 ACL에서 MySQL/Aurora(3306) 유형의 인바운드 허용 규칙을 만듭니다. 소스를 세 번째 웹 서브넷으로 지정합니다.
D. 데이터베이스 서브넷의 네트워크 ACL에서 임시 포트 범위와 대상을 세 번째 웹 서브넷으로 지정하는 TCP 유형의 아웃바운드 허용 규칙을 만듭니다.
E. 데이터베이스 서브넷의 네트워크 ACL에서 MySQL/Aurora(3306) 유형의 아웃바운드 허용 규칙을 만듭니다. 대상을 세 번째 웹 서브넷으로 지정합니다.


SysOps 관리자가 웹 서버가 DB 인스턴스와 통신할 수 있도록 해야 하는 작업 조합은 다음과 같습니다:

**C.** 데이터베이스 서브넷의 네트워크 ACL에서 MySQL/Aurora(3306) 유형의 인바운드 허용 규칙을 만듭니다. 소스를 세 번째 웹 서브넷으로 지정합니다.

**D.** 데이터베이스 서브넷의 네트워크 ACL에서 임시 포트 범위와 대상을 세 번째 웹 서브넷으로 지정하는 TCP 유형의 아웃바운드 허용 규칙을 만듭니다.

### 이유:
- **C**: 웹 서버가 DB 인스턴스에 연결할 수 있도록 하기 위해서는 데이터베이스 서브넷의 네트워크 ACL에서 인바운드 규칙을 설정해야 합니다. 이를 통해 세 번째 웹 서브넷에서 오는 MySQL 트래픽(포트 3306)이 데이터베이스에 도달할 수 있습니다.

- **D**: DB 인스턴스가 세 번째 웹 서브넷으로 응답할 수 있도록 하려면 아웃바운드 규칙을 설정해야 합니다. TCP 유형의 아웃바운드 규칙을 추가하여 데이터베이스 서브넷에서 세 번째 웹 서브넷으로의 트래픽을 허용해야 합니다. 임시 포트 범위는 EC2 인스턴스가 데이터베이스에 연결하는 동안 사용할 수 있는 포트를 정의합니다.

### 다른 옵션들:
- **A**: 기본 ACL에서 임시 포트 범위를 설정하는 것은 적절하지 않습니다. 기본 ACL은 전체 서브넷에 적용되며, 특정 서브넷에 대한 제어가 필요합니다.
- **B**: 기본 ACL에서 아웃바운드 규칙을 추가하는 것은 기본적으로 적용되는 ACL에서 문제가 될 수 있습니다. 특정 서브넷에 대한 제어가 필요합니다.
- **E**: 데이터베이스 서브넷의 아웃바운드 규칙을 추가하는 것은 좋지만, 대상을 세 번째 웹 서브넷으로 설정하는 것은 잘못된 방식입니다. DB 인스턴스가 웹 서버로 응답할 수 있도록 하려면 올바른 인바운드 및 아웃바운드 규칙이 필요합니다.

따라서 **C**와 **D**가 정답입니다.


## 질문 #277 +

SysOps 관리자는 여러 개의 보안 웹사이트를 단일 서버로 통합할 수 있었고, 각 사이트는 다른 포트에서 실행되고 있습니다. 이제 관리자는 두 번째 가용성 영역에서 복제 서버를 시작하고 둘 다 고가용성을 위해 로드 밸런서 뒤에 두려고 합니다.

사이트 중 하나의 인증서를 로드 밸런서에 배포하는 데 필요한 명령줄은 무엇입니까?


A aws kms modify-listener 
  –-load-balancer-name my-load-balancer
  -–certificates CertificateArn=arn:aws:iam::123456789012:server-certifiate/my-new-server-cert
B aws elb set-load-balancer-listener-ssl-certificate 
  --load-balancer-name my-load-balancer 
  –-load-balancer-port 443 
  –-ssl-certificate-id arn:aws:iam::123456789012:server-certificate/new-server-cert
C aws ec2 put-ssl-certificate 
  –-load-balancer-name my-load-balancer 
  –-load-balancer-port 443 
  –-ssl-certificate-id arn:aws:iam::123456789012:server-certificate/new-server-cert
D aws acm put-ssl-certificate 
  –-load-balancer-name my-load-balancer 
  –-load-balancer-port 443 
  –-ssl-certificate-id arn:aws:iam::123456789012:server-certificate/new-server-cert


사이트 중 하나의 인증서를 로드 밸런서에 배포하는 데 필요한 명령줄은 **B.**입니다:
이유:
AWS ELB (Elastic Load Balancing): set-load-balancer-listener-ssl-certificate 명령은 Classic Load Balancer에서 SSL 인증서를 설정하는 데 사용됩니다. 이 명령은 특정 로드 밸런서와 포트에 대한 SSL 인증서를 구성하는 데 필요합니다.
--ssl-certificate-id 매개변수는 인증서의 ARN(Amazon Resource Name)을 지정하여 SSL 연결을 설정합니다.

## 질문 #278 +++

SysOps 관리자가 Auto Scaling 그룹에 있는 Amazon EC2 인스턴스에 애플리케이션을 배포할 준비를 하고 있습니다. 

애플리케이션에는 종속성을 설치해야 합니다. 애플리케이션 업데이트는 매주 발행됩니다.

SysOps 관리자는 정기적으로 애플리케이션 업데이트를 통합하는 솔루션을 구현해야 합니다. 솔루션은 또한 Amazon Machine Image(AMI) 생성 중에 취약성 검사를 수행해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. Packer를 사용하는 스크립트를 만듭니다. 스크립트를 실행하기 위한 cron 작업을 예약합니다.
B. EC2 인스턴스에 애플리케이션과 종속성을 설치합니다. EC2 인스턴스의 AMI를 만듭니다.
C. 사용자 정의 레시피와 함께 EC2 Image Builder를 사용하여 애플리케이션과 종속성을 설치합니다.
D. Amazon EventBridge 예약된 규칙을 사용하여 EC2 CreateImage API 작업을 호출합니다.


이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 **C. 사용자 정의 레시피와 함께 EC2 Image Builder를 사용하여 애플리케이션과 종속성을 설치합니다**입니다.

### 이유:
- **EC2 Image Builder**: EC2 Image Builder는 AMI를 자동으로 생성하고, 업데이트하고, 검증할 수 있는 관리형 서비스입니다. 이 서비스는 자동화된 방식으로 애플리케이션과 그 종속성을 설치하는 데 필요한 사용자 정의 레시피를 지원하며, 이미지 생성 중에 취약성 검사도 수행할 수 있습니다. 이는 반복적이고 수동 작업을 최소화하여 운영 효율성을 높입니다.

### 다른 옵션들:
- **A. Packer를 사용하는 스크립트를 만듭니다. 스크립트를 실행하기 위한 cron 작업을 예약**: Packer는 이미지 생성을 지원하지만, 이 경우에는 취약성 검사와 업데이트 통합을 수동으로 처리해야 할 수 있습니다. 운영 효율성이 떨어질 수 있습니다.
- **B. EC2 인스턴스에 애플리케이션과 종속성을 설치합니다. EC2 인스턴스의 AMI를 만듭니다**: 이 방법은 수동적이며 애플리케이션 업데이트를 자동으로 통합하는데 적합하지 않습니다. 매주 업데이트를 수동으로 관리해야 할 수 있습니다.
- **D. Amazon EventBridge 예약된 규칙을 사용하여 EC2 CreateImage API 작업을 호출**: EventBridge를 사용하여 AMI 생성을 자동화할 수는 있지만, 애플리케이션의 종속성을 관리하거나 취약성 검사를 수행하는 기능이 없습니다.

결론적으로 **C. 사용자 정의 레시피와 함께 EC2 Image Builder를 사용하여 애플리케이션과 종속성을 설치**하는 것이 가장 효율적이고 자동화된 솔루션입니다.


## 질문 #279 ++++

AWS CloudFormation 템플릿은 Amazon RDS 인스턴스를 생성합니다. 

이 템플릿은 필요에 따라 개발 환경을 구축한 다음 환경이 더 이상 필요하지 않으면 스택을 삭제하는 데 사용됩니다. RDS에 저장된 데이터는 CloudFormation 스택이 삭제된 후에도 추가 사용을 위해 보관해야 합니다.

이를 안정적이고 효율적인 방식으로 어떻게 달성할 수 있을까요?

A. 5분마다 RDS 인스턴스를 계속 백업하는 스크립트를 작성합니다.
B. RDS 인스턴스의 스냅샷을 찍기 위해 AWS Lambda 함수를 만들고, 스택을 삭제하기 전에 함수를 수동으로 호출합니다.
C. RDS 인스턴스의 CloudFormation 템플릿 정의에서 삭제 정책을 스냅샷으로 설합니다.
D. RDS 인스턴스의 백업을 수행하기 위해 새 CloudFormation 템플릿을 만들고, 스택을 삭제하기 전에 이 템플릿을 실행합니다.

RDS에 저장된 데이터를 CloudFormation 스택이 삭제된 후에도 추가 사용을 위해 보관하기 위해 **C. RDS 인스턴스의 CloudFormation 템플릿 정의에서 스냅샷 삭제 정책을 사용합니다**를 선택하는 것이 가장 적합합니다.

### 이유:
- **스냅샷 삭제 정책**: CloudFormation 템플릿에서 RDS 인스턴스의 삭제 정책을 `Snapshot`으로 설정하면 스택이 삭제될 때 인스턴스의 스냅샷이 자동으로 생성됩니다. 이렇게 하면 데이터가 안전하게 보존되고, 이후에 필요할 경우 이 스냅샷을 사용하여 RDS 인스턴스를 복원할 수 있습니다. 

### 다른 옵션들:
- **A. 5분마다 RDS 인스턴스를 계속 백업하는 스크립트를 작성**: 이는 관리와 유지보수의 부담이 커지며, 자동화되지 않은 백업은 신뢰성이 떨어질 수 있습니다.
- **B. RDS 인스턴스의 스냅샷을 찍기 위해 AWS Lambda 함수를 만들고, 스택을 삭제하기 전에 함수를 수동으로 호출**: 이 방법은 자동화되지 않으며 수동 호출이 필요하기 때문에 효율적이지 않습니다.
- **D. RDS 인스턴스의 백업을 수행하기 위해 새 CloudFormation 템플릿을 만들고, 스택을 삭제하기 전에 이 템플릿을 실행**: 이 방법은 별도의 템플릿을 만들어야 하며, 불필요한 복잡성을 추가합니다.

결론적으로 **C. RDS 인스턴스의 CloudFormation 템플릿 정의에서 스냅샷 삭제 정책을 사용**하는 것이 가장 안정적이고 효율적인 방법입니다.

## 질문 #280 +++

AnyCompany는 Example Corp를 인수하여 두 회사의 비즈니스 시스템을 통합하려고 시도하고 있습니다. 

AnyCompany의 IT 부서는 Example Corp의 IT 티켓팅 시스템과 통합해야 합니다.

SysOps 관리자는 AnyCompany 계정의 Amazon EC2 인스턴스에 대한 Amazon CloudWatch 알람을 사용하여 Example Corp의 티켓팅 시스템에서 새 티켓을 만드는 솔루션을 구현해야 합니다. 티켓팅 시스템은 새 티켓을 만들기 위한 HTTPS 엔드포인트를 제공합니다. 티켓팅 시스템은 다음 JSON 형식의 메시지를 허용합니다. CloudWatch 알람에서 티켓을 만드는 어떤 접근 방식이 가장 적은 개발 시간으로 이러한 요구 사항을 충족할까요?


A. 적절한 이벤트를 필터링하고 EventBridge API 대상을 대상으로 지정하는 Amazon EventBridge 규칙을 만듭니다. HTTPS 엔드포인트로 이벤트를 보내도록 EventBridge API 대상을 구성합니다. EventBridge 규칙에서 소스를 티켓팅 시스템에 호환되는 출력으로 변환하는 입력 변환기를 만듭니다.
B. 적절한 이벤트를 필터링하고 Amazon Kinesis 데이터 스트림을 대상으로 지정하는 Amazon EventBridge 규칙을 만듭니다. Kinesis 데이터 스트림에서 이벤트를 수신하는 AWS Lambda 함수를 만듭니다. Lambda 함수를 구성하여 AWS Glue 작업을 시작하여 데이터를 변환하고 출력을 HTTPS 엔드포인트로 전달합니다.
C. 적절한 이벤트를 필터링하고 Amazon Simple Notification Service(Amazon SNS)를 대상으로 지정하는 Amazon EventBridge 규칙을 만듭니다. 이벤트를 변환하고 HTTPS 엔드포인트로 이벤트를 보내도록 Amazon SNS를 구성합니다.
D. 적절한 이벤트를 필터링하고 AWS Step Functions 상태 머신을 대상으로 지정하는 Amazon EventBridge 규칙을 만듭니다. Step Functions에서 AWS Lambda 함수와 AWS Glue 작업을 만들어 이벤트를 변환하고 HTTPS 엔드포인트로 전송합니다.


이 요구 사항을 충족하기 위해 가장 적은 개발 시간으로 구현할 수 있는 접근 방식은 **A. 적절한 이벤트를 필터링하고 EventBridge API 대상을 대상으로 지정하는 Amazon EventBridge 규칙을 만듭니다. HTTPS 엔드포인트로 이벤트를 보내도록 EventBridge API 대상을 구성합니다. EventBridge 규칙에서 소스를 티켓팅 시스템에 호환되는 출력으로 변환하는 입력 변환기를 만듭니다.**입니다.

### 이유:
1. **직접적인 통합**: EventBridge API 대상을 사용하면 CloudWatch 알람에서 발생하는 이벤트를 직접 HTTPS 엔드포인트로 전송할 수 있습니다. 이 접근 방식은 간단하고 신속하게 설정할 수 있어 통합 시간이 단축됩니다.

2. **입력 변환기 사용**: EventBridge의 입력 변환기를 사용하면 발생하는 이벤트를 티켓팅 시스템에서 기대하는 JSON 형식으로 쉽게 변환할 수 있습니다. 이는 추가적인 Lambda 함수나 복잡한 데이터 처리 없이도 요구사항을 충족할 수 있게 해줍니다.

3. **AWS 서비스 통합**: EventBridge는 AWS 서비스 간의 이벤트 기반 통합을 지원하므로, 다른 서비스와의 상호 작용을 간소화하고 유지 관리가 용이합니다.

### 다른 옵션 분석:
- **B. Amazon Kinesis 데이터 스트림**: 이 방법은 복잡도가 높고, Kinesis와 Lambda 및 AWS Glue 작업을 추가로 설정해야 하므로 개발 시간이 길어질 수 있습니다.

- **C. Amazon SNS**: SNS는 간단한 알림 서비스를 제공하지만, HTTP 엔드포인트로 직접 요청을 전송할 수 있는 기능은 제한적입니다. 또한, 이벤트 변환이 필요할 경우 추가 작업이 필요합니다.

- **D. AWS Step Functions**: Step Functions는 복잡한 워크플로우를 관리할 수 있지만, 이 경우 단순한 HTTP 요청을 처리하는 데는 과한 솔루션입니다. Lambda와 Glue 작업을 설정하는 데 추가적인 시간과 노력이 필요합니다.

결론적으로, **EventBridge API 대상을 활용하여 CloudWatch 알람과 Example Corp의 티켓팅 시스템 간의 통합을 쉽게 구현하는 방법**이 가장 적합합니다.

## 질문 #281 ++++

SysOps 관리자는 Amazon EC2 Auto Scaling 그룹에서 새로운 Amazon EC2 Spot Instances를 프로비저닝해야 합니다. 

Auto Scaling 그룹은 광범위한 인스턴스 유형을 사용합니다. 구성된 플릿은 시작된 인스턴스 수에 대해 가장 가용성이 높은 풀에서 가져와야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 자동 확장 그룹의 최대 용량까지 스팟 인스턴스를 시작합니다.
B. 다양한 전략을 사용하여 스팟 인스턴스를 시작합니다.
C. 용량 최적화 전략을 사용하여 스팟 인스턴스를 시작합니다.
D. Spot Instance Advisor를 활용하여 가장 적합한 Spot 할당 전략을 결정하세요.

SysOps 관리자가 Amazon EC2 Auto Scaling 그룹에서 새로운 Amazon EC2 Spot Instances를 프로비저닝하고 가용성이 높은 풀에서 인스턴스를 가져오도록 구성하려면 
**C. 용량 최적화 전략을 사용하여 스팟 인스턴스를 시작합니다**를 선택하는 것이 가장 적합합니다.

### 이유:
- **용량 최적화 전략**: 이 전략을 사용하면 Auto Scaling 그룹이 시작할 때 가용성이 높은 인스턴스 풀에서 Spot Instances를 선택합니다. 이를 통해 인스턴스가 중단되는 가능성을 줄이고, 전체적인 가용성을 향상시킬 수 있습니다.
- **스팟 인스턴스의 가용성**: Spot Instances는 수요와 공급에 따라 가용성이 다르기 때문에, 용량 최적화 전략을 통해 가용성이 높은 인스턴스 유형을 선택하면 인스턴스의 가용성을 높이는 데 도움이 됩니다.

### 다른 옵션들:
- **A. 최대 용량까지 스팟 인스턴스를 시작**: 단순히 최대 용량까지 시작하는 것은 가용성을 보장하지 않습니다.
- **B. 다양한 전략을 사용하여 스팟 인스턴스를 시작**: 다양한 전략을 사용하더라도 가용성 최적화에 특화된 것이 아니므로, 최선의 선택이 아닙니다.
- **D. Spot Instance Advisor를 활용**: Spot Instance Advisor는 유용한 도구이지만, 자동으로 인스턴스를 프로비저닝하는 데 직접적으로 도움이 되지는 않습니다.

따라서 **C. 용량 최적화 전략을 사용하여 스팟 인스턴스를 시작**하는 것이 요구 사항을 가장 잘 충족합니다.

## 질문 #282

SysOps 관리자가 eu-west-2 지역에서 사용자 지정 Amazon Machine Image(AMI)를 만들고 AMI를 사용하여 Amazon EC2 인스턴스를 시작합니다. 

SysOps 관리자는 동일한 AMI를 사용하여 다른 두 지역(us-east-1 및 us-east-2)에서 EC2 인스턴스를 시작해야 합니다.

SysOps 관리자는 추가 지역에서 사용자 지정 AMI를 사용하려면 무엇을 해야 합니까?

A. 추가 지역에 AMI를 복사합니다.
B. AWS Management Console의 커뮤니티 AMI 섹션에서 AMI를 공개합니다.
C. 추가 리전에 AMI를 공유합니다. 필요한 액세스 권한을 할당합니다.
D. AMI를 새 Amazon S3 버킷에 복사합니다. 추가 리전에 대한 AMI에 액세스 권한을 할당합니다.

SysOps 관리자가 추가 지역(us-east-1 및 us-east-2)에서 사용자 지정 Amazon Machine Image(AMI)를 사용하려면 **A. 추가 지역에 AMI를 복사합니다**를 선택하는 것이 가장 적합합니다.

### 이유:
- **AMI 복사**: AWS에서는 AMI를 다른 리전으로 복사할 수 있는 기능을 제공합니다. 이렇게 하면 각 리전에서 AMI를 사용할 수 있으며, AMI의 원본 리전에서 모든 설정과 구성을 그대로 유지합니다.
- **간편한 배포**: AMI를 복사한 후, 해당 리전에서 EC2 인스턴스를 쉽게 시작할 수 있습니다.

### 다른 옵션들:
- **B. AMI를 공개**: AMI를 공개하면 다른 AWS 사용자들이 AMI에 접근할 수 있지만, 특정 리전에서 AMI를 사용할 수 있게 하지는 않습니다.
- **C. AMI를 공유**: AMI를 공유하는 것도 가능하지만, 이는 동일한 AWS 계정 내에서만 해당됩니다. 복사를 통해 다른 리전에서 사용할 수 있게 하는 것이 더 일반적입니다.
- **D. AMI를 S3 버킷에 복사**: AMI 자체는 S3에 직접적으로 복사할 수 없으며, AMI를 S3에 저장하려면 다른 방법이 필요합니다.

따라서, **A. 추가 지역에 AMI를 복사**하는 것이 가장 적절한 해결책입니다.

## 질문 #283

회사는 AWS Organizations의 조직에 여러 계정을 가지고 있습니다. 

회사는 조직의 관리 계정에서 멤버 계정으로 리소스 프로비저닝을 자동화해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

A. AWS CloudFormation 변경 세트를 만듭니다. 모든 멤버 계정에 변경 세트를 배포합니다.
B. AWS CloudFormation 중첩 스택을 만듭니다. 중첩 스택을 모든 멤버 계정에 배포합니다.
C. AWS CloudFormation 스택 세트를 만듭니다. 스택 세트를 모든 멤버 계정에 배포합니다.
D. AWS Serverless Application Model(AWS SAM) 템플릿을 만듭니다. 모든 멤버 계정에 템플릿을 배포합니다.

이 요구 사항을 충족하기 위한 최적의 솔루션은 **C. AWS CloudFormation 스택 세트를 만듭니다. 스택 세트를 모든 멤버 계정에 배포합니다**입니다.

### 이유:
- **다수 계정 지원**: CloudFormation 스택 세트는 여러 AWS 계정 및 리전에서 CloudFormation 스택을 쉽게 배포하고 관리할 수 있게 해줍니다. 이를 통해 관리 계정에서 멤버 계정으로 리소스를 자동으로 프로비저닝할 수 있습니다.
- **자동화 및 일관성**: 스택 세트를 사용하면 모든 멤버 계정에서 동일한 리소스 구성을 쉽게 설정하고, 업데이트 및 삭제할 수 있습니다. 이렇게 함으로써 일관성을 유지할 수 있습니다.

### 다른 옵션들:
- **A. CloudFormation 변경 세트**: 변경 세트는 스택의 업데이트를 미리 볼 수 있게 해주지만, 여러 계정에 자동으로 배포할 수는 없습니다.
- **B. CloudFormation 중첩 스택**: 중첩 스택은 다른 스택을 포함하여 모듈화할 수 있지만, 여러 계정에 걸쳐 자동으로 배포하는 기능은 제공하지 않습니다.
- **D. AWS Serverless Application Model(AWS SAM) 템플릿**: AWS SAM은 서버리스 애플리케이션을 구축하고 배포하기 위한 도구이지만, 여러 계정에 리소스를 자동으로 프로비저닝하는 기능을 제공하지 않습니다.

따라서, **C. AWS CloudFormation 스택 세트를 선택하는 것이 가장 적합**합니다.

## 질문 #284 +++++

한 회사가 개인 금융을 위한 대화형 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 Amazon S3에 금융 데이터를 저장하며, 데이터는 암호화되어야 합니다. 이 회사는 자체 암호화 키를 제공하고 싶어하지 않습니다. 그러나 이 회사는 암호화 키가 사용된 시기와 키를 사용한 사람을 보여주는 감사 추적을 유지하고 싶어합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. 클라이언트가 제공한 키로 클라이언트 측 암호화를 사용합니다. 암호화된 사용자 데이터를 Amazon S3에 업로드합니다.
B. S3 관리 암호화 키(SSE-S3)를 사용하는 서버 측 암호화를 사용하여 Amazon S3의 사용자 데이터를 암호화합니다.
C. 고객이 제공한 암호화 키(SSE-C)를 사용하는 서버 측 암호화를 사용하여 Amazon S3의 사용자 데이터를 암호화합니다.
D. AWS KMS 관리 암호화 키(SSE-KMS)를 사용하여 서버 측 암호화를 사용하여 Amazon S3의 사용자 데이터를 암호화합니다.

이 회사의 요구 사항을 충족하는 최적의 솔루션은 **D. AWS KMS 관리 암호화 키(SSE-KMS)를 사용하여 서버 측 암호화를 사용하여 Amazon S3의 사용자 데이터를 암호화합니다**입니다. 

### 이유:
- **자체 암호화 키 제공을 원하지 않음**: SSE-KMS는 AWS에서 관리하는 키를 사용하므로 회사가 직접 암호화 키를 관리할 필요가 없습니다.
- **감사 추적**: SSE-KMS를 사용하면 AWS Key Management Service(KMS)를 통해 키를 사용한 시기와 키를 사용한 주체에 대한 감사 로그를 CloudTrail을 통해 기록할 수 있습니다. 이 기능은 키의 사용과 관련된 모든 활동을 추적할 수 있습니다.

### 다른 옵션들:
- **A. 클라이언트 측 암호화**: 이 방법은 클라이언트에서 직접 암호화하고 데이터를 업로드하는 방식으로, AWS에서 키 관리와 관련된 감사 추적을 제공하지 않습니다.
- **B. S3 관리 암호화 키(SSE-S3)**: S3에서 자동으로 암호화 키를 관리하지만, KMS처럼 세분화된 감사 추적 기능은 제공되지 않습니다.
- **C. 고객 제공 암호화 키(SSE-C)**: 이 방법은 고객이 직접 키를 제공해야 하므로 회사가 암호화 키를 제공하지 않으려는 요구와 일치하지 않습니다.


## 질문 #285 ++

한 회사에 Amazon S3 버킷을 만드는 AWS CloudFormation 템플릿이 있습니다. 

사용자는 Active Directory 자격 증명으로 회사 AWS 계정에 인증하고 CloudFormation 템플릿을 배포하려고 시도합니다. 그러나 스택 생성이 실패합니다.

어떤 요인이 이 실패를 일으킬 수 있을까요? (두 가지를 선택하세요.)

A. 사용자의 IAM 정책은 cloudformation:CreateStack 작업을 허용하지 않습니다.
B. 사용자의 IAM 정책은 cloudformation:CreateStackSet 작업을 허용하지 않습니다.
C. 사용자의 IAM 정책은 s3:CreateBucket 작업을 허용하지 않습니다.
D. 사용자의 IAM 정책은 s3:ListBucket 작업을 명시적으로 거부합니다.
E. 사용자의 IAM 정책은 s3:PutObject 작업을 명시적으로 거부합니다.

CloudFormation 스택 생성이 실패할 수 있는 두 가지 가능한 원인은 다음과 같습니다:

**A. 사용자의 IAM 정책은 cloudformation:CreateStack 작업을 허용하지 않습니다.**  
- CloudFormation 스택을 생성하려면 `cloudformation:CreateStack` 권한이 필요합니다. 이 권한이 없으면 스택 생성이 실패합니다.

**C. 사용자의 IAM 정책은 s3:CreateBucket 작업을 허용하지 않습니다.**  
- CloudFormation 템플릿이 S3 버킷을 생성하려면 `s3:CreateBucket` 권한이 필요합니다. 이 권한이 없으면 S3 버킷을 만들 수 없고, 따라서 스택 생성이 실패할 수 있습니다.

### 나머지 선택지 분석:
- **B. 사용자의 IAM 정책은 cloudformation:CreateStackSet 작업을 허용하지 않습니다.**  
  `CreateStackSet` 권한은 CloudFormation StackSet을 생성할 때 필요하지만, 일반적인 CloudFormation 스택 생성과는 관련이 없습니다.

- **D. 사용자의 IAM 정책은 s3:ListBucket 작업을 명시적으로 거부합니다.**  
  `ListBucket` 권한은 S3 버킷의 객체 목록을 조회할 때 필요하지만, 버킷 생성과는 직접적으로 관련이 없습니다.

- **E. 사용자의 IAM 정책은 s3:PutObject 작업을 명시적으로 거부합니다.**  
  `PutObject` 권한은 S3 버킷에 객체를 업로드할 때 필요하지만, 버킷 생성과는 직접 관련이 없습니다.


## 질문 #286 ++

Amazon RDS for PostgreSQL DB 클러스터는 7일 보관 기간으로 자동 백업을 켭니다. 

SysOps 관리자는 원래 DB 클러스터에서 24시간 이내에 생성된 데이터를 사용하여 새 RDS DB 클러스터를 만들어야 합니다.

어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요? (두 가지를 선택하세요.)

A. 가장 최근의 자동화된 스냅샷을 식별합니다. 스냅샷을 새 RDS DB 클러스터로 복원합니다.
B. 네이티브 데이터베이스 백업 도구를 사용하여 Amazon S3에 데이터베이스를 백업합니다. 새 RDS DB 클러스터를 만들고 새 RDS DB 클러스터에 데이터를 복원합니다.
C. 원래 RDS DB 클러스터에서 읽기 복제본 인스턴스를 만듭니다. 읽기 복제본을 독립형 DB 클러스터로 승격합니다.
D. 새 RDS DB 클러스터를 만듭니다. AWS Database Migration Service(AWS DMS)를 사용하여 현재 RDS DB 클러스터에서 새로 만든 RDS DB 클러스터로 데이터를 마이그레이션합니다.
E. pg_dump 유틸리티를 사용하여 원래 RDS DB 클러스터에서 Amazon EC2 인스턴스로 데이터를 내보냅니다. 새 RDS DB 클러스터를 만듭니다. pg_restore 유틸리티를 사용하여 EC2 인스턴스에서 새 RDS DB 클러스터로 데이터를 가져옵니다.

이 요구 사항을 충족하는 솔루션은 다음과 같습니다:

**A. 가장 최근의 자동화된 스냅샷을 식별합니다. 스냅샷을 새 RDS DB 클러스터로 복원합니다.**  
- 자동화된 스냅샷을 사용하여 최근의 백업을 신속하게 새 RDS 클러스터로 복원할 수 있습니다. 이는 최소한의 운영 오버헤드로 요구 사항을 충족할 수 있는 방법입니다.

**C. 원래 RDS DB 클러스터에서 읽기 복제본 인스턴스를 만듭니다. 읽기 복제본을 독립형 DB 클러스터로 승격합니다.**  
- 읽기 복제본을 생성한 후 이를 독립형 DB 클러스터로 승격하면 데이터를 빠르게 복제하고 사용할 수 있습니다. 이는 원본 데이터와 가까운 상태의 데이터를 사용하는 방법입니다.

### 나머지 선택지 분석:
- **B. 네이티브 데이터베이스 백업 도구를 사용하여 Amazon S3에 데이터베이스를 백업합니다.**  
  이 방법은 데이터를 복원하는 데 시간이 많이 소요되며, 더 많은 운영 오버헤드가 발생합니다.

- **D. 새 RDS DB 클러스터를 만듭니다. AWS Database Migration Service(AWS DMS)를 사용하여 현재 RDS DB 클러스터에서 새로 만든 RDS DB 클러스터로 데이터를 마이그레이션합니다.**  
  AWS DMS를 사용하면 실시간 데이터 마이그레이션이 가능하지만, 이는 더 많은 운영 오버헤드가 발생할 수 있습니다.

- **E. pg_dump 유틸리티를 사용하여 원래 RDS DB 클러스터에서 Amazon EC2 인스턴스로 데이터를 내보냅니다.**  
  pg_dump와 pg_restore를 사용하는 방식은 수동 작업이 필요하며, 자동화된 스냅샷 복원보다 시간이 더 많이 소요됩니다.


## 질문 #287 +++

한 회사가 애플리케이션 로드 밸런서(ALB)를 사용하여 Amazon EC2에 호스팅된 글로벌 사용자 기반이 있는 웹사이트를 관리하고 있습니다. 

웹 서버의 부하를 줄이기 위해 SysOps 관리자는 ALB를 원본으로 하는 Amazon CloudFront 배포를 구성합니다. 솔루션을 모니터링한 지 일주일 후, 관리자는 ALB에서 여전히 요청이 처리되고 있으며 웹 서버 부하에 변화가 없음을 알게 됩니다.

이 문제의 가능한 원인은 무엇입니까? (두 가지를 선택하세요.)

A. CloudFront에는 ALB가 원본 액세스 ID로 구성되어 있지 않습니다.
B. DNS는 여전히 CloudFront 배포 대신 ALB를 가리키고 있습니다.
C. ALB 보안 그룹은 CloudFront에서 들어오는 트래픽을 허용하지 않습니다.
D. CloudFront 배포에서는 기본, 최소, 최대 TTL(Time to Live)이 0초로 설정됩니다.
E. ALB와 연관된 대상 그룹은 스티키 세션에 대해 구성됩니다.

이 문제의 가능한 원인은 다음과 같습니다:

**B. DNS는 여전히 CloudFront 배포 대신 ALB를 가리키고 있습니다.**  
- CloudFront가 웹 트래픽을 처리하도록 설정되지 않고, DNS가 여전히 직접적으로 ALB를 가리키고 있다면 요청이 CloudFront를 우회하고 ALB로 전달될 수 있습니다. 이로 인해 웹 서버에 부하가 여전히 발생할 수 있습니다.

**C. ALB 보안 그룹은 CloudFront에서 들어오는 트래픽을 허용하지 않습니다.**  
- ALB의 보안 그룹이 CloudFront에서 오는 트래픽을 허용하지 않으면, CloudFront가 ALB와 통신할 수 없습니다. 이로 인해 CloudFront가 작동하지 않고, 트래픽이 ALB로 직접 전달될 수 있습니다.

### 나머지 선택지 분석:
- **A. CloudFront에는 ALB가 원본 액세스 ID로 구성되어 있지 않습니다.**  
  CloudFront에서 ALB를 원본으로 사용하는 경우 OAI(Origin Access Identity)는 필요하지 않습니다. OAI는 S3 버킷을 원본으로 사용할 때만 필요합니다.

- **D. CloudFront 배포에서는 기본, 최소, 최대 TTL(Time to Live)이 0초로 설정됩니다.**  
  TTL 설정이 낮으면 캐싱 이점이 줄어들 수는 있지만, 이것이 ALB로 직접 트래픽이 전달되는 주 원인은 아닙니다.

- **E. ALB와 연관된 대상 그룹은 스티키 세션에 대해 구성됩니다.**  
  스티키 세션은 개별 사용자 세션이 동일한 서버로 전달되도록 보장하지만, 이 설정이 부하 문제와는 직접적인 관련이 없습니다.

## 질문 #288 +++

SysOps 관리자는 example.com 및 www.example.com의 Amazon Route 53 호스팅 존을 구성하여 Application Load Balancer(ALB)를 가리켜야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 작업 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. example.com에 대한 A 레코드를 ALB의 IP 주소를 가리키도록 구성합니다.
B. www.example.com에 대한 A 레코드를 구성하여 ALB의 IP 주소를 가리키도록 합니다.
C. example.com에 대한 별칭 레코드를 ALB의 CNAME을 가리키도록 구성합니다.
D. www.example.com에 대한 별칭 레코드를 구성하여 Route 53 example.com 레코드를 가리키도록 합니다.
E. example.com에 대한 CNAME 레코드를 ALB의 CNAME을 가리키도록 구성합니다.

SysOps 관리자가 Amazon Route 53을 사용하여 **example.com** 및 **www.example.com** 도메인에 대해 Application Load Balancer(ALB)를 가리키기 위해 취할 수 있는 올바른 작업은 다음과 같습니다:

**C. example.com에 대한 별칭 레코드를 ALB의 CNAME을 가리키도록 구성합니다.**  
**D. www.example.com에 대한 별칭 레코드를 구성하여 Route 53 example.com 레코드를 가리키도록 합니다.**

### 설명:
- **별칭 레코드**는 ALB와 같은 AWS 리소스에 대한 DNS 레코드를 설정할 때 사용됩니다. ALB는 IP 주소를 직접 제공하지 않으므로, **별칭 레코드**로 설정해야 합니다.
- **C.**는 ALB의 DNS 이름을 **example.com**에 연결하는 적절한 방법입니다.
- **D.**는 **www.example.com**을 **example.com**으로 연결하여 트래픽이 동일한 ALB로 전달되도록 설정하는 방법입니다.


## 질문 #289 ++

한 회사에 하이브리드 환경이 있습니다. 

이 회사는 회사의 온프레미스 데이터 센터와 VPC에서 실행되는 워크로드 간에 AWS Direct Connect 연결을 설정했습니다. 이 회사는 AWS의 DNS에 Amazon Route 53을 사용합니다. 이 회사는 프라이빗 호스팅 영역을 사용하여 AWS에서 호스팅되는 일련의 서비스에 대한 DNS 이름을 관리합니다. 이 회사는 온프레미스 서버에서 프라이빗 호스팅 영역의 DNS 확인을 위해 Route 53을 사용하기를 원합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. Route 53 인바운드 엔드포인트를 만듭니다. 보안 그룹과 라우팅이 온프레미스 데이터 센터의 트래픽을 허용하는지 확인합니다. 온프레미스 네트워크의 DNS 서버를 구성하여 개인 호스팅 영역의 도메인 이름에 대한 DNS 쿼리를 인바운드 엔드포인트의 IP 주소로 조건부로 전달합니다.
B. Route 53 아웃바운드 엔드포인트를 만듭니다. 보안 그룹과 라우팅이 VPC에서 트래픽을 허용하는지 확인합니다. 온프레미스 네트워크의 DNS 서버를 구성하여 개인 호스팅 영역의 도메인 이름에 대한 DNS 쿼리를 아웃바운드 엔드포인트의 IP 주소로 조건부로 전달합니다.
C. 온프레미스 DNS 서버를 참조하는 TXT 레코드로 Route 53의 개인 호스팅 영역을 편집합니다. 온프레미스 네트워크의 DNS 서버를 구성하여 개인 호스팅 영역의 도메인 이름에 대한 DNS 쿼리를 VPC CIDR IPv4 네트워크 범위의 베이스와 2개로 조건부로 전달합니다.
D. 온프레미스 DNS 서버를 참조하는 PTR 레코드로 Route 53의 개인 호스팅 영역을 편집합니다. 온프레미스 네트워크의 DNS 서버를 구성하여 개인 호스팅 영역의 도메인 이름에 대한 DNS 쿼리를 VPC CIDR IPv4 네트워크 범위의 베이스와 2개로 조건부로 전달합니다.

온프레미스 환경에서 Amazon Route 53의 프라이빗 호스팅 영역을 사용하여 AWS에서 호스팅되는 서비스에 대한 DNS 확인을 수행하려면, 다음 솔루션이 적합합니다:

**A. Route 53 인바운드 엔드포인트를 만듭니다. 보안 그룹과 라우팅이 온프레미스 데이터 센터의 트래픽을 허용하는지 확인합니다. 온프레미스 네트워크의 DNS 서버를 구성하여 개인 호스팅 영역의 도메인 이름에 대한 DNS 쿼리를 인바운드 엔드포인트의 IP 주소로 조건부로 전달합니다.**

이 솔루션은 **Route 53 Resolver 인바운드 엔드포인트**를 사용하여 온프레미스 DNS 서버가 AWS의 프라이빗 호스팅 영역에 대해 DNS 쿼리를 할 수 있도록 합니다. 온프레미스 네트워크의 DNS 서버는 프라이빗 호스팅 영역에 대한 DNS 요청을 인바운드 엔드포인트로 전달하여 해결하게 됩니다.


## 질문 #290 +++++

SysOps 관리자가 온프레미스 웹사이트의 고가용성에 대한 우려를 해결하기 위해 Amazon Route 53 DNS 옵션을 평가하고 있습니다. 

이 웹사이트는 두 개의 서버로 구성되어 있습니다. 기본 활성 서버와 보조 수동 서버입니다. Route 53은 연관된 상태 검사에서 2xx 또는 3xx HTTP 코드가 반환되면 트래픽을 기본 서버로 라우팅해야 합니다. 다른 모든 트래픽은 보조 수동 서버로 전달해야 합니다. 장애 조치 레코드 유형, 세트 ID 및 라우팅 정책은 기본 서버와 보조 서버 모두에 대해 적절하게 설정되었습니다.

Route 53을 구성하기 위해 다음으로 취해야 할 단계는 무엇입니까?


A. 각 서버에 대한 A 레코드를 만듭니다. 레코드를 Route 53 HTTP 상태 검사와 연결합니다.
B. 각 서버에 대해 A 레코드를 만듭니다. 레코드를 Route 53 TCP 상태 검사와 연결합니다.
C. 각 서버에 대해 별칭 레코드를 만들고 평가 대상 상태를 yes로 설정합니다. 레코드를 Route 53 HTTP 상태 검사와 연결합니다.
D. 각 서버에 대해 별칭 레코드를 만들고 평가 대상 상태를 yes로 설정합니다. 레코드를 Route 53 TCP 상태 검사와 연결합니다.


Amazon Route 53을 사용하여 온프레미스 웹사이트의 고가용성을 보장하기 위해, 다음 단계가 적절합니다:

**C. 각 서버에 대해 별칭 레코드를 만들고 평가 대상 상태를 yes로 설정합니다. 레코드를 Route 53 HTTP 상태 검사와 연결합니다.**

이 구성은 기본 서버가 정상적으로 응답하면(2xx 또는 3xx HTTP 코드) 트래픽을 해당 서버로 라우팅하고, 기본 서버가 장애 상태일 때 보조 서버로 자동으로 트래픽을 라우팅하는 데 적합합니다. Route 53에서 **별칭 레코드**와 **HTTP 상태 검사**를 사용하는 것은 최적의 방식이며, 고가용성을 유지하는 데 중요한 설정입니다.



## 질문 #291 +++

Amazon EC2 인스턴스는 Amazon Simple Queue Service(Amazon SQS) 대기열을 사용하는 애플리케이션을 실행하고 있습니다. 

SysOps 관리자는 애플리케이션이 SQS 대기열에서 메시지를 읽고, 쓰고, 삭제할 수 있는지 확인해야 합니다.

어떤 솔루션이 가장 안전한 방식으로 이러한 요구 사항을 충족할까요?

A. sqs:SendMessage 권한, sqs:ReceiveMessage 권한, sqs:DeleteMessage 권한을 해당 대기열에 허용하는 IAM 정책이 있는 IAM 사용자를 만듭니다. 애플리케이션 구성에 IAM 사용자의 자격 증명을 포함합니다.
B. sqs:SendMessage 권한, sqs:RecelveMessage 권한, sqs:DeleteMessage 권한을 해당 대기열에 허용하는 IAM 정책으로 IAM 사용자를 만듭니다. IAM 사용자의 액세스 키와 비밀 액세스 키를 EC2 인스턴스의 환경 변수로 내보냅니다.
C. EC2 인스턴스가 AWS 서비스를 호출할 수 있도록 허용하는 IAM 역할을 만들고 연결합니다. 해당 큐에 sqs:* 권한을 허용하는 역할에 IAM 정책을 연결합니다.
D. EC2 인스턴스가 AWS 서비스를 호출할 수 있도록 허용하는 IAM 역할을 만들고 연결합니다. 해당 큐에 sqs:SendMessage 권한, sqs:ReceiveMessage 권한, sqs:DeleteMessage 권한을 허용하는 IAM 정책을 역할에 연결합니다.

가장 안전한 방식으로 Amazon EC2 인스턴스가 SQS 대기열에서 메시지를 읽고, 쓰고, 삭제할 수 있도록 하기 위해서는 다음 솔루션이 적합합니다:

**D. EC2 인스턴스가 AWS 서비스를 호출할 수 있도록 허용하는 IAM 역할을 만들고 연결합니다. 해당 큐에 sqs:SendMessage 권한, sqs:ReceiveMessage 권한, sqs:DeleteMessage 권한을 허용하는 IAM 정책을 역할에 연결합니다.**

이 방법은 EC2 인스턴스에 역할 기반 권한을 부여하여 안전하고 관리 가능한 방식으로 SQS 대기열과 상호작용할 수 있게 해 줍니다. IAM 역할을 사용하는 것이 사용자의 자격 증명을 코드에 직접 포함하는 것보다 훨씬 안전한 방식입니다.


## 질문 #292

SysOps 관리자는 웹 애플리케이션을 호스팅하기 위해 Amazon S3 버킷을 구성해야 합니다. 

SysOps 관리자는 S3 버킷을 생성하고 웹 애플리케이션의 정적 파일을 S3 버킷에 복사했습니다.

이 회사는 모든 $3 버킷이 공개되어서는 안 된다는 정책을 가지고 있습니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. Amazon CloudFront 배포를 만듭니다. S3 버킷을 OAI(Origin Access Identity)를 사용하여 오리진으로 구성합니다. S3 버킷 정책에서 OAI에 s3:GetObject 권한을 부여합니다.
B. S3 버킷에서 정적 웹사이트 호스팅을 구성합니다. Amazon Route 53을 사용하여 S3 웹사이트 엔드포인트를 가리키는 DNS CNAME을 만듭니다.
C. 애플리케이션 로드 밸런서(ALB)를 만듭니다. ALB 리스너 구성에서 프로토콜을 HTTPS로 변경합니다. 트래픽을 S3 버킷으로 전달합니다.
D. AWS Global Accelerator에서 가속기를 만듭니다. 포트 443에 대한 리스너 구성을 설정합니다. 트래픽을 S3 버킷으로 전달하도록 엔드포인트 유형을 설정합니다.

SysOps 관리자가 S3 버킷을 웹 애플리케이션을 호스팅하면서도 공개적으로 접근할 수 없게 하려면 다음과 같은 해결책이 적합합니다:

A. **Amazon CloudFront 배포를 만듭니다. S3 버킷을 OAI(Origin Access Identity)를 사용하여 오리진으로 구성합니다. S3 버킷 정책에서 OAI에 s3:GetObject 권한을 부여합니다.**

이 방법을 통해 S3 버킷을 비공개로 유지하면서도 CloudFront를 통해 안전하게 콘텐츠를 제공할 수 있습니다.


## 질문 #293 +++++

한 회사가 AWS에서 웹 애플리케이션을 구축하고 있습니다. 

이 회사는 www.example.com이라는 도메인 이름으로 Amazon CloudFront를 사용하고 있습니다. CloudFront로의 모든 트래픽은 전송 중에 암호화되어야 합니다. 이 회사는 이미 AWS Certificate Manager(ACM)에서 www.example.com에 대한 SSL 인증서를 프로비저닝했습니다.

SysOps 관리자는 전송 중인 트래픽을 암호화하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. CloudFront 배포의 각 캐시 동작에 대해 Viewer Protocol Policy 설정을 수정하여 HTTP를 HTTPS로 리디렉션합니다.
B. CloudFront 배포의 각 캐시 동작에 대해 Viewer Protocol Policy 설정을 수정하여 HTTP 및 HTTPS를 허용합니다.
C. CloudFront 배포를 위한 www.example.com의 대체 도메인 이름(CNAME)을 입력합니다. 사용자 지정 SSL 인증서를 선택합니다.
D. CloudFront 배포에 대한 AWS WAF 웹 ACL을 구성합니다.
E. CloudFront 원본에 대해 CloudFront Origin Shield를 구성합니다.

이 문제는 Amazon CloudFront 배포에서 전송 중 트래픽을 암호화하기 위해 필요한 설정을 다룹니다. 이를 해결하기 위해서는 다음 두 가지 단계를 수행해야 합니다:

### 선택:
1. **A. CloudFront 배포의 각 캐시 동작에 대해 Viewer Protocol Policy 설정을 수정하여 HTTP를 HTTPS로 리디렉션합니다.**
   - HTTP 요청이 있을 때 HTTPS로 리디렉션하도록 `Viewer Protocol Policy`를 "Redirect HTTP to HTTPS"로 설정해야 합니다. 이를 통해 모든 트래픽이 HTTPS로 암호화됩니다.

2. **C. CloudFront 배포를 위한 www.example.com의 대체 도메인 이름(CNAME)을 입력합니다. 사용자 지정 SSL 인증서를 선택합니다.**
   - www.example.com 도메인을 사용하기 위해 CloudFront 배포에서 CNAME으로 www.example.com을 설정해야 합니다. 또한, 이미 AWS Certificate Manager(ACM)에서 프로비저닝된 SSL 인증서를 CloudFront 배포에 연결해야 합니다.

### 다른 선택지 분석:
- **B. CloudFront 배포의 각 캐시 동작에 대해 Viewer Protocol Policy 설정을 수정하여 HTTP 및 HTTPS를 허용합니다.**
  - 이 설정은 HTTP 및 HTTPS 모두를 허용하므로, HTTPS로만 트래픽을 제한하지 않기 때문에 적합하지 않습니다.

- **D. CloudFront 배포에 대한 AWS WAF 웹 ACL을 구성합니다.**
  - AWS WAF는 웹 애플리케이션 방화벽으로, 보안 규칙을 설정할 수 있지만 전송 중 암호화와 직접적으로 관련이 없습니다.

- **E. CloudFront 원본에 대해 CloudFront Origin Shield를 구성합니다.**
  - CloudFront Origin Shield는 캐싱을 최적화하고 백엔드 트래픽을 줄이기 위한 옵션으로, 암호화와 관련이 없습니다.

### 결론:
따라서 **A**와 **C**를 선택하여 CloudFront 배포에서 모든 트래픽이 HTTPS로 암호화되도록 설정할 수 있습니다.

## 질문 #294 +++++

한 회사가 3개의 가용성 영역에 있는 수백 개의 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

애플리케이션은 퍼블릭 인터넷을 통해 타사 API를 호출합니다. SysOps 관리자는 타사가 애플리케이션의 트래픽을 허용할 수 있도록 타사에 정적 IP 주소 목록을 제공해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. 각 가용성 영역의 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. NAT 게이트웨이를 해당 가용성 영역의 모든 프라이빗 서브넷의 기본 경로로 만듭니다.
B. 각 가용성 영역에 하나의 Elastic IP 주소를 할당합니다. 가용성 영역의 모든 인스턴스에 Elastic IP 주소를 연결합니다.
C. 인스턴스를 네트워크 로드 밸런서(NLB) 뒤에 배치합니다. 트래픽을 NLB의 개인 IP 주소를 통해 인터넷으로 보냅니다.
D. 각 인스턴스에 할당된 Elastic IP 주소를 통해 트래픽을 인터넷으로 전송하도록 기본 경로 테이블을 업데이트합니다.


이 요구 사항을 충족하기 위해서는 Amazon EC2 인스턴스가 퍼블릭 인터넷을 통해 타사 API를 호출할 때 사용되는 정적 IP 주소를 타사에 제공해야 합니다. 이를 위해 다음과 같은 접근 방법이 필요합니다:

### 정답:
- **B. 각 가용성 영역에 하나의 Elastic IP 주소를 할당합니다. 가용성 영역의 모든 인스턴스에 Elastic IP 주소를 연결합니다.**

### 이유:
- **Elastic IP 주소**는 고정된 퍼블릭 IP 주소로, 인스턴스가 중지되거나 재부팅되더라도 IP 주소가 변경되지 않습니다. 각 가용성 영역에 하나의 Elastic IP 주소를 할당하고, 해당 가용성 영역의 모든 인스턴스에 연결하면 타사에 제공할 수 있는 정적 IP 주소 목록을 쉽게 관리할 수 있습니다.

### 다른 선택지 분석:
- **A. 각 가용성 영역의 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. NAT 게이트웨이를 해당 가용성 영역의 모든 프라이빗 서브넷의 기본 경로로 만듭니다.**
  - NAT 게이트웨이는 프라이빗 서브넷의 인스턴스가 인터넷에 접근할 수 있도록 해주지만, NAT 게이트웨이는 동적 IP 주소를 사용하기 때문에 타사에 제공할 수 있는 정적 IP 주소를 생성하지 않습니다.

- **C. 인스턴스를 네트워크 로드 밸런서(NLB) 뒤에 배치합니다. 트래픽을 NLB의 개인 IP 주소를 통해 인터넷으로 보냅니다.**
  - NLB는 트래픽을 분산시키는 데 유용하지만, NLB가 제공하는 IP 주소는 정적 IP 주소가 아닙니다. NLB를 사용할 경우, 추가적인 구성이 필요하며 타사에 제공할 수 있는 고정된 IP 주소가 필요합니다.

- **D. 각 인스턴스에 할당된 Elastic IP 주소를 통해 트래픽을 인터넷으로 전송하도록 기본 경로 테이블을 업데이트합니다.**
  - 이 옵션은 유효한 방법이지만, 수백 개의 인스턴스에 대해 Elastic IP 주소를 할당하는 것이 비효율적입니다. 또한 각 인스턴스가 개별 Elastic IP 주소를 가질 경우 관리가 복잡해질 수 있습니다.

### 결론:
따라서 **B** 옵션이 각 가용성 영역에 고정된 퍼블릭 IP 주소를 제공하며, 타사에 제공할 수 있는 정적 IP 주소 목록을 생성하는 가장 효율적인 방법입니다.


## 질문 #295 ++++

한 회사가 AWS Organizations를 사용하여 다중 계정 환경을 관리합니다. 

이 회사는 기본 AWS 계정 중 하나에 Lifecycle: Production 태그가 표시된 모든 Amazon Elastic Block Store(Amazon EBS) 볼륨의 일일 증분 백업 생성을 자동화해야 합니다.

이 회사는 사용자가 Amazon EC2 * 권한을 사용하여 이러한 프로덕션 스냅샷을 삭제하지 못하도록 하려고 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?


A. Amazon Data Lifecycle Manager를 사용하여 모든 EBS 볼륨의 일일 스냅샷을 만듭니다. 태그 키로 Lifecycle을 지정합니다. 태그 값으로 Production을 지정합니다.
B. 사용자가 EBS 스냅샷을 삭제할 수 없도록 계정과 서비스 제어 정책(SCP)을 연결합니다. 24시간 cron 일정이 있는 Amazon EventBridge 규칙을 만듭니다. EBS Create Snapshot을 대상으로 구성합니다. 지정된 태그가 있는 모든 EBS 볼륨을 대상으로 지정합니다.
C. AWS Backup을 사용하여 모든 EBS 볼륨의 일일 스냅샷을 만듭니다. 태그 키로 Lifecycle을 지정합니다. 태그 값으로 Production을 지정합니다.
D. Amazon Data Lifecycle Manager를 사용하여 AWS 계정 내의 모든 프로덕션 EC2 인스턴스의 일일 Amazon Machine Image(AMI)를 생성합니다.

이 요구 사항을 충족하기 위해서는 Amazon EBS 볼륨의 일일 증분 백업을 자동화하고, 사용자가 이러한 스냅샷을 삭제하지 못하도록 하는 두 가지 주요 작업을 수행해야 합니다. 

### 정답:
- **A. Amazon Data Lifecycle Manager를 사용하여 모든 EBS 볼륨의 일일 스냅샷을 만듭니다. 태그 키로 Lifecycle을 지정합니다. 태그 값으로 Production을 지정합니다.**

### 이유:
- **Amazon Data Lifecycle Manager (DLM)**는 EBS 볼륨의 스냅샷을 생성하는 작업을 자동화할 수 있는 서비스입니다. DLM을 사용하면 태그를 기반으로 특정 EBS 볼륨에 대한 스냅샷 생성을 자동화할 수 있습니다. 여기서는 `Lifecycle: Production` 태그를 사용하여 해당 볼륨에 대한 스냅샷을 일일로 생성할 수 있습니다.

- **정책 관리**: AWS Organizations에서 서비스 제어 정책(SCP)을 사용하여 사용자가 특정 작업(예: EBS 스냅샷 삭제)에 대한 권한을 가지지 않도록 설정할 수 있습니다. 이를 통해 사용자가 이러한 스냅샷을 삭제할 수 없게 할 수 있습니다.

### 다른 선택지 분석:
- **B. 사용자가 EBS 스냅샷을 삭제할 수 없도록 계정과 서비스 제어 정책(SCP)을 연결합니다. 24시간 cron 일정이 있는 Amazon EventBridge 규칙을 만듭니다. EBS Create Snapshot을 대상으로 구성합니다. 지정된 태그가 있는 모든 EBS 볼륨을 대상으로 지정합니다.**
  - 이 방법은 스냅샷 생성을 수동으로 설정해야 하며, DLM을 사용하는 것보다 관리가 복잡합니다.

- **C. AWS Backup을 사용하여 모든 EBS 볼륨의 일일 스냅샷을 만듭니다. 태그 키로 Lifecycle을 지정합니다. 태그 값으로 Production을 지정합니다.**
  - AWS Backup은 EBS 볼륨의 스냅샷 생성을 자동화할 수 있지만, 이 솔루션이 DLM보다 더 나은 운영 효율성을 제공하지는 않습니다. 또한, 요구 사항에서 특별히 DLM을 언급하고 있기 때문에 A가 더 적합합니다.

- **D. Amazon Data Lifecycle Manager를 사용하여 AWS 계정 내의 모든 프로덕션 EC2 인스턴스의 일일 Amazon Machine Image(AMI)를 생성합니다.**
  - AMI 생성은 EBS 스냅샷과는 다른 작업이며, 주어진 요구 사항에는 적합하지 않습니다.

### 결론:
따라서 **A** 옵션이 EBS 볼륨의 일일 증분 백업을 자동화하고, 사용자가 이러한 스냅샷을 삭제하지 못하도록 하기에 가장 적합한 솔루션입니다.


## 질문 #296 ++

한 회사가 여러 가용성 영역에 걸쳐 Amazon EC2 인스턴스 플릿에 Windows 기반 파일 서버를 호스팅합니다.

현재 설정에서는 애플리케이션 서버가 EC2 플릿에서 동시에 파일에 액세스할 수 없습니다.

어떤 솔루션이 가장 운영 효율적인 방식으로 이 액세스를 허용할까요?

A. Amazon Elastic File System(Amazon EFS) Multi-AZ 파일 시스템을 만듭니다. 파일을 EFS 파일 시스템에 복사합니다. EFS 파일 시스템을 애플리케이션 서버의 마운트 지점에 연결합니다.
B. Amazon FSx for Windows File Server Multi-AZ 파일 시스템을 만듭니다. 파일을 Amazon FSx 파일 시스템에 복사합니다. 애플리케이션 서버에서 연결을 조정하여 Amazon FSx 파일 시스템이 노출하는 공유를 사용합니다.
C. EBS Multi-Attach가 활성화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 만듭니다. Windows 파일 서버에 대한 자동 확장 그룹을 만듭니다. 파일 서버의 사용자 데이터에 있는 스크립트를 사용하여 시작 중에 SharedFileAccess 태그를 EBS 볼륨에 연결합니다.
D. 두 개의 Amazon FSx for Windows File Server 파일 시스템을 만듭니다. 파일 시스템 간에 분산 파일 시스템(DFS) 복제를 구성합니다. 파일을 Amazon FSx 파일 시스템에 복사합니다. Amazon FSx 파일 시스템이 노출하는 공유를 사용하도록 애플리케이션 서버의 연결을 조정합니다.

여러 가용성 영역에 걸쳐 있는 Amazon EC2 인스턴스 플릿에서 Windows 기반 파일 서버에 대한 동시에 파일 액세스를 허용하려면 **Amazon FSx for Windows File Server**를 사용하는 것이 가장 적합합니다. FSx는 Windows 환경에 최적화된 파일 시스템으로, 여러 인스턴스에서 동시에 파일에 접근할 수 있도록 지원합니다.

### 정답:
- **B. Amazon FSx for Windows File Server Multi-AZ 파일 시스템을 만듭니다. 파일을 Amazon FSx 파일 시스템에 복사합니다. 애플리케이션 서버에서 연결을 조정하여 Amazon FSx 파일 시스템이 노출하는 공유를 사용합니다.**

### 이유:
- **Amazon FSx for Windows File Server**는 SMB (Server Message Block) 프로토콜을 지원하여 Windows 기반 애플리케이션에서 파일 공유를 효율적으로 처리할 수 있습니다. 
- Multi-AZ 구성으로 고가용성과 내구성을 제공하며, 여러 EC2 인스턴스가 동시에 파일에 접근할 수 있습니다.
- 애플리케이션 서버에서 FSx 파일 시스템의 공유를 마운트하고 사용하도록 설정하면, 여러 서버에서 동시에 파일에 액세스할 수 있습니다.

### 다른 선택지 분석:
- **A. Amazon Elastic File System(Amazon EFS) Multi-AZ 파일 시스템을 만듭니다. 파일을 EFS 파일 시스템에 복사합니다. EFS 파일 시스템을 애플리케이션 서버의 마운트 지점에 연결합니다.**
  - EFS는 Linux 환경에서 최적화되어 있으며 Windows와의 호환성은 있지만, Windows 환경에서 FSx만큼 원활하지 않을 수 있습니다.

- **C. EBS Multi-Attach가 활성화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 만듭니다. Windows 파일 서버에 대한 자동 확장 그룹을 만듭니다. 파일 서버의 사용자 데이터에 있는 스크립트를 사용하여 시작 중에 SharedFileAccess 태그를 EBS 볼륨에 연결합니다.**
  - EBS 볼륨은 EC2 인스턴스 간에 동시에 공유할 수 있는 설계가 아니라서 파일 서버에 대한 동시에 액세스하는 요구를 충족시키지 못합니다.

- **D. 두 개의 Amazon FSx for Windows File Server 파일 시스템을 만듭니다. 파일 시스템 간에 분산 파일 시스템(DFS) 복제를 구성합니다. 파일을 Amazon FSx 파일 시스템에 복사합니다. Amazon FSx 파일 시스템이 노출하는 공유를 사용하도록 애플리케이션 서버의 연결을 조정합니다.**
  - 두 개의 FSx 파일 시스템을 사용하는 방법은 복잡하며, 필요 이상으로 관리 오버헤드가 발생할 수 있습니다. 하나의 Multi-AZ FSx 파일 시스템을 사용하는 것이 더 효율적입니다.

### 결론:
따라서 **B** 옵션이 여러 가용성 영역에 걸쳐 있는 Windows 기반 EC2 인스턴스가 파일에 동시에 접근할 수 있는 가장 운영 효율적인 방법입니다.


## 질문 #297 ++

한 회사가 단일 VPC의 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. 

이 회사는 EC2 인스턴스를 VPC의 프라이빗 서브넷에 배치했습니다.

EC2 인스턴스는 EC2 인스턴스와 동일한 AWS 리전에 있는 Amazon S3 버킷에 액세스할 수 있어야 합니다. SysOps 관리자는 EC2 인스턴스나 애플리케이션을 변경하지 않고도 EC2 인스턴스에 S3 버킷에 대한 액세스 권한을 제공해야 합니다. EC2 인스턴스는 인터넷에 액세스할 수 없어야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 기본 게이트웨이 엔드포인트 정책을 사용하는 S3 게이트웨이 엔드포인트를 만듭니다. 프라이빗 서브넷을 게이트웨이 엔드포인트와 연결합니다.
B. S3 인터페이스 엔드포인트를 만듭니다. EC2 인스턴스를 인터페이스 엔드포인트와 연결합니다.
C. NAT 게이트웨이를 구성합니다. 개인 서브넷을 NAT 게이트웨이와 연결합니다.
D. 프록시 EC2 인스턴스를 구성합니다. 프록시 EC2 인스턴스를 통해 트래픽을 라우팅하도록 프라이빗 서브넷 경로 테이블을 업데이트합니다. 모든 S3 요청을 대상 S3 버킷으로 라우팅하도록 프록시를 구성합니다.

회사에서 Amazon EC2 인스턴스가 VPC의 프라이빗 서브넷에 위치하고, 인터넷에 접근하지 않으면서도 S3 버킷에 접근할 수 있도록 하려면 **VPC 엔드포인트**를 사용하는 것이 가장 적절한 방법입니다. 

### 정답:
- **A. 기본 게이트웨이 엔드포인트 정책을 사용하는 S3 게이트웨이 엔드포인트를 만듭니다. 프라이빗 서브넷을 게이트웨이 엔드포인트와 연결합니다.**

### 이유:
- **S3 게이트웨이 엔드포인트**는 프라이빗 서브넷에서 인터넷을 통해 S3에 접근할 필요 없이 AWS 리전 내에서 직접 S3 버킷에 접근할 수 있는 방법을 제공합니다. 
- 이를 통해 EC2 인스턴스는 외부 인터넷에 접근하지 않고도 S3 리소스에 안전하게 접근할 수 있습니다.
- 엔드포인트 정책을 설정하여 S3 버킷에 대한 접근을 제어할 수 있습니다.

### 다른 선택지 분석:
- **B. S3 인터페이스 엔드포인트를 만듭니다. EC2 인스턴스를 인터페이스 엔드포인트와 연결합니다.**
  - S3는 **게이트웨이 엔드포인트**를 통해 접근하는 것이 일반적이며, S3에 대한 인터페이스 엔드포인트는 필요하지 않습니다.

- **C. NAT 게이트웨이를 구성합니다. 개인 서브넷을 NAT 게이트웨이와 연결합니다.**
  - NAT 게이트웨이는 인터넷에 접근할 수 있는 경로를 제공하므로, 요구 사항에서 EC2 인스턴스가 인터넷에 접근할 수 없어야 한다는 조건에 맞지 않습니다.

- **D. 프록시 EC2 인스턴스를 구성합니다. 프록시 EC2 인스턴스를 통해 트래픽을 라우팅하도록 프라이빗 서브넷 경로 테이블을 업데이트합니다. 모든 S3 요청을 대상 S3 버킷으로 라우팅하도록 프록시를 구성합니다.**
  - 프록시 EC2 인스턴스를 사용하는 방법은 복잡하고 추가적인 관리 작업이 필요합니다. 이는 필요하지 않은 추가 리소스를 사용하는 것이며, 기본적인 요구 사항을 충족시키기 위한 최적의 방법이 아닙니다.

### 결론:
따라서 **A** 옵션이 EC2 인스턴스가 프라이빗 서브넷에 위치하면서도 S3 버킷에 안전하게 접근할 수 있는 가장 효율적인 솔루션입니다.

## 질문 #298

SysOps 관리자는 웹사이트 페이지를 제공하는 Amazon CloudFront 배포의 캐싱을 관리합니다. 

SysOps 관리자는 개별 페이지의 TTL이 달라질 수 있도록 배포를 구성해야 합니다. 개별 페이지의 TTL은 배포에 설정된 최대 TLL 및 최소 TTL 내에 있어야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 캐시 시간을 변경해야 할 때 Createlnvalidation API 작업을 호출하는 AWS Lambda 함수를 만듭니다.
B. 콘텐츠가 CloudFront로 반환될 때 원본 객체에 Cache-Control: max-age 지침을 추가합니다.
C. Viewer 응답에 Lambda@Edge 함수를 통해 no-cache 헤더를 추가합니다.
D. Viewer 응답에 대한 응답으로 CloudFront 함수를 통해 Expires 헤더를 추가합니다

각 페이지의 TTL(Time to Live)을 개별적으로 조정할 수 있도록 Amazon CloudFront 배포를 구성하려면 원본 객체에서 제공하는 캐시 제어 헤더를 활용하는 것이 가장 효과적입니다. 이를 통해 각 페이지에 대한 캐싱 규칙을 세밀하게 관리할 수 있습니다.

### 정답:
- **B. 콘텐츠가 CloudFront로 반환될 때 원본 객체에 Cache-Control: max-age 지침을 추가합니다.**

### 이유:
- **Cache-Control: max-age** 헤더를 사용하여 원본 객체에서 개별 페이지의 TTL을 지정할 수 있습니다. 이 헤더는 클라이언트와 캐시 간의 캐싱 동작을 제어하며, CloudFront는 이 값을 기준으로 캐시를 만듭니다. 
- 최대 TTL 및 최소 TTL이 배포에 설정되어 있다면, 원본에서 제공하는 TTL은 이러한 한계를 존중하게 되므로 요구 사항을 충족합니다.

### 다른 선택지 분석:
- **A. 캐시 시간을 변경해야 할 때 CreateInvalidation API 작업을 호출하는 AWS Lambda 함수를 만듭니다.**
  - 이 방법은 캐시된 콘텐츠를 무효화하는 방법으로, TTL을 조정하는 것과는 다릅니다. 개별 페이지의 TTL을 동적으로 관리하기에는 비효율적입니다.

- **C. Viewer 응답에 Lambda@Edge 함수를 통해 no-cache 헤더를 추가합니다.**
  - `no-cache` 헤더를 추가하면 클라이언트가 캐시된 콘텐츠를 사용할 수 없게 되어 페이지 로딩 성능이 저하될 수 있습니다. 이는 특정 페이지의 TTL을 설정하는 데 적합하지 않습니다.

- **D. Viewer 응답에 대한 응답으로 CloudFront 함수를 통해 Expires 헤더를 추가합니다.**
  - Expires 헤더를 사용할 수 있지만, Cache-Control 헤더가 더 유연하고 강력한 캐싱 전략을 제공하므로, 일반적으로 Cache-Control 헤더를 사용하는 것이 좋습니다.

### 결론:
따라서 **B** 옵션이 개별 페이지의 TTL을 최대 및 최소 TTL 내에서 적절하게 관리할 수 있는 최적의 솔루션입니다. Cache-Control 헤더를 통해 개별 페이지에 대한 캐시 제어를 보다 세밀하게 설정할 수 있습니다.

## 질문 #299 

한 회사에는 로컬 텔레비전에 광고가 게재된 후 트래픽이 급격히 증가하는 퍼블릭 웹 애플리케이션이 있습니다. 

이 애플리케이션은 Auto Scaling 그룹에 있는 Amazon EC2 인스턴스에서 실행됩니다. Auto Scaling 그룹은 광고가 게재된 후 트래픽 급증에 대처하지 못합니다. 이 회사는 트래픽 급증 시 종종 100개의 EC2 인스턴스로 확장해야 합니다.

인스턴스 시작 시간은 각 인스턴스에 고유한 머신별 데이터 캐시를 생성하는 부팅 프로세스로 인해 깁니다. 광고가 텔레비전에 게재되는 정확한 시점은 알 수 없습니다. SysOps 관리자는 트래픽 급증 시 애플리케이션이 제대로 작동할 수 있도록 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 따뜻한 풀을 만듭니다. 증가된 수요를 충족시키기 위해 충분한 인스턴스를 중지됨 상태로 유지합니다.
B. 100개의 인스턴스를 시작합니다. 부팅 프로세스가 실행을 완료하도록 합니다. 인스턴스를 중지하기 전에 이 데이터를 인스턴스 스토어 볼륨에 저장합니다.
C. 스케일링 정책에서 인스턴스 워밍업 시간 값을 늘립니다.
D. 자동 확장 그룹에 예측적 확장을 사용합니다.

트래픽 급증 시 애플리케이션이 원활하게 작동하도록 보장하기 위해서는 빠르게 EC2 인스턴스를 시작할 수 있는 솔루션이 필요합니다. 일반적으로 이러한 시나리오에서는 **따뜻한 풀**(warm pool)을 사용하는 것이 효과적입니다. 

### 정답:
- **A. 따뜻한 풀을 만듭니다. 증가된 수요를 충족시키기 위해 충분한 인스턴스를 중지된 상태로 유지합니다.**

### 이유:
- **따뜻한 풀**을 사용하면 Auto Scaling 그룹에서 미리 시작된 인스턴스를 유지하고, 이러한 인스턴스가 중지된 상태에서 머신별 데이터 캐시를 초기화할 수 있습니다. 광고가 방영된 후에 트래픽이 급증할 때, 중지된 인스턴스를 빠르게 시작하여 서비스 요청을 처리할 수 있습니다. 이렇게 하면 인스턴스 시작 시간이 크게 단축되고 트래픽 급증에 효과적으로 대응할 수 있습니다.

### 다른 선택지 분석:
- **B. 100개의 인스턴스를 시작합니다. 부팅 프로세스가 실행을 완료하도록 합니다. 인스턴스를 중지하기 전에 이 데이터를 인스턴스 스토어 볼륨에 저장합니다.**
  - 이 방법은 인스턴스를 시작하는 데 시간이 걸리며, 트래픽 급증이 발생할 때 인스턴스를 사전에 시작해 두지 않으면 효과적이지 않습니다.

- **C. 스케일링 정책에서 인스턴스 워밍업 시간 값을 늘립니다.**
  - 인스턴스 워밍업 시간을 늘리는 것은 인스턴스가 완전히 준비되는 시간을 늘리지만, 인스턴스가 필요할 때 즉시 제공하는 데에는 한계가 있습니다. 이미 활성화된 인스턴스가 없는 상황에서 이 방법은 유용하지 않습니다.

- **D. 자동 확장 그룹에 예측적 확장을 사용합니다.**
  - 예측적 확장은 과거의 트래픽 패턴을 기반으로 확장하는 것이지만, 광고의 방송 시간에 따른 갑작스러운 트래픽 급증을 예측하기 어려운 경우 효과적이지 않을 수 있습니다.

### 결론:
따라서 **A** 옵션이 트래픽 급증에 대한 가장 적절한 솔루션입니다. 따뜻한 풀을 통해 인스턴스를 미리 준비해 놓음으로써, 광고가 방송된 후의 급증하는 트래픽을 효과적으로 처리할 수 있습니다.


## 질문 #300 +++

한 회사가 애플리케이션 로드 밸런서(ALB) 뒤의 Amazon EC2 온디맨드 인스턴스에서 내부 애플리케이션을 호스팅합니다. 

인스턴스는 Amazon EC2 자동 확장 그룹에 있습니다. 직원들은 애플리케이션을 사용하여 잠재 고객에게 제품 가격을 제공합니다. 자동 확장 그룹은 동적 확장 정책으로 구성되고 인스턴스의 평균 CPU 사용률을 추적합니다.

직원들은 때때로 애플리케이션이 느리거나 응답하지 않는다는 것을 알아챘습니다. SysOps 관리자는 일부 인스턴스에서 CPU 부하가 높다는 것을 발견했습니다. 회사가 EC2 인스턴스 서비스 할당량에 도달했기 때문에 자동 확장 그룹은 확장할 수 없습니다.

SysOps 관리자는 회사가 EC2 인스턴스 서비스 할당량의 70% 이상에 도달하면 알림을 제공하는 솔루션을 구현해야 합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이러한 요구 사항을 충족할까요?

A. Service Quotas API를 사용하여 EC2 인스턴스를 나열하고, EC2 인스턴스를 계산하고, 총 수를 적용된 할당량 값과 비교하는 AWS Lambda 함수를 만듭니다. 할당량 사용률이 70% 이상인 경우 Amazon Simple Notification Service(Amazon SNS) 알림을 게시하도록 Lambda 함수를 구성합니다. Lambda 함수를 호출하는 Amazon EventBridge 규칙을 만듭니다.
B. Amazon CloudWatch Metrics API를 사용하여 EC2 인스턴스를 나열하고, EC2 인스턴스를 계산하고, 총 개수를 적용된 할당량 값과 비교하는 AWS Lambda 함수를 만듭니다. 할당량 사용률이 70% 이상인 경우 Amazon Simple Notification Service(Amazon SNS) 알림을 게시하도록 Lambda 함수를 구성합니다. Lambda 함수를 호출하는 Amazon EventBridge 규칙을 만듭니다.
C. Service Quotas 콘솔을 사용하여 EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만듭니다. 알람을 할당량 사용률이 70% 이상이 되도록 구성합니다. 알람이 ALARM 상태로 전환되면 Amazon Simple Notification Service(Amazon SNS) 알림을 게시하도록 알람을 구성합니다.
D. Amazon CloudWatch 알람을 만듭니다. EC2 인스턴스의 CPUUtilization 메트릭에 대해 70%의 임계값으로 알람을 구성합니다. 알람이 ALARM 상태로 전환되면 Amazon Simple Notification Service(Amazon SNS) 알림을 게시하도록 알람을 구성합니다.

회사가 EC2 인스턴스 서비스 할당량의 70% 이상에 도달하면 알림을 제공하는 솔루션을 구현하려면 **AWS Service Quotas**를 활용하는 방법이 가장 운영적으로 효율적입니다. Service Quotas는 AWS 리소스의 할당량을 관리하고 모니터링하는 데 특화된 서비스입니다. 

### 정답:
- **A. Service Quotas API를 사용하여 EC2 인스턴스를 나열하고, EC2 인스턴스를 계산하고, 총 수를 적용된 할당량 값과 비교하는 AWS Lambda 함수를 만듭니다. 할당량 사용률이 70% 이상인 경우 Amazon Simple Notification Service(Amazon SNS) 알림을 게시하도록 Lambda 함수를 구성합니다. Lambda 함수를 호출하는 Amazon EventBridge 규칙을 만듭니다.**

### 이유:
- **Service Quotas API**를 사용하여 EC2 인스턴스의 현재 수와 할당량 값을 가져올 수 있습니다. Lambda 함수는 이 값을 주기적으로 확인하여 할당량 사용률이 70%를 초과하는지 여부를 판단하고, 초과할 경우 SNS를 통해 알림을 보냅니다.
- **Amazon EventBridge** 규칙은 Lambda 함수를 주기적으로 호출하여 현재 사용량을 모니터링하도록 설정할 수 있습니다.

### 다른 선택지 분석:
- **B. Amazon CloudWatch Metrics API를 사용하여 EC2 인스턴스를 나열합니다.**
  - CloudWatch Metrics API는 인스턴스의 메트릭(예: CPU 사용률)을 모니터링하는 데 사용되지만, EC2 인스턴스의 서비스 할당량을 직접적으로 확인할 수 없습니다. 

- **C. Service Quotas 콘솔을 사용하여 EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만듭니다.**
  - Service Quotas 콘솔에서 직접 CloudWatch 알람을 설정하는 기능은 제공되지 않으며, API를 통해 Lambda 함수를 사용해야 합니다.

- **D. Amazon CloudWatch 알람을 만듭니다. EC2 인스턴스의 CPUUtilization 메트릭에 대해 70%의 임계값으로 알람을 구성합니다.**
  - 이 방법은 CPU 사용량에 대한 알람을 설정하지만, 서비스 할당량을 모니터링하는 것이 아니므로 요구 사항을 충족하지 않습니다.

### 결론:
따라서 **A** 옵션이 할당량을 모니터링하고 알림을 제공하는 가장 운영적으로 효율적인 방법입니다.

## 질문 #301 ++

SysOps 관리자가 AWS 계정 이름을 업데이트해야 합니다.

SysOps 관리자는 이 목표를 달성하기 위해 무엇을 해야 합니까?

A. SysOps 관리자의 IAM 사용자에게 AdministratorAccess 정책을 추가합니다.
B. SysOps 관리자의 IAM 사용자에게 AWS_ConfigureRole 정책을 추가합니다.
C. AWS Trusted Advisor 인터페이스를 통해 AWS 계정 이름을 변경합니다.
D. 변경하려면 AWS 계정 루트 사용자로 로그인하세요.

AWS 계정 이름을 업데이트하려면 **AWS 계정의 루트 사용자로 로그인**해야 합니다. AWS 계정 이름은 루트 사용자에만 변경할 수 있으며, IAM 사용자에게 관리자 권한을 부여하더라도 변경할 수 없습니다.

### 정답:
- **D. 변경하려면 AWS 계정 루트 사용자로 로그인하세요.**

### 이유:
- AWS 계정 이름은 계정의 고유한 속성으로, 이 이름을 변경하는 작업은 보안상의 이유로 루트 사용자에게만 허용됩니다. 따라서 루트 사용자로 로그인한 후에 AWS Management Console에서 계정 이름을 변경할 수 있습니다.

### 다른 선택지 분석:
- **A. SysOps 관리자의 IAM 사용자에게 AdministratorAccess 정책을 추가합니다.**
  - IAM 사용자에게 AdministratorAccess 정책을 추가하더라도 계정 이름 변경은 불가능합니다.

- **B. SysOps 관리자의 IAM 사용자에게 AWS_ConfigureRole 정책을 추가합니다.**
  - AWS_ConfigureRole 정책은 특정 역할을 설정하는 데 사용되며, 계정 이름 변경과는 관련이 없습니다.

- **C. AWS Trusted Advisor 인터페이스를 통해 AWS 계정 이름을 변경합니다.**
  - AWS Trusted Advisor는 계정 관리와 관련된 권장 사항을 제공하지만, 계정 이름 변경 기능은 제공하지 않습니다.

### 결론:
따라서 AWS 계정 이름을 변경하기 위해서는 **루트 사용자로 로그인**하여 해당 설정을 진행해야 합니다.


## 질문 #302

개발자 팀은 여러 Amazon S3 버킷을 중앙 저장소로 사용하고 있습니다. 

전 세계 사용자가 이러한 저장소에 대량의 파일을 업로드합니다. 개발팀의 애플리케이션은 나중에 이러한 파일을 처리합니다.

SysOps 관리자가 새로운 워크로드를 지원하기 위해 새 S3 버킷인 DOC-EXAMPLE-BUCKET을 설정합니다. rew S3 버킷은 또한 전 세계 사용자로부터 대량의 파일을 정기적으로 업로드합니다. 새 S3 버킷이 프로덕션에 투입되면 특정 지리적 영역의 업로드 성능이 기존 $3 버킷이 제공하는 업로드 성능보다 낮습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 새 S3 버킷에 대한 Amazon ElastiCache for Redis 클러스터를 프로비저닝합니다. API 호출에 사용할 클러스터의 구성 엔드포인트를 개발자에게 제공합니다.
B. 새 Amazon CloudFront 배포에 새 S3 버킷을 추가합니다. 개발자에게 API 호출에 사용할 새 배포의 도메인 이름을 제공합니다.
C. 새 S3 버킷에 대해 S3 Transfer Acceleration을 활성화합니다. 개발자가 API 호출에서 DOC-EXAMPLE-BUCKET.s3-accelerate.amazonaws.com 엔드포인트 이름을 사용하고 있는지 확인합니다.
D. 새로운 S3 버킷에 S3 멀티파트 업로드를 사용합니다. 개발자가 API 호출에서 DOC-EXAMPLE-BUCKETS3, [Region] amazonaws.com과 같은 지역별 S3 엔드포인트 이름을 사용하고 있는지 확인합니다.

새로운 S3 버킷이 전 세계 사용자로부터 대량의 파일을 정기적으로 업로드하는 경우, 특정 지리적 영역에서의 업로드 성능 문제를 해결하기 위해 **S3 Transfer Acceleration**을 활성화하는 것이 가장 효과적입니다. S3 Transfer Acceleration은 전 세계적으로 S3 버킷으로 파일을 업로드할 때 성능을 개선하기 위해 Amazon CloudFront의 엣지 로케이션을 사용하는 기능입니다.

### 정답:
- **C. 새 S3 버킷에 대해 S3 Transfer Acceleration을 활성화합니다. 개발자가 API 호출에서 DOC-EXAMPLE-BUCKET.s3-accelerate.amazonaws.com 엔드포인트 이름을 사용하고 있는지 확인합니다.**

### 이유:
1. **성능 개선**:
   - S3 Transfer Acceleration은 엣지 로케이션을 통해 업로드를 가속화하므로, 사용자가 버킷에 파일을 업로드할 때 대기 시간을 줄이고 성능을 개선합니다. 이는 전 세계 사용자들이 있는 경우 특히 유용합니다.

2. **간편한 구성**:
   - S3 Transfer Acceleration을 활성화하는 것은 간단하며, 특정 API 엔드포인트를 사용하여 자동으로 최적의 경로로 전송됩니다. 개발자는 이를 쉽게 구현할 수 있습니다.

### 다른 선택지 분석:
- **A. 새 S3 버킷에 대한 Amazon ElastiCache for Redis 클러스터를 프로비저닝합니다. API 호출에 사용할 클러스터의 구성 엔드포인트를 개발자에게 제공합니다.**
  - ElastiCache는 주로 데이터베이스 캐싱을 위한 서비스로, S3 업로드 성능 개선과는 관련이 없습니다.

- **B. 새 Amazon CloudFront 배포에 새 S3 버킷을 추가합니다. 개발자에게 API 호출에 사용할 새 배포의 도메인 이름을 제공합니다.**
  - CloudFront는 주로 콘텐츠 배포에 사용되며, S3 버킷에 대한 업로드 성능 개선에는 직접적인 영향을 미치지 않습니다.

- **D. 새로운 S3 버킷에 S3 멀티파트 업로드를 사용합니다. 개발자가 API 호출에서 DOC-EXAMPLE-BUCKETS3, [Region] amazonaws.com과 같은 지역별 S3 엔드포인트 이름을 사용하고 있는지 확인합니다.**
  - S3 멀티파트 업로드는 큰 파일을 여러 부분으로 나누어 업로드하는 데 유용하지만, 전체 업로드 성능을 개선하는 데는 한계가 있습니다. 지리적 성능 문제를 해결하는 데는 S3 Transfer Acceleration이 더 적합합니다.

### 결론:
따라서 **S3 Transfer Acceleration을 활성화하여 전 세계 사용자의 업로드 성능을 개선하는 것이 최선의 해결책입니다.**

## 질문 #303 +++

SysOps 관리자가 AWS Systems Manager Patch Manager를 사용하여 Amazon EC2 Windows 인스턴스 패치 프로세스를 자동화하려고 합니다. 

SysOps 관리자는 개발 인스턴스의 경우 릴리스 날짜로부터 2일 후에 패치가 자동 승인되도록 하려고 합니다. 또한 프로덕션 인스턴스의 경우 릴리스 날짜로부터 5일 후에 패치가 자동 승인되어야 합니다. 모든 인스턴스의 경우 유지 관리가 2시간 동안만 이루어져야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 태그를 사용하여 개발 인스턴스와 프로덕션 인스턴스를 식별합니다. Patch Manager에서 두 개의 패치 그룹과 하나의 패치 베이스라인을 만듭니다. 각 패치 그룹에 자동 승인 지연을 추가합니다. 단일 유지 관리 창을 만듭니다.
B. 태그를 사용하여 개발 인스턴스와 프로덕션 인스턴스를 식별합니다. Patch Manager에서 두 개의 패치 그룹과 두 개의 패치 베이스라인을 만듭니다. 각 패치 베이스라인에서 자동 승인 지연을 지정합니다. 단일 유지 관리 창을 만듭니다.
C. 태그를 사용하여 개발 인스턴스와 프로덕션 인스턴스를 식별합니다. Patch Manager에서 두 개의 패치 그룹과 하나의 패치 베이스라인을 만듭니다. 각각 자동 승인 지연이 있는 두 개의 별도 유지 관리 창을 만듭니다.
D. 태그를 사용하여 개발 인스턴스를 식별합니다. Patch Manager에서 하나의 패치 그룹과 하나의 패치 베이스라인을 만듭니다. 패치 베이스라인에서 자동 승인 지연을 지정합니다. 개발 인스턴스를 새 패치 그룹에 추가합니다. 나머지 모든 인스턴스에 대해 미리 정의된 Patch Manager 패치 베이스라인을 사용합니다. 단일 유지 관리 창을 만듭니다.


이 요구 사항을 충족하는 최적의 솔루션은 **B. 태그를 사용하여 개발 인스턴스와 프로덕션 인스턴스를 식별합니다. Patch Manager에서 두 개의 패치 그룹과 두 개의 패치 베이스라인을 만듭니다. 각 패치 베이스라인에서 자동 승인 지연을 지정합니다. 단일 유지 관리 창을 만듭니다.**입니다.

### 이유:
- **두 개의 패치 그룹과 두 개의 패치 베이스라인**을 사용하면 개발 인스턴스와 프로덕션 인스턴스에 서로 다른 자동 승인 지연을 설정할 수 있습니다. 개발 인스턴스의 경우 2일 후, 프로덕션 인스턴스의 경우 5일 후에 패치를 자동 승인하도록 구성할 수 있습니다.
- **태그를 사용**하여 개발 인스턴스와 프로덕션 인스턴스를 구분하면 AWS Systems Manager에서 인스턴스를 쉽게 식별하고 해당 패치 그룹과 베이스라인을 적용할 수 있습니다.
- **단일 유지 관리 창**을 사용하면 모든 인스턴스에 대해 동일한 2시간 유지 관리 기간을 지정하여 패치가 이루어지는 시간을 제어할 수 있습니다.

### 다른 옵션 분석:
- **A**: 이 옵션은 하나의 패치 베이스라인을 사용하므로 개발과 프로덕션 인스턴스에 대해 서로 다른 자동 승인 지연을 설정할 수 없습니다.
  
- **C**: 두 개의 별도 유지 관리 창을 만드는 것은 요구 사항에서 명시된 2시간 유지 관리 창 하나를 사용하는 것과 다르며, 추가적인 복잡성을 가져옵니다.

- **D**: 이 옵션은 개발 인스턴스에만 적용되며, 프로덕션 인스턴스에 대해 미리 정의된 패치 베이스라인을 사용하는 것은 요구 사항에서 명시된 5일 후 자동 승인 지연을 구현하지 못합니다.

따라서 **B**가 요구 사항을 완전히 충족하는 최적의 솔루션입니다.


## 질문 #304  +++

SysOps 관리자는 10개의 AWS Lambda 함수에서 Amazon CloudWatch 로그를 분석하여 과거 오류를 파악해야 합니다.

로그는 JSON 형식이며 Amazon S3에 저장됩니다. 오류는 때때로 동일한 필드에 나타나지 않지만 모든 오류는 동일한 문자열 접두사로 시작합니다.

SysOps 관리자가 로그 파일을 분석하는 가장 운영 효율적인 방법은 무엇입니까?

A. S3 Select를 사용하여 오류를 검색하는 쿼리를 작성합니다. 관심 있는 모든 로그 그룹에서 쿼리를 실행합니다.
B. 관심 있는 로그를 인덱싱하기 위해 AWS Glue 처리 작업을 만듭니다. Amazon Athena에서 쿼리를 실행하여 오류를 검색합니다.
C. Amazon CloudWatch Logs Insights를 사용하여 오류를 검색하는 쿼리를 작성합니다. 관심 있는 모든 로그 그룹에서 쿼리를 실행합니다.
D. Amazon CloudWatch Contributor Insights를 사용하여 규칙을 만듭니다. 관심 있는 모든 로그 그룹에 규칙을 적용합니다.

SysOps 관리자가 Amazon CloudWatch 로그를 분석하여 과거 오류를 파악하는 가장 운영 효율적인 방법은 **Amazon Athena**를 사용하는 것입니다. 주어진 조건에서는 JSON 형식의 로그가 Amazon S3에 저장되어 있으므로, Athena는 이러한 로그에 대한 SQL 쿼리를 작성하고 실행할 수 있는 강력한 도구입니다.

### 정답:
- **B. 관심 있는 로그를 인덱싱하기 위해 AWS Glue 처리 작업을 만듭니다. Amazon Athena에서 쿼리를 실행하여 오류를 검색합니다.**

### 이유:
1. **AWS Glue와 Amazon Athena의 통합**:
   - AWS Glue는 ETL(Extract, Transform, Load) 서비스를 제공하며, S3에 저장된 JSON 로그 데이터를 인덱싱하여 Athena에서 쉽게 쿼리할 수 있도록 합니다.
   - AWS Glue 크롤러를 사용하여 JSON 로그의 스키마를 자동으로 감지하고 AWS Glue 데이터 카탈로그에 저장할 수 있습니다. 이를 통해 Athena에서 데이터를 쿼리할 때 필요한 메타데이터를 제공합니다.

2. **유연한 쿼리 기능**:
   - Athena는 SQL 기반 쿼리를 사용하여 S3에 저장된 데이터에 대한 다양한 분석을 수행할 수 있습니다. 오류를 식별하기 위해 문자열 접두사를 기준으로 필터링할 수 있습니다.

### 다른 선택지 분석:
- **A. S3 Select를 사용하여 오류를 검색하는 쿼리를 작성합니다. 관심 있는 모든 로그 그룹에서 쿼리를 실행합니다.**
  - S3 Select는 특정 객체에서 데이터를 필터링하는 데 유용하지만, 여러 로그 파일을 한 번에 쿼리하는 데는 효율적이지 않습니다. 따라서 여러 파일에 대한 반복적인 쿼리가 필요할 수 있습니다.

- **C. Amazon CloudWatch Logs Insights를 사용하여 오류를 검색하는 쿼리를 작성합니다. 관심 있는 모든 로그 그룹에서 쿼리를 실행합니다.**
  - CloudWatch Logs Insights는 실시간 로그 분석에 좋지만, S3에 저장된 로그에 대한 쿼리는 지원하지 않습니다. 이 방법은 주어진 로그 파일이 S3에 저장되어 있다는 점에서 사용할 수 없습니다.

- **D. Amazon CloudWatch Contributor Insights를 사용하여 규칙을 만듭니다. 관심 있는 모든 로그 그룹에 규칙을 적용합니다.**
  - Contributor Insights는 주로 사용자의 기여도를 모니터링하는 데 유용하지만, 특정 오류 로그를 검색하는 데 적합하지 않습니다.

### 결론:
따라서 **AWS Glue와 Amazon Athena를 사용하여 S3에 저장된 JSON 로그를 효율적으로 분석하고 오류를 식별하는 것이 가장 운영 효율적인 방법입니다.**


## 질문 #305

한 회사에서는 모든 Amazon EC2 인스턴스 로그를 Amazon CloudWatch Logs에 게시해야 한다는 정책을 가지고 있습니다. 

SysOps 관리자가 Amazon Linux 2를 실행하는 EC2 인스턴스의 문제를 해결하고 있습니다. EC2 인스턴스가 CloudWatch Logs에 로그를 게시하지 않습니다. Amazon CloudWatch 에이전트가 EC2 인스턴스에서 실행 중이고 에이전트 구성 파일이 올바릅니다.

SysOps 관리자는 문제를 해결하기 위해 무엇을 해야 합니까?

A. EC2 인스턴스에서 AWS CLI를 구성합니다. PutLogEvents API 작업을 호출하여 5분마다 CloudWatch에 로그 파일을 푸시하는 cron 작업을 만듭니다.
B. CloudWatch Logs 로그 그룹의 보존 기간을 검사합니다. 보존 기간이 1일보다 큰 값으로 설정되어 있는지 확인합니다.
C. EC2 인스턴스와 동일한 AWS 지역에서 실행되는 Amazon Kinesis 데이터 스트림을 설정합니다. EC2 인스턴스에서 CloudWatch 에이전트를 구성하여 CloudWatch 이벤트를 데이터 스트림으로 보냅니다.
D. EC2 인스턴스에 연결된 IAM 역할에 CloudWatch Logs에서 CreateLogGroup, CreateLogStream, PutLogEvents 및 DescribeLogStreams 작업에 대한 권한이 있는지 확인하세요.


EC2 인스턴스에서 Amazon CloudWatch Logs에 로그를 게시하지 않는 문제를 해결하기 위해 가장 적합한 방법은 EC2 인스턴스에 연결된 IAM 역할에 필요한 권한이 있는지 확인하는 것입니다.

### 정답:
- **D. EC2 인스턴스에 연결된 IAM 역할에 CloudWatch Logs에서 CreateLogGroup, CreateLogStream, PutLogEvents 및 DescribeLogStreams 작업에 대한 권한이 있는지 확인하세요.**

### 이유:
1. **IAM 역할의 권한 확인**:
   - EC2 인스턴스가 CloudWatch Logs에 로그를 게시하려면 필요한 IAM 권한이 있어야 합니다. 이 권한이 없으면 로그가 CloudWatch Logs에 게시되지 않습니다.
   - **필요한 권한**:
     - `CreateLogGroup`: 로그 그룹을 생성할 수 있는 권한.
     - `CreateLogStream`: 로그 스트림을 생성할 수 있는 권한.
     - `PutLogEvents`: 로그 이벤트를 게시할 수 있는 권한.
     - `DescribeLogStreams`: 로그 스트림을 조회할 수 있는 권한.

2. **문제 해결 프로세스**:
   - 먼저 EC2 인스턴스에 연결된 IAM 역할을 확인하고, 위의 작업들에 대한 권한이 있는지 검토합니다. 필요한 권한이 없다면 적절한 정책을 추가해야 합니다.

### 다른 선택지 분석:
- **A. EC2 인스턴스에서 AWS CLI를 구성합니다. PutLogEvents API 작업을 호출하여 5분마다 CloudWatch에 로그 파일을 푸시하는 cron 작업을 만듭니다.**
  - 이 방법은 추가적인 작업이 필요하며, CloudWatch 에이전트를 사용하는 목적과 맞지 않습니다.

- **B. CloudWatch Logs 로그 그룹의 보존 기간을 검사합니다. 보존 기간이 1일보다 큰 값으로 설정되어 있는지 확인합니다.**
  - 보존 기간은 로그가 저장되는 기간과 관련이 있지만, 로그가 게시되지 않는 문제와는 직접적인 관련이 없습니다.

- **C. EC2 인스턴스와 동일한 AWS 지역에서 실행되는 Amazon Kinesis 데이터 스트림을 설정합니다. EC2 인스턴스에서 CloudWatch 에이전트를 구성하여 CloudWatch 이벤트를 데이터 스트림으로 보냅니다.**
  - 이 방법은 불필요하게 복잡하며, 기본적으로 CloudWatch Logs에 로그를 게시하기 위해 Kinesis를 사용하는 것은 일반적인 해결책이 아닙니다.

### 결론:
따라서, **EC2 인스턴스에 연결된 IAM 역할의 권한을 확인하는 것이 로그를 CloudWatch Logs에 게시하지 않는 문제를 해결하는 가장 효율적인 방법입니다.**


## 질문 #306

한 회사가 Amazon EC2 인스턴스에서 워크로드를 실행합니다. 

워크로드에는 자주 변경되는 데이터가 포함된 임시 캐시가 필요합니다. 워크로드는 인스턴스 재시작 시 캐시를 유지할 필요가 없습니다.

어떤 스토리지 옵션이 캐시에 가장 높은 성능을 제공할까요?

A. 일반용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨
B. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨
C. 처리량 최적화 HDD(st1) Amazon Elastic Block Store(Amazon EBS) 볼륨
D. EC2 인스턴스 스토어

캐시를 위한 스토리지 옵션을 선택할 때, 성능과 워크로드의 특성을 고려해야 합니다. 주어진 상황에서 **D. EC2 인스턴스 스토어**가 가장 높은 성능을 제공합니다.

### 정답:
- **D. EC2 인스턴스 스토어**

### 이유:
1. **고속 스토리지**:
   - EC2 인스턴스 스토어는 인스턴스에 직접 연결된 물리적 디스크로, 매우 높은 I/O 성능과 낮은 지연 시간을 제공합니다. 이는 임시 캐시와 같은 높은 성능이 요구되는 워크로드에 이상적입니다.

2. **임시 데이터 저장**:
   - 인스턴스 스토어는 데이터가 임시적이며 인스턴스가 종료되거나 재부팅될 때 데이터가 사라진다는 점에서 캐시의 요구 사항에 잘 맞습니다.

3. **비용 효율성**:
   - EC2 인스턴스 스토어는 추가 비용이 없으므로 스토리지 비용을 절감할 수 있습니다.

### 다른 선택지 분석:
- **A. 일반용 SSD(gp3) Amazon Elastic Block Store(EBS) 볼륨**:
  - gp3 볼륨은 좋은 성능을 제공하지만, 인스턴스 스토어보다 낮은 IOPS와 처리량을 가집니다.

- **B. 프로비저닝된 IOPS SSD(io2) Amazon EBS 볼륨**:
  - io2 볼륨은 높은 성능을 제공하지만, 비용이 비쌉니다. 캐시와 같이 임시 데이터를 저장하는 데는 과한 성능일 수 있습니다.

- **C. 처리량 최적화 HDD(st1) Amazon EBS 볼륨**:
  - st1 볼륨은 대량의 데이터에 대한 높은 처리량을 제공하지만, 지연 시간과 IOPS는 SSD에 비해 낮습니다. 캐시를 위한 용도로는 적합하지 않습니다.

### 결론:
따라서, **EC2 인스턴스 스토어는 높은 성능을 제공하고, 임시 데이터에 적합하여 캐시 용도로 가장 적합한 선택입니다.**

## 질문 #307 ++++

한 회사가 AWS Organizations에서 조직 전반에 걸쳐 여러 워크로드를 실행합니다. 

회사의 재무 팀은 비용 변화를 추적하고 자세한 비용 지표를 제공하기 위한 자세한 대시보드가 ​​필요합니다. 재무 팀은 매시간 세부적으로 추세를 추적해야 합니다.

SysOps 관리자는 이러한 요구 사항을 가장 운영적으로 효율적인 방식으로 충족하기 위해 무엇을 해야 합니까?

A. CloudWatch Insights와 AWS Cost Explorer 데이터를 사용하여 Amazon CloudWatch 대시보드를 생성합니다.
B. AWS 비용 및 사용 보고서를 생성합니다. Amazon S3에 보고서를 저장합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다. Amazon QuickSight를 사용하여 AWS 비용 및 사용 보고서의 데이터를 기반으로 대시보드를 개발합니다.
C. 하루에 한 번 실행되고 조직의 모든 계정에서 역할을 맡는 AWS Lambda 함수를 만듭니다. Lambda 함수를 구성하여 각 계정에서 AWS Cost Explorer 데이터를 읽고 Amazon S3 버킷에 비용 데이터를 저장합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다. Amazon QuickSight를 사용하여 대시보드에 데이터를 표시합니다.
D. 재무팀을 위한 IAM 사용자를 만듭니다. IAM 사용자에게 관리 계정에서 AWS Cost Explorer 데이터와 청구 데이터를 볼 수 있는 권한을 부여합니다.

회사가 AWS Organizations에서 여러 워크로드를 실행하고, 재무 팀이 비용 변화를 추적하고 세부적인 비용 지표를 제공하기 위한 대시보드를 필요로 하는 경우, **B** 옵션이 가장 운영적으로 효율적인 방법입니다.

### 정답:
- **B. AWS 비용 및 사용 보고서를 생성합니다. Amazon S3에 보고서를 저장합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다. Amazon QuickSight를 사용하여 AWS 비용 및 사용 보고서의 데이터를 기반으로 대시보드를 개발합니다.**

### 이유:
1. **세부적인 비용 보고**:
   - AWS 비용 및 사용 보고서(Usage Report)는 비용과 사용에 대한 매우 상세한 데이터를 제공하며, 모든 AWS 계정에 대해 조직적으로 비용을 추적할 수 있습니다.

2. **시간 단위 데이터**:
   - 이 보고서는 시간 단위로 데이터를 제공하여 재무 팀이 비용 변화를 세밀하게 추적할 수 있도록 지원합니다.

3. **유연한 쿼리 및 시각화**:
   - Amazon Athena를 사용하여 S3에 저장된 데이터를 SQL로 쿼리할 수 있으며, Amazon QuickSight를 통해 대시보드를 쉽게 시각화할 수 있습니다. 이 조합은 효율적으로 데이터를 관리하고 시각화하는 데 도움이 됩니다.

### 다른 선택지 분석:
- **A. CloudWatch Insights와 AWS Cost Explorer 데이터를 사용하여 Amazon CloudWatch 대시보드를 생성합니다.**
  - CloudWatch Insights는 로그와 메트릭에 대한 분석에 적합하지만, 세부적인 비용 분석에는 적합하지 않습니다. AWS Cost Explorer는 개별 계정 수준의 데이터에 대한 시각화에 유용하지만 시간 단위로 상세하게 데이터를 제공하기에는 제한적입니다.

- **C. 하루에 한 번 실행되고 조직의 모든 계정에서 역할을 맡는 AWS Lambda 함수를 만듭니다. Lambda 함수를 구성하여 각 계정에서 AWS Cost Explorer 데이터를 읽고 Amazon S3 버킷에 비용 데이터를 저장합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다. Amazon QuickSight를 사용하여 대시보드에 데이터를 표시합니다.**
  - 이 옵션은 더 복잡하며, 하루에 한 번만 실행되므로 세부적인 시간 단위 추적이 필요하다는 요구 사항을 충족하지 못합니다. 

- **D. 재무팀을 위한 IAM 사용자를 만듭니다. IAM 사용자에게 관리 계정에서 AWS Cost Explorer 데이터와 청구 데이터를 볼 수 있는 권한을 부여합니다.**
  - 이 방법은 데이터 접근 권한을 설정하는 데는 유용하지만, 세부적인 대시보드를 제공하거나 시간 단위로 비용 변화를 추적하는 데는 부족합니다.

### 결론:
따라서, **AWS 비용 및 사용 보고서를 사용하여 S3에 저장하고 Athena와 QuickSight를 통해 대시보드를 생성하는 방법이 가장 효율적이고 효과적인 솔루션입니다.**


## 질문 #308 ++++

회사에는 주 7일, 하루 24시간 실행해야 하는 핵심 애플리케이션이 있습니다. 

이 애플리케이션은 Amazon EC2, AWS Fargate, AWS Lambda를 사용합니다. 이 회사는 여러 AWS 지역에서 운영 체제를 조합하여 사용합니다.

이 회사는 변경에 유연성을 제공하는 가격 책정 모델을 고수하면서 비용 절감을 극대화해야 합니다. 이 회사는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 저축 계획 권장 사항을 기반으로 하는 컴퓨팅 저축 계획을 구매하세요.
B. EC2 인스턴스 유형과 Fargate, Lambda vCPU와 동등한 항목을 포함하는 EC2 인스턴스 절감 플랜을 구매하세요.
C. 인스턴스 유형, 운영 체제, 지역 및 테넌시에 대한 예약 인스턴스를 구매하세요.
D. 각 지역에서 실행되는 기존 인스턴스의 유형 및 크기와 일치하는 EC2 스팟 인스턴스를 사용합니다.


회사가 핵심 애플리케이션을 주 7일, 하루 24시간 실행해야 하며, 가격 책정 모델에 유연성을 제공하고 비용 절감을 극대화해야 하는 경우, 가장 적합한 솔루션은 **D**입니다.

### 정답:
- **D. 각 지역에서 실행되는 기존 인스턴스의 유형 및 크기와 일치하는 EC2 스팟 인스턴스를 사용합니다.**

### 이유:
1. **비용 절감**:
   - EC2 스팟 인스턴스는 온디맨드 인스턴스보다 최대 90%까지 저렴할 수 있습니다. 애플리케이션이 항상 실행되어야 하는 경우 스팟 인스턴스를 활용하여 비용을 절감할 수 있습니다.

2. **유연성**:
   - 스팟 인스턴스는 필요에 따라 더 많은 용량을 확보할 수 있으며, 유연성을 제공합니다. 필요에 따라 다른 인스턴스 유형으로 전환할 수 있는 능력을 제공하므로, 운영 체제를 조합하여 사용하는 회사에 유리합니다.

3. **운영 효율성**:
   - 스팟 인스턴스를 사용할 때, AWS는 필요에 따라 인스턴스를 종료할 수 있지만, 회사는 적절한 오토 스케일링 및 인스턴스 관리를 통해 이 문제를 해결할 수 있습니다.

### 다른 선택지 분석:
- **A. 저축 계획 권장 사항을 기반으로 하는 컴퓨팅 저축 계획을 구매하세요.** 
  - 저축 계획은 일정 기간 동안 특정 컴퓨팅 리소스를 예약하는 모델이지만, 스팟 인스턴스처럼 유연성이 높지 않습니다.

- **B. EC2 인스턴스 유형과 Fargate, Lambda vCPU와 동등한 항목을 포함하는 EC2 인스턴스 절감 플랜을 구매하세요.**
  - 이 옵션은 유연성을 제공할 수 있지만, Fargate와 Lambda를 포함한 가격 책정 모델은 완전히 최적화되지 않을 수 있습니다.

- **C. 인스턴스 유형, 운영 체제, 지역 및 테넌시에 대한 예약 인스턴스를 구매하세요.**
  - 예약 인스턴스는 일정 기간 동안 리소스를 확보하지만, 고정된 리소스에 대한 선불 비용이 발생하여 가격 변화에 대한 유연성이 부족합니다.

### 결론:
따라서, **EC2 스팟 인스턴스를 사용하는 것은 가격 책정 모델에 대한 유연성을 유지하면서도 비용 절감을 극대화하는 데 가장 효과적인 방법**입니다.


## 질문 #309

회사의 아키텍처 팀은 회사의 주 AWS 프로덕션 계정에서 새로운 Amazon EC2 인스턴스가 시작될 때마다 즉시 이메일 알림을 받아야 합니다.

'SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 스마트 호스트 커넥터를 통해 이메일 메시지를 보내는 사용자 데이터 스크립트를 만듭니다. 아키텍처 팀의 이메일 주소를 수신자로 사용자 데이터 스크립트에 포함합니다. 모든 새 EC2 인스턴스에 표준화된 빌드 프로세스의 일부로 사용자 데이터 스크립트가 포함되어 있는지 확인합니다.
B. Amazon Simple Notification Service(Amazon SNS) 토픽과 이메일 프로토콜을 사용하는 구독을 만듭니다. 구독자로 아키텍처 팀의 이메일 주소를 입력합니다. EC2 인스턴스가 시작될 때 반응하는 Amazon EventBridge 규칙을 만듭니다. 규칙의 대상으로 SNS 토픽을 지정합니다.
C. Amazon Simple Queue Service(Amazon SQS) 대기열과 이메일 프로토콜을 사용하는 구독을 만듭니다. 구독자로 아키텍처 팀의 이메일 주소를 입력합니다. EC2 인스턴스가 시작될 때 반응하는 Amazon EventBridge 규칙을 만듭니다. 규칙의 대상으로 SQS 대기열을 지정합니다.
D. Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. AWS Systems Manager를 구성하여 EC2 이벤트를 SNS 토픽에 게시합니다. AWS Lambda 함수를 만들어 SNS 토픽을 폴링합니다. Lambda 함수를 구성하여 모든 메시지를 아키텍처 팀의 이메일 주소로 보냅니다.

회사의 아키텍처 팀이 새로운 Amazon EC2 인스턴스가 시작될 때마다 즉시 이메일 알림을 받기 위해 SysOps 관리자가 취해야 할 가장 효율적인 솔루션은 **B**입니다.

### 정답:
- **B. Amazon Simple Notification Service(Amazon SNS) 토픽과 이메일 프로토콜을 사용하는 구독을 만듭니다. 구독자로 아키텍처 팀의 이메일 주소를 입력합니다. EC2 인스턴스가 시작될 때 반응하는 Amazon EventBridge 규칙을 만듭니다. 규칙의 대상으로 SNS 토픽을 지정합니다.**

### 이유:
1. **Amazon SNS**:
   - SNS를 사용하여 간단하게 이메일 알림을 보낼 수 있습니다. SNS 토픽을 생성하고 아키텍처 팀의 이메일 주소를 구독자로 추가하면 EC2 인스턴스가 시작될 때 알림을 받을 수 있습니다.

2. **EventBridge**:
   - EventBridge를 사용하여 EC2 인스턴스 시작 이벤트를 캡처하고, 이 이벤트가 발생할 때 SNS 토픽에 메시지를 게시하도록 규칙을 설정할 수 있습니다. 이는 거의 실시간으로 알림을 받을 수 있도록 해줍니다.

3. **운영 효율성**:
   - 이 방법은 기존 AWS 서비스(즉, SNS와 EventBridge)를 활용하여 구현이 간단하며, 추가적인 복잡성을 필요로 하지 않습니다. Lambda 함수나 추가적인 시스템 구성 없이도 이메일 알림을 직접 받을 수 있습니다.

### 다른 선택지 분석:
- **A.** 사용자 데이터 스크립트를 통해 이메일을 보내는 것은 비효율적이며, 인스턴스가 시작될 때마다 수동으로 확인해야 할 필요가 있어 운영 오버헤드가 증가합니다.

- **C.** SQS 대기열을 사용하여 이메일을 보내는 것은 불필요하게 복잡하며, 알림을 받기 위해 SQS와 Lambda를 사용해야 하므로 더 많은 설정과 관리가 필요합니다.

- **D.** SNS와 Lambda를 결합하는 것은 가능하지만, SNS만으로도 충분히 요구 사항을 충족할 수 있으므로 과도한 솔루션입니다.

### 결론:
따라서 아키텍처 팀이 새로운 EC2 인스턴스가 시작될 때 즉시 이메일 알림을 받기 위해 SysOps 관리자가 취해야 할 최적의 방법은 **B**입니다.


## 질문 #310 +++++

SysOps 관리자는 개발자가 Amazon EC2 인스턴스에서 CPU 집약적 작업을 실행하는 AWS 계정을 관리합니다. 

작업을 완료하는 데 며칠이 걸릴 수 있으며 때로는 여러 번 반복해야 할 수도 있습니다. 개발자는 작업이 완료되면 인스턴스를 종료하는 것을 종종 잊어버립니다.

SysOps 관리자는 EC2 CPU 사용률을 모니터링하고 사용률이 낮은 인스턴스를 자동으로 종료하는 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. EC2 CPU 활용도에 기반한 Amazon GuardDuty 결과를 구성합니다. GuardDuty 결과에 AWS Lambda 함수를 연결하여 유휴로 식별된 모든 인스턴스를 종료합니다.
B. AWS Health Dashboard에서 EC2 사용률 메시지를 수신하도록 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다. AWS Lambda 함수를 만듭니다. Lambda 함수를 SNS 토픽에 구독합니다. ec2.stop_instances 작업을 사용하여 유휴 인스턴스를 종료합니다.
C. AWS Trusted Advisor에서 Low Utilization Amazon EC2 Instances 검사를 구성하여 Amazon Simple Notification Service(Amazon SNS) 토픽에 상태 변경 사항을 게시합니다. AWS Lambda 함수를 만듭니다. Lambda 함수를 SNS 토픽에 구독합니다. ec2.stop_instances 작업을 사용하여 유휴 인스턴스를 종료합니다.
D. AWS Trusted Advisor에서 Low Utilization Amazon EC2 Instances 확인에 대한 Amazon EventBridge 규칙을 구성합니다. EC2 Terminatelnstances API 호출을 대상으로 선택합니다.

개발자가 Amazon EC2 인스턴스에서 CPU 집약적 작업을 실행하며, 작업이 완료된 후 인스턴스를 종료하지 않는 문제를 해결하기 위해 EC2 CPU 사용률을 모니터링하고 사용률이 낮은 인스턴스를 자동으로 종료하는 솔루션으로는 **D**가 가장 적합합니다.

### 정답:
- **D. AWS Trusted Advisor에서 Low Utilization Amazon EC2 Instances 확인에 대한 Amazon EventBridge 규칙을 구성합니다. EC2 Terminatelnstances API 호출을 대상으로 선택합니다.**

### 이유:
1. **AWS Trusted Advisor**:
   - Trusted Advisor는 AWS 계정의 리소스를 모니터링하고 최적화를 위한 권장 사항을 제공합니다. Low Utilization EC2 Instances 검사를 사용하면 사용률이 낮은 EC2 인스턴스를 자동으로 식별할 수 있습니다.

2. **Amazon EventBridge**:
   - EventBridge를 사용하면 Trusted Advisor에서 발생하는 특정 이벤트(예: 사용률이 낮은 EC2 인스턴스가 발견됨)에 대해 규칙을 설정할 수 있습니다. 이를 통해 자동으로 EC2 TerminateInstances API를 호출하여 유휴 인스턴스를 종료할 수 있습니다.

3. **자동화**:
   - 이 솔루션은 자동화되어 있으며, 운영 오버헤드가 적고, 특정 조건에 따라 인스턴스를 종료하므로 개발자가 인스턴스를 수동으로 종료하는 것을 잊어버리는 문제를 해결할 수 있습니다.

### 다른 선택지 분석:
- **A.** GuardDuty는 보안 관련 활동을 모니터링하는 서비스로, CPU 활용도에 기반한 결과를 구성하는 것은 적합하지 않습니다.

- **B.** AWS Health Dashboard는 시스템 상태와 관련된 정보를 제공하지만, EC2 사용률 메시지를 수신하는 것은 최적의 접근 방식이 아닙니다. SNS와 Lambda를 사용한 종료 방법도 다소 복잡할 수 있습니다.

- **C.** Trusted Advisor에서 상태 변경 사항을 SNS 토픽에 게시하는 것도 가능하지만, 직접적으로 EventBridge를 사용하는 것보다는 덜 효율적입니다.

### 결론:
따라서 EC2 인스턴스의 CPU 사용률을 모니터링하고 자동으로 종료하는 가장 적합한 방법은 **D**입니다.

## 질문 #311 ++++

한 회사에 Amazon EC2를 사용하고자 하는 여러 사업부가 있습니다. 

이 회사는 모든 사업부가 승인된 EC2 인스턴스 구성만 사용하여 EC2 인스턴스를 프로비저닝하도록 요구하고자 합니다.

이 요구 사항을 구현하기 위해 SysOps 관리자는 무엇을 해야 합니까?

A. EC2 인스턴스 시작 구성을 만듭니다. AWS Management Console에서 이 시작 구성을 지정하여 사업부가 EC2 인스턴스를 시작하도록 허용합니다.
B. 사업부가 EC2 인스턴스만 프로비저닝하도록 제한하는 IAM 정책을 개발합니다. 사업부가 AWS CloudFormation 템플릿을 사용하여 인스턴스를 시작하도록 지시합니다.
C. AWS Service Catalog를 사용하여 EC2 인스턴스에 대한 제품 및 시작 제약 역할을 게시합니다. 사업부가 AWS Service Catalog에서만 작업을 수행하도록 허용합니다.
D. AWS CloudFormation 템플릿을 사업부와 공유합니다. 사업부에 AWS CloudFormation에 역할을 전달하여 서비스가 EC2 인스턴스를 관리할 수 있도록 지시합니다.


여러 사업부가 승인된 EC2 인스턴스 구성만 사용하여 EC2 인스턴스를 프로비저닝하도록 요구하는 경우, 가장 적합한 솔루션은 **C**입니다.

### 정답:
- **C. AWS Service Catalog를 사용하여 EC2 인스턴스에 대한 제품 및 시작 제약 역할을 게시합니다. 사업부가 AWS Service Catalog에서만 작업을 수행하도록 허용합니다.**

### 이유:
1. **AWS Service Catalog**:
   - AWS Service Catalog는 승인된 제품(이 경우 EC2 인스턴스 구성)을 조직 내에서 쉽게 배포하고 관리할 수 있도록 도와줍니다. 이를 통해 각 사업부는 미리 정의된 템플릿과 구성을 사용하여 EC2 인스턴스를 프로비저닝할 수 있습니다.
   
2. **제품과 제약**:
   - Service Catalog를 사용하면 다양한 EC2 인스턴스 제품을 정의하고 이를 기반으로 제약 조건을 설정하여 사업부가 승인된 구성만 사용할 수 있도록 할 수 있습니다. 이를 통해 각 사업부는 필요한 인스턴스를 손쉽게 배포하되, 회사의 정책을 준수할 수 있습니다.

3. **관리 용이성**:
   - Service Catalog를 사용하면 관리자가 승인된 인스턴스 구성을 쉽게 업데이트하거나 변경할 수 있으며, 이러한 변경 사항은 자동으로 모든 사업부에 적용됩니다.

### 다른 선택지 분석:
- **A.** EC2 인스턴스 시작 구성을 사용하는 것은 EC2 인스턴스를 시작하는 방법 중 하나이지만, 모든 사업부가 시작 구성만 사용하도록 강제할 수는 없습니다.

- **B.** IAM 정책을 개발하는 것은 제한적일 수 있으며, IAM 정책만으로는 EC2 인스턴스의 구성을 제어하기 어렵습니다. CloudFormation 템플릿을 사용하는 것은 다소 복잡할 수 있습니다.

- **D.** CloudFormation 템플릿을 공유하는 것도 유용하지만, 각 사업부가 템플릿을 사용할 수 있도록 역할을 부여하는 것은 관리 측면에서 비효율적이며, 각 인스턴스의 구성을 일관되게 관리하는 데 한계가 있습니다.

### 결론:
따라서 승인된 EC2 인스턴스 구성을 사용하여 인스턴스를 프로비저닝하도록 요구하는 경우 **C**를 선택하는 것이 가장 적합합니다.


## 질문 #312

SysOps 관리자는 AWS CloudFormation 템플릿에서 생성된 Amazon RDS 데이터베이스의 자격 증명을 보호해야 합니다. 


솔루션은 자격 증명을 암호화해야 하며 자동 로테이션을 지원해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. CloudFormation 템플릿에서 AWS::SecretsManager::Secret 리소스를 만듭니다. resolve:secretsmanager 동적 참조를 사용하여 AWS::RDS::DBInstance 리소스에서 자격 증명을 참조합니다.
B. CloudFormation 템플릿에서 AWS::SecretsManager::Secret 리소스를 만듭니다. resolve:ssm-secure 동적 참조를 사용하여 AWS::RDS::DBInstance 리소스에서 자격 증명을 참조합니다.
C. CloudFormation 템플릿에서 AWS::SSM::Parameter 리소스를 만듭니다. resolve:ssm 동적 참조를 사용하여 AWS::RDS::DBInstance 리소스에서 자격 증명을 참조합니다.
D. CloudFormation 템플릿에서 데이터베이스 자격 증명에 대한 매개변수를 만듭니다. Ref 내장 함수를 사용하여 AWS::RDS::DBInstance 리소스에 자격 증명을 제공합니다.


RDS 데이터베이스 자격 증명을 보호하고, 암호화 및 자동 로테이션을 지원하는 가장 적합한 솔루션은 **A**입니다.

### 정답:
- **A. CloudFormation 템플릿에서 AWS::SecretsManager::Secret 리소스를 만듭니다. resolve:secretsmanager 동적 참조를 사용하여 AWS::RDS::DBInstance 리소스에서 자격 증명을 참조합니다.**

### 이유:
1. **AWS Secrets Manager 사용**:
   - AWS Secrets Manager는 비밀번호 및 자격 증명과 같은 중요한 정보를 안전하게 저장하고 관리할 수 있는 서비스입니다. 자격 증명을 자동으로 로테이션할 수 있는 기능을 제공하므로 데이터베이스 자격 증명 관리에 적합합니다.

2. **동적 참조**:
   - CloudFormation 템플릿에서 `resolve:secretsmanager` 동적 참조를 사용하면 Secrets Manager에 저장된 비밀을 안전하게 참조할 수 있습니다. 이 방식은 템플릿의 안전성과 효율성을 높이고, 자격 증명을 템플릿의 코드에 직접 포함하지 않도록 합니다.

3. **암호화**:
   - Secrets Manager는 저장된 비밀을 자동으로 암호화하여 보안을 강화합니다. 이를 통해 자격 증명이 안전하게 저장됩니다.

### 다른 선택지 분석:
- **B.** `resolve:ssm-secure` 동적 참조는 AWS Systems Manager Parameter Store에서 보안 매개변수를 사용할 때 유용하지만, 자동 로테이션 기능은 제공하지 않습니다.

- **C.** `AWS::SSM::Parameter`를 사용하여 자격 증명을 저장할 수 있지만, 이 경우 자동 로테이션 기능은 제공되지 않습니다.

- **D.** CloudFormation 템플릿에서 매개변수를 직접 정의하고 제공하는 방법은 자격 증명을 암호화할 수 없으며, 자동 로테이션을 지원하지 않습니다.

### 결론:
따라서 RDS 데이터베이스 자격 증명을 암호화하고 자동 로테이션을 지원하는 가장 적절한 솔루션은 **A**입니다.


## 질문 #313

한 회사가 AWS 내에서 Amazon EC2와 Amazon RDS에 대한 지출을 추적하고자 합니다. 

이 회사는 AWS 계정의 리소스에 대해 더 엄격한 태그 지정 요구 사항을 구현하기로 결정했습니다. SysOps 관리자는 모든 비준수 리소스를 식별해야 합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 지정된 태그에 대해 생성되거나 업데이트된 모든 리소스를 평가하는 사용자 지정 AWS Lambda 함수를 호출하는 Amazon EventBridge에서 규칙을 만듭니다.
B. AWS Config에서 지정된 태그에 대해 모든 리소스를 평가하는 사용자 지정 AWS Lambda 함수를 호출하는 규칙을 만듭니다.
C. 지정된 태그에 대해 모든 리소스를 평가하기 위해 필수 태그 관리 규칙으로 AWS Config에 규칙을 만듭니다.
D. 지정된 태그에 대해 생성되거나 업데이트된 모든 리소스를 평가하는 관리형 규칙으로 Amazon EventBridge에서 규칙을 만듭니다.

비준수 리소스를 식별하기 위한 가장 운영 효율적인 솔루션은 **C**입니다.

### 정답:
- **C. 지정된 태그에 대해 모든 리소스를 평가하기 위해 필수 태그 관리 규칙으로 AWS Config에 규칙을 만듭니다.**

### 이유:
1. **AWS Config의 규칙 사용**:
   - AWS Config는 AWS 리소스의 구성 변경을 추적하고, 규정 준수를 평가할 수 있는 기능을 제공합니다. 필수 태그 관리 규칙을 설정하면 AWS Config는 자동으로 리소스를 스캔하여 지정된 태그가 있는지 확인하고, 비준수 리소스를 식별하여 상태를 보고합니다.

2. **운영 효율성**:
   - AWS Config를 사용하는 것은 수동 개입 없이 리소스의 태그 준수 상태를 지속적으로 모니터링하고 평가할 수 있도록 하여 관리 오버헤드를 최소화합니다.

### 다른 선택지 분석:
- **A.** 사용자 지정 AWS Lambda 함수를 호출하는 Amazon EventBridge 규칙을 만들면 비준수 리소스를 감지할 수 있지만, Lambda 함수의 유지 관리가 필요하여 운영 효율성이 떨어집니다.

- **B.** AWS Config에서 사용자 지정 Lambda 함수를 호출하여 리소스를 평가할 수 있지만, 이 또한 관리해야 할 코드와 복잡성을 증가시킵니다.

- **D.** 관리형 규칙으로 EventBridge를 사용하여 태그를 평가할 수 있지만, AWS Config가 제공하는 태그 준수 상태 모니터링과 보고 기능에 비해 상대적으로 제한적입니다.

### 결론:
따라서 모든 비준수 리소스를 식별하고 추적하기 위해 가장 운영 효율적인 솔루션은 **C**입니다.

## 질문 #314 +++

한 회사에서 새로운 Amazon FSx for Windows File Server 파일 시스템을 만듭니다.

 비용을 관리하기 위해 회사는 최소한의 성장 여지를 두고 파일 시스템의 스토리지 용량을 구성합니다.

회사는 파일 시스템이 있는 동일한 AWS 계정에 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. 회사는 SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다. SysOps 관리자는 파일 시스템의 사용 가능한 공간이 100GB 미만일 때 이메일 알림을 받아야 합니다. SysOps 관리자 는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. FreeStorageCapacity 지표가 100,000,000,000바이트(100GB) 이하일 때 Amazon EventBridge 규칙을 생성합니다.
B. FreeStorageCapacity 메트릭이 100,000,000,000바이트(100GB) 이하일 때 Amazon CloudWatch 알람을 생성합니다.
C. Amazon CloudWatch 알람이 ALARM 상태로 전환되면 실행되는 AWS Lambda 함수를 만듭니다. Lambda 함수를 구성하여 SNS 토픽에 게시합니다.
D. 규칙이 ALARM 상태로 전환되면 SNS 주제에 게시하도록 Amazon EventBridge 규칙의 알람 동작을 구성합니다.
E. 알람이 ALARM 상태로 전환되면 SNS 주제에 게시하도록 Amazon CloudWatch 알람 작업을 구성합니다.

SysOps 관리자가 Amazon FSx for Windows File Server의 사용 가능한 공간이 100GB 미만일 때 이메일 알림을 받도록 요구 사항을 충족하기 위해 필요한 단계의 조합은 **B**와 **E**입니다.

### 정답:
- **B. FreeStorageCapacity 메트릭이 100,000,000,000바이트(100GB) 이하일 때 Amazon CloudWatch 알람을 생성합니다.**
- **E. 알람이 ALARM 상태로 전환되면 SNS 주제에 게시하도록 Amazon CloudWatch 알람 작업을 구성합니다.**

### 이유:
1. **B 선택지**: 
   - `FreeStorageCapacity` 메트릭을 모니터링하여 파일 시스템의 사용 가능한 공간을 감지하고, 이 메트릭이 100GB(100,000,000,000바이트) 미만일 때 CloudWatch 알람을 생성하여 해당 상황을 인지할 수 있게 합니다.

2. **E 선택지**: 
   - CloudWatch 알람이 ALARM 상태로 전환될 때 SNS 주제에 알림을 게시하도록 구성하면, SysOps 관리자는 설정한 이메일로 알림을 받을 수 있습니다. 이는 직접적인 방법으로 요구 사항을 충족합니다.

### 다른 선택지 분석:
- **A.** EventBridge 규칙을 사용하여 `FreeStorageCapacity`를 모니터링할 수 있지만, CloudWatch 알람을 직접 사용하는 것이 더 일반적이고 효율적입니다.
  
- **C.** Lambda 함수를 사용하는 대신 CloudWatch 알람 자체에서 SNS에 직접 게시하는 것이 더 간단하고 운영 효율성이 높습니다.

- **D.** EventBridge 규칙을 사용하는 것도 가능하지만, 이 경우 CloudWatch 알람이 ALARM 상태로 전환될 때 SNS로 직접 게시하는 것이 더 효과적입니다.

### 결론:
따라서 SysOps 관리자가 Amazon FSx for Windows File Server의 사용 가능한 공간에 대한 알림을 받기 위해 수행해야 할 최적의 단계는 **B**와 **E**입니다.



## 질문 #315

한 회사가 EC2 인스턴스 중에 비생산 Amazon EC2 인스턴스를 중지하기로 결정했습니다.

회사의 IT 관리자는 밤에 비생산이라는 환경 유형 태그 값을 가진 EC2 인스턴스가 시작될 때마다 거의 실시간으로 알림을 받아야 합니다.

어떤 솔루션이 가장 높은 운영 효율성으로 이 요구 사항을 충족할까요?

A. SMTP 클라이언트 라이브러리로 AWS Lambda 함수를 구성합니다. EC2 인스턴스가 실행 상태일 때마다 알림을 받으려면 Lambda 함수를 AWS Health Dashboard에 구독합니다. Amazon Pinpoint를 사용하여 IT 관리자에게 이메일 알림을 보내도록 Lambda 함수를 구성합니다. 낮 동안 첫 번째 Lambda 함수의 호출을 제한하기 위해 두 번째 Lambda 함수를 배포합니다.
B. 각 EC2 인스턴스의 상태를 확인하기 위해 Amazon EC2 API를 쿼리하는 AWS Lambda 함수를 배포합니다. EC2 인스턴스 스케줄러를 사용하여 Lambda 함수를 밤 동안 매분 실행하고 실행 중인 상태인 각 비생산 EC2 인스턴스에 대해 IT 관리자에게 이메일 알림을 보내도록 구성합니다.
C. EC2 인스턴스 상태 변경 알림 이벤트 유형을 포함하는 Amazon EventBridge 규칙을 만듭니다. 실행 상태만 캡처하도록 이벤트를 필터링합니다. 규칙의 대상으로 AWS Lambda 함수를 만듭니다. Lambda 함수가 현재 시간과 EC2 인스턴스의 태그를 확인하여 환경 유형을 확인하도록 구성합니다. 알림에 대한 Lambda 함수의 대상으로 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. IT 관리자의 이메일 주소를 SNS 토픽에 구독합니다.
D. 환경 유형을 포함한 EC2 인스턴스 메타데이터를 Amazon DynamoDB 테이블에 저장합니다. EC2 인스턴스에 사용자 지정 애플리케이션을 배포합니다. 사용자 지정 애플리케이션을 구성하여 밤에 매분 DynamoDB 데이터를 폴링하고 Amazon EC2 API를 쿼리하여 각 인스턴스의 상태를 확인합니다. 또한 사용자 지정 애플리케이션을 구성하여 실행 상태인 각 비생산 EC2 인스턴스에 대해 IT 관리자에게 이메일 알림을 보냅니다.

IT 관리자가 비생산 Amazon EC2 인스턴스가 시작될 때마다 거의 실시간으로 알림을 받을 수 있도록 하려면 가장 효율적인 솔루션은 **C**입니다.

### 정답:
- **C. EC2 인스턴스 상태 변경 알림 이벤트 유형을 포함하는 Amazon EventBridge 규칙을 만듭니다. 실행 상태만 캡처하도록 이벤트를 필터링합니다. 규칙의 대상으로 AWS Lambda 함수를 만듭니다. Lambda 함수가 현재 시간과 EC2 인스턴스의 태그를 확인하여 환경 유형을 확인하도록 구성합니다. 알림에 대한 Lambda 함수의 대상으로 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. IT 관리자의 이메일 주소를 SNS 토픽에 구독합니다.**

### 이유:
1. **EventBridge 사용:** Amazon EventBridge는 AWS 서비스에서 발생하는 이벤트를 캡처하고 처리하는 데 최적화되어 있습니다. EC2 인스턴스의 상태 변경 이벤트(예: 시작 또는 중지)를 캡처할 수 있으며, 이를 통해 비생산 환경 태그가 있는 인스턴스에 대한 실시간 알림을 설정할 수 있습니다.
  
2. **Lambda와 SNS 통합:** Lambda 함수를 사용하여 EC2 인스턴스의 태그를 확인하고 비생산 인스턴스의 시작 이벤트에 대해 알림을 전송할 수 있습니다. SNS는 알림을 IT 관리자에게 전달하는 데 효율적인 방법입니다.

3. **운영 효율성:** 이 솔루션은 간단하고 관리가 용이하며, 수동 개입이 필요하지 않아서 운영 오버헤드가 낮습니다.

### 다른 선택지 분석:
- **A.** 이 옵션은 AWS Health Dashboard에 의존하고 SMTP 클라이언트를 구성해야 하며, 이는 불필요하게 복잡합니다.
  
- **B.** 매분 Lambda 함수를 실행하는 것은 불필요한 리소스 소모를 초래하고, 상태를 확인하는 것보다 이벤트 기반 접근 방식이 더 효율적입니다.
  
- **D.** DynamoDB와 사용자 지정 애플리케이션을 사용하는 것은 관리와 유지보수가 복잡하고, AWS의 기본 제공 기능을 활용하는 것보다 운영 효율성이 낮습니다.

### 결론:
따라서 **C**가 요구 사항을 가장 잘 충족하고 높은 운영 효율성을 제공하는 솔루션입니다.


## 질문 #316 +++++

회사의 SysOps 관리자는 단일 AWS 계정에서 실행되는 Windows Amazon EC2 인스턴스의 플릿을 관리합니다. 

인스턴스에는 "OS" 키와 "Windows" 값이 포함된 태그가 있습니다. 회사는 AWS Systems Manager를 사용하여 인스턴스에 패치를 적용합니다.

회사는 인스턴스에 Amazon CloudWatch 에이전트를 설치했지만 구성이 일관되지 않습니다. SysOps 관리자는 모든 인스턴스를 재구성하여 동일한 사전 정의된 CloudWatch 구성을 사용해야 합니다.

이러한 요구 사항을 충족하는 단계의 조합은 무엇입니까? (두 가지를 선택하십시오.)

A. CloudWatch 에이전트 구성 파일을 Amazon S3 버킷에 저장합니다.
B. CloudWatch 에이전트 구성 파일의 내용을 Systems Manager OpsCenter에 저장합니다.
C. CloudWatch 에이전트 구성 파일의 내용을 Systems Manager Parameter Store에 저장합니다.
D. AmazonCloudWatch-ManageAgent Systems Manager Run Command 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. Systems Manager를 선택적 구성 소스로 선택합니다. 태그 값에 따라 인스턴스를 타겟팅합니다.
E. AmazonCloudWatch-ManageAgent Systems Manager Run Command 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. S3 버킷 위치를 구성 소스로 사용하도록 문서를 구성합니다. 태그 값을 기준으로 인스턴스를 타겟팅합니다.

요구 사항을 충족하기 위해 필요한 단계를 선택하는 것은 AWS Systems Manager를 사용하여 모든 Windows EC2 인스턴스에 일관된 Amazon CloudWatch 에이전트 구성을 적용하는 것입니다. 이 경우 가장 적합한 두 가지 단계를 선택하면 다음과 같습니다.

### 정답:
- **A. CloudWatch 에이전트 구성 파일을 Amazon S3 버킷에 저장합니다.**
- **D. AmazonCloudWatch-ManageAgent Systems Manager Run Command 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. Systems Manager를 선택적 구성 소스로 선택합니다. 태그 값에 따라 인스턴스를 타겟팅합니다.**

### 설명:
1. **A. CloudWatch 에이전트 구성 파일을 Amazon S3 버킷에 저장합니다.**
   - CloudWatch 에이전트의 구성을 S3 버킷에 저장하면, 인스턴스에서 쉽게 접근할 수 있고, 일관된 구성 파일을 유지할 수 있습니다.

2. **D. AmazonCloudWatch-ManageAgent Systems Manager Run Command 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. Systems Manager를 선택적 구성 소스로 선택합니다. 태그 값에 따라 인스턴스를 타겟팅합니다.**
   - Systems Manager State Manager를 사용하면 태그를 기반으로 EC2 인스턴스를 자동으로 관리할 수 있으며, 모든 인스턴스에 일관된 CloudWatch 에이전트 구성을 적용할 수 있습니다. 이 단계에서는 S3 버킷에서 구성 파일을 가져오도록 설정할 수 있습니다.

### 다른 선택지 분석:
- **B. CloudWatch 에이전트 구성 파일의 내용을 Systems Manager OpsCenter에 저장합니다.**
  - OpsCenter는 문제 해결을 위한 도구로, 구성 파일을 저장하기에 적합하지 않습니다.

- **C. CloudWatch 에이전트 구성 파일의 내용을 Systems Manager Parameter Store에 저장합니다.**
  - Parameter Store를 사용할 수 있지만, S3에 저장하는 것이 구성 관리 및 배포 측면에서 더 유연하고 적합합니다.

- **E. AmazonCloudWatch-ManageAgent Systems Manager Run Command 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. S3 버킷 위치를 구성 소스로 사용하도록 문서를 구성합니다. 태그 값을 기준으로 인스턴스를 타겟팅합니다.**
  - 이 선택지의 경우, S3 버킷을 소스로 사용하지만, 이미 A 단계에서 S3에 구성을 저장한다고 가정하면 D 단계가 더 적합합니다.

### 결론:
따라서 **A**와 **D**를 선택하면 모든 Windows EC2 인스턴스에 대해 일관된 CloudWatch 에이전트 구성을 성공적으로 적용할 수 있습니다.


## 질문 #317 +

한 회사에서 Amazon EC2 인스턴스에서 실행되는 레거시 소프트웨어에 문제가 있습니다. 

EC2 인스턴스의 총 CPU 사용률이 80%를 초과하면 오류가 발생합니다. 소프트웨어를 다시 작성하는 동안 단기 솔루션이 필요합니다. SysOps 관리자는 CPU 사용률이 80%를 초과하면 인스턴스를 다시 시작하는 솔루션을 만드는 작업을 맡았습니다.

어떤 솔루션이 이러한 요구 사항을 가장 적은 운영 오버헤드로 충족합니까?

A. EC2 인스턴스의 CPU 사용률을 모니터링하고 사용률이 80%를 초과하면 인스턴스를 재부팅하는 스크립트를 작성합니다. 스크립트를 cron 작업으로 실행합니다.
B. CPU 사용률에 대한 Amazon CloudWatch 알람을 추가하고 EC2 인스턴스를 재부팅하도록 알람 작업을 구성합니다.
C. EC2 인스턴스의 CPU 사용률에 대한 사전 정의된 패턴을 사용하여 Amazon EventBridge 규칙을 만듭니다. 사용률이 80%를 초과하면 AWS Lambda 함수를 호출하여 인스턴스를 다시 시작합니다.
D. CPU 사용률에 대한 Amazon CloudWatch 알람을 추가하고 사용률이 80%를 초과하면 EC2 인스턴스를 재부팅하도록 AWS Systems Manager Automation 런북을 구성합니다.


요구 사항에 따라 Amazon EC2 인스턴스의 CPU 사용률이 80%를 초과할 때 자동으로 인스턴스를 다시 시작하는 가장 적은 운영 오버헤드 솔루션은 다음과 같습니다.

### 정답: **B. CPU 사용률에 대한 Amazon CloudWatch 알람을 추가하고 EC2 인스턴스를 재부팅하도록 알람 작업을 구성합니다.**

### 설명:
- **B. CPU 사용률에 대한 Amazon CloudWatch 알람을 추가하고 EC2 인스턴스를 재부팅하도록 알람 작업을 구성합니다.**  
  - 이 솔루션은 CloudWatch 알람을 사용하여 CPU 사용률을 모니터링하고, 80%를 초과할 경우 자동으로 인스턴스를 재부팅하는 작업을 설정합니다. 이 방법은 최소한의 운영 오버헤드로 관리할 수 있으며, 다른 방법보다 간단하고 신뢰성이 높습니다.

### 다른 선택지 분석:
- **A. EC2 인스턴스의 CPU 사용률을 모니터링하고 사용률이 80%를 초과하면 인스턴스를 재부팅하는 스크립트를 작성합니다. 스크립트를 cron 작업으로 실행합니다.**  
  - 이 방법은 스크립트를 관리해야 하므로 운영 오버헤드가 발생합니다. 또한 cron 작업이 실패할 경우를 대비한 복원력 문제가 발생할 수 있습니다.

- **C. EC2 인스턴스의 CPU 사용률에 대한 사전 정의된 패턴을 사용하여 Amazon EventBridge 규칙을 만듭니다. 사용률이 80%를 초과하면 AWS Lambda 함수를 호출하여 인스턴스를 다시 시작합니다.**  
  - EventBridge 규칙과 Lambda를 사용하는 방법은 유연하지만, Lambda 함수를 생성하고 관리해야 하므로 운영 오버헤드가 증가할 수 있습니다.

- **D. CPU 사용률에 대한 Amazon CloudWatch 알람을 추가하고 사용률이 80%를 초과하면 EC2 인스턴스를 재부팅하도록 AWS Systems Manager Automation 런북을 구성합니다.**  
  - 이 방법은 CloudWatch 알람을 사용하지만, Systems Manager Automation을 설정하고 관리해야 하므로 상대적으로 더 복잡하고 운영 오버헤드가 발생합니다.

### 결론:
가장 적은 운영 오버헤드를 가지면서도 요구 사항을 충족하는 방법은 **B**입니다. CloudWatch 알람을 사용하여 EC2 인스턴스를 자동으로 재부팅하는 것이 가장 간단하고 효율적인 솔루션입니다.


## 질문 #318 +

SysOps 관리자가 VPC의 프라이빗 서브넷에서 Amazon EC2 인스턴스를 시작합니다. 
SysOps 관리자가 EC2 인스턴스의 명령줄에서 curl 명령을 시도하면 SysOps 관리자가 https:www.example.com에 연결할 수 없습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?


A. 포트 443에서 0.0.0.0/0으로의 아웃바운드 보안 그룹이 있는지 확인하세요.
B. 0.0.0.0/0에서 포트 443에 대한 인바운드 보안 그룹이 있는지 확인하세요.
C. 1024-66535~0.0.0.0/0의 임시 포트에 대한 아웃바운드 네트워크 ACL이 있는지 확인하세요.
D. 포트 80에서 0.0.0.0/0으로의 아웃바운드 네트워크 ACL이 있는지 확인하세요.

EC2 인스턴스가 프라이빗 서브넷에 있을 때, 외부 인터넷에 연결하기 위해서는 NAT 게이트웨이를 사용하거나 인터넷 게이트웨이를 통해 아웃바운드 트래픽을 허용해야 합니다. curl 명령을 사용하여 HTTPS(포트 443) 사이트에 연결할 수 없는 문제를 해결하기 위해 SysOps 관리자가 확인해야 할 사항은 다음과 같습니다.

### 정답: **A. 포트 443에서 0.0.0.0/0으로의 아웃바운드 보안 그룹이 있는지 확인하세요.**

### 설명:
- **A. 포트 443에서 0.0.0.0/0으로의 아웃바운드 보안 그룹이 있는지 확인하세요.**  
  - EC2 인스턴스에서 HTTPS 요청을 수행하려면 아웃바운드 보안 그룹에서 포트 443이 0.0.0.0/0으로 열려 있어야 합니다. 이를 통해 EC2 인스턴스가 외부 웹사이트에 대한 HTTPS 요청을 보낼 수 있습니다.

### 다른 선택지 분석:
- **B. 0.0.0.0/0에서 포트 443에 대한 인바운드 보안 그룹이 있는지 확인하세요.**  
  - 인바운드 규칙은 외부에서 EC2 인스턴스로의 트래픽을 허용하는 규칙으로, curl 명령의 경우 아웃바운드 연결이 필요하므로 이 선택지는 적절하지 않습니다.

- **C. 1024-65535의 임시 포트에 대한 아웃바운드 네트워크 ACL이 있는지 확인하세요.**  
  - NAT 게이트웨이를 사용하여 인터넷에 연결하려는 경우, 임시 포트에 대한 아웃바운드 규칙도 필요하지만, 포트 443에 대한 직접적인 아웃바운드 규칙이 우선적으로 확인되어야 합니다.

- **D. 포트 80에서 0.0.0.0/0으로의 아웃바운드 네트워크 ACL이 있는지 확인하세요.**  
  - 포트 80은 HTTP 요청을 위한 것이며, 이 경우 HTTPS 요청을 수행하려고 하므로 포트 443의 아웃바운드 규칙을 확인해야 합니다.

### 결론:
따라서, EC2 인스턴스가 https://www.example.com에 연결할 수 없을 때 SysOps 관리자가 확인해야 할 사항은 **A. 포트 443에서 0.0.0.0/0으로의 아웃바운드 보안 그룹이 있는지 확인하세요.**입니다.


## 질문 #319

SysOps 관리자는 Amazon EC2 리소스와 Amazon RDS 리소스에 대한 백업 전략을 구현해야 합니다. 백업 전략은 다음 보존 요구 사항을 충족해야 합니다.

• 일일 백업: 6일 동안 보관해야 함
• 주간 백업: 4주 동안 보관해야 함:
• 월간 백업: 11개월 동안 보관해야 함
• 연간 백업: 7년 동안 보관해야 함

어떤 백업 전략이 최소한의 관리 노력으로 이러한 요구 사항을 충족할까요?

A. Amazon Data Lifecycle Manager를 사용하여 Amazon Elastic Block Store(Amazon EBS) 스냅샷 정책을 만듭니다. 백업해야 하는 각 리소스에 태그를 만듭니다. 정책 내 요구 사항에 따라 여러 일정을 만듭니다. 적절한 빈도와 보관 기간을 설정합니다.
B. AWS Backup을 사용하여 매일, 매주, 매월 또는 매년 백업 빈도로 각 보존 요구 사항에 대한 새 백업 계획을 만듭니다. 요구 사항에 맞게 보존 기간을 설정합니다. 백업해야 하는 각 리소스에 태그를 만듭니다. 태그를 사용하여 리소스 할당을 설정합니다.
C. AWS Lambda 함수를 만듭니다. Lambda 함수를 프로그래밍하여 네이티브 툴링을 사용하여 Amazon EC2의 파일 시스템을 백업하고 Amazon RDS의 데이터베이스를 복사합니다. Lambda 함수를 호출하는 Amazon EventBridge 규칙을 만듭니다.
D. Amazon Data Lifecycle Manager를 사용하여 Amazon Elastic Block Store(Amazon EBS) 스냅샷 정책을 만듭니다. 백업해야 하는 각 리소스에 태그를 만듭니다. 태그를 사용하여 리소스 할당을 설정합니다. 정책 내의 요구 사항에 따라 여러 일정을 만듭니다. 적절한 빈도와 보관 기간을 설정합니다. Amazon RDS에서 필요한 DB 인스턴스에 대한 자동 백업을 활성화합니다.

주어진 백업 요구 사항을 충족하기 위한 최소한의 관리 노력으로 적합한 백업 전략은 **B. AWS Backup을 사용하여 매일, 매주, 매월 또는 매년 백업 빈도로 각 보존 요구 사항에 대한 새 백업 계획을 만듭니다. 요구 사항에 맞게 보존 기간을 설정합니다. 백업해야 하는 각 리소스에 태그를 만듭니다. 태그를 사용하여 리소스 할당을 설정합니다.**입니다.

### 선택 이유:
1. **중앙 집중식 관리**: AWS Backup은 여러 AWS 서비스의 백업을 중앙에서 관리할 수 있게 해주므로, EC2 및 RDS 리소스에 대한 백업을 일관된 방식으로 수행할 수 있습니다.

2. **정확한 보존 기간 설정**: AWS Backup을 사용하면 각 백업 계획에 대해 일일, 주간, 월간, 연간 백업에 대한 보존 기간을 쉽게 설정할 수 있어, 요구 사항에 부합하는 정확한 관리가 가능합니다.

3. **태그를 통한 리소스 관리**: 각 리소스에 태그를 추가하여 백업할 리소스를 쉽게 식별하고 관리할 수 있습니다. 이를 통해 리소스 할당을 효율적으로 설정할 수 있습니다.

4. **자동화**: AWS Backup은 백업 작업을 자동으로 수행하여 관리자의 수동 개입을 최소화하므로 운영 효율성이 높아집니다.

### 다른 옵션 분석:
- **A. Amazon Data Lifecycle Manager**: EBS 스냅샷 정책을 통해 EC2 리소스의 백업을 관리할 수 있지만, RDS 리소스에 대한 백업을 별도로 관리해야 하며, 이는 추가적인 관리 노력을 요구합니다.

- **C. AWS Lambda 함수**: 이 방법은 프로그래밍과 관리 노력이 많이 들어가며, 코드의 유지보수가 필요합니다. 또한, EC2와 RDS 각각의 백업 작업을 관리해야 하므로 비효율적입니다.

- **D. Amazon Data Lifecycle Manager와 RDS 자동 백업 결합**: EBS 스냅샷과 RDS 자동 백업을 결합한 방식은 괜찮지만, AWS Backup을 사용하는 것보다 관리가 복잡할 수 있으며, 각 리소스를 위한 별도의 정책을 설정해야 하므로 여전히 관리 노력이 필요합니다.

### 결론:
따라서, 가장 간편하고 효율적으로 백업 요구 사항을 충족할 수 있는 방법은 **B. AWS Backup을 사용하여 매일, 매주, 매월 또는 매년 백업 빈도로 각 보존 요구 사항에 대한 새 백업 계획을 만듭니다.**입니다. 이 방법은 관리 노력을 최소화하면서도 필요한 백업을 적절하게 수행할 수 있습니다.


## 질문 #320 +++++ 

애플리케이션 팀은 하나의 Aurora Replica가 있는 Amazon Aurora MySQL DB 클러스터를 사용합니다. 

애플리케이션 팀은 사용자 연결이 200을 초과하면 애플리케이션 읽기 성능이 저하된다는 것을 알아차렸습니다. 사용자 연결 수는 일반적으로 180으로 일정하며, 가끔 200개 이상의 연결로 갑자기 증가합니다. 애플리케이션 팀은 사용자 수요가 증가하거나 감소함에 따라 애플리케이션이 자동으로 확장되기를 원합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 새로운 Aurora 멀티마스터 DB 클러스터로 마이그레이션합니다. 애플리케이션 데이터베이스 연결 문자열을 수정합니다.
B. 사용자 연결이 200개를 초과할 때마다 서버리스 모드로 변경하여 DB 클러스터를 수정합니다.
C. 195개의 DatabaseConnections를 대상 메트릭으로 자동 크기 조정 정책을 만듭니다.
D. Aurora Replica 인스턴스 크기를 늘려 DB 클러스터를 수정합니다.

애플리케이션 팀이 Amazon Aurora MySQL DB 클러스터에서 사용자 연결 수가 200을 초과할 때 읽기 성능 저하를 경험하고 있으며, 사용자 수요에 따라 애플리케이션이 자동으로 확장되기를 원하는 경우, 가장 적절한 솔루션은 **C. 195개의 DatabaseConnections를 대상 메트릭으로 자동 크기 조정 정책을 만듭니다.**입니다.

### 선택 이유:
1. **자동 크기 조정**: 이 방법은 Aurora DB 클러스터의 연결 수를 기준으로 자동으로 리소스를 조정하여, 수요에 따라 인스턴스가 자동으로 추가되거나 제거됩니다. 이로 인해 애플리케이션이 사용자 수요에 대응할 수 있습니다.

2. **성능 최적화**: 195개의 데이터베이스 연결을 기준으로 설정함으로써, 연결 수가 증가할 때 자동으로 필요한 리소스를 추가하여 성능 저하를 방지할 수 있습니다. 이를 통해 200개 이상의 연결이 발생할 경우에도 애플리케이션의 읽기 성능이 유지됩니다.

3. **비용 효율성**: 필요할 때만 인스턴스를 추가함으로써 비용을 최적화할 수 있습니다. 이 방법은 특히 변동성이 큰 트래픽을 처리하는 데 유리합니다.

### 다른 옵션 분석:
- **A. 새로운 Aurora 멀티마스터 DB 클러스터로 마이그레이션합니다.**: 멀티마스터 클러스터는 여러 마스터 노드에서 읽기 및 쓰기가 가능하지만, 설정과 마이그레이션 과정이 복잡하고, 현재의 연결 문제를 해결하는 즉각적인 해결책이 아닙니다.

- **B. 사용자 연결이 200개를 초과할 때마다 서버리스 모드로 변경하여 DB 클러스터를 수정합니다.**: Aurora Serverless는 요청에 따라 자동으로 인스턴스를 시작하고 중지하지만, 이 방법은 현재 설정된 DB 클러스터에서 직접 적용할 수 없습니다. Aurora Serverless는 서버리스 아키텍처를 원할 때 사용하는 것이 더 적합합니다.

- **D. Aurora Replica 인스턴스 크기를 늘려 DB 클러스터를 수정합니다.**: 인스턴스 크기를 늘리면 읽기 성능이 향상될 수 있지만, 애플리케이션이 사용자 수요에 따라 자동으로 확장되는 것을 보장하지 않습니다. 또한, 성능 문제를 해결하기 위한 근본적인 원인인 연결 수 조정에 대한 직접적인 해결책이 아닙니다.

### 결론:
따라서, 사용자 수요에 따라 자동으로 애플리케이션이 확장되기를 원하고, 연결 수가 200개를 초과할 때 성능 저하를 방지하기 위해 가장 적절한 솔루션은 **C. 195개의 DatabaseConnections를 대상 메트릭으로 자동 크기 조정 정책을 만듭니다.**입니다.

## 질문 #321 +++

한 회사가 Amazon Elastic Block Store(Amazon EBS)가 지원하는 Amazon EC2 인스턴스에 프로덕션 데이터베이스를 호스팅합니다. 

연간 재해 복구 작업의 일환으로 회사는 최근 EBS 스냅샷을 두 번째 가용성 영역의 새 EC2 인스턴스로 복원해야 합니다.

스냅샷이 EBS 볼륨으로 복원된 후, 결과 볼륨은 프로비저닝된 모든 성능을 제공해야 합니다. 회사는 가능한 한 빨리 복원된 데이터에 대한 검증 테스트를 수행해야 합니다.

어떤 구성이 이러한 요구 사항을 충족할까요?

A. 두 번째 가용성 영역의 스냅샷에서 EBS 빠른 스냅샷 복원(FSR)을 활성화합니다. 스냅샷에서 두 번째 가용성 영역에 새 EBS 볼륨을 만듭니다. 새 EBS 볼륨을 새 EC2 인스턴스에 연결합니다.
B. 현재 가용성 영역에 대한 스냅샷에서 EBS 빠른 스냅샷 복원(FSR)을 활성화합니다. 스냅샷에서 두 번째 가용성 영역에 새 EBS 볼륨을 만듭니다. 새 EBS 볼륨을 새 EC2 인스턴스에 연결합니다.
C. 스냅샷에서 프로비저닝된 IOPS를 지정하고, 스냅샷에서 두 번째 가용성 영역에 새 EBS 볼륨을 만듭니다. 새 EBS 볼륨을 새 EC2 인스턴스에 연결합니다.
D. 기존 EBS 볼륨에 프로비저닝된 IOPS를 지정합니다. 스냅샷을 만듭니다. 스냅샷이 완료되면 스냅샷에서 두 번째 가용성 영역에 새 EBS 볼륨을 만듭니다. 새 EBS 볼륨을 새 EC2 인스턴스에 연결합니다.


회사가 최근 EBS 스냅샷을 두 번째 가용성 영역에 있는 새 EC2 인스턴스로 복원하고, 결과 볼륨이 프로비저닝된 모든 성능을 제공하며, 가능한 한 빨리 복원된 데이터에 대한 검증 테스트를 수행할 수 있도록 하는 가장 적절한 구성은 **C. 스냅샷에서 프로비저닝된 IOPS를 지정하고, 스냅샷에서 두 번째 가용성 영역에 새 EBS 볼륨을 만듭니다. 새 EBS 볼륨을 새 EC2 인스턴스에 연결합니다.**입니다.

### 선택 이유:
1. **프로비저닝된 IOPS**: 이 옵션에서는 스냅샷에서 새 EBS 볼륨을 만들 때 프로비저닝된 IOPS를 지정할 수 있습니다. 이는 성능 요구 사항을 충족하는 데 중요합니다. EBS 볼륨의 성능이 데이터베이스의 효율성과 응답성에 직접적인 영향을 미치기 때문입니다.

2. **빠른 복원**: 이 방법은 EBS 스냅샷에서 직접 EBS 볼륨을 생성하는 것이므로, 복원이 신속하게 이루어집니다. 스냅샷이 이미 존재하므로 데이터를 읽고 복원하는 데 시간이 최소화됩니다.

3. **가용성 영역**: 두 번째 가용성 영역에 볼륨을 생성하여 재해 복구 전략을 충족하는 것이므로, 이 솔루션은 재해 복구 작업을 지원하는 최적의 방법입니다.

### 다른 옵션 분석:
- **A. 두 번째 가용성 영역의 스냅샷에서 EBS 빠른 스냅샷 복원(FSR)을 활성화합니다.**: EBS 스냅샷에서 FSR을 사용하는 것은 유용하지만, 두 번째 가용성 영역에서 생성된 볼륨이 성능을 보장하기 위해 IOPS를 명시적으로 지정할 수 있는 옵션이 없으므로 요구 사항을 충족하지 않을 수 있습니다.

- **B. 현재 가용성 영역에 대한 스냅샷에서 EBS 빠른 스냅샷 복원(FSR)을 활성화합니다.**: 이 옵션은 스냅샷이 현재 가용성 영역에 있고, FSR을 활성화하는 것이지만, 두 번째 가용성 영역으로의 복원이기 때문에 요구 사항을 충족하지 않습니다.

- **D. 기존 EBS 볼륨에 프로비저닝된 IOPS를 지정합니다. 스냅샷을 만듭니다.**: 이 방법은 스냅샷을 만드는 단계가 포함되므로, 복원 작업이 두 번째 가용성 영역에서 이루어질 때 다소 비효율적입니다. 스냅샷을 만들고 복원하는 과정이 시간이 소모될 수 있습니다.

### 결론:
따라서, 요구 사항을 가장 잘 충족하는 구성은 **C. 스냅샷에서 프로비저닝된 IOPS를 지정하고, 스냅샷에서 두 번째 가용성 영역에 새 EBS 볼륨을 만듭니다. 새 EBS 볼륨을 새 EC2 인스턴스에 연결합니다.**입니다.



## 질문 #322 +

SysOps 관리자가 레거시 CPU 중심 애플리케이션을 담당하고 있습니다. 

애플리케이션은 수직으로만 확장할 수 있습니다. 현재 애플리케이션은 단일 t3.large Amazon EC2 인스턴스에 배포되어 있습니다. 시스템은 몇 분 후에 90%의 CPU 사용률과 상당한 성능 지연을 보이고 있습니다.

성능 문제를 완화하기 위해 어떤 변경을 해야 합니까?
A. Amazon EBS 볼륨을 프로비저닝된 IOP로 변경합니다.
B. 컴퓨팅 최적화된 인스턴스로 업그레이드하세요.
C. 애플리케이션에 t2.large 인스턴스를 추가합니다.
D. 예약 인스턴스를 구매하세요.

이 요구 사항을 충족하기 위한 최적의 솔루션은 **B. 컴퓨팅 최적화된 인스턴스로 업그레이드하세요.**입니다.

### 이유:
- **컴퓨팅 최적화 인스턴스**는 CPU 집약적인 워크로드를 처리하도록 설계된 인스턴스 유형입니다. 현재 애플리케이션은 CPU 사용률이 높아 성능 지연이 발생하므로, CPU 성능이 더 높은 컴퓨팅 최적화 인스턴스로 업그레이드하는 것이 적합합니다.
- 예를 들어, **c5.large** 또는 **c6g.large**와 같은 인스턴스 유형은 t3.large보다 더 강력한 CPU 성능을 제공하여 CPU 사용률을 낮추고 성능을 개선할 수 있습니다.

### 다른 옵션 분석:
- **A. Amazon EBS 볼륨을 프로비저닝된 IOP로 변경**: 이는 스토리지 성능을 개선하는 데 사용되며, CPU 성능 문제를 해결하지 못합니다.
- **C. 애플리케이션에 t2.large 인스턴스를 추가**: 애플리케이션이 수직 확장만 가능하다고 했기 때문에 추가 인스턴스를 도입하는 수평 확장은 적합하지 않습니다.
- **D. 예약 인스턴스를 구매**: 예약 인스턴스는 비용 절감에 유용하지만, 성능 문제를 해결하는 데는 도움이 되지 않습니다.

따라서 **컴퓨팅 최적화 인스턴스로 업그레이드**하는 것이 성능 문제를 완화하는 최선의 해결책입니다.


##  질문 #323

사용자가 프라이빗 서브넷의 Amazon EC2 인스턴스에 연결되어 있습니다. 사용자는 다음 curl 명령을 사용하여 인스턴스에서 인터넷에 액세스할 수 없습니다. curl http:/www.example.com.

SysOps 관리자가 VPC 구성을 검토하고 다음 정보를 알아냅니다.

• 프라이빗 서브넷에 CIDR 0.0.0.0/0의 NAT 게이트웨이로 가는 경로가 있습니다.
• EC2 인스턴스의 아웃바운드 보안 그룹에는 포트 443에서 CIDR 0.0.0.0/0으로의 아웃바운드라는 규칙이 하나 있습니다. 
• EC2 인스턴스의 인바운드 보안 그룹은 사용자 IP 주소에서 포트 22와 443을 허용합니다.
• 서브넷의 인바운드 네트워크 ACL은 CIDR 0.0.0.0/0에서 포트 22와 포트 범위 1024-65535를 허용합니다.

어떤 작업을 수행하면 사용자가 curl 요청을 성공적으로 완료할 수 있을까요?
A. CIDR 0.0.0.0/0에 포트 80에 대한 추가 인바운드 네트워크 ACL 규칙을 추가합니다.
B. CIDR 0.0.0.0/0에 포트 80에 대한 추가 인바운드 보안 그룹 규칙을 추가합니다.
C. CIDR 0.0.0.0/0에 포트 80에 대한 추가 아웃바운드 보안 그룹 규칙을 추가합니다.
D. 사용자의 IP 주소에 포트 80에 대한 추가 아웃바운드 보안 그룹 규칙을 추가합니다.

사용자가 프라이빗 서브넷의 Amazon EC2 인스턴스에서 인터넷에 액세스하기 위해 `curl http://www.example.com` 명령을 성공적으로 완료하기 위해 필요한 작업은 **C. CIDR 0.0.0.0/0에 포트 80에 대한 추가 아웃바운드 보안 그룹 규칙을 추가하는 것**입니다.

### 선택 이유:
- **HTTP 요청**: `curl http://www.example.com` 명령은 기본적으로 HTTP 프로토콜을 사용하여 80번 포트로 요청을 보냅니다. 현재 EC2 인스턴스의 아웃바운드 보안 그룹 규칙에는 포트 443 (HTTPS)로의 아웃바운드 연결만 허용되어 있으므로, HTTP 요청은 차단됩니다.

- **아웃바운드 보안 그룹 규칙 추가**: CIDR 0.0.0.0/0에 대해 포트 80에 대한 아웃바운드 보안 그룹 규칙을 추가하면 EC2 인스턴스에서 외부 서버(예: www.example.com)로의 HTTP 요청이 가능해집니다.

### 다른 옵션 분석:
- **A. CIDR 0.0.0.0/0에 포트 80에 대한 추가 인바운드 네트워크 ACL 규칙을 추가합니다.**: 인바운드 규칙은 EC2 인스턴스로 들어오는 요청에 대한 것이며, 아웃바운드 요청이 성공적으로 이루어지기 위해서는 아웃바운드 규칙이 필요합니다.

- **B. CIDR 0.0.0.0/0에 포트 80에 대한 추가 인바운드 보안 그룹 규칙을 추가합니다.**: 인바운드 규칙은 EC2 인스턴스로 들어오는 트래픽에 대한 것이므로, 사용자의 아웃바운드 요청을 성공적으로 완료하기 위해서는 아웃바운드 규칙이 필요합니다.

- **D. 사용자의 IP 주소에 포트 80에 대한 추가 아웃바운드 보안 그룹 규칙을 추가합니다.**: 사용자의 IP 주소에 대한 규칙은 일반적으로 EC2 인스턴스의 아웃바운드 연결과 관련이 없습니다. 아웃바운드 규칙은 EC2 인스턴스에 적용되어야 합니다.

### 결론:
따라서, 사용자가 curl 요청을 성공적으로 완료할 수 있도록 하기 위해서는 **C. CIDR 0.0.0.0/0에 포트 80에 대한 추가 아웃바운드 보안 그룹 규칙을 추가하는 것**이 필요합니다.

## 질문 #324 

회사의 재무 부서는 AWS 계정에서 각 프로젝트의 비용 세부 정보를 확인해야 합니다. 

SysOps 관리자는 Cost Explorer에서 각 프로젝트의 비용을 확인하는 데 필요한 초기 구성을 수행해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

A. 비용 할당 태그를 활성화합니다. 적절한 리소스에 프로젝트 태그를 추가합니다.
B. 통합 청구를 구성합니다. AWS 비용 및 사용 보고서를 만듭니다.
C. AWS Budgets를 사용하세요. AWS Budgets 보고서를 만드세요.
D. 비용 범주를 사용하여 AWS 비용 및 사용량 차원을 기반으로 사용자 정의 그룹을 정의합니다.


회사의 재무 부서가 각 프로젝트의 비용 세부 정보를 확인할 수 있도록 AWS Cost Explorer에서 초기 구성을 수행하기 위한 가장 적합한 솔루션은 
**A. 비용 할당 태그를 활성화합니다. 적절한 리소스에 프로젝트 태그를 추가합니다.**입니다.

### 선택 이유:
- **비용 할당 태그 활성화**: 비용 할당 태그를 사용하면 AWS 리소스에 태그를 추가하고, 이 태그를 기반으로 비용을 추적할 수 있습니다. 이를 통해 각 프로젝트별로 발생한 비용을 구분할 수 있으며, Cost Explorer에서 태그별로 비용을 조회할 수 있습니다.

- **프로젝트 태그 추가**: 각 프로젝트에 해당하는 태그를 리소스에 추가하면, 이후에 Cost Explorer에서 각 프로젝트의 비용을 쉽게 확인하고 분석할 수 있습니다.

### 다른 옵션 분석:
- **B. 통합 청구를 구성합니다. AWS 비용 및 사용 보고서를 만듭니다.**: 통합 청구는 여러 AWS 계정의 비용을 관리하는 데 유용하지만, 각 프로젝트의 비용을 세부적으로 확인하기 위한 초기 구성으로는 적합하지 않습니다.

- **C. AWS Budgets를 사용하세요. AWS Budgets 보고서를 만드세요.**: AWS Budgets는 예산 관리 및 초과 경고에 유용하지만, 비용 추적을 위한 초기 구성을 위한 직접적인 해결책은 아닙니다.

- **D. 비용 범주를 사용하여 AWS 비용 및 사용량 차원을 기반으로 사용자 정의 그룹을 정의합니다.**: 비용 범주는 유용한 기능이지만, 태그를 사용하여 비용을 관리하는 것보다 초기 구성으로는 더 복잡할 수 있습니다.

### 결론:
따라서, 각 프로젝트의 비용 세부 정보를 확인하기 위해서는 **A. 비용 할당 태그를 활성화하고 적절한 리소스에 프로젝트 태그를 추가하는 것**이 가장 적합한 솔루션입니다.


## 질문 #325 ++++

SysOps 관리자가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 실행되는 웹 애플리케이션을 관리하고 있습니다. 

인스턴스는 EC2 Auto Scaling 그룹에서 실행됩니다. 관리자는 ALB와 연관된 모든 대상 인스턴스가 비정상일 때 알람을 설정하려고 합니다.

알람과 함께 사용해야 하는 조건은 무엇입니까?

A. AWS/ApplicationELB HealthyHostCount <= 0
B. AWS/ApplicationELB 비정상 호스트 수 >= 1 
C. AWS/EC2 상태 확인 실패 <= 0
D. AWS/EC2 상태 확인 실패 >= 1

ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 실행되는 웹 애플리케이션의 상태를 모니터링하고, 모든 대상 인스턴스가 비정상일 때 알람을 설정하려는 경우, 가장 적합한 조건은 **A. AWS/ApplicationELB HealthyHostCount <= 0**입니다.

### 선택 이유:
- **HealthyHostCount**: 이 메트릭은 ALB에 등록된 헬시(정상) 호스트(인스턴스)의 수를 나타냅니다. 따라서 이 값이 0 이하가 되면, ALB에 연결된 모든 대상 인스턴스가 비정상적임을 의미합니다.

- **비정상 호스트 수와의 차이**: 비정상 호스트 수를 모니터링하는 것(B 옵션)은 유용하지만, 모든 인스턴스가 비정상인 경우를 직접적으로 반영하지는 않습니다. 반면, HealthyHostCount가 0이 되는 것을 모니터링하면, 전체 인스턴스가 비정상임을 정확하게 감지할 수 있습니다.

### 다른 옵션 분석:
- **B. AWS/ApplicationELB UnhealthyHostCount >= 1**: 이 조건은 하나 이상의 비정상 호스트가 존재할 때 알람을 발생시키지만, 비정상 호스트가 1개 이상일 경우에도 전체 인스턴스가 정상일 수 있기 때문에 원하는 조건과는 다릅니다.

- **C. AWS/EC2 StatusCheckFailed <= 0**: 이 조건은 EC2 인스턴스의 상태 확인이 실패하지 않았을 때를 의미합니다. 이는 ALB 상태와는 관련이 없으므로 적절하지 않습니다.

- **D. AWS/EC2 StatusCheckFailed >= 1**: 이 조건은 인스턴스의 상태 확인 실패가 있을 때 알람을 발생시키지만, ALB의 대상 인스턴스 상태를 직접적으로 반영하지 않습니다.

### 결론:
따라서, 모든 대상 인스턴스가 비정상일 때 알람을 설정하기 위한 가장 적합한 조건은 **A. AWS/ApplicationELB HealthyHostCount <= 0**입니다.


## 질문 #326 ++++

한 회사에서 AWS Organizations를 사용하여 다중 계정 환경을 관리합니다. 

이 조직에는 보안을 위한 전담 계정과 로깅을 위한 전담 계정이 있습니다. SysOps 관리자는 모든 계정의 리소스 메트릭이 표준 정의된 임계값을 넘을 때 알림을 제공하는 중앙 집중식 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 조직의 계정에 AWS CloudFormation 스택 세트를 배포합니다. 필요한 Amazon CloudWatch 알람을 생성하고 모든 계정에 대한 게시 권한이 있는 로깅 계정에서 Amazon Simple Notification Service(Amazon SNS) 토픽을 참조하는 템플릿을 사용합니다.
가장 많이 투표된
B. 각 계정에 AWS CloudFormation 스택을 배포합니다. 스택을 사용하여 필요한 Amazon CloudWalch 알람과 필요한 Amazon Simple Notification Service(Amazon SNS) 토픽을 배포합니다.
C. 각 계정의 cron 작업에 AWS Lambda 함수를 배포합니다. Lambda 함수를 구성하여 계정에 있는 리소스를 읽고 메트릭이 정의된 임계값을 넘으면 Amazon Simple Notification Service(Amazon SNS) 토픽을 호출합니다.
D. 조직에 AWS CloudFormation 변경 세트를 배포합니다. 템플릿을 사용하여 필요한 Amazon CloudWatch 알람을 만들고 검증된 Amazon Simple Email Service(Amazon SES) ID에 알림을 보냅니다.


이 시나리오에서는 AWS Organizations를 사용하여 다중 계정 환경에서 모든 계정의 리소스 메트릭을 중앙 집중식으로 모니터링하고, 표준 정의된 임계값을 초과할 때 알림을 제공하는 솔루션을 구현해야 합니다. 이를 위해 가장 적합한 옵션은 **A. 조직의 계정에 AWS CloudFormation 스택 세트를 배포합니다. 필요한 Amazon CloudWatch 알람을 생성하고 모든 계정에 대한 게시 권한이 있는 로깅 계정에서 Amazon Simple Notification Service(Amazon SNS) 토픽을 참조하는 템플릿을 사용합니다.**입니다.

### 선택 이유:
1. **AWS CloudFormation 스택 세트**: AWS CloudFormation 스택 세트를 사용하면 여러 계정과 리전에서 동일한 리소스를 반복적으로 배포할 수 있습니다. 이를 통해 모든 계정에 필요한 CloudWatch 알람을 표준화하고 효율적으로 생성할 수 있습니다.

2. **중앙 집중식 모니터링**: 로깅 계정에서 SNS 토픽을 참조하여 알림을 중앙에서 수신하고 관리할 수 있습니다. 이렇게 하면 모든 계정의 메트릭을 중앙 집중식으로 모니터링하면서 필요한 경우 쉽게 알림을 관리할 수 있습니다.

3. **비용 효율성**: CloudFormation 스택 세트를 사용하여 한 번의 배포로 모든 계정에 리소스를 설정할 수 있기 때문에 운영 효율성이 향상됩니다.

### 다른 옵션 분석:
- **B.**는 각 계정에 CloudFormation 스택을 개별적으로 배포하는 방법인데, 이는 관리 및 유지 관리의 복잡성을 증가시킵니다. 모든 계정에 대해 동일한 알람을 설정하려면 여러 번 배포해야 하므로 비효율적입니다.

- **C.**는 각 계정의 cron 작업에 Lambda 함수를 배포하는 방법으로, 수많은 계정에 대해 각기 다른 Lambda 함수를 관리해야 하므로 복잡성과 운영 비용이 증가할 수 있습니다.

- **D.**는 CloudFormation 변경 세트를 사용하는 방법인데, 이는 메트릭 알람 생성과 이메일 알림을 결합하지만, SNS를 사용하는 것이 더 일반적이고 관리하기 쉬운 방법입니다. SES를 사용하는 경우 추가적인 인증 및 설정 과정이 필요합니다.

### 결론:
따라서 **A.**가 모든 계정의 리소스 메트릭을 효율적으로 모니터링하고 표준화된 알림을 제공할 수 있는 최적의 해결책입니다.

## 질문 #327 +

한 회사에는 인터넷을 통해 외부 소스에서 데이터 세트를 검색하기 위해 예약된 AWS Lambda 함수를 사용하는 애플리케이션이 있습니다. 

이 함수는 VPC와 연결되어 있지 않습니다. 이 회사는 Lambda 함수가 검색하는 정보를 프라이빗 서브넷의 Amazon RDS DB 인스턴스에 저장하도록 애플리케이션을 수정하고 있습니다. VPC에는 퍼블릭 서브넷 2개와 프라이빗 서브넷 2개가 있습니다.

SysOps 관리자는 Lambda 함수가 새 데이터베이스에 액세스하고 인터넷에 계속 액세스할 수 있도록 하는 솔루션을 배포해야 합니다.

이러한 요구 사항을 충족하는 솔루션은 무엇입니까?


A. VPC 액세스와 Elastic IP 주소가 있는 새 Lambda 함수를 만듭니다. 두 개의 가용성 영역의 퍼블릭 서브넷에 함수를 연결합니다. Elastic IP 주소에 보안 그룹을 연결합니다. Lambda가 필요한 리소스에 액세스할 수 있도록 보안 그룹 아웃바운드 규칙을 구성합니다.

B. VPC 액세스와 두 개의 퍼블릭 IP 주소가 있는 새 Lambda 함수를 만듭니다. 데이터베이스가 사용하는 동일한 가용성 영역의 퍼블릭 서브넷에 함수를 연결합니다. 함수에 보안 그룹을 연결합니다. Lambda가 필요한 리소스에 액세스할 수 있도록 보안 그룹 인바운드 규칙을 구성합니다.

C. VPC 액세스를 위해 Lambda 함수를 재구성합니다. VP의 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. 프라이빗 서브넷에 경로 테이블 항목을 추가하여 NAT 게이트웨이를 통해 인터넷으로 라우팅합니다. 데이터베이스를 지원하는 프라이빗 서브넷에 함수를 연결합니다. 함수에 보안 그룹을 연결합니다. Lambda가 인터넷에 액세스할 수 있도록 보안 그룹 아웃바운드 규칙을 구성합니다.
가장 많이 투표된

D. VPC 액세스를 위해 Lambda 함수를 재구성합니다. 함수를 프라이빗 서브넷에 연결합니다. 프라이빗 서브넷에 경로 테이블 항목을 추가하여 인터넷 게이트웨이를 통해 인터넷으로 라우팅합니다. 보안 그룹을 서브넷에 연결합니다. Lambda가 인터넷 게이트웨이를 통해 필요한 리소스에 액세스할 수 있도록 보안 그룹 인바운드 규칙을 구성합니다.


AWS Lambda 함수가 프라이빗 서브넷의 Amazon RDS DB 인스턴스에 액세스하면서 인터넷에 계속 액세스할 수 있도록 하려면, **C. VPC 액세스를 위해 Lambda 함수를 재구성합니다. VPC의 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. 프라이빗 서브넷에 경로 테이블 항목을 추가하여 NAT 게이트웨이를 통해 인터넷으로 라우팅합니다. 데이터베이스를 지원하는 프라이빗 서브넷에 함수를 연결합니다. 함수에 보안 그룹을 연결합니다. Lambda가 인터넷에 액세스할 수 있도록 보안 그룹 아웃바운드 규칙을 구성합니다.**라는 옵션이 가장 적합합니다.

### 선택 이유:
1. **프라이빗 서브넷에서의 RDS 접근**: Lambda 함수가 프라이빗 서브넷에 연결되면 RDS DB 인스턴스에 직접 액세스할 수 있습니다. RDS는 프라이빗 서브넷에 있으므로, Lambda 함수를 프라이빗 서브넷에 배치해야 합니다.

2. **인터넷 접근을 위한 NAT 게이트웨이**: Lambda 함수가 인터넷에 액세스할 수 있도록 NAT 게이트웨이를 퍼블릭 서브넷에 배치해야 합니다. NAT 게이트웨이를 사용하면 프라이빗 서브넷의 리소스가 인터넷에 나가는 요청을 처리하고 응답을 수신할 수 있습니다.

3. **경로 테이블 구성**: 프라이빗 서브넷의 경로 테이블에 NAT 게이트웨이를 통한 인터넷 라우팅을 설정하여 Lambda 함수가 외부 소스와 통신할 수 있도록 합니다.

4. **보안 그룹 설정**: Lambda 함수와 RDS 인스턴스 모두에 적절한 보안 그룹 규칙을 설정하여 필요한 트래픽이 허용되도록 합니다. Lambda 함수는 아웃바운드 트래픽을 통해 NAT 게이트웨이를 사용하여 인터넷에 접근할 수 있습니다.

### 다른 옵션 분석:
- **A.**와 **B.**는 Lambda 함수를 퍼블릭 서브넷에 배치하려고 하지만, 퍼블릭 서브넷에 배치된 Lambda 함수는 프라이빗 서브넷의 RDS DB 인스턴스에 직접 연결할 수 없습니다. 또한, 이러한 옵션은 인터넷에 접근하기 위한 NAT 게이트웨이를 설정하지 않으므로 적절하지 않습니다.

- **D.**는 프라이빗 서브넷에 Lambda 함수를 연결하고 인터넷 게이트웨이를 사용하려고 하지만, 프라이빗 서브넷은 인터넷 게이트웨이에 직접 연결할 수 없으므로 NAT 게이트웨이가 필요합니다.

### 결론:
따라서 **C.**가 최선의 해결책이며, Lambda 함수가 RDS DB 인스턴스에 액세스하면서도 외부 데이터 소스에 연결할 수 있도록 하는 적절한 구성을 제공합니다.



## 질문 #328 

한 회사가 Amazon RDS for MySQL db.m6g.xlarge(일반 용도) 표준 DB 인스턴스의 Multi-AZ 배포를 사용하는 프로덕션 워크로드를 실행하고 있습니다. 

사용자들은 "연결이 너무 많음" 오류가 자주 발생한다고 보고합니다. SysOps 관리자는 데이터베이스의 연결 수가 많다는 것을 관찰합니다. SysOps 관리자는 코드 변경을 최소한으로 유지하면서 이 문제를 해결해야 합니다.

어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요?

A. RDS for MySQL DB 인스턴스를 더 큰 인스턴스 크기로 수정합니다.
B. RDS for MySQL DB 인스턴스를 Amazon DynamoDB로 수정합니다.
C. RDS 프록시 구성. RDS 프록시 엔드포인트를 사용하도록 애플리케이션 구성 파일을 수정합니다.
가장 많이 투표된
D. RDS for MySQL DB 인스턴스를 메모리 최적화된 DB 인스턴스로 수정합니다.

사용자들이 "연결이 너무 많음" 오류를 자주 경험하고 있으며, 코드 변경을 최소한으로 유지하면서 문제를 해결해야 하는 경우, 가장 비용 효율적이고 적절한 솔루션은 **C. RDS 프록시 구성. RDS 프록시 엔드포인트를 사용하도록 애플리케이션 구성 파일을 수정합니다.**입니다.

### 선택 이유:
- **RDS 프록시 사용**: RDS 프록시는 데이터베이스 연결을 효율적으로 관리하고, 다수의 데이터베이스 연결을 통합하여 연결 수를 줄일 수 있습니다. 이를 통해 동시에 여러 클라이언트 연결을 처리할 수 있어 "연결이 너무 많음" 오류를 줄이는 데 효과적입니다.
- **코드 변경 최소화**: RDS 프록시를 사용하면 기존 애플리케이션에서 프록시 엔드포인트로의 간단한 변경만으로 기존 코드 변경을 최소화할 수 있습니다. 애플리케이션 구성 파일에서 엔드포인트를 변경하면 되므로 복잡한 코드 변경이 필요 없습니다.
- **비용 효율성**: RDS 프록시는 사용량에 따라 비용이 청구되므로, 직접적으로 인스턴스 크기를 늘리는 것보다 경제적인 방법이 될 수 있습니다. 더 큰 인스턴스 크기로 수정하는 경우, 리소스와 비용이 증가할 수 있습니다.

### 다른 옵션 분석:
- **A. RDS for MySQL DB 인스턴스를 더 큰 인스턴스 크기로 수정합니다.**
  - 더 큰 인스턴스 크기로 수정하면 연결 수가 증가할 수 있지만, 비용이 더 높아지고, 코드 변경 없이 처리할 수 있는 방법이 아닙니다.

- **B. RDS for MySQL DB 인스턴스를 Amazon DynamoDB로 수정합니다.**
  - RDS에서 DynamoDB로의 전환은 데이터베이스의 구조와 쿼리 방식이 크게 달라질 수 있으므로 코드 변경이 많아질 수 있으며, 이는 문제를 해결하기 위한 비용 효율적인 접근 방식이 아닙니다.

### 결론:
따라서 **C. RDS 프록시 구성**이 가장 적합한 솔루션이며, 이는 "연결이 너무 많음" 오류 문제를 해결하면서도 코드 변경을 최소화할 수 있는 방법입니다.


## 질문 #329 ++

한 회사에 개발 환경에서 리소스 집약적 애플리케이션을 실행하는 여러 Amazon EC2 인스턴스가 있습니다. 

SysOps 관리자가 사용되지 않을 때 이러한 EC2 인스턴스를 중지하는 솔루션을 구현하고 있습니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

A. AWS CloudTrail 로그를 평가하여 EC2 API 활동이 없는지 확인합니다. AWS Lambda 함수를 호출하여 EC2 인스턴스를 중지합니다.
B. 평균 CPU 사용률이 30분 동안 5% 미만으로 낮으면 EC2 인스턴스를 중지하는 Amazon CloudWatch 알람을 생성합니다.
가장 많이 투표된
C. VolumeReadBytes 메트릭이 30분 동안 500보다 낮을 때 EC2 인스턴스를 중지하는 Amazon CloudWatch 메트릭을 생성합니다.
D. AWS Config를 사용하면 리소스 구성 변경에 따라 EC2 인스턴스를 중지하기 위해 AWS Lambda 함수를 호출할 수 있습니다.

리소스 집약적 애플리케이션을 실행하는 여러 Amazon EC2 인스턴스를 사용하지 않을 때 중지하기 위한 가장 효과적인 솔루션은 **B. 평균 CPU 사용률이 30분 동안 5% 미만으로 낮으면 EC2 인스턴스를 중지하는 Amazon CloudWatch 알람을 생성합니다.**입니다.

### 선택 이유:
- **CPU 사용률 모니터링**: 평균 CPU 사용률이 낮은 것은 인스턴스가 활동하지 않거나 사용되지 않고 있다는 좋은 지표입니다. 30분 동안 CPU 사용률이 5% 미만일 경우, 해당 인스턴스는 중지할 수 있습니다. 이는 리소스 낭비를 줄이고 비용을 절감하는 데 효과적입니다.
- **자동화**: CloudWatch 알람을 사용하면 특정 조건이 충족될 때 자동으로 EC2 인스턴스를 중지하는 Lambda 함수를 호출할 수 있어 관리 효율성을 높입니다.

### 다른 옵션 분석:
- **A. AWS CloudTrail 로그를 평가하여 EC2 API 활동이 없는지 확인합니다.**
  - CloudTrail 로그를 평가하는 것은 다소 복잡하고 지연이 발생할 수 있으며, 실시간으로 인스턴스 상태를 모니터링하는 데 비효율적입니다.

- **C. VolumeReadBytes 메트릭이 30분 동안 500보다 낮을 때 EC2 인스턴스를 중지하는 Amazon CloudWatch 메트릭을 생성합니다.**
  - Disk I/O 활동(VolumeReadBytes)은 CPU 사용량보다 덜 일반적인 지표일 수 있으며, CPU 사용량과 비교할 때 애플리케이션 사용 여부를 덜 잘 반영할 수 있습니다.

- **D. AWS Config를 사용하면 리소스 구성 변경에 따라 EC2 인스턴스를 중지하기 위해 AWS Lambda 함수를 호출할 수 있습니다.**
  - AWS Config는 리소스의 구성 변경을 모니터링하는 데 유용하지만, 사용 중인 인스턴스를 실시간으로 중지하는 데 적합하지 않습니다. 이는 관리 복잡성을 증가시킬 수 있습니다.

### 결론:
따라서 **B. 평균 CPU 사용률이 30분 동안 5% 미만으로 낮으면 EC2 인스턴스를 중지하는 Amazon CloudWatch 알람을 생성하는 것**이 가장 효율적이고 직관적인 방법으로, 시스템 자원을 효과적으로 관리할 수 있습니다.

## 질문 #330 +

한 회사에는 MySQL을 실행하는 Amazon EC2 인스턴스로 구성된 데이터베이스 계층이 있는 웹 애플리케이션이 있습니다. 

SysOps 관리자는 잠재적인 데이터 손실과 데이터베이스 장애 발생 시 복구하는 데 필요한 시간을 최소화해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. StatusCheckFailed_System 메트릭에 대한 Amazon CloudWatch 알람을 생성하여 EC2 인스턴스를 중지하고 시작하는 AWS Lambda 함수를 호출합니다.
B. Amazon RDS for MySQL Multi-AZ DB 인스턴스를 만듭니다. Amazon S3에 저장된 MySQL 네이티브 백업을 사용하여 데이터를 새 데이터베이스로 복원합니다. 웹 애플리케이션에서 연결 문자열을 업데이트합니다.
가장 많이 투표된
C. 읽기 복제본이 있는 Amazon RDS for MySQL Single-AZ DB 인스턴스를 만듭니다. Amazon S3에 저장된 MySQL 네이티브 백업을 사용하여 데이터를 새 데이터베이스로 복원합니다. 웹 애플리케이션에서 연결 문자열을 업데이트합니다.
D. Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 매 시간 Amazon Elastic Block Store(Amazon EBS) 볼륨의 스냅샷을 찍습니다. EC2 인스턴스 장애가 발생하는 경우 스냅샷에서 EBS 볼륨을 복원합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 **B. Amazon RDS for MySQL Multi-AZ DB 인스턴스를 만듭니다. Amazon S3에 저장된 MySQL 네이티브 백업을 사용하여 데이터를 새 데이터베이스로 복원합니다. 웹 애플리케이션에서 연결 문자열을 업데이트합니다.**입니다.

### 이유:
- **Amazon RDS for MySQL Multi-AZ**는 고가용성과 장애 복구를 제공하는 솔루션입니다. Multi-AZ 구성에서는 하나의 가용 영역에서 장애가 발생하면 다른 가용 영역의 스탠바이 인스턴스로 자동으로 장애 조치가 이루어집니다. 따라서 데이터 손실이 최소화되며, 데이터베이스 복구 시간도 짧아집니다.
- 추가적으로, **MySQL 네이티브 백업**을 Amazon S3에 저장하고 이를 사용해 복원하면 장기적인 데이터 보호와 복구가 가능해집니다.

### 다른 옵션 분석:
- **A. CloudWatch 알람과 Lambda 함수**는 인스턴스를 중지하고 다시 시작하는 데 도움이 될 수 있지만, 데이터 손실을 방지하거나 장애 복구 시간을 최소화하는 데 직접적인 해결책이 아닙니다.
- **C. 읽기 복제본이 있는 Single-AZ RDS 인스턴스**는 읽기 성능을 높이지만, 장애 발생 시 Multi-AZ만큼 빠른 장애 조치나 가용성을 제공하지 않습니다.
- **D. Amazon Data Lifecycle Manager로 EBS 스냅샷을 찍는 방법**은 EC2 기반 데이터베이스 복구 방법이지만, RDS의 자동 복구 및 고가용성 기능을 제공하지 않으므로 운영 효율성이 낮습니다.

따라서 **Multi-AZ RDS 인스턴스를 사용한 구성**이 데이터 손실을 최소화하고, 장애 발생 시 복구 시간을 가장 효과적으로 줄이는 방법입니다.

## 질문 #331 ++


한 회사가 AWS CloudFormation을 사용하여 AWS에서 Amazon EC2 인스턴스 스택을 관리합니다. 

SysOps 관리자는 누군가가 스택을 삭제하더라도 인스턴스와 모든 인스턴스 데이터를 보관해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. CloudFormation 템플릿에서 EC2 인스턴스 리소스에 대한 DeletionPolicy 속성을 스냅샷으로 설정합니다.
B. Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 백업을 자동화합니다.
C. AWS Backup에서 백업 계획을 만듭니다.
D. CloudFormation 템플릿에서 EC2 인스턴스 리소스에 대한 DeletionPolicy 속성을 Retain으로 설정합니다.

회사가 AWS CloudFormation을 사용하여 Amazon EC2 인스턴스 스택을 관리하면서, 스택이 삭제되더라도 인스턴스와 모든 인스턴스 데이터를 보관해야 하는 경우, **D. CloudFormation 템플릿에서 EC2 인스턴스 리소스에 대한 DeletionPolicy 속성을 Retain으로 설정합니다.**가 가장 적합한 솔루션입니다.

### 선택 이유:
- **DeletionPolicy 속성**: CloudFormation에서 `DeletionPolicy` 속성을 사용하면 스택 삭제 시 리소스를 어떻게 처리할지를 정의할 수 있습니다. `Retain`으로 설정하면 스택이 삭제될 때 해당 리소스(이 경우 EC2 인스턴스)는 삭제되지 않고 남아 있게 됩니다. 이를 통해 인스턴스와 데이터를 보존할 수 있습니다.

### 다른 옵션 분석:
- **A. CloudFormation 템플릿에서 EC2 인스턴스 리소스에 대한 DeletionPolicy 속성을 스냅샷으로 설정합니다.**
  - `Snapshot` 설정을 사용하면 EC2 인스턴스의 EBS 볼륨에 대한 스냅샷을 생성하지만, 인스턴스 자체는 삭제됩니다. 이 옵션은 데이터 보존을 위한 스냅샷을 생성할 수 있지만 인스턴스는 남지 않습니다.

- **B. Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 백업을 자동화합니다.**
  - Amazon DLM은 EBS 볼륨의 스냅샷 관리를 자동화하는 도구입니다. 그러나 스택 삭제 시 인스턴스 및 그 데이터를 자동으로 보존하지는 않습니다.

- **C. AWS Backup에서 백업 계획을 만듭니다.**
  - AWS Backup은 AWS 리소스의 백업 및 복원을 관리하는 서비스입니다. 하지만 CloudFormation 스택 삭제와는 별개로 작동하므로, 인스턴스 자체를 유지할 수는 없습니다.

### 결론:
따라서 **D. CloudFormation 템플릿에서 EC2 인스턴스 리소스에 대한 DeletionPolicy 속성을 Retain으로 설정하는 것**이 스택 삭제 후에도 인스턴스와 데이터를 보존하는 최선의 방법입니다.

## 질문 #332 ++++

Accompany는 실행 중인 Amazon EC2 인스턴스 수를 모니터링하려고 합니다. 

또한 인스턴스 수가 특정 임계값에 도달하면 서비스 할당량 증가를 자동화하려고 합니다.

이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 서비스 할당량을 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 알람이 임계값에 도달하면 할당량 증가를 요청하기 위해 AWS Lambda 함수를 호출하도록 알람을 구성합니다.
B. 서비스 할당량을 모니터링하기 위한 AWS Config 규칙을 만듭니다. AWS Lambda 함수를 호출하여 작업을 수정하고 할당량을 늘립니다.
C. AWS Health Dashboard를 모니터링하기 위해 Amazon CloudWateh 알람을 만듭니다. 알람이 임계값에 도달하면 할당량 증가를 요청하는 AWS Lambda 함수를 호출하도록 알람을 구성합니다.
D. AWS Trusted Advisor 서비스 할당량을 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 할당량을 늘리기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다.

Accompany가 실행 중인 Amazon EC2 인스턴스 수를 모니터링하고, 특정 임계값에 도달할 때 서비스 할당량 증가를 자동화하려면 **A. 서비스 할당량을 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 알람이 임계값에 도달하면 할당량 증가를 요청하기 위해 AWS Lambda 함수를 호출하도록 알람을 구성합니다.**가 가장 적합한 솔루션입니다.

### 선택 이유:
- **Amazon CloudWatch 알람**: CloudWatch 알람은 EC2 인스턴스 수와 같은 메트릭을 모니터링할 수 있으며, 지정한 임계값에 도달했을 때 트리거될 수 있습니다. 이를 통해 특정 수의 인스턴스가 실행 중일 때 알림을 받을 수 있습니다.
- **AWS Lambda 함수 호출**: 알람이 트리거되면 Lambda 함수를 호출하여 자동으로 서비스 할당량 증가 요청을 처리할 수 있습니다. Lambda 함수는 AWS API를 호출하여 할당량 증가를 요청하는 데 필요한 로직을 포함할 수 있습니다.

### 다른 옵션 분석:
- **B. AWS Config 규칙을 만듭니다.**
  - AWS Config는 리소스의 구성을 관리하고 감사하는 데 유용하지만, 서비스 할당량을 모니터링하고 증가 요청을 자동화하는 데는 적합하지 않습니다.

- **C. AWS Health Dashboard를 모니터링합니다.**
  - AWS Health Dashboard는 AWS 서비스 상태에 대한 정보를 제공하지만, EC2 인스턴스 수를 모니터링하는 데 적합하지 않으며 할당량 증가 요청을 자동화하는 데도 도움이 되지 않습니다.

- **D. AWS Trusted Advisor를 모니터링합니다.**
  - Trusted Advisor는 AWS 리소스 최적화에 대한 권장 사항을 제공하지만, 서비스 할당량을 직접 모니터링하지 않습니다. CloudWatch 알람과 Lambda를 사용하여 자동화하는 것보다는 수동적입니다.

### 결론:
따라서, **A. Amazon CloudWatch 알람을 만들고 Lambda 함수를 호출하여 서비스 할당량 증가를 자동화하는 것**이 Accompany의 요구 사항을 충족하는 최적의 솔루션입니다.


## 질문 #333 +++++

SysOps 관리자는 단일 프로덕션 AWS 계정에 배포된 50개 이상의 Amazon EC2 인스턴스를 담당합니다. 

EC2 인스턴스는 여러 가지 운영 체제를 실행합니다. 회사의 표준에 따라 패치는 한 달에 한 번 이상 완료해야 합니다.

SysOps 관리자는 AWS Systems Manager를 사용하여 회사가 매달 운영 체제 패치에 사용하는 시간을 줄이려고 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (세 가지를 선택하십시오.)


A. AWS 리소스 그룹을 사용하여 유사한 EC2 인스턴스를 리소스 그룹으로 그룹화합니다.
B. Systems Manager Patch Manager에서 일정을 만듭니다. 적절한 리소스 그룹을 대상으로 지정합니다.
C. Systems Manager Automation 런북을 지정하여 운영 체제를 패치합니다. 런북을 유지 관리 창에서 작업으로 등록합니다. 적절한 리소스 그룹을 대상으로 지정합니다.
D. 필요한 패치의 상태를 모니터링하고 제어하기 위해 Systems Manager Automation 런북을 만듭니다. 런북을 Systems Manager Patch Manager에 적용합니다.
E. 각 리소스 그룹에 대해 단일 Systems Manager 유지 관리 창을 만듭니다.
F. Systems Manager Fleet Manager를 구성하여 적절한 리소스 그룹에 Systems Manager Automation 런북을 적용합니다.

SysOps 관리자가 AWS Systems Manager를 사용하여 여러 운영 체제를 실행하는 Amazon EC2 인스턴스에 대한 월간 패치를 자동화하려면 다음 단계 조합을 통해 요구 사항을 충족할 수 있습니다:

**A. AWS 리소스 그룹을 사용하여 유사한 EC2 인스턴스를 리소스 그룹으로 그룹화합니다.**  
- 유사한 EC2 인스턴스(운영 체제 또는 기타 속성 기반)를 그룹화하여 관리 효율성을 높일 수 있습니다.

**B. Systems Manager Patch Manager에서 일정을 만듭니다. 적절한 리소스 그룹을 대상으로 지정합니다.**  
- Systems Manager Patch Manager에서 리소스 그룹을 대상으로 패치 스케줄을 구성하여 지정된 시간에 자동으로 패치를 적용합니다.

**E. 각 리소스 그룹에 대해 단일 Systems Manager 유지 관리 창을 만듭니다.**  
- 유지 관리 창을 사용하여 패치를 적용할 시간을 정의하고, 각 리소스 그룹별로 관리 창을 설정하여 패치가 지정된 시간 동안만 수행되도록 보장합니다.

### 다른 옵션 분석:
- **C. Systems Manager Automation 런북을 지정하여 운영 체제를 패치합니다.** 이 방법도 가능하지만, 패치 작업을 자동화하려면 **Patch Manager**가 더 적합합니다.  
- **D. Systems Manager Automation 런북을 통해 상태를 모니터링**하는 대신, Patch Manager는 자체적으로 패치 상태를 모니터링하고 보고하는 기능을 제공합니다.
- **F. Fleet Manager**는 EC2 인스턴스 관리와 관련이 있지만, 패치 관리는 Patch Manager에서 더 효과적으로 처리됩니다.

따라서 **A, B, E** 단계가 요구 사항을 충족하는 최적의 조합입니다.


## 질문 #334

회사에 여러 AWS 계정이 있습니다. 

회사는 프로덕션 계정에 대한 조직 단위(OU)와 개발 계정에 대한 또 다른 OU가 있는 AWS Organizations를 사용합니다. 회사 정책에 따르면 개발자는 프로덕션 계정에서 승인된 AWS 서비스만 사용할 수 있습니다.

프로덕션 계정을 제어하는 ​​가장 운영 효율적인 솔루션은 무엇입니까?

A. AWS Identity and Access Management(IAM)에서 고객 관리 정책을 만듭니다. 프로덕션 계정 내의 모든 사용자에게 정책을 적용합니다.
B. AWS Identity and Access Management(IAM)에서 작업 기능 정책을 만듭니다. 프로덕션 OU 내의 모든 사용자에게 정책을 적용합니다.
C. 서비스 제어 정책(SCP)을 만듭니다. SCP를 프로덕션 OU에 적용합니다.
D. IAM 정책을 만듭니다. Amazon API Gateway에서 정책을 적용하여 프로덕션 계정을 제한합니다.

회사가 여러 AWS 계정을 관리하고 있으며, 프로덕션 계정에서 승인된 AWS 서비스만 사용하도록 제한해야 한다면, **C. 서비스 제어 정책(SCP)을 만듭니다. SCP를 프로덕션 OU에 적용합니다.**가 가장 운영 효율적인 솔루션입니다.

### 선택 이유:
- **서비스 제어 정책(SCP)**: AWS Organizations에서 SCP를 사용하면 조직의 모든 계정에 대해 허용 또는 거부할 수 있는 정책을 설정할 수 있습니다. SCP를 통해 프로덕션 OU에 적용함으로써, 해당 OU의 모든 계정에서 특정 AWS 서비스의 사용을 명시적으로 제한할 수 있습니다. 이는 계정의 IAM 정책에 영향을 주지 않으면서도, 권한을 중앙에서 관리할 수 있는 효율적인 방법입니다.

### 다른 옵션 분석:
- **A. AWS Identity and Access Management(IAM)에서 고객 관리 정책을 만듭니다. 프로덕션 계정 내의 모든 사용자에게 정책을 적용합니다.**
  - IAM 정책은 특정 계정 내 사용자에게 권한을 부여하는 데 사용되지만, 프로덕션 계정의 모든 서비스에 대한 사용을 제한하는 데는 효과적이지 않습니다. 또한, 여러 계정을 관리할 때 중앙 집중식 관리가 어렵습니다.

- **B. AWS Identity and Access Management(IAM)에서 작업 기능 정책을 만듭니다. 프로덕션 OU 내의 모든 사용자에게 정책을 적용합니다.**
  - 작업 기능 정책도 IAM 정책의 한 종류로, 서비스 사용을 제한하는 데는 유용하지만, SCP처럼 중앙 집중식으로 관리되지는 않습니다.

- **D. IAM 정책을 만듭니다. Amazon API Gateway에서 정책을 적용하여 프로덕션 계정을 제한합니다.**
  - API Gateway에서 IAM 정책을 적용하는 것은 특정 API 요청에 대한 제어를 제공하지만, 전체 AWS 서비스에 대한 제한을 적용하는 데는 적합하지 않습니다.

### 결론:
따라서, **C. 서비스 제어 정책(SCP)을 만들고 프로덕션 OU에 적용하는 것**이 가장 운영 효율적인 방법이며, 회사 정책을 준수할 수 있는 최적의 솔루션입니다.



## 질문 #335 +++++

한 회사에는 매분 여러 번 트랜잭션 요청을 처리하는 애플리케이션이 있습니다. 

이 애플리케이션은 단일 Amazon RDS DB 인스턴스에 트랜잭션 데이터를 씁니다. 회사가 더 많은 트랜잭션을 처리하기 시작하면서 회사는 재해 복구(DR)를 위한 장애 조치 솔루션이 없다는 점에 대해 우려하게 됩니다. 이 회사는 커밋된 트랜잭션을 잃지 않고 DB 인스턴스가 자동으로 장애 조치되어야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 동일한 AWS 리전에서 RDS 읽기 복제본을 만듭니다. DR 시나리오 동안 복제본을 기본 DB 인스턴스로 승격하도록 AWS Lambda 함수를 구성합니다.
B. 다른 AWS 지역에서 RDS 읽기 복제본을 만듭니다. DR 시나리오 동안 복제본을 기본 DB 인스턴스로 승격하도록 AWS Lambda 함수를 구성합니다.
C. DB 인스턴스를 다중 AZ 배포로 수정합니다.
D. DB 인스턴스 메모리 사용률을 90% 이상의 임계값으로 모니터링하는 Amazon CloudWatch 알람을 설정합니다. AWS Lambda 함수를 호출하여 DB 인스턴스를 다시 시작합니다.

회사가 트랜잭션 데이터를 처리하는 Amazon RDS DB 인스턴스를 사용하고 있으며, 장애 조치(DR) 솔루션이 필요하다면 **C. DB 인스턴스를 다중 AZ 배포로 수정합니다.**가 가장 적합한 솔루션입니다.

### 선택 이유:
- **다중 AZ 배포**: Amazon RDS의 다중 AZ 배포를 사용하면 자동으로 장애 조치를 수행할 수 있는 리저널 리플리케이션이 활성화됩니다. 기본 DB 인스턴스에서 데이터가 지속적으로 스탠바이 인스턴스에 복제되므로, 기본 인스턴스에 장애가 발생하더라도 스탠바이 인스턴스가 자동으로 활성화되어 트랜잭션 손실 없이 서비스가 유지됩니다. 이 방식은 커밋된 트랜잭션을 잃지 않고 자동으로 장애 조치를 수행할 수 있어 요구 사항을 충족합니다.

### 다른 옵션 분석:
- **A. 동일한 AWS 리전에서 RDS 읽기 복제본을 만듭니다. DR 시나리오 동안 복제본을 기본 DB 인스턴스로 승격하도록 AWS Lambda 함수를 구성합니다.**
  - 읽기 복제본은 장애 조치에 사용할 수 없으며, 수동으로 승격해야 하므로 자동화된 장애 조치 솔루션이 아닙니다.

- **B. 다른 AWS 지역에서 RDS 읽기 복제본을 만듭니다. DR 시나리오 동안 복제본을 기본 DB 인스턴스로 승격하도록 AWS Lambda 함수를 구성합니다.**
  - 다른 리전에서 읽기 복제본을 사용하는 것도 마찬가지로 수동으로 승격해야 하며, 트랜잭션 손실을 방지하기 위해서는 복제 지연 문제가 발생할 수 있습니다.

- **D. DB 인스턴스 메모리 사용률을 90% 이상의 임계값으로 모니터링하는 Amazon CloudWatch 알람을 설정합니다. AWS Lambda 함수를 호출하여 DB 인스턴스를 다시 시작합니다.**
  - 이 방법은 장애 조치와는 관련이 없으며, 메모리 사용률로 인해 인스턴스를 재시작하는 것은 서비스 중단을 초래할 수 있습니다.

### 결론:
따라서, **C. DB 인스턴스를 다중 AZ 배포로 수정**하는 것이 트랜잭션 데이터 손실 없이 자동으로 장애 조치를 수행할 수 있는 가장 효과적인 방법입니다.


## 질문 #336  +++

ASysOps 관리자는 기본 설정을 사용하여 간단한 확장 자동 확장 그룹에서 애플리케이션 로드 밸런서(ALB) 뒤의 Amazon EC2 인스턴스에서 실행되도록 애플리케이션을 구성합니다. 

자동 확장 그룹은 확장을 위해 RequestCountPerTarget 메트릭을 사용하도록 구성됩니다. SysOps 관리자는 RequestCountPerTarget 메트릭이 180초 동안 지정된 한도를 두 번 초과했다는 것을 알아챘습니다.

이 시나리오에서 이 자동 확장 그룹의 EC2 인스턴스 수는 어떻게 영향을 받을까요?

A. 자동 크기 조정 그룹은 RequestCountPerTarget 메트릭이 사전 정의된 한도를 초과할 때마다 추가 EC2 인스턴스를 시작합니다.
B. 자동 크기 조정 그룹은 하나의 EC2 인스턴스를 시작하고 다른 인스턴스를 시작하기 전에 기본 쿨다운 기간 동안 기다립니다.
C. 자동 확장 그룹은 ALB에 알림을 보내 트래픽을 재분배하고 부하가 정상화될 때까지 새로운 EC2 인스턴스를 추가하지 않습니다.
D. 자동 크기 조정 그룹은 다른 인스턴스를 시작하기 전에 모든 EC2 인스턴스에 트래픽을 분산하려고 합니다.

이 시나리오에서 **자동 크기 조정 그룹(Auto Scaling group)**은 `RequestCountPerTarget` 메트릭이 180초 동안 지정된 한도를 두 번 초과했으므로 **자동 크기 조정**이 발생합니다. **기본 설정에서는 쿨다운 기간**이 있기 때문에, 메트릭이 임계값을 초과할 때마다 추가 인스턴스를 시작하는 대신 **쿨다운(cooldown) 기간 동안 대기한 후에** 추가적인 확장이 이루어집니다.

따라서 가장 적절한 답변은:

**비. 자동 크기 조정 그룹은 하나의 EC2 인스턴스를 시작하고 다른 인스턴스를 시작하기 전에 기본 쿨다운 기간 동안 기다립니다.**

쿨다운 기간은 확장이 지나치게 빠르게 이루어져 과도하게 리소스가 프로비저닝되는 것을 방지하는 메커니즘입니다.


## 질문 #337 ++++

한 회사에는 ALB(Application Load Balancer) 뒤의 Amazon EC2 인스턴스에서 실행되는 보안 웹사이트가 있습니다. 

AWS Certificate Manager(ACM)의 SSL 인증서가 ALB에 사용됩니다. 레거시 웹 브라우저를 사용하는 사용자는 웹사이트에서 문제를 겪고 있습니다.

SysOps 관리자는 이러한 문제를 가장 운영 효율적인 방식으로 어떻게 해결해야 합니까?

A. ACM에서 새로운 SSL 인증서를 만들고 ALB에 새로운 인증서를 설치하여 레거시 웹 브라우저를 지원합니다.
B. 두 번째 ALB를 만들고 두 번째 ALB에 다른 도메인 이름을 사용하여 사용자 정의 SSL 인증서를 설치하여 레거시 웹 브라우저를 지원합니다.
C. 구성에서 ALB를 제거하고 각 웹 서버에 사용자 정의 SSL 인증서를 설치합니다.
D. 레거시 웹 브라우저에 대한 암호가 포함된 보안 정책으로 ALB의 SSL 협상 구성을 업데이트합니다.

레거시 웹 브라우저를 사용하는 사용자들이 웹사이트에서 문제를 겪고 있다면, **D. 레거시 웹 브라우저에 대한 암호가 포함된 보안 정책으로 ALB의 SSL 협상 구성을 업데이트합니다.**가 가장 운영 효율적인 방식입니다.

### 선택 이유:
- **SSL/TLS 보안 정책 조정**: ALB에서 SSL/TLS 보안 정책을 업데이트하여 레거시 웹 브라우저에서 사용하는 구식 암호화 알고리즘 및 프로토콜을 지원하도록 구성할 수 있습니다. 이를 통해 브라우저 호환성을 높이고, 레거시 사용자들이 웹사이트에 문제없이 접근할 수 있도록 합니다.

- **효율적인 운영**: 기존 ALB를 계속 사용하면서 SSL/TLS 정책만 조정하면 추가적인 리소스(예: 두 번째 ALB)를 생성할 필요가 없고, 운영 복잡성을 줄일 수 있습니다.

### 다른 옵션 분석:
- **A. ACM에서 새로운 SSL 인증서를 만들고 ALB에 새로운 인증서를 설치하여 레거시 웹 브라우저를 지원합니다.**
  - 새로운 인증서를 설치한다고 해서 레거시 브라우저 문제를 해결할 수는 없습니다. 레거시 브라우저가 지원하지 않는 암호화 알고리즘을 사용하는 인증서일 수 있습니다.

- **B. 두 번째 ALB를 만들고 두 번째 ALB에 다른 도메인 이름을 사용하여 사용자 정의 SSL 인증서를 설치하여 레거시 웹 브라우저를 지원합니다.**
  - 추가 ALB를 만드는 것은 비용 및 관리의 복잡성을 증가시키며, 문제를 해결하는 가장 효율적인 방법이 아닙니다.

- **C. 구성에서 ALB를 제거하고 각 웹 서버에 사용자 정의 SSL 인증서를 설치합니다.**
  - ALB를 제거하면 전체 아키텍처가 복잡해지고, 관리 부담이 증가합니다. ALB의 이점을 활용하지 못하게 됩니다.

### 결론:
따라서, ALB의 SSL 협상 구성을 업데이트하여 레거시 웹 브라우저에서 사용할 수 있는 암호화 정책을 지원하는 것이 가장 운영 효율적인 해결책입니다.


## 질문 #338 +

한 회사가 Amazon EC2 인스턴스에서 인터넷 웹 애플리케이션을 호스팅합니다. 

이 회사는 애플리케이션을 새로운 AWS Lambda 함수로 대체하고 있습니다. 전환 기간 동안 이 회사는 일부 트래픽을 레거시 애플리케이션으로, 일부 트래픽을 새로운 Lambda 함수로 라우팅해야 합니다. 이 회사는 라우팅을 결정하기 위해 요청의 URL 경로를 사용해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. URL 경로를 사용하여 트래픽을 레거시 애플리케이션과 새로운 Lambda 함수로 전달하도록 Gateway Load Balancer를 구성합니다.
B. URL 경로를 사용하여 트래픽을 레거시 애플리케이션과 새 Lambda 함수로 전달하도록 네트워크 로드 밸런서를 구성합니다.
C. 정규 표현식을 사용하여 URL 경로와 일치하도록 네트워크 로드 밸런서를 구성하여 트래픽을 새 Lambda 함수로 전달합니다.
D. URL 경로를 사용하여 레거시 애플리케이션과 새로운 Lambda 함수로 트래픽을 전달하도록 애플리케이션 로드 밸런서를 구성합니다.

URL 경로를 사용하여 트래픽을 레거시 애플리케이션과 새로운 AWS Lambda 함수로 라우팅하기 위한 최적의 솔루션은 **D. URL 경로를 사용하여 레거시 애플리케이션과 새로운 Lambda 함수로 트래픽을 전달하도록 애플리케이션 로드 밸런서를 구성합니다.**입니다.

### 선택 이유:
- **애플리케이션 로드 밸런서 (ALB)**: ALB는 HTTP/HTTPS 요청을 처리하고, URL 경로, HTTP 헤더, 쿠키 등 다양한 메트릭에 기반하여 트래픽을 라우팅할 수 있습니다. 이는 특정 URL 경로에 따라 레거시 애플리케이션과 Lambda 함수를 쉽게 구분하여 트래픽을 분배하는 데 적합합니다.
  
- **Lambda 통합**: ALB는 Lambda 함수와 직접 통합될 수 있어, 요청을 Lambda 함수로 라우팅하는 것이 간편합니다. 이를 통해 요청을 URL 경로에 따라 적절한 서비스로 전달할 수 있습니다.

### 다른 옵션 분석:
- **A. URL 경로를 사용하여 트래픽을 레거시 애플리케이션과 새로운 Lambda 함수로 전달하도록 Gateway Load Balancer를 구성합니다.**
  - Gateway Load Balancer는 주로 가상 appliance(예: 보안 장비)와 통합하여 트래픽을 처리하는 데 사용되며, URL 경로 기반 라우팅 기능이 없습니다.

- **B. URL 경로를 사용하여 트래픽을 레거시 애플리케이션과 새 Lambda 함수로 전달하도록 네트워크 로드 밸런서를 구성합니다.**
  - 네트워크 로드 밸런서(NLB)는 TCP 및 UDP 트래픽을 처리하며, URL 경로 기반의 HTTP 요청 라우팅을 지원하지 않습니다.

- **C. 정규 표현식을 사용하여 URL 경로와 일치하도록 네트워크 로드 밸런서를 구성하여 트래픽을 새 Lambda 함수로 전달합니다.**
  - NLB는 정규 표현식을 통한 URL 경로 기반 라우팅을 지원하지 않기 때문에 이 옵션은 유효하지 않습니다.

### 결론:
따라서, **애플리케이션 로드 밸런서를 구성**하여 URL 경로에 따라 레거시 애플리케이션과 새로운 Lambda 함수로 트래픽을 전달하는 것이 가장 적절한 솔루션입니다.



## 질문 #339 ++++

SysOps 관리자가 퍼블릭 서브넷에서 Amazon EC2 Linux 인스턴스를 시작합니다. 

인스턴스가 실행 중일 때 SysOps 관리자는 퍼블릭 IP 주소를 얻고 인스턴스에 원격으로 여러 번 연결을 시도합니다. 그러나 SysOps 관리자는 항상 시간 초과 오류를 받습니다.

SysOps 관리자가 인스턴스에 원격으로 연결할 수 있도록 하는 작업은 무엇입니까?

A. SysOps 관리자의 IP 주소에 대한 공개 서브넷에 경로 테이블 항목을 추가합니다.
B. SysOps 관리자의 IP 주소에 대해 TCP 포트 22를 허용하도록 아웃바운드 네트워크 ACL 규칙을 추가합니다.
C. SysOps 관리자의 IP 주소에서 들어오는 SSH 트래픽을 허용하도록 인스턴스 보안 그룹을 수정합니다.
D. SysOps 관리자의 IP 주소로의 아웃바운드 SSH 트래픽을 허용하도록 인스턴스 보안 그룹을 수정합니다.


SysOps 관리자가 인스턴스에 원격으로 연결할 수 있도록 하는 가장 적절한 작업은 **C. SysOps 관리자의 IP 주소에서 들어오는 SSH 트래픽을 허용하도록 인스턴스 보안 그룹을 수정합니다.**입니다.

### 선택 이유:
- **SSH 연결**: 원격으로 EC2 인스턴스에 연결하려면 SSH (Secure Shell) 프로토콜을 사용합니다. 기본적으로 SSH는 TCP 포트 22를 사용합니다.
- **보안 그룹 설정**: EC2 인스턴스의 보안 그룹은 인스턴스로 들어오는 트래픽을 제어하는 방화벽 역할을 합니다. 따라서 SysOps 관리자의 IP 주소에서 들어오는 SSH 트래픽을 허용하도록 보안 그룹을 수정해야 합니다.

### 다른 옵션 분석:
- **A. SysOps 관리자의 IP 주소에 대한 공개 서브넷에 경로 테이블 항목을 추가합니다.**
  - 경로 테이블 항목은 인스턴스의 트래픽 경로를 결정하지만, SSH 연결을 허용하는 데는 도움이 되지 않습니다.
  
- **B. SysOps 관리자의 IP 주소에 대해 TCP 포트 22를 허용하도록 아웃바운드 네트워크 ACL 규칙을 추가합니다.**
  - 아웃바운드 네트워크 ACL은 인스턴스에서 나가는 트래픽에 대한 규칙입니다. SSH 연결은 인바운드 트래픽이므로 아웃바운드 규칙을 추가해도 연결에 영향을 미치지 않습니다.
  
- **D. SysOps 관리자의 IP 주소로의 아웃바운드 SSH 트래픽을 허용하도록 인스턴스 보안 그룹을 수정합니다.**
  - 인스턴스에서 나가는 트래픽에 대한 설정이므로, 이는 필요하지 않습니다. SysOps 관리자가 인스턴스로 들어오는 트래픽을 허용해야 합니다.

### 결론:
따라서, 인스턴스에 원격으로 연결할 수 있도록 하려면 **SysOps 관리자의 IP 주소에서 들어오는 SSH 트래픽을 허용하도록 인스턴스 보안 그룹을 수정**해야 합니다.


## 질문 #340

시뮬레이션
-

지침.이 요구 사항을 충족하는 가장 적합한 솔루션은 **A. 클러스터 배치 그룹을 만듭니다. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. AMI에서 배치 그룹으로 EC2 인스턴스를 복원합니다. 추가 EC2 인스턴스를 배치 그룹으로 시작합니다.**입니다.

### 선택 이유:
1. **클러스터 배치 그룹**:
   - 클러스터 배치 그룹은 Amazon EC2 인스턴스를 동일한 가용성 영역 내에서 물리적으로 가까운 위치에 배치하여 높은 네트워크 성능을 제공합니다. 이 아키텍처는 HPC 애플리케이션의 요구 사항인 낮은 대기 시간과 높은 통신 속도를 지원하는 데 최적입니다.
   - 클러스터 배치 그룹을 사용하면 인스턴스 간의 네트워크 성능이 크게 향상되어 HPC 작업에 필요한 데이터 전송 속도와 응답성을 제공합니다.

2. **다른 옵션 분석**:
   - **B. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. AMI를 지정하여 기존 EC2 인스턴스에서 시작 템플릿을 만듭니다. 자동 확장 그룹을 만들고 원하는 인스턴스 수를 구성합니다.**
     - 이 방법은 자동 확장을 가능하게 하지만, 인스턴스 간의 네트워크 성능을 보장하지 않습니다. 자동 확장 그룹의 인스턴스가 배치되는 위치에 따라 네트워크 성능이 저하될 수 있습니다.
   - **C. 네트워크 로드 밸런서(NLB)와 대상 그룹을 만듭니다. 새 EC2 인스턴스를 시작하고 대상 그룹에 등록합니다. 기존 EC2 인스턴스를 대상 그룹에 등록합니다. 모든 애플리케이션 트래픽을 NLB를 통해 전달합니다.**
     - NLB는 트래픽을 분산시키는 데 도움이 되지만, EC2 인스턴스 간의 저지연 통신을 직접적으로 보장하지 않습니다.
   - **D. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. 기존 EC2 인스턴스가 있는 동일한 가용성 영역에서 AMI에서 EC2 인스턴스의 추가 복제본을 만듭니다.**
     - 이 방법은 인스턴스의 복제본을 만드는 것이지만, 동일한 가용성 영역 내에서 무작위로 배치될 수 있으므로 최적의 네트워크 성능을 보장하지 않습니다.

### 결론:
따라서 클러스터 배치 그룹을 사용하여 EC2 인스턴스를 시작하면 낮은 대기 시간으로 서로 통신해야 하는 HPC 애플리케이션의 요구 사항을 가장 잘 충족할 수 있습니다.

AWS Management Console 브라우저에 AWS 계정에 로그인한 것으로 표시되지 않으면 브라우저를 닫고 VM 데스크톱에서 AWS Management Console 바로 가기를 사용하여 콘솔을 다시 시작합니다.

환경에서 복사-붙여넣기 기능이 작동하지 않으면 VM 데스크톱의 지침 파일을 참조하고 Ctrl+C, Ctrl+V 또는 Command-C, Command-V를 사용합니다.

Amazon Data Lifecycle Manager를 사용하여 Amazon EBS Volume 스냅샷을 자동화하는 솔루션을 만듭니다.

1. 모든 리소스에 us-east-2 Region을 사용합니다.
2. 아래에 지정되지 않은 경우 기본 구성 설정을 사용합니다.
3. OriginalVolume이라는 기존 EBS Volume의 스냅샷을 만듭니다.
4. 기본 암호화를 사용하여 스냅샷에서 1GB EBS Volume을 만듭니다.
5. 새 EBS Volume에 Snapshot: true 태그를 추가합니다.
6. Snapshot:true 태그가 있는 모든 볼륨의 스냅샷이 6시간마다 생성되어 90일 동안 보관되는지 확인합니다. cron 표현식을 사용하지 마십시오. 이것이 존재하는 유일한 수명 주기 정책인지 확인합니다. DLMRole이라는 IAM 역할을 사용합니다.

중요: 다음 버튼을 클릭하여 이 랩을 완료하고 다음 랩으로 넘어갑니다. 다음 버튼을 클릭하면 이 랩으로 돌아갈 수 없습니다.



## 질문 #341

시뮬레이션
-

지침.

AWS Management Console 브라우저에 AWS 계정에 로그인한 것으로 표시되지 않으면 브라우저를 닫고 VM 데스크톱에서 AWS Management Console 바로 가기를 사용하여 콘솔을 다시 시작합니다.

환경에서 복사-붙여넣기 기능이 작동하지 않으면 VM 데스크톱의 지침 파일을 참조하고 Ctrl+C, Ctrl+V 또는 Command-C, Command-V를 사용합니다.

다음 구성 요구 사항을 사용하여 Amazon DynamoDB Accelerator(DAX) 클러스터를 만들고 기존 DynamoDB 테이블을 수정합니다.

1. 모든 리소스에 us-east-2 리전을 사용합니다.
2. 다음 지침에 다른 설정이 지정되지 않은 경우 기본 구성 설정을 사용합니다.
3. 캐시된 데이터 항목은 240초 후에 만료되고 캐시된 쿼리는 120초 후에 만료되도록 DAX 클러스터를 구성합니다. ***참고: 클러스터 생성을 완료하기 전에 이러한 값을 구성합니다. 그렇지 않으면 이 단계를 수행하기 전에 클러스터 생성이 완료될 때까지 기다려야 합니다.
4. DaxLabCluster라는 이름의 3노드 DynamoDB DAX 클러스터를 만듭니다.
a. dax.t3.small 인스턴스를 사용합니다.
b. LabVPC VPC와 PrimaryPrivateSubnet 및 FailoverPrivateSubnet 서브넷을 사용합니다.
c. LabDAXSG 보안 그룹을 사용합니다.
d. DynamoDBAccessRole IAM 역할을 사용하도록 DAX 클러스터를 구성합니다.
5. LabDynamoDBTable DynamoDB 테이블을 수정하여 테이블이 주문형 용량을 사용하도록 합니다.

참고: 이 시험 랩을 제출하기 전에 클러스터 생성이 완료될 때까지 기다리지 마십시오.

중요: 다음 버튼을 클릭하여 이 랩을 완료하고 다음 랩으로 넘어갑니다. 다음 버튼을 클릭하면 이 랩으로 돌아갈 수 없습니다.




## 질문 #342 ++

한 회사가 Amazon EC2 인스턴스에서 고성능 컴퓨팅(HPC) 애플리케이션을 실행합니다.

이 회사는 이 아키텍처를 두 개 이상의 EC2 인스턴스로 확장해야 합니다. EC2 인스턴스는 애플리케이션을 지원하기 위해 낮은 대기 시간으로 고속으로 서로 통신해야 합니다.

이 회사는 네트워크 성능이 EC2 인스턴스 간의 필요한 통신을 지원할 수 있는지 확인하고자 합니다 .

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 클러스터 배치 그룹을 만듭니다. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. AMI에서 배치 그룹으로 EC2 인스턴스를 복원합니다. 추가 EC2 인스턴스를 배치 그룹으로 시작합니다.
B. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. AMI를 지정하여 기존 EC2 인스턴스에서 시작 템플릿을 만듭니다. 자동 확장 그룹을 만들고 원하는 인스턴스 수를 구성합니다.
C. 네트워크 로드 밸런서(NLB)와 대상 그룹을 만듭니다. 새 EC2 인스턴스를 시작하고 대상 그룹에 등록합니다. 기존 EC2 인스턴스를 대상 그룹에 등록합니다. 모든 애플리케이션 트래픽을 NLB를 통해 전달합니다.
D. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. 기존 EC2 인스턴스가 있는 동일한 가용성 영역에서 AMI에서 EC2 인스턴스의 추가 복제본을 만듭니다.

이 요구 사항을 충족하는 가장 적합한 솔루션은 **A. 클러스터 배치 그룹을 만듭니다. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. AMI에서 배치 그룹으로 EC2 인스턴스를 복원합니다. 추가 EC2 인스턴스를 배치 그룹으로 시작합니다.**입니다.

### 선택 이유:
1. **클러스터 배치 그룹**:
   - 클러스터 배치 그룹은 Amazon EC2 인스턴스를 동일한 가용성 영역 내에서 물리적으로 가까운 위치에 배치하여 높은 네트워크 성능을 제공합니다. 이 아키텍처는 HPC 애플리케이션의 요구 사항인 낮은 대기 시간과 높은 통신 속도를 지원하는 데 최적입니다.
   - 클러스터 배치 그룹을 사용하면 인스턴스 간의 네트워크 성능이 크게 향상되어 HPC 작업에 필요한 데이터 전송 속도와 응답성을 제공합니다.

2. **다른 옵션 분석**:
   - **B. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. AMI를 지정하여 기존 EC2 인스턴스에서 시작 템플릿을 만듭니다. 자동 확장 그룹을 만들고 원하는 인스턴스 수를 구성합니다.**
     - 이 방법은 자동 확장을 가능하게 하지만, 인스턴스 간의 네트워크 성능을 보장하지 않습니다. 자동 확장 그룹의 인스턴스가 배치되는 위치에 따라 네트워크 성능이 저하될 수 있습니다.
   - **C. 네트워크 로드 밸런서(NLB)와 대상 그룹을 만듭니다. 새 EC2 인스턴스를 시작하고 대상 그룹에 등록합니다. 기존 EC2 인스턴스를 대상 그룹에 등록합니다. 모든 애플리케이션 트래픽을 NLB를 통해 전달합니다.**
     - NLB는 트래픽을 분산시키는 데 도움이 되지만, EC2 인스턴스 간의 저지연 통신을 직접적으로 보장하지 않습니다.
   - **D. 기존 EC2 인스턴스를 Amazon Machine Image(AMI)로 백업합니다. 기존 EC2 인스턴스가 있는 동일한 가용성 영역에서 AMI에서 EC2 인스턴스의 추가 복제본을 만듭니다.**
     - 이 방법은 인스턴스의 복제본을 만드는 것이지만, 동일한 가용성 영역 내에서 무작위로 배치될 수 있으므로 최적의 네트워크 성능을 보장하지 않습니다.

### 결론:
따라서 클러스터 배치 그룹을 사용하여 EC2 인스턴스를 시작하면 낮은 대기 시간으로 서로 통신해야 하는 HPC 애플리케이션의 요구 사항을 가장 잘 충족할 수 있습니다.


## 질문 #343 ++

개발자가 객체가 Amazon S3 버킷에 들어갈 때 실행되는 AWS Lambda 함수를 만듭니다. 

이 함수는 객체를 다시 포맷하고 객체를 다시 S3 버킷에 넣습니다. 테스트하는 동안 개발자는 재귀적 호출 루프를 알아차립니다. 개발자는 SysOps 관리자에게 재귀적 호출을 즉시 중지해 달라고 요청합니다.

SysOps 관리자는 오류 없이 루프를 중지하기 위해 무엇을 해야 합니까?
A. S3 버킷에서 모든 객체를 삭제합니다.
B. 함수의 예약된 동시성을 0으로 설정합니다.
가장 많이 투표된
C. S3 버킷 정책을 업데이트하여 해당 함수에 대한 액세스를 거부합니다.
D. 함수의 새로운 버전을 게시합니다.

이 시나리오에서 재귀적 호출을 즉시 중지하려면 가장 신속하고 효율적인 방법은 **AWS Lambda 함수의 예약된 동시성을 0으로 설정하는 것**입니다. 이렇게 하면 Lambda 함수가 더 이상 실행되지 않으며, 재귀적 호출을 즉시 멈출 수 있습니다.

따라서 가장 적절한 답변은:

**비. 함수의 예약된 동시성을 0으로 설정합니다.**

이 방법은 실행을 중지하는 동시에, Lambda 함수와 관련된 다른 설정이나 구성에 영향을 미치지 않기 때문에 안전하고 효과적입니다.


## 질문 #344 ++++

한 회사에는 us-west-2 지역의 Application Load Balancer(ALB) 뒤에서 실행되는 애플리케이션이 있습니다. 

Amazon Route 53 레코드 세트에는 us-west-2의 ALB를 참조하고 간단한 라우팅 정책을 사용하는 app.anycompany.com에 대한 별칭 레코드가 포함되어 있습니다. 이 애플리케이션은 전 세계 다른 지역에서 온 사용자가 증가하고 있습니다. 이러한 사용자는 높은 지연 시간을 겪고 있습니다.

대부분의 새로운 사용자는 ap-southeast-2 지역과 가깝습니다. 이 회사는 애플리케이션의 사본을 ap-southeast-2에 배포합니다. SysOps 관리자는 URL을 변경하지 않고도 사용자의 가장 낮은 지연 시간 엔드포인트로 요청을 자동으로 라우팅하는 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. ap-southeast-2의 새 ALB의 DNS 이름을 사용하여 app.anycompany.com의 기존 별칭 레코드에 새 값을 추가합니다.
B. 기존 별칭 레코드를 변경하여 지리적 위치 라우팅 정책을 사용합니다. 두 개의 지리적 위치 레코드를 만듭니다. 각 AL을 참조하는 레코드가 하나 있습니다. 각 Region에 가장 가까운 위치를 선택합니다.
C. 기존 별칭 레코드를 변경하여 대기 시간 라우팅 정책을 사용합니다. 각 ALB를 참조하는 레코드 1개, 대기 시간 레코드 2개를 만듭니다.
D. 기존 별칭 레코드를 변경하여 다중값 라우팅 정책을 사용합니다. 각 ALB의 DNS 이름을 레코드에 추가합니다.

이 요구 사항을 충족하는 가장 적합한 솔루션은 **C. 기존 별칭 레코드를 변경하여 대기 시간 라우팅 정책을 사용합니다. 각 ALB를 참조하는 레코드 1개, 대기 시간 레코드 2개를 만듭니다.**입니다.

### 선택 이유:
1. **대기 시간 라우팅 정책**:
   - 이 정책은 사용자 요청을 가장 낮은 지연 시간을 가진 엔드포인트로 자동으로 라우팅합니다. 따라서, ap-southeast-2 리전의 ALB와 us-west-2 리전의 ALB를 모두 포함시킴으로써 사용자의 위치에 따라 가장 적합한 리전으로의 요청을 보낼 수 있습니다.
   - 두 ALB를 참조하는 별칭 레코드를 설정하면 Route 53이 각 요청에 대해 가장 낮은 지연 시간을 가진 엔드포인트를 선택할 수 있습니다.

2. **다른 옵션 분석**:
   - **A. ap-southeast-2의 새 ALB의 DNS 이름을 사용하여 app.anycompany.com의 기존 별칭 레코드에 새 값을 추가합니다.**
     - 이 방법은 URL을 변경하지 않겠다는 요구 사항을 충족하지 않으며, ALB 간에 로드 밸런싱을 제공하지 않습니다.
   - **B. 기존 별칭 레코드를 변경하여 지리적 위치 라우팅 정책을 사용합니다. 두 개의 지리적 위치 레코드를 만듭니다. 각 ALB를 참조하는 레코드가 하나 있습니다.**
     - 지리적 위치 라우팅 정책은 특정 지역에서 사용자에게 요청을 전달할 수 있지만, 대기 시간에 기반한 최적의 라우팅을 보장하지 않습니다.
   - **D. 기존 별칭 레코드를 변경하여 다중값 라우팅 정책을 사용합니다. 각 ALB의 DNS 이름을 레코드에 추가합니다.**
     - 다중값 라우팅 정책은 여러 IP 주소를 반환할 수 있지만, 최적의 대기 시간을 보장하는 것은 아닙니다.

### 결론:
따라서 대기 시간 라우팅 정책을 사용하여 각 ALB를 참조하는 별칭 레코드를 설정하는 것이 전 세계 사용자에게 가장 낮은 지연 시간으로 요청을 자동으로 라우팅하는 최적의 방법입니다.


## 질문 #345 +++++

한 회사가 동일한 AWS 리전의 50개 Amazon S3 버킷에 파일을 저장합니다. 

이 회사는 Amazon EC2 인스턴스에서 개인 연결을 통해 S3 버킷에 안전하게 연결하려고 합니다. 이 회사는 추가 비용이 발생하지 않는 솔루션이 필요합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 각 S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 만듭니다. 게이트웨이 VPC 엔드포인트를 VPC 내부의 각 서브넷에 연결합니다.
B. 각 S3 버킷에 대한 인터페이스 VPC 엔드포인트를 만듭니다. 인터페이스 VPC 엔드포인트를 VPC 내부의 각 서브넷에 연결합니다.
C. 모든 S3 버킷에 대해 하나의 게이트웨이 VPC 엔드포인트를 만듭니다. 게이트웨이 VPC 엔드포인트를 VPC 경로 테이블에 추가합니다.
D. 모든 S3 버킷에 대해 하나의 인터페이스 VPC 엔드포인트를 만듭니다. 인터페이스 VPC 엔드포인트를 VPC 경로 테이블에 추가합니다.

이 회사의 요구 사항에 맞는 가장 비용 효율적인 솔루션은 **C. 모든 S3 버킷에 대해 하나의 게이트웨이 VPC 엔드포인트를 만듭니다. 게이트웨이 VPC 엔드포인트를 VPC 경로 테이블에 추가합니다.**입니다.

### 선택 이유:
1. **게이트웨이 VPC 엔드포인트**:
   - Amazon S3와의 연결을 위해 게이트웨이 VPC 엔드포인트를 사용할 수 있으며, 이 경우 **추가 비용이 발생하지 않습니다.** 게이트웨이 VPC 엔드포인트는 S3와 같은 AWS 서비스에 대한 트래픽을 인터넷을 경유하지 않고도 안전하게 라우팅할 수 있습니다.
   - 게이트웨이 VPC 엔드포인트를 생성하면 S3 버킷에 대한 액세스를 위한 전용 연결을 제공하고, EC2 인스턴스가 VPC 내부에서 안전하게 S3 버킷에 연결할 수 있도록 합니다.

2. **다른 옵션 분석**:
   - **A. 각 S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 만듭니다. 게이트웨이 VPC 엔드포인트를 VPC 내부의 각 서브넷에 연결합니다.**
     - 이 방법은 불필요한 엔드포인트 생성을 유도하므로, 비용이 증가할 수 있습니다. 모든 S3 버킷에 대해 단일 엔드포인트를 사용하는 것이 더 효율적입니다.
   - **B. 각 S3 버킷에 대한 인터페이스 VPC 엔드포인트를 만듭니다. 인터페이스 VPC 엔드포인트를 VPC 내부의 각 서브넷에 연결합니다.**
     - 인터페이스 VPC 엔드포인트는 추가 비용이 발생하므로 요구 사항에 부합하지 않습니다.
   - **D. 모든 S3 버킷에 대해 하나의 인터페이스 VPC 엔드포인트를 만듭니다. 인터페이스 VPC 엔드포인트를 VPC 경로 테이블에 추가합니다.**
     - 마찬가지로, 인터페이스 VPC 엔드포인트는 추가 비용이 발생하며, S3에 접근하기 위한 적절한 솔루션이 아닙니다.

### 결론:
따라서, 모든 S3 버킷에 대해 하나의 게이트웨이 VPC 엔드포인트를 설정하여 안전하고 비용 효율적으로 EC2 인스턴스에서 S3 버킷에 연결하는 것이 최적의 선택입니다.


## 질문 #346 +++++

회사의 보안 정책에 따르면 SSH 및 ROP를 통한 Amazon EC2 인스턴스 연결이 허용되지 않습니다. 

액세스가 필요한 경우 권한이 있는 직원은 AWS Systems Manager Session Manager를 사용하여 인스턴스에 연결할 수 있습니다.

사용자는 Ubuntu를 실행하고 AWS Systems Manager Agent(SSM Agent)가 사전 설치된 특정 Amazon EC2 인스턴스에 연결할 수 없다고 보고합니다. 이러한 사용자는 Session Manager를 사용하여 동일한 서브넷의 다른 인스턴스에 연결할 수 있으며 모든 인스턴스에 대한 Session Manager 권한이 있는 IAM 그룹에 있습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?
A. Ubuntu 인스턴스와 연결된 보안 그룹의 포트 22에 대한 인바운드 규칙을 추가합니다.
B. Ubuntu 인스턴스의 EC2 인스턴스 프로필에 AmazonSSMManagedInstanceCore 관리 정책을 할당합니다.
C. SSM 에이전트가 "ubuntu"라는 사용자 이름으로 로그인하도록 구성합니다.
D. 새로운 키 쌍을 생성하고, 이 새로운 키 쌍을 사용하도록 세션 관리자를 구성한 후, 사용자에게 개인 키를 제공합니다.

사용자가 Ubuntu를 실행하는 Amazon EC2 인스턴스에 AWS Systems Manager Session Manager를 사용하여 연결할 수 없는 문제를 해결하기 위한 가장 적절한 조치는 **B. Ubuntu 인스턴스의 EC2 인스턴스 프로필에 AmazonSSMManagedInstanceCore 관리 정책을 할당합니다.**입니다.

### 선택 이유:
1. **AmazonSSMManagedInstanceCore 관리 정책**:
   - 이 정책은 Systems Manager가 인스턴스와 상호작용할 수 있도록 필요한 권한을 부여합니다. 이 정책이 인스턴스 프로필에 포함되어 있지 않으면 SSM 에이전트가 AWS Systems Manager와 통신할 수 없어 Session Manager를 통한 연결이 실패할 수 있습니다.

2. **다른 옵션 분석**:
   - **A. Ubuntu 인스턴스와 연결된 보안 그룹의 포트 22에 대한 인바운드 규칙을 추가합니다.**
     - 이 옵션은 SSH 연결을 허용하는 것이므로 요구 사항에 부합하지 않습니다. 보안 정책에 따라 SSH 연결은 허용되지 않습니다.

   - **C. SSM 에이전트가 "ubuntu"라는 사용자 이름으로 로그인하도록 구성합니다.**
     - SSM Agent는 사용자 이름을 사용하여 연결하는 것이 아니라 AWS API를 통해 인스턴스와 상호작용합니다. 따라서 사용자 이름을 변경하는 것은 필요하지 않습니다.

   - **D. 새로운 키 쌍을 생성하고, 이 새로운 키 쌍을 사용하도록 세션 관리자를 구성한 후, 사용자에게 개인 키를 제공합니다.**
     - 이 옵션은 SSH 연결을 사용하는 방법으로, 보안 정책에 위배됩니다. Session Manager를 사용하기 위해 SSH 키 쌍을 설정할 필요가 없습니다.

### 결론:
따라서, 문제를 해결하기 위해 EC2 인스턴스 프로필에 **AmazonSSMManagedInstanceCore** 정책을 할당하여 SSM 에이전트가 AWS Systems Manager와 정상적으로 통신할 수 있도록 하는 것이 가장 효과적인 방법입니다.

## 질문 #347 ++

SysOps 관리자가 Amazon CloudWatch 알람을 구성하고 있습니다. 특정 알람은 항상 ALARM 상태입니다.

이 문제의 원인은 무엇일까요?

A. 알람은 트리거된 후에도 구성된 임계값에 대해 계속해서 메트릭을 평가합니다.
B. 경보가 발생하면 수동으로 비활성화할 때까지 ALARM 상태를 유지합니다.
C. 경보가 발생하고 작업이 수행된 후 애플리케이션 로직은 경보를 정상 상태로 재설정해야 합니다.
D. 알람이 적절한 측정 항목을 수신하지 못하고 있습니다.

특정 Amazon CloudWatch 알람이 항상 ALARM 상태인 경우, 이 문제의 가장 가능성이 높은 원인은 **D. 알람이 적절한 측정 항목을 수신하지 못하고 있습니다.**입니다.

### 선택 이유:
1. **측정 항목 수신 문제**:
   - CloudWatch 알람은 지정된 메트릭에 대한 평가를 기반으로 작동합니다. 메트릭 데이터가 수신되지 않으면 알람은 항상 ALARM 상태로 유지될 수 있습니다. 이 경우 알람은 비정상적인 상태를 지속적으로 보고하지만, 실제로는 메트릭이 존재하지 않거나 잘못 구성된 상태일 수 있습니다.

2. **다른 옵션 분석**:
   - **A. 알람은 트리거된 후에도 구성된 임계값에 대해 계속해서 메트릭을 평가합니다.**
     - 알람이 ALARM 상태로 전환된 후에도 평가를 계속하긴 하지만, 이 자체가 항상 ALARM 상태를 유발하지는 않습니다.

   - **B. 경보가 발생하면 수동으로 비활성화할 때까지 ALARM 상태를 유지합니다.**
     - 알람은 수동으로 비활성화할 수 있지만, 기본적으로 비정상적인 메트릭이 발생했을 때만 ALARM 상태로 유지됩니다.

   - **C. 경보가 발생하고 작업이 수행된 후 애플리케이션 로직은 경보를 정상 상태로 재설정해야 합니다.**
     - 경보가 ALARM 상태에 있는 경우, 이 자체가 문제를 유발하지는 않으며, 정상 상태로 재설정되는 것은 일반적으로 메트릭 값이 임계값을 초과하는 경우입니다.

결론적으로, 알람이 항상 ALARM 상태인 가장 확실한 원인은 **적절한 메트릭을 수신하지 못하고 있다는 점**입니다. 이를 확인하고 필요한 메트릭이 올바르게 수집되고 있는지 점검해야 합니다.


## 질문 #348

한 회사가 AWS 환경과 온프레미스 데이터 센터 사이에 IPsec 터널을 설정했습니다. 터널은 UP으로 보고되지만 Amazon EC2 인스턴스는 온프레미스 리소스를 ping할 수 없습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?
A. 온프레미스 CIDR에서 ICMP 트래픽을 허용하기 위해 EC2 인스턴스의 보안 그룹에 새로운 인바운드 규칙을 만듭니다.
B. IPsec 터널과 EC2 인스턴스의 서브넷 사이에 피어링 연결을 만듭니다.
C. EC2 인스턴스의 서브넷에 할당된 경로 테이블에서 가상 사설 게이트웨이에 대한 경로 전파를 활성화합니다.
D. VPC의 DHCP 옵션 세트를 수Amazon Aurora 단일 노드 DB 클러스터에서 높은 CPU 사용률과 최대 연결 오류로 인해 성능 저하가 발생하고 있는 상황에서, 데이터베이스의 안정성을 개선하기 위한 가장 효과적인 솔루션은 **A. Aurora Replica 노드를 만듭니다. CPU 사용률에 따라 복제본을 확장하기 위한 자동 확장 정책을 만듭니다. 모든 보고 요청이 읽기 전용 연결 문자열을 사용하는지 확인합니다.**입니다.

### 선택 이유:

1. **Aurora Replica의 장점**:
   - **읽기 전용 요청 처리**: Aurora Replica를 사용하면 읽기 전용 쿼리를 처리할 수 있으므로 기본 DB 인스턴스의 부하를 줄여 CPU 사용률과 연결 오류를 완화할 수 있습니다.
   - **자동 확장**: 필요에 따라 Replica를 추가하여 성능을 더욱 향상시킬 수 있으며, 자동 확장 정책을 설정하면 수요에 따라 Replica 수를 조정할 수 있습니다.

2. **성능 향상**:
   - 보고 쿼리와 같은 읽기 집중형 요청이 Aurora Replica로 라우팅되면, 기본 DB 인스턴스는 쓰기 작업과 관리 작업에 더 많은 리소스를 할당할 수 있어 전체 성능이 향상됩니다.

3. **기타 옵션 분석**:
   - **B. 두 번째 가용성 영역에 두 번째 Aurora MySQL 단일 노드 DB 클러스터를 만듭니다.**
     - 이 방법은 추가 노드를 만드는 대신 별도의 클러스터를 생성하므로, 비용과 관리 복잡성이 증가할 수 있습니다. 또한, 기본 클러스터의 부하를 직접적으로 줄이지는 못합니다.
   
   - **C. 보고 요청을 캐시하는 AWS Lambda 함수를 만듭니다.**
     - Lambda 함수는 쿼리 성능을 개선할 수 있지만, 대량의 쿼리를 처리하는 경우 관리와 유지보수가 복잡해질 수 있습니다.
   
   - **D. 다중 노드 Amazon ElastiCache 클러스터를 만듭니다.**
     - ElastiCache는 캐싱을 통해 성능을 개선할 수 있지만, 데이터 일관성 및 캐시 미스 처리와 같은 추가적인 관리 부담이 발생할 수 있습니다.

결론적으로, **Aurora Replica를 활용하여 읽기 전용 요청을 처리하는 것이 안정성과 성능을 개선하는 가장 효과적인 방법**입니다.정합니다. VPN 섹션에 IPsec 터널을 추가합니다.



## 질문 #349 ***

한 회사가 Amazon Aurora 단일 노드 DB 클러스터에 프로덕션 MySQL 데이터베이스를 호스팅합니다. 

이 데이터베이스는 보고 목적으로 대량으로 쿼리됩니다. DB 클러스터는 높은 CPU 사용률과 최대 연결 오류로 인해 성능 저하 기간을 겪고 있습니다. SysOps 관리자는 데이터베이스의 안정성을 개선해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. Aurora Replica 노드를 만듭니다. CPU 사용률에 따라 복제본을 확장하기 위한 자동 확장 정책을 만듭니다. 모든 보고 요청이 읽기 전용 연결 문자열을 사용하는지 확인합니다.
B. 두 번째 가용성 영역에 두 번째 Aurora MySQL 단일 노드 DB 클러스터를 만듭니다. 모든 보고 요청이 이 추가 노드에 대한 연결 문자열을 사용하는지 확인합니다.
C. 보고 요청을 캐시하는 AWS Lambda 함수를 만듭니다. 모든 보고 요청이 Lambda 함수를 호출하는지 확인합니다.
D. 다중 노드 Amazon ElastiCache 클러스터를 만듭니다. 모든 보고 요청이 ElastiCache 클러스터를 사용하는지 확인합니다. 데이터가 캐시에 없으면 데이터베이스를 사용합니다.

Amazon Aurora 단일 노드 DB 클러스터에서 높은 CPU 사용률과 최대 연결 오류로 인해 성능 저하가 발생하고 있는 상황에서, 데이터베이스의 안정성을 개선하기 위한 가장 효과적인 솔루션은 **A. Aurora Replica 노드를 만듭니다. CPU 사용률에 따라 복제본을 확장하기 위한 자동 확장 정책을 만듭니다. 모든 보고 요청이 읽기 전용 연결 문자열을 사용하는지 확인합니다.**입니다.

### 선택 이유:

1. **Aurora Replica의 장점**:
   - **읽기 전용 요청 처리**: Aurora Replica를 사용하면 읽기 전용 쿼리를 처리할 수 있으므로 기본 DB 인스턴스의 부하를 줄여 CPU 사용률과 연결 오류를 완화할 수 있습니다.
   - **자동 확장**: 필요에 따라 Replica를 추가하여 성능을 더욱 향상시킬 수 있으며, 자동 확장 정책을 설정하면 수요에 따라 Replica 수를 조정할 수 있습니다.

2. **성능 향상**:
   - 보고 쿼리와 같은 읽기 집중형 요청이 Aurora Replica로 라우팅되면, 기본 DB 인스턴스는 쓰기 작업과 관리 작업에 더 많은 리소스를 할당할 수 있어 전체 성능이 향상됩니다.

3. **기타 옵션 분석**:
   - **B. 두 번째 가용성 영역에 두 번째 Aurora MySQL 단일 노드 DB 클러스터를 만듭니다.**
     - 이 방법은 추가 노드를 만드는 대신 별도의 클러스터를 생성하므로, 비용과 관리 복잡성이 증가할 수 있습니다. 또한, 기본 클러스터의 부하를 직접적으로 줄이지는 못합니다.
   
   - **C. 보고 요청을 캐시하는 AWS Lambda 함수를 만듭니다.**
     - Lambda 함수는 쿼리 성능을 개선할 수 있지만, 대량의 쿼리를 처리하는 경우 관리와 유지보수가 복잡해질 수 있습니다.
   
   - **D. 다중 노드 Amazon ElastiCache 클러스터를 만듭니다.**
     - ElastiCache는 캐싱을 통해 성능을 개선할 수 있지만, 데이터 일관성 및 캐시 미스 처리와 같은 추가적인 관리 부담이 발생할 수 있습니다.

결론적으로, **Aurora Replica를 활용하여 읽기 전용 요청을 처리하는 것이 안정성과 성능을 개선하는 가장 효과적인 방법**입니다.



## 질문 #350 *****

어떤 회사가 사용자가 www example com이라는 이름으로 액세스하는 웹 애플리케이션을 실행합니다. 

이 회사는 Amazon Route 53을 사용하여 example.com이라는 도메인 이름을 관리합니다. 이 회사는 애플리케이션 앞에 Amazon CloudFront 배포를 생성했고 www.example.com이 CloudFront를 통해 애플리케이션에 액세스하기를 원합니다.

이를 달성하는 가장 비용 효율적인 방법은 무엇입니까?

A. Amazon Route 53에 CloudFront 배포 URL을 가리키는 CNAME 레코드를 만듭니다.
B. Amazon Route 53에 CioudFront 배포 URL을 가리키는 ALIAS 레코드를 생성합니다.
C. Amazon Route 53에 웹 애플리케이션의 공용 IP 주소를 가리키는 A 레코드를 만듭니다.
D. Amazon Route 53에 웹 애플리케이션의 공용 IP 주소를 가리키는 PTR 레코드를 만듭니다

www.example.com이 Amazon CloudFront를 통해 애플리케이션에 액세스하도록 설정하는 가장 비용 효율적인 방법은 **B. Amazon Route 53에 CloudFront 배포 URL을 가리키는 ALIAS 레코드를 생성합니다.**입니다.

### 선택 이유:

1. **ALIAS 레코드**:
   - Route 53의 ALIAS 레코드는 AWS 리소스를 가리킬 때 사용됩니다. ALIAS 레코드를 사용하면 CloudFront 배포 URL을 직접 가리킬 수 있으며, Route 53이 이를 자동으로 관리하여 비용을 절감할 수 있습니다.
   - ALIAS 레코드는 최상위 도메인(root domain) 및 하위 도메인(subdomain) 모두에 대해 사용 가능하므로 www.example.com을 CloudFront에 쉽게 연결할 수 있습니다.

2. **CNAME 레코드와의 차이**:
   - CNAME 레코드는 하위 도메인에 대해만 사용할 수 있으며, 최상위 도메인에서 사용하면 DNS 설정에 문제가 발생합니다. ALIAS 레코드는 이러한 제한이 없습니다.
   - CNAME 레코드는 요청의 지연을 초래할 수 있으며, ALIAS 레코드는 이러한 지연을 방지합니다.

3. **기타 옵션 분석**:
   - **A. Amazon Route 53에 CloudFront 배포 URL을 가리키는 CNAME 레코드를 만듭니다.**
     - 최상위 도메인에서는 사용할 수 없으므로 이 방법은 적절하지 않습니다.
   
   - **C. Amazon Route 53에 웹 애플리케이션의 공용 IP 주소를 가리키는 A 레코드를 만듭니다.**
     - CloudFront를 통해 애플리케이션에 액세스하는 것을 원하고 있으므로, 직접 공용 IP 주소를 가리키는 것은 CloudFront의 이점을 활용하지 못합니다.
   
   - **D. Amazon Route 53에 웹 애플리케이션의 공용 IP 주소를 가리키는 PTR 레코드를 만듭니다.**
     - PTR 레코드는 주로 역방향 DNS 조회에 사용되며, 이 경우 적절하지 않습니다.

결론적으로, **Amazon Route 53에 CloudFront 배포 URL을 가리키는 ALIAS 레코드를 생성하는 것이 가장 비용 효율적이고 올바른 방법**입니다.


## 질문 #351 ***

한 회사가 AWS Organizations에서 여러 AWS 계정을 관리하고 있습니다. 

이 회사는 AWS 환경의 내부 보안을 검토하고 있습니다. 이 회사의 보안 관리자는 자체 AWS 계정을 가지고 있으며 개발자 AWS 계정의 VPC 구성을 검토하려고 합니다.

어떤 솔루션이 가장 안전한 방식으로 이러한 요구 사항을 충족할까요?

A. VPC 리소스와 관련된 읽기 전용 액세스 권한이 있는 각 개발자 계정에서 IAM 정책을 만듭니다. 정책을 IAM 사용자에게 할당합니다. 사용자 자격 증명을 보안 관리자와 공유합니다.
B. VPC 작업을 포함하여 모든 Amazon EC2 작업에 대한 관리자 액세스 권한이 있는 각 개발자 계정에서 IAM 정책을 만듭니다. 정책을 IAM 사용자에게 할당합니다. 사용자 자격 증명을 보안 관리자와 공유합니다.
C. VPC 리소스와 관련된 관리자 액세스 권한이 있는 각 개발자 계정에서 IAM 정책을 만듭니다. 정책을 교차 계정 IAM 역할에 할당합니다. 보안 관리자에게 해당 계정에서 역할을 맡도록 요청합니다.
D. VPC 리소스와 관련된 읽기 전용 액세스 권한이 있는 각 개발자 계정에서 IAM 정책을 만듭니다. 정책을 교차 계정 IAM 역할에 할당합니다. 보안 관리자에게 해당 계정에서 역할을 맡도록 요청합니다.

보안 관리자가 개발자 AWS 계정의 VPC 구성을 안전하게 검토하기 위해 선택해야 할 솔루션은 **D. VPC 리소스와 관련된 읽기 전용 액세스 권한이 있는 각 개발자 계정에서 IAM 정책을 만듭니다. 정책을 교차 계정 IAM 역할에 할당합니다. 보안 관리자에게 해당 계정에서 역할을 맡도록 요청합니다.**입니다.

### 선택 이유:

- **최소 권한 원칙**: 읽기 전용 액세스 권한을 제공하는 IAM 정책을 사용하면 보안 관리자가 개발자 계정의 VPC 구성을 검토할 수 있지만 변경할 수는 없습니다. 이는 보안 사고를 줄이고 시스템의 무결성을 보호하는 데 중요합니다.

- **교차 계정 역할**: IAM 역할을 사용하여 다른 계정의 리소스에 안전하게 접근할 수 있습니다. 보안 관리자는 교차 계정 IAM 역할을 맡아 개발자 계정의 VPC 리소스에 접근할 수 있으며, 이 과정은 자격 증명 공유 없이 안전하게 이루어집니다.

### 기타 옵션 분석:

- **A. VPC 리소스와 관련된 읽기 전용 액세스 권한이 있는 각 개발자 계정에서 IAM 정책을 만듭니다. 정책을 IAM 사용자에게 할당합니다. 사용자 자격 증명을 보안 관리자와 공유합니다.**
  - 사용자 자격 증명을 공유하는 것은 보안상의 위험을 초래할 수 있으며, 보안 관리자가 자격 증명을 안전하게 관리할 수 없게 됩니다.

- **B. VPC 작업을 포함하여 모든 Amazon EC2 작업에 대한 관리자 액세스 권한이 있는 각 개발자 계정에서 IAM 정책을 만듭니다. 정책을 IAM 사용자에게 할당합니다. 사용자 자격 증명을 보안 관리자와 공유합니다.**
  - 관리 액세스 권한은 필요 이상으로 권한을 부여하므로 보안 리스크가 증가합니다. 또한 자격 증명 공유 문제도 있습니다.

- **C. VPC 리소스와 관련된 관리자 액세스 권한이 있는 각 개발자 계정에서 IAM 정책을 만듭니다. 정책을 교차 계정 IAM 역할에 할당합니다. 보안 관리자에게 해당 계정에서 역할을 맡도록 요청합니다.**
  - 관리자 액세스 권한을 부여하는 것은 불필요한 리스크를 초래합니다. 보안 관리자는 읽기 전용 권한으로 필요한 정보만 검토하는 것이 더 안전합니다.

결론적으로, **읽기 전용 액세스 권한을 가진 IAM 역할을 사용하여 교차 계정으로 안전하게 VPC 리소스를 검토하는 방식**이 가장 효과적이고 안전한 솔루션입니다.

## 질문 #352 ***

한 회사에서는 SSH가 대중에게 공개되지 않았는지 확인하기 위해 Amazon EC2 인스턴스의 보안 그룹을 모니터링하려고 합니다. 포트가 열려 있으면 회사는 가능한 한 빨리 포트를 닫아야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. SSH를 허용하는 보안 그룹을 감지하기 위해 Amazon CloudWatch 알람을 추가합니다.
B. SSH를 허용하는 보안 그룹을 감지하기 위해 AWS Config 규칙을 추가합니다.
C. Amazon Inspector에 평가 템플릿을 추가하여 SSH를 허용하는 보안 그룹을 감지합니다.
D. AWS Systems Manager Automation 런북을 호출하여 포트를 닫습니다.
E. AWS Systems Manager Run Command를 호출하여 포트를 닫습니다.

주어진 요구 사항을 충족하기 위해 SysOps 관리자가 취해야 할 조치 조합은 **B. SSH를 허용하는 보안 그룹을 감지하기 위해 AWS Config 규칙을 추가합니다.**와 **D. AWS Systems Manager Automation 런북을 호출하여 포트를 닫습니다.**입니다.

### 선택 이유:

- **B. SSH를 허용하는 보안 그룹을 감지하기 위해 AWS Config 규칙을 추가합니다.**
  - **자동 모니터링**: AWS Config는 리소스 구성을 모니터링하고 규정 준수를 평가할 수 있는 서비스를 제공합니다. 보안 그룹의 규칙을 모니터링하는 규칙을 추가하여 SSH 포트(포트 22)가 열려 있는 보안 그룹을 실시간으로 감지할 수 있습니다.

- **D. AWS Systems Manager Automation 런북을 호출하여 포트를 닫습니다.**
  - **자동화된 대응**: AWS Systems Manager Automation 런북을 사용하면 보안 그룹 규칙을 자동으로 수정하여 SSH 포트를 닫을 수 있습니다. 이를 통해 SSH 포트가 감지되었을 때 신속하게 대응할 수 있습니다.

### 기타 옵션 분석:

- **A. SSH를 허용하는 보안 그룹을 감지하기 위해 Amazon CloudWatch 알람을 추가합니다.**
  - CloudWatch 알람은 메트릭 기반으로 동작하므로 보안 그룹 규칙에 직접적인 감지를 수행할 수 없습니다. AWS Config가 더 적합합니다.

- **C. Amazon Inspector에 평가 템플릿을 추가하여 SSH를 허용하는 보안 그룹을 감지합니다.**
  - Amazon Inspector는 주로 애플리케이션의 보안 취약성을 평가하는 데 사용되므로 보안 그룹 규칙 감지에는 적합하지 않습니다.

- **E. AWS Systems Manager Run Command를 호출하여 포트를 닫습니다.**
  - Run Command는 특정 인스턴스에서 작업을 실행하는 데 사용되며 보안 그룹을 직접 수정할 수는 없습니다. 보안 그룹 규칙을 수정하는 데는 Automation 런북이 더 적합합니다.

결론적으로, **AWS Config 규칙을 추가**하여 SSH 포트를 감지하고, **AWS Systems Manager Automation 런북을 호출**하여 포트를 닫는 조합이 요구 사항을 효과적으로 충족합니다.

## 질문 #353 *

한 회사가 Amazon EC2 Auto Scaling 그룹에 있는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

확장 작업은 오래 실행되는 부팅 스크립트로 인해 완료되는 데 오랜 시간이 걸립니다. SysOps 관리자는 Auto Scaling 그룹을 과도하게 프로비저닝하지 않고도 확장 작업에 필요한 시간을 줄이는 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. 더 큰 인스턴스 크기를 사용하도록 시작 구성을 변경합니다.
B. 자동 크기 조정 그룹의 최소 인스턴스 수를 늘립니다.
C. 자동 크기 조정 그룹에 예측적 크기 조정 정책을 추가합니다.
D. 자동 크기 조정 그룹에 따뜻한 풀을 추가합니다.

주어진 요구 사항을 충족하기 위한 가장 적합한 솔루션은 **D. 자동 크기 조정 그룹에 따뜻한 풀을 추가합니다.**입니다.

### 선택 이유:
- **D. 자동 크기 조정 그룹에 따뜻한 풀을 추가합니다.**
  - **효율적인 확장**: 따뜻한 풀은 미리 준비된 인스턴스를 유지하여 필요할 때 빠르게 확장할 수 있도록 도와줍니다. 인스턴스가 이미 부팅되고 애플리케이션이 초기화된 상태이므로, 확장 요청이 발생할 때 즉시 사용할 수 있습니다.
  - **비용 효율성**: 이 접근법은 과도한 프로비저닝을 방지하면서도 애플리케이션의 확장성을 높여줍니다.

### 기타 옵션 분석:
- **A. 더 큰 인스턴스 크기를 사용하도록 시작 구성을 변경합니다.**
  - 더 큰 인스턴스는 리소스를 더 많이 제공할 수 있지만, 단일 인스턴스의 부팅 시간이 개선되지 않을 수 있으며, 비용이 증가할 수 있습니다.

- **B. 자동 크기 조정 그룹의 최소 인스턴스 수를 늘립니다.**
  - 최소 인스턴스 수를 늘리면 항상 더 많은 인스턴스가 실행되지만, 이는 과도한 리소스 사용으로 이어질 수 있고 비용이 증가할 수 있습니다.

- **C. 자동 크기 조정 그룹에 예측적 크기 조정 정책을 추가합니다.**
  - 예측적 크기 조정은 수요를 예측하여 미리 인스턴스를 추가할 수 있지만, 부팅 시간이 긴 경우에는 즉각적인 문제 해결이 되지 않을 수 있습니다.

결론적으로, **따뜻한 풀을 추가**하는 것이 가장 효과적인 방법으로, 확장 작업의 시간을 줄이고 과도한 프로비저닝을 방지하는 데 도움이 됩니다.


## 질문 #354 *

한 회사가 SysOps 관리자에게 4개의 추가 AWS 리전에서 애플리케이션에 대한 추가 환경을 프로비저닝해 달라고 요청했습니다. 

이 애플리케이션은 us-east-1 리전에서 100개가 넘는 Amazon C2 인스턴스에서 완전히 구성된 Amazon Machine Images(AMI)를 사용하여 실행 중입니다. 이 회사에는 us-east-1에 리소스를 배포하기 위한 AWS CloudFormation 템플릿이 있습니다.

SysOps 관리자는 가장 운영 효율적인 방식으로 애플리케이션을 프로비저닝하기 위해 무엇을 해야 합니까?


A. aws ec2 copy-image 명령을 사용하여 각 리전에 AMI를 복사합니다. 복사된 AMI에 대한 매핑을 포함하도록 CloudFormation 템플릿을 업데이트합니다.
B. 실행 중인 인스턴스의 스냅샷을 만듭니다. 스냅샷을 다른 리전으로 복사합니다. 스냅샷에서 AMI를 만듭니다. 각 리전의 CloudFormation 템플릿을 업데이트하여 새 AMI를 사용합니다.
C. 현재 us-east-1에서 사용되는 템플릿의 성공 여부에 따라 각 추가 지역에서 기존 CloudFormation 템플릿을 실행합니다.
D. CloudF ormation 템플릿을 업데이트하여 Auto Scaling 그룹에 추가 Regions를 포함합니다. us-east-1에 있는 기존 스택을 업데이트합니다.

주어진 요구 사항에 가장 적합하고 운영 효율적인 방식은 **A**입니다.

### **선택 이유:**
- **A. aws ec2 copy-image 명령을 사용하여 각 리전에 AMI를 복사합니다. 복사된 AMI에 대한 매핑을 포함하도록 CloudFormation 템플릿을 업데이트합니다.**
  - **효율성**: `aws ec2 copy-image` 명령을 사용하면 us-east-1 리전에서 생성된 AMI를 다른 AWS 리전으로 손쉽게 복사할 수 있습니다. 복사된 AMI는 각 리전에서 인스턴스를 시작하는 데 사용될 수 있습니다.
  - **템플릿 업데이트**: CloudFormation 템플릿을 업데이트하여 각 리전에서 복사된 AMI의 ID를 매핑할 수 있으므로, 나중에 환경을 쉽게 프로비저닝할 수 있습니다.

### **기타 옵션 분석:**
- **B. 실행 중인 인스턴스의 스냅샷을 만듭니다. 스냅샷을 다른 리전으로 복사합니다. 스냅샷에서 AMI를 만듭니다. 각 리전의 CloudFormation 템플릿을 업데이트하여 새 AMI를 사용합니다.**
  - 이 방법은 스냅샷을 생성하고 이를 기반으로 AMI를 만드는 과정을 포함하며, 다소 복잡하고 시간이 많이 소요됩니다. AMI를 직접 복사하는 것이 더 간단합니다.

- **C. 현재 us-east-1에서 사용되는 템플릿의 성공 여부에 따라 각 추가 지역에서 기존 CloudFormation 템플릿을 실행합니다.**
  - 이 방법은 템플릿이 현재 리전에서 잘 작동한다고 가정하지만, 다른 리전에서의 AMI 또는 리소스 설정과 관련된 문제를 고려하지 않기 때문에 효율적이지 않습니다.

- **D. CloudFormation 템플릿을 업데이트하여 Auto Scaling 그룹에 추가 Regions를 포함합니다. us-east-1에 있는 기존 스택을 업데이트합니다.**
  - 이 방법은 Auto Scaling 그룹의 리전을 직접 업데이트하는 것처럼 보이지만, AMI 복사 및 템플릿의 수정이 필요하므로 다른 리전에서의 리소스를 프로비저닝하는 데 적합하지 않습니다.

결론적으로, 가장 운영 효율적이고 직관적인 방법은 **A**를 선택하는 것입니다.

## 질문 #355

한 회사가 많은 수의 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

SysOps 관리자는 EC2 인스턴스 상태가 변경될 때마다 운영 팀에 알리는 솔루션을 구현해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 인스턴스 상태 변경 사항을 캡처하고 Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 게시하는 스크립트를 만듭니다. AWS Systems Manager Run Command를 사용하여 모든 EC2 인스턴스에서 스크립트를 실행합니다.
B. EC2 인스턴스 상태 변경 사항을 캡처하는 Amazon EventBridge 이벤트 규칙을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 설정합니다.
C. EC2 인스턴스 상태 변경을 캡처하는 Amazon EventBridge 이벤트 규칙을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 게시하는 AWS Lambda 함수를 대상으로 설정합니다.
D. 자동 수정을 통해 인스턴스 상태 변경을 평가하는 AWS Config 사용자 지정 규칙을 만듭니다. 규칙을 사용하여 Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 게시하는 AWS Lambda 함수를 호출합니다.

주어진 요구 사항에 가장 적합하고 운영 효율적인 솔루션은 **B**입니다.

### **선택 이유:**
- **B. EC2 인스턴스 상태 변경 사항을 캡처하는 Amazon EventBridge 이벤트 규칙을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 설정합니다.**
  - **효율성**: Amazon EventBridge는 EC2 인스턴스 상태 변경과 같은 AWS 서비스의 이벤트를 쉽게 캡처하고 필터링할 수 있습니다. 이를 통해 상태 변경 이벤트에 대해 간단하게 SNS 주제로 알림을 보낼 수 있습니다.
  - **관리 용이성**: EventBridge를 사용하면 별도의 스크립트를 작성할 필요가 없으며, 모든 설정을 AWS 관리 콘솔에서 쉽게 구성할 수 있습니다.

### **기타 옵션 분석:**
- **A. 인스턴스 상태 변경 사항을 캡처하고 Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 게시하는 스크립트를 만듭니다. AWS Systems Manager Run Command를 사용하여 모든 EC2 인스턴스에서 스크립트를 실행합니다.**
  - 이 방법은 스크립트 관리 및 실행이 필요하므로 복잡성이 증가하고 운영 효율성이 떨어집니다.

- **C. EC2 인스턴스 상태 변경을 캡처하는 Amazon EventBridge 이벤트 규칙을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 게시하는 AWS Lambda 함수를 대상으로 설정합니다.**
  - 이 방법도 유효하지만 Lambda 함수를 사용하는 것은 추가적인 컴퓨팅 리소스를 요구하고, B와 비교했을 때 약간의 복잡성이 증가합니다. EventBridge에서 직접 SNS로 알림을 전송하는 것이 더 간단하고 효율적입니다.

- **D. 자동 수정을 통해 인스턴스 상태 변경을 평가하는 AWS Config 사용자 지정 규칙을 만듭니다. 규칙을 사용하여 Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 게시하는 AWS Lambda 함수를 호출합니다.**
  - 이 방법은 Config와 Lambda를 사용하는 복잡한 설정을 필요로 하며, 일반적인 상태 변경 알림을 위한 요구 사항에는 과도할 수 있습니다.

결론적으로, 가장 효율적이고 관리하기 쉬운 솔루션은 **B**입니다.

## 질문 #356 *****

한 회사가 레거시 온프레미스 웹 애플리케이션을 Amazon EC2 인스턴스로 마이그레이션했습니다. 

웹 애플리케이션에는 트래픽을 수락하고 요청을 처리하기 위한 단일 정적 공용 IP 주소가 필요합니다. 최종 사용자는 example.com 도메인을 통해 웹 애플리케이션에 접속할 수 있어야 합니다. SysOps 관리자는 최소한의 노력으로 웹 애플리케이션을 유지 관리하는 솔루션을 구현해야 합니다.

이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하세요.)

A. 애플리케이션 로드 밸런서(ALB)를 구성합니다. ALB와 연결된 대상 그룹에 EC2 인스턴스를 추가합니다.
B. 연관된 EC2 IP 주소에 대한 Amazon Route 53 A 레코드를 생성합니다.
C. 연관된 EC2 IP 주소에 대한 Amazon Route 53 CNAME 레코드를 만듭니다.
D. Elastic IP 주소를 생성하고 EC2 인스턴스와 연결합니다.
E. 최소 용량 1, 최대 용량 2의 자동 크기 조정 그룹을 만듭니다.


CNAME 레코드와 A 레코드 하위 도메인을 비교해보면 알 수 있듯이 A 레코드의 목적은 상위 도메인 또는 호스트 네임을 올바른 IP 주소와 연결하는 것입니다. 반면 CNAME 레코드는 도메인 별칭(www)과 하위 도메인(메일)을 A 레코드에 나열된 기본 도메인에 연결합니다.

주어진 요구 사항을 충족하기 위해 필요한 작업의 조합은 다음과 같습니다:

### **선택할 작업:**
1. **D. Elastic IP 주소를 생성하고 EC2 인스턴스와 연결합니다.**
   - Elastic IP 주소는 고정된 공용 IP 주소를 제공하여, 인스턴스가 종료되거나 재부팅되어도 IP 주소가 변경되지 않도록 합니다. 이는 레거시 웹 애플리케이션이 필요로 하는 단일 정적 공용 IP 주소를 충족합니다.

2. **B. 연관된 EC2 IP 주소에 대한 Amazon Route 53 A 레코드를 생성합니다.**
   - Route 53 A 레코드를 사용하여 example.com 도메인이 Elastic IP 주소로 매핑되도록 설정합니다. 이를 통해 최종 사용자는 example.com을 통해 웹 애플리케이션에 접근할 수 있게 됩니다.

### **기타 옵션 분석:**
- **A. 애플리케이션 로드 밸런서(ALB)를 구성합니다. ALB와 연결된 대상 그룹에 EC2 인스턴스를 추가합니다.**
  - ALB는 트래픽을 분산시키는 데 유용하지만, 단일 정적 공용 IP 주소를 제공하는 데는 필요하지 않습니다.

- **C. 연관된 EC2 IP 주소에 대한 Amazon Route 53 CNAME 레코드를 만듭니다.**
  - CNAME 레코드는 도메인 이름을 다른 도메인 이름에 매핑하는 데 사용되며, IP 주소에는 사용할 수 없습니다.

- **E. 최소 용량 1, 최대 용량 2의 자동 크기 조정 그룹을 만듭니다.**
  - 자동 크기 조정 그룹은 인스턴스 수를 조정하는 데 유용하지만, 단일 정적 공용 IP 주소의 요구 사항과는 직접적인 관련이 없습니다.

따라서 최적의 선택은 **D**와 **B**입니다.

## 질문 #357 ***

한 회사가 데이터에 Amazon DynamoDB 테이블을 사용하고 있습니다. 

SysOps 관리자는 재해 복구를 위해 다른 AWS 리전으로 테이블 복제를 구성해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?


A. DynamoDB Accelerator(DAX)를 활성화합니다.
B. DynamoDB Streams를 활성화하고 GSI(글로벌 보조 인덱스)를 추가합니다.
C. DynamoDB Streams를 활성화하고 글로벌 테이블 지역을 추가합니다.
D. 특정 시점 복구를 활성화합니다.

SysOps 관리자가 Amazon DynamoDB 테이블의 재해 복구를 위해 다른 AWS 리전으로 테이블 복제를 구성하려면 다음 단계를 수행해야 합니다:

**C. DynamoDB Streams를 활성화하고 글로벌 테이블 지역을 추가합니다.**

### **이유:**

1. **DynamoDB 글로벌 테이블**: 글로벌 테이블은 여러 AWS 리전 간에 DynamoDB 테이블의 데이터를 자동으로 복제하는 기능을 제공합니다. 이 기능을 사용하면 다른 리전에 복제된 테이블이 항상 최신 상태를 유지할 수 있어 재해 복구 시 유용합니다.

2. **DynamoDB Streams 활성화**: 글로벌 테이블을 만들기 위해서는 DynamoDB Streams를 활성화해야 합니다. 이를 통해 변경 사항이 다른 리전의 테이블로 전파됩니다.

### **기타 옵션 분석:**

- **A. DynamoDB Accelerator(DAX)를 활성화합니다.**  
  - DAX는 DynamoDB의 캐싱을 제공하는 기능으로, 데이터 복제와는 관련이 없습니다.

- **B. DynamoDB Streams를 활성화하고 GSI(글로벌 보조 인덱스)를 추가합니다.**  
  - GSI는 데이터 쿼리 성능을 향상시키기 위한 것으로, 재해 복구 목적의 테이블 복제와는 관련이 없습니다.

- **D. 특정 시점 복구를 활성화합니다.**  
  - 특정 시점 복구(PITR)는 테이블의 데이터를 특정 시점으로 복원할 수 있게 해주는 기능이지만, 다른 리전으로 복제하는 기능은 아닙니다.

따라서 **C** 옵션이 다른 AWS 리전으로 DynamoDB 테이블을 복제하는 가장 적합한 방법입니다.


## 질문 #358 ***

회사에 www.example.com에 대한 기존 퍼블릭 웹 애플리케이션이 있습니다. 

애플리케이션 로드 밸런서(ALB)는 단일 HTTP 80 리스너로 구성되어 있습니다. SysOps 관리자는 www.example.com에 대한 모든 웹 요청이 클라이언트와 ALB 간에 암호화되도록 해야 합니다.

SysOps 관리자는 이미 AWS Certificate Manager(ACM)에서 www.example.com에 대한 퍼블릭 인증서를 요청하고 검증했습니다. 애플리케이션의 기존 사용자는 연결하는 엔드포인트를 변경할 필요가 없습니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 추가 단계를 수행해야 합니까?

A. 포트 443에서 HTTPS에 대한 추가 ALB 리스너를 만듭니다. 모든 트래픽을 대상 그룹으로 전달하도록 기본 동작을 설정합니다. www.example.com에 대해 생성된 ACM 인증서를 기본 SSL 인증서로 지정합니다.
B. 포트 443에서 HTTPS에 대한 추가 ALB 리스너를 만듭니다. 모든 트래픽을 대상 그룹으로 전달하도록 기본 동작을 설정합니다. www.example.com에 대해 생성된 ACM 인증서를 기본 SSL 인증서로 지정합니다. 포트 80에서 원래 HTTP 리스너를 삭제합니다.
C. HTTP 포트 80 리스너에 대한 ALB 기본 규칙을 수정합니다. 리스너에서 호스트 www example.com에 대한 모든 트래픽을 대상 그룹으로 전달하는 규칙을 만듭니다. www.example.com에 대해 생성된 ACM 인증서를 기본 SSL 인증서로 지정합니다.
D. HTTP 포트 80 리스너에 대한 ALB 기본 규칙을 수정하여 포트 443에서 HTTPS로 리디렉션합니다. 포트 443에서 추가 HTTPS 리스너를 만듭니다. 모든 트래픽을 대상 그룹으로 전달하도록 기본 작업을 설정합니다. www example.com에 대해 생성된 ACM 인증서를 기본 SSL 인증서로 지정합니다.

SysOps 관리자가 기존 웹 애플리케이션에 대한 모든 웹 요청을 암호화하려면 다음 단계를 수행해야 합니다:

**D. HTTP 포트 80 리스너에 대한 ALB 기본 규칙을 수정하여 포트 443에서 HTTPS로 리디렉션합니다. 포트 443에서 추가 HTTPS 리스너를 만듭니다. 모든 트래픽을 대상 그룹으로 전달하도록 기본 작업을 설정합니다. www.example.com에 대해 생성된 ACM 인증서를 기본 SSL 인증서로 지정합니다.**

### **이유:**

1. **HTTPS 리스너 추가**: 포트 443에서 HTTPS 리스너를 추가하여 ALB가 클라이언트와의 암호화된 연결을 지원합니다. ACM 인증서를 이를 위해 사용합니다.

2. **HTTP에서 HTTPS로 리디렉션**: 기존 HTTP 요청(포트 80)도 여전히 처리해야 하므로, HTTP 요청을 HTTPS로 리디렉션하도록 ALB 리스너를 구성하는 것이 좋습니다. 이렇게 하면 사용자가 www.example.com에 HTTP로 접근할 경우 자동으로 HTTPS로 전환됩니다.

3. **기존 엔드포인트 유지**: 사용자는 엔드포인트를 변경할 필요가 없으며, 리디렉션 설정을 통해 기존 HTTP 요청을 안전하게 처리할 수 있습니다.

### **기타 옵션 분석:**

- **A. 포트 443에서 HTTPS에 대한 추가 ALB 리스너를 만듭니다.**  
  - HTTPS 리스너는 필요하지만 HTTP 요청을 리디렉션하지 않으면 기존 사용자는 여전히 HTTP로 접근할 수 있습니다.

- **B. 포트 443에서 HTTPS에 대한 추가 ALB 리스너를 만듭니다. 원래 HTTP 리스너를 삭제하면 사용자는 HTTP에 접근할 수 없게 됩니다.**  
  - 이 경우 기존 사용자는 엔드포인트를 변경해야 하므로 요구 사항을 충족하지 않습니다.

- **C. HTTP 포트 80 리스너에 대한 ALB 기본 규칙을 수정합니다.**  
  - ALB 기본 규칙을 수정하는 것은 도움이 되지 않으며, HTTPS 리스너를 추가하는 것이 중요합니다.

따라서, **D** 옵션이 모든 웹 요청을 암호화하고 기존 사용자가 엔드포인트를 변경하지 않도록 하는 가장 적합한 솔루션입니다.


## 질문 #359 ***

한 회사가 Amazon EC2 인스턴스에서 전체 애플리케이션 제품군을 실행합니다. 

이 회사는 애플리케이션을 컨테이너와 AWS Fargate로 옮길 계획입니다. 이 회사는 6개월 이내에 EC2 인스턴스를 폐기하고 Fargate만 사용할 계획입니다. 이 회사는 향후 Fargate 비용을 추산할 수 있었습니다.

SysOps 관리자는 회사가 비용을 최소화할 수 있도록 구매 옵션을 선택해야 합니다. SysOps 관리자는 사용 가능한 모든 할인을 최대한 활용해야 하며 사용되지 않은 예약이 없는지 확인해야 합니다.

어떤 구매 옵션이 이러한 요구 사항을 충족할까요?

A. 선불 없이 1년간 저축 계획을 계산하세요
B. 부분 선불 결제 옵션을 사용하여 1년 동안 저축 계획을 계산하세요
C. 선불 결제 옵션을 포함한 1년 EC2 인스턴스 절약 플랜
D. 부분 선불 결제 옵션을 사용한 1년 EC2 예약 인스턴스

이 시나리오에서 회사가 Amazon EC2 인스턴스를 Fargate로 옮길 계획이 있고, 6개월 이내에 EC2 인스턴스를 폐기할 계획이므로, 가장 적합한 구매 옵션은 **A. 선불 없이 1년간 저축 계획을 계산하세요**입니다.

### **이유:**

1. **전환 계획**: 회사는 EC2 인스턴스를 Fargate로 전환할 계획이기 때문에 EC2 인스턴스를 구매할 필요가 없습니다. Fargate는 서버 관리가 필요 없는 컨테이너 서비스로, 사용자가 인프라를 관리하지 않아도 됩니다.

2. **예측 가능성**: 저축 계획(Savings Plans)은 Fargate와 같은 사용 기반의 서비스에 대해 유연한 할인을 제공하므로, 향후 비용을 절감하면서 비용 예측 가능성을 높이는 데 도움이 됩니다.

3. **유연성**: 저축 계획은 사용량에 따라 조정할 수 있는 유연성을 제공하며, 특정 인스턴스 유형이나 AZ에 고정되지 않기 때문에 Fargate 사용량이 변화하더라도 비용을 최소화할 수 있습니다.

### **기타 옵션 분석:**

- **B. 부분 선불 결제 옵션을 사용하여 1년 동안 저축 계획을 계산하세요**  
  - 이 옵션은 저축 계획을 통해 할인을 제공하지만, 현재 EC2 인스턴스에서 Fargate로 전환할 계획이므로 필요하지 않습니다.

- **C. 선불 결제 옵션을 포함한 1년 EC2 인스턴스 절약 플랜**  
  - EC2 인스턴스의 절약 플랜은 전환 계획과 맞지 않으며, EC2 인스턴스를 6개월 후에 폐기할 예정이기 때문에 이 옵션은 불필요합니다.

- **D. 부분 선불 결제 옵션을 사용한 1년 EC2 예약 인스턴스**  
  - 예약 인스턴스는 EC2 인스턴스에 대해 제공되며, Fargate로 전환할 계획이므로 사용되지 않을 예약이 발생할 수 있습니다.

결론적으로, **A** 옵션이 현재 계획과 가장 잘 맞으며, 비용을 최소화하는 동시에 향후 Fargate 사용을 지원하는 최적의 솔루션입니다.


## 질문 #360n *

제조 회사는 Amazon RDS DB 인스턴스를 사용하여 모든 재고 품목의 재고를 저장합니다. 

이 회사는 품목을 추가, 업데이트 및 삭제하기 위해 데이터베이스와 상호 작용하는 여러 AWS Lambda 함수를 유지 관리합니다. Lambda 함수는 하드코딩된 자격 증명을 사용하여 데이터베이스에 연결합니다.

SysOps 관리자는 데이터베이스 자격 증명이 일반 텍스트로 저장되지 않고 암호가 30일마다 순환되도록 해야 합니다.

어떤 솔루션이 가장 운영 효율적인 방식으로 이러한 요구 사항을 충족할까요?

A. 각 Lambda 함수에 대한 환경 변수로 데이터베이스 비밀번호를 저장합니다. PasswordRotate라는 이름의 새 Lambda 함수를 만듭니다. Amazon EventBridge를 사용하여 30일마다 PasswordRotate 함수를 예약하여 데이터베이스 비밀번호를 변경하고 각 Lambda 함수에 대한 환경 변수를 업데이트합니다.
B. AWS Key Management Service(AWS KMS)를 사용하여 데이터베이스 비밀번호를 암호화하고 암호화된 비밀번호를 각 Lambda 함수의 환경 변수로 저장합니다. 각 Lambda 함수에 KMS 키에 대한 액세스 권한을 부여하여 필요할 때 데이터베이스 비밀번호를 해독할 수 있도록 합니다. PasswordRotate라는 이름의 새 Lambda 함수를 만들어 30일마다 비밀번호를 변경합니다.
C. AWS Secrets Manager를 사용하여 데이터베이스의 자격 증명을 저장합니다. Secrets Manager 비밀을 만들고 Secrets Manager가 Lambda 함수를 사용하여 데이터베이스 비밀번호를 자동으로 업데이트하도록 데이터베이스를 선택합니다. 30일의 자동 로테이션 일정을 지정합니다. Secrets Manager에서 데이터베이스 비밀번호에 액세스하도록 각 Lambda 함수를 업데이트합니다.
D. AWS Systems Manager Parameter Store를 사용하여 데이터베이스의 자격 증명을 저장할 보안 문자열을 만듭니다. PasswordRotate라는 새 Lambda 함수를 만듭니다. Amazon EventBridge를 사용하여 30일마다 PasswordRotate 함수를 예약하여 데이터베이스 암호를 변경하고 Parameter Store 내에서 비밀을 업데이트합니다. 각 Lambda 함수를 업데이트하여 Parameter Store에서 데이터베이스 암호에 액세스합니다.

이 시나리오에서 가장 효율적이고 안전한 솔루션은 **C. AWS Secrets Manager를 사용하여 데이터베이스의 자격 증명을 저장합니다. Secrets Manager 비밀을 만들고 Secrets Manager가 Lambda 함수를 사용하여 데이터베이스 비밀번호를 자동으로 업데이트하도록 데이터베이스를 선택합니다. 30일의 자동 로테이션 일정을 지정합니다. Secrets Manager에서 데이터베이스 비밀번호에 액세스하도록 각 Lambda 함수를 업데이트합니다.**입니다.

### **이유:**

1. **자동 비밀번호 로테이션**: AWS Secrets Manager는 비밀번호를 자동으로 로테이션할 수 있는 기능을 제공합니다. 이를 통해 보안 요구 사항을 충족하면서 수동 작업을 최소화할 수 있습니다.

2. **보안**: Secrets Manager는 비밀번호를 안전하게 저장하고, 암호화하여 일반 텍스트로 노출되지 않도록 보장합니다. 또한 IAM(Identity and Access Management) 정책을 통해 각 Lambda 함수가 비밀에 액세스할 수 있도록 세밀하게 제어할 수 있습니다.

3. **손쉬운 통합**: Lambda 함수는 Secrets Manager와 쉽게 통합될 수 있어, 비밀번호를 필요할 때 쉽게 조회하고 사용할 수 있습니다.

4. **운영 효율성**: Secrets Manager는 비밀번호 관리와 로테이션을 자동화함으로써 운영 효율성을 극대화합니다. 이를 통해 SysOps 관리자는 수동으로 비밀번호를 업데이트할 필요가 없어집니다.

### **기타 옵션 분석:**

- **A. 각 Lambda 함수에 대한 환경 변수로 데이터베이스 비밀번호를 저장합니다.**  
  - 환경 변수에 비밀번호를 저장하는 것은 보안 위험이 있으며, 수동으로 업데이트해야 하는 단점이 있습니다.

- **B. AWS Key Management Service(AWS KMS)를 사용하여 데이터베이스 비밀번호를 암호화하고 암호화된 비밀번호를 각 Lambda 함수의 환경 변수로 저장합니다.**  
  - KMS는 데이터 암호화에 유용하지만, 비밀번호 로테이션을 자동화하는 기능은 제공하지 않으며, 여전히 환경 변수에 비밀번호가 노출될 수 있습니다.

- **D. AWS Systems Manager Parameter Store를 사용하여 데이터베이스의 자격 증명을 저장할 보안 문자열을 만듭니다.**  
  - Parameter Store는 비밀번호를 안전하게 저장할 수 있지만, 자동 로테이션 기능이 기본적으로 제공되지 않으며, 수동으로 비밀번호를 관리해야 하는 번거로움이 있습니다.

결론적으로, **C** 옵션이 보안, 자동화, 운영 효율성을 모두 갖춘 최적의 솔루션입니다. AWS Secrets Manager를 사용하여 자격 증명을 관리하는 것이 가장 좋은 방법입니다.


## 질문 #361 **

개발자가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 실행되는 웹 애플리케이션을 만듭니다. 

인스턴스는 Auto Scaling 그룹에 있습니다. 개발자는 배포를 검토하고 애플리케이션으로의 의심스러운 트래픽을 알아차립니다. 트래픽은 악성이며 단일 공용 IP 주소에서 발생합니다. SysOps 관리자는 공용 IP 주소를 차단해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

A. 의심스러운 IP 주소에서 들어오는 모든 트래픽을 거부하는 보안 그룹 규칙을 만듭니다. 보안 그룹을 ALB와 연결합니다.
B. Amazon Detective를 구현하여 트래픽을 모니터링하고 인터넷에서 악성 활동을 차단합니다. Detective를 구성하여 ALB와 통합합니다.
C. 트래픽 규칙을 관리하고 인터넷에서 악성 활동을 차단하기 위해 AWS Resource Access Manager(AWS RAM)를 구현합니다. AWS RAM을 ALB와 연결합니다.
D. AWS WAF의 IP 세트에 악성 IP 주소를 추가합니다. 웹 ACL을 만듭니다. BLOCK으로 설정된 동작이 있는 IP 세트 규칙을 포함합니다. 웹 ACL을 ALB와 연결합니다.

악성 트래픽을 차단하려면 가장 효과적이고 안전한 방법을 사용하는 것이 중요합니다. 제시된 옵션 중에서 공용 IP 주소를 차단하는 데 적합한 솔루션은 다음과 같습니다:

### **D. AWS WAF의 IP 세트에 악성 IP 주소를 추가합니다. 웹 ACL을 만듭니다. BLOCK으로 설정된 동작이 있는 IP 세트 규칙을 포함합니다. 웹 ACL을 ALB와 연결합니다.**

#### **이유:**
- **AWS WAF**: AWS Web Application Firewall(WAF)는 웹 애플리케이션에 대한 트래픽을 필터링하고 모니터링할 수 있는 기능을 제공합니다. 이를 통해 특정 IP 주소에서 오는 트래픽을 차단할 수 있습니다.
- **IP 세트**: IP 세트를 사용하여 차단할 IP 주소를 정의하고, 웹 ACL을 생성하여 해당 IP 세트의 트래픽을 BLOCK으로 설정하여 차단할 수 있습니다.
- **ALB와의 통합**: 생성한 웹 ACL을 ALB와 연결하여 웹 애플리케이션에 대한 모든 요청에 대해 필터링 규칙을 적용할 수 있습니다.

### **기타 옵션 분석:**
- **A. 의심스러운 IP 주소에서 들어오는 모든 트래픽을 거부하는 보안 그룹 규칙을 만듭니다. 보안 그룹을 ALB와 연결합니다.**
  - 보안 그룹은 EC2 인스턴스와 연결되는 네트워크 수준의 접근 제어이므로 ALB에서 들어오는 트래픽을 필터링하는 데 적합하지 않습니다. ALB가 여러 EC2 인스턴스에 요청을 분산시키므로 보안 그룹으로는 충분한 제어를 제공하지 않습니다.

- **B. Amazon Detective를 구현하여 트래픽을 모니터링하고 인터넷에서 악성 활동을 차단합니다. Detective를 구성하여 ALB와 통합합니다.**
  - Amazon Detective는 보안 분석 및 모니터링 도구이지만, 실시간으로 트래픽을 차단하는 기능이 없습니다. 따라서 악성 트래픽을 차단하는 데 사용될 수 없습니다.

- **C. 트래픽 규칙을 관리하고 인터넷에서 악성 활동을 차단하기 위해 AWS Resource Access Manager(AWS RAM)를 구현합니다. AWS RAM을 ALB와 연결합니다.**
  - AWS RAM은 리소스 공유를 위한 도구이며, 악성 트래픽 차단과는 관련이 없습니다.

결론적으로, **D** 옵션이 악성 트래픽을 효과적으로 차단하는 데 적합한 솔루션입니다. AWS WAF를 사용하여 공용 IP 주소를 차단하는 것이 가장 안전하고 효율적인 방법입니다.


## 질문 #362 *****

SysOps 관리자가 AWS에서 리소스를 생성하고 있습니다. 

Amazon EC2 인스턴스의 자동 확장 그룹을 정의하는 CloudFormation 템플릿입니다. 자동 확장 그룹 시작 템플릿은 사용자 데이터 스크립트를 사용하여 각 EC2 인스턴스를 프로비저닝합니다. 오류로 인해 자동 확장 그룹 리소스 생성이 실패합니다. 대기 조건이 필요한 수의 신호를 수신하지 못합니다.

SysOps 관리자는 이 오류를 어떻게 해결해야 합니까?

A. 사용자 데이터 스크립트가 완료되면 cfn-signal을 실행합니다.
B. EC2 인스턴스의 보안 그룹을 수정하여 포트 443에서 나가는 트래픽을 허용합니다.
C. CloudFormation 템플릿에서 자동 크기 조정 그룹의 DesiredCapacity 값을 줄입니다.
D. Auto Scaling 그룹 시작 템플릿에서 AssociatePublicIpAddress 속성을 True로 설정합니다.

AWS CloudFormation에서 자동 확장 그룹(Auto Scaling Group, ASG) 리소스를 생성할 때 오류가 발생하고 "대기 조건이 필요한 수의 신호를 수신하지 못했습니다"라는 메시지가 표시되는 경우, 이는 EC2 인스턴스가 설정된 대기 시간 내에 `cfn-signal`을 호출하지 않았음을 의미합니다. 이 문제를 해결하기 위해 필요한 작업은 다음과 같습니다:

### **A. 사용자 데이터 스크립트가 완료되면 cfn-signal을 실행합니다.**

#### **이유:**
- **cfn-signal 사용**: CloudFormation은 EC2 인스턴스가 정상적으로 시작되었는지 확인하기 위해 `cfn-signal`을 사용합니다. 사용자 데이터 스크립트가 완료된 후, `cfn-signal`을 호출하여 인스턴스가 준비되었음을 CloudFormation에 알려줘야 합니다.
- **정상적인 신호 전송**: `cfn-signal`은 인스턴스가 성공적으로 실행되고 준비되었다는 것을 CloudFormation에게 알리므로, 이는 오류를 해결하는 데 핵심적인 단계입니다.

### **기타 옵션 분석:**
- **B. EC2 인스턴스의 보안 그룹을 수정하여 포트 443에서 나가는 트래픽을 허용합니다.**
  - 이 옵션은 보안 그룹의 설정과 관련이 있지만, `cfn-signal` 호출 문제와는 직접적인 관련이 없습니다. 신호를 보내는 데 필요한 포트(일반적으로 HTTP 또는 HTTPS)와 관련된 사항이 아니라면 이 조치는 도움이 되지 않습니다.

- **C. CloudFormation 템플릿에서 자동 크기 조정 그룹의 DesiredCapacity 값을 줄입니다.**
  - `DesiredCapacity` 값을 줄이는 것은 생성되는 인스턴스 수에 영향을 미치겠지만, 이 오류와는 관계가 없습니다. 인스턴스가 신호를 보내는지 여부와 관련이 없습니다.

- **D. Auto Scaling 그룹 시작 템플릿에서 AssociatePublicIpAddress 속성을 True로 설정합니다.**
  - 이 옵션은 EC2 인스턴스에 공인 IP 주소를 할당하는 것이지만, 인스턴스가 준비되었는지 확인하기 위한 신호 전송 문제를 해결하지 않습니다.

결론적으로, **A** 옵션이 이 오류를 해결하기 위한 올바른 조치입니다. 사용자 데이터 스크립트의 마지막에 `cfn-signal`을 호출하여 EC2 인스턴스가 정상적으로 시작되었음을 CloudFormation에 알리는 것이 필요합니다.


## 질문 #363 *****

한 회사가 두 애플리케이션을 연결하려고 합니다. 

한 애플리케이션은 호스트 이름이 host1.onprem private인 온프레미스 데이터 센터에서 실행됩니다. 다른 애플리케이션은 호스트 이름이 host1.awscloud private인 Amazon EC2 인스턴스에서 실행됩니다. 온프레미스 네트워크와 AWS 사이에 AWS 사이트 간 VPN 연결이 있습니다.

데이터 센터에서 실행되는 애플리케이션은 EC2 인스턴스에서 실행되는 애플리케이션에 연결하려고 하지만 DNS 확인이 실패합니다. SysOps 관리자는 온프레미스와 AWS 리소스 간에 DNS 확인을 구현해야 합니다.

온프레미스 애플리케이션이 EC2 인스턴스 호스트 이름을 확인할 수 있도록 하는 솔루션은 무엇입니까?


A. onprem.private 호스팅 존에 대한 전달 규칙이 있는 Amazon Route 53 인바운드 리졸버 엔드포인트를 설정합니다. 리졸버를 EC2 인스턴스의 VPC와 연결합니다. 온프레미스 DNS 리졸버를 구성하여 onprem.private DNS 쿼리를 인바운드 리졸버 엔드포인트로 전달합니다.
B. Amazon Route 53 인바운드 리졸버 엔드포인트를 설정합니다. 리졸버를 EC2 인스턴스의 VPC와 연결합니다. 온프레미스 DNS 리졸버를 구성하여 awscloud.private DNS 쿼리를 인바운드 리졸버 엔드포인트로 전달합니다.
C. onprem.private 호스팅 존에 대한 전달 규칙이 있는 Amazon Route 53 아웃바운드 리졸버 엔드포인트를 설정합니다. 리졸버를 EC2 인스턴스의 AWS 리전과 연결합니다. 온프레미스 DNS 리졸버를 구성하여 onprem.private DNS 쿼리를 아웃바운드 리졸버 엔드포인트로 전달합니다.
D. Amazon Route 53 아웃바운드 리졸버 엔드포인트를 설정합니다. 리졸버를 EC2 인스턴스의 AWS 리전과 연결합니다. 온프레미스 DNS 리졸버를 구성하여 awscloud.private DNS 쿼리를 아웃바운드 리졸버 엔드포인트로 전달합니다.

온프레미스 애플리케이션이 Amazon EC2 인스턴스의 호스트 이름을 확인할 수 있도록 하기 위해서는 적절한 DNS 리졸버 설정이 필요합니다. 이 경우 가장 적합한 솔루션은 다음과 같습니다:

### **A. onprem.private 호스팅 존에 대한 전달 규칙이 있는 Amazon Route 53 인바운드 리졸버 엔드포인트를 설정합니다. 리졸버를 EC2 인스턴스의 VPC와 연결합니다. 온프레미스 DNS 리졸버를 구성하여 onprem.private DNS 쿼리를 인바운드 리졸버 엔드포인트로 전달합니다.**

#### **이유:**
1. **전달 규칙**: 인바운드 리졸버는 온프레미스 DNS 쿼리를 AWS의 Route 53으로 전달할 수 있는 기능을 제공합니다. 이로 인해 온프레미스 네트워크의 DNS 리졸버가 EC2 인스턴스의 private DNS 이름을 확인할 수 있게 됩니다.
2. **DNS 쿼리 처리**: EC2 인스턴스의 VPC에 연결된 인바운드 리졸버를 통해 온프레미스 DNS 요청을 받아들여 AWS 리소스에 대한 DNS 해석을 수행할 수 있습니다.
3. **양방향 DNS 해석**: 이 설정은 온프레미스 애플리케이션이 EC2 인스턴스를 찾을 수 있게 하며, 필요할 경우 반대 방향으로도 DNS 요청이 가능하도록 유연성을 제공합니다.

### **기타 옵션 분석:**
- **B.** 이 옵션은 온프레미스 DNS 리졸버가 `awscloud.private` DNS 쿼리를 인바운드 리졸버에 전달하도록 구성하고 있으나, 온프레미스에서 AWS의 DNS 이름을 확인할 수 있도록 하는 목적과는 맞지 않습니다.
- **C.** 아웃바운드 리졸버는 AWS에서 온프레미스 DNS 요청을 외부로 전달하는 데 사용되지만, 이 시나리오에서는 온프레미스에서 AWS 리소스를 확인해야 하므로 적절하지 않습니다.
- **D.** 이 옵션 역시 아웃바운드 리졸버를 사용하는데, 온프레미스에서 AWS의 private DNS를 확인하려는 목적에 적합하지 않습니다.

따라서 **A** 옵션이 요구 사항을 가장 잘 충족하는 솔루션입니다.


## 질문 #364 ***

한 회사가 여러 AWS 리전에 애플리케이션 인스턴스와 관련 인프라를 배포해야 합니다. 

이 회사는 이 목표를 달성하기 위해 단일 AWS CloudFormation 템플릿을 사용하려고 합니다. 이 회사는 AWS Organizations를 사용하고 중앙 관리 계정에서 이 템플릿을 관리하고 실행하려고 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. Amazon S3에 저장되는 CloudFormation 템플릿을 만듭니다. S3 버킷에서 Cross-Region Replication(CRR)을 구성합니다. 입력 템플릿 매개변수에서 필요한 계정과 원격 지역을 참조합니다.
B. 중앙 관리 계정에서 대상 지역의 Amazon S3 버킷에서 CloudFormation 중첩 스택을 로드하는 CloudFormation 기본 템플릿을 만듭니다.
C. 중앙 관리 계정의 기본 템플릿을 사용하여 CloudFormation 중첩 스택을 만듭니다. 중첩 스택 배포에 필요한 계정과 지역을 구성합니다.
D. 서비스 관리 권한을 포함하는 CloudFormation 스택 세트를 만듭니다. 중앙 관리 계정에서 필요한 계정 및 리전에 스택 세트를 배포합니다.

SysOps 관리자가 여러 AWS 리전에 애플리케이션 인스턴스와 관련 인프라를 배포하기 위해 단일 AWS CloudFormation 템플릿을 사용하려는 경우, 가장 적합한 솔루션은 다음과 같습니다:

### **D. 서비스 관리 권한을 포함하는 CloudFormation 스택 세트를 만듭니다. 중앙 관리 계정에서 필요한 계정 및 리전에 스택 세트를 배포합니다.**

#### **이유:**
1. **스택 세트 기능**: AWS CloudFormation 스택 세트를 사용하면 단일 템플릿을 여러 AWS 계정 및 리전에 배포할 수 있습니다. 이는 관리 계정에서 여러 리전 및 계정에 걸쳐 일관된 인프라를 쉽게 배포할 수 있도록 합니다.
2. **서비스 관리 권한**: 스택 세트는 관리자가 다른 AWS 계정에 스택을 배포하는 데 필요한 권한을 중앙 집중식으로 관리할 수 있게 해줍니다. 이는 AWS Organizations와 잘 통합되어 운영 효율성을 높입니다.
3. **편리함 및 확장성**: 스택 세트를 통해 중앙 관리 계정에서 관리하며 여러 리전에 걸쳐 인프라를 배포할 수 있으므로, 대규모 인프라 관리를 간소화하고 확장성을 제공합니다.

### **기타 옵션 분석:**
- **A.** S3에서 Cross-Region Replication을 사용하는 것은 데이터를 복제하는 데 유용하지만, CloudFormation 템플릿을 여러 리전에 배포하는 데는 직접적인 해결책이 아닙니다. 템플릿 관리가 복잡해질 수 있습니다.
- **B.** 중첩 스택을 로드하는 기본 템플릿을 사용하는 것은 유용하지만, 여러 계정과 리전을 대상으로 하는 자동화 및 관리 기능이 부족합니다.
- **C.** 기본 템플릿을 사용하여 중첩 스택을 만드는 것은 좋은 접근 방식이지만, 여러 계정과 리전으로의 배포 자동화가 되지 않아 관리가 비효율적일 수 있습니다.

따라서 **D** 옵션이 요구 사항을 가장 잘 충족하는 솔루션입니다.


## 질문 #365 *

회사의 SysOps 관리자는 Windows 기반 워크로드와 Linux 기반 워크로드를 실행하는 수백 개의 Amazon EC2 인스턴스 플릿을 관리합니다. 

각 EC2 인스턴스에는 운영 체제를 식별하는 태그가 있습니다. 모든 EC2 인스턴스는 AWS Systems Manager Session Manager를 실행합니다.

제로데이 취약성이 보고되었으며 패치가 제공되지 않습니다. 회사의 보안 팀은 취약성의 위험을 줄이기 위해 모든 관련 운영 체제에 대한 코드를 제공합니다. SysOps 관리자는 EC2 인스턴스에 코드를 구현해야 하며 코드가 모든 인스턴스에서 성공적으로 실행되었음을 보여주는 보고서를 제공해야 합니다.

SysOps 관리자는 이러한 요구 사항을 가능한 한 빨리 충족하기 위해 무엇을 해야 합니까?

A. Systems Manager Run Command를 사용합니다. AWS-RunShellScript 문서 또는 AWS-RunPowerShellScript 문서를 선택합니다. 보안 팀의 코드로 Run Command를 구성합니다. Targets 매개변수에 운영 체제 태그를 지정합니다. 명령을 실행합니다. 보안 팀에 명령 기록의 증거를 제공합니다.
B. Session Manager를 통해 EC2 인스턴스에 연결하는 AWS Lambda 함수를 만듭니다. Lambda 함수를 구성하여 운영 체제를 식별하고, 보안 팀의 코드를 실행하고, 결과를 Amazon RDS DB 인스턴스로 반환합니다. DB 인스턴스에서 결과를 쿼리합니다. 결과를 보안 팀에 증거로 제공합니다.
C. 각 EC2 인스턴스에 로그인합니다. 각 EC2 인스턴스에서 보안 팀의 코드를 실행합니다. 각 실행의 결과를 단일 스프레드시트에 복사하여 붙여넣습니다. 스프레드시트를 보안 팀에 증거로 제공합니다.
D. EC2 인스턴스의 시작 템플릿을 업데이트하여 보안 팀의 코드를 사용자 데이터에 포함합니다. 업데이트된 시작 템플릿을 사용하여 EC2 인스턴스를 다시 시작합니다. 각 인스턴스의 EC2 인스턴스 로그를 검색합니다. EC2 인스턴스 로그를 보안 팀에 증거로 제공합니다.


Amazon EC2 플릿은 여러 Amazon EC2 인스턴스 유형과 가용 영역 간에, 그리고 온디멘드 구매 모델, Amazon EC2 예약 인스턴스(RI) 구매 모델 및 Amazon EC2 Spot 구매 모델에 걸쳐 Amazon EC2 용량을 간편하게 프로비저닝할 수 있는 새로운 기능


SysOps 관리자가 코드의 실행을 모든 관련 Amazon EC2 인스턴스에서 신속하게 구현하고 실행 결과를 보고하는 가장 효율적인 방법은 다음과 같습니다:

### **A. Systems Manager Run Command를 사용합니다. AWS-RunShellScript 문서 또는 AWS-RunPowerShellScript 문서를 선택합니다. 보안 팀의 코드로 Run Command를 구성합니다. Targets 매개변수에 운영 체제 태그를 지정합니다. 명령을 실행합니다. 보안 팀에 명령 기록의 증거를 제공합니다.**

#### **이유:**
1. **중앙 집중화된 관리**: AWS Systems Manager Run Command는 EC2 인스턴스에 직접 접근하지 않고도 명령을 실행할 수 있는 강력한 도구입니다. 이를 통해 SysOps 관리자는 수백 개의 인스턴스에서 효율적으로 코드를 실행할 수 있습니다.
2. **자동화**: `Targets` 매개변수를 사용하여 특정 태그가 있는 인스턴스를 선택하면, 보안 팀의 코드가 해당 운영 체제에 맞는 인스턴스에서 자동으로 실행됩니다.
3. **보고 및 감사**: Run Command는 실행 기록을 자동으로 저장하여, 코드가 성공적으로 실행되었음을 입증할 수 있는 증거를 제공합니다. 이는 보안 팀의 요구 사항을 충족하는 데 필요합니다.

### **기타 옵션 분석:**
- **B.** Lambda 함수를 통해 세부적인 작업을 수행하는 것은 가능하지만, 구현이 복잡하고 EC2 인스턴스에 대한 연결 및 코드 실행 관리를 위한 추가 구성이 필요합니다. 보안 팀의 요구 사항을 신속하게 충족하기에는 비효율적입니다.
- **C.** 각 EC2 인스턴스에 로그인하여 수동으로 코드를 실행하는 것은 시간 소모가 크고 비효율적입니다. 또한, 수동 작업은 오류의 가능성을 높입니다.
- **D.** 시작 템플릿을 업데이트하여 코드를 사용자 데이터에 포함하는 방법은 새로운 인스턴스를 생성해야 하며, 이는 이미 실행 중인 인스턴스에 대한 패치 관리 요구 사항을 충족하지 않습니다. 또한, 로그 검색도 복잡한 프로세스가 될 수 있습니다.

따라서, **A** 옵션이 가장 적합한 해결책이며, SysOps 관리자가 효율적으로 코드 실행 및 보고 요구 사항을 충족할 수 있습니다.


## 질문 #366

한 회사에는 수천 개의 경보 시스템에서 알림을 수집하는 애플리케이션이 있습니다. 

알림에는 경보 알림과 정보 알림이 포함됩니다. 정보 알림에는 시스템 무장 프로세스, 무장 해제 프로세스 및 센서 상태가 포함됩니다.

모든 알림은 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지로 보관됩니다. Auto Scaling 그룹에 있는 Amazon EC2 인스턴스가 메시지를 처리합니다. SysOps 관리자는 정보 알림보다 경보 알림을 우선시하는 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. 대기열에 많은 수의 메시지가 있는 경우 자동 크기 조정 그룹을 조정하여 더 빠르게 크기를 조정합니다.
B. Amazon SQS와 함께 Amazon Simple Notification Service(Amazon SNS) 팬아웃 기능을 사용하여 모든 C2 인스턴스에 병렬로 알림을 보냅니다.
C. Amazon DynamoDB 스트림을 추가하여 메시지 처리를 가속화합니다.
D. 알람 알림 큐와 정보 알림 큐를 만듭니다. 알람 알림 큐에서 먼저 메시지를 수집하도록 애플리케이션을 업데이트합니다.

정보 알림보다 경보 알림을 우선시하는 솔루션을 구현하기 위해 가장 적절한 방법은 다음과 같습니다:

### **D. 알람 알림 큐와 정보 알림 큐를 만듭니다. 알람 알림 큐에서 먼저 메시지를 수집하도록 애플리케이션을 업데이트합니다.**

#### **이유:**
1. **우선순위 처리**: 두 개의 별도 SQS 큐(하나는 경보 알림용, 다른 하나는 정보 알림용)를 설정하면 경보 알림을 별도로 처리할 수 있습니다. 이로 인해 경보 알림이 항상 우선적으로 처리됩니다.
2. **구조화된 접근**: 알람 알림 큐에서 경보 알림을 먼저 수집하고 처리하도록 애플리케이션을 구성하면, 정보 알림은 경보 알림이 처리된 후에만 처리됩니다.
3. **유연성**: 각 큐에서 별도로 Auto Scaling을 적용할 수 있으므로, 경보 알림 처리량이 많아질 때 인스턴스를 확장할 수 있습니다.

### **기타 옵션 분석:**
- **A.** 자동 크기 조정 그룹을 조정하는 것은 메시지 수를 줄이는 데 도움이 될 수 있지만, 경보 알림의 우선순위를 직접적으로 보장하지는 않습니다.
- **B.** SNS 팬아웃 기능은 메시지를 여러 구독자에게 전달하는 데 유용하지만, 경보 알림과 정보 알림의 우선순위를 관리하는 데는 적합하지 않습니다.
- **C.** DynamoDB 스트림은 데이터 변경 이벤트를 처리하는 데 사용되며, SQS 메시지의 우선순위를 관리하는 데 도움이 되지 않습니다.

따라서, **D** 옵션이 경보 알림과 정보 알림의 우선순위를 효과적으로 관리할 수 있는 최선의 솔루션입니다.

## 질문 #367  *****

SysOps 관리자는 여러 AWS 리전에 애플리케이션을 배포해야 합니다. 

SysOps 관리자는 사용자를 가장 낮은 지연 시간을 가진 리전으로 라우팅하는 솔루션을 구현해야 합니다. 장애가 발생할 경우 솔루션은 애플리케이션의 건강한 인스턴스가 있는 리전으로 요청을 자동으로 라우팅해야 합니다. 회사에는 장애 조치 시간이 가장 짧은 솔루션이 필요합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 각 엔드포인트에 대해 동일한 이름을 갖는 Amazon Route 53 A 레코드를 만듭니다. 지연 라우팅 정책을 사용합니다. 각 레코드에 상태 검사를 연결합니다.
B. 각 엔드포인트에 대해 동일한 이름을 갖는 Amazon Route 53 A 레코드를 만듭니다. 장애 조치 라우팅 정책을 사용합니다. 각 레코드에 상태 검사를 연결합니다.
C. AWS Global Accelerator 표준 가속기를 만듭니다. 각 리전에 대한 엔드포인트 그룹을 만듭니다. 가속기에 리스너를 추가합니다. 엔드포인트 그룹을 리스너와 연결합니다.
D. 각 엔드포인트에 대해 동일한 이름을 갖는 Amazon Route 53 A 레코드를 만듭니다. 지리적 위치 라우팅 정책을 사용합니다. 각 레코드에 상태 검사를 연결합니다.

SysOps 관리자가 여러 AWS 리전에 애플리케이션을 배포하고, 사용자를 가장 낮은 지연 시간을 가진 리전으로 라우팅하며, 장애 발생 시 자동으로 요청을 건강한 인스턴스가 있는 리전으로 라우팅해야 하는 요구 사항을 충족하기 위한 가장 적절한 솔루션은 다음과 같습니다:

### **C. AWS Global Accelerator 표준 가속기를 만듭니다. 각 리전에 대한 엔드포인트 그룹을 만듭니다. 가속기에 리스너를 추가합니다. 엔드포인트 그룹을 리스너와 연결합니다.**

#### **이유:**
1. **지연 시간 최소화**: AWS Global Accelerator는 사용자의 위치와 리전 간의 지연 시간을 최적화하여, 가장 가까운 AWS 리전으로 자동으로 트래픽을 라우팅합니다.
2. **자동 장애 조치**: Global Accelerator는 엔드포인트 상태를 모니터링하고, 건강하지 않은 인스턴스가 감지되면 자동으로 트래픽을 건강한 인스턴스가 있는 리전으로 전환합니다. 이 기능은 빠른 장애 조치 시간을 보장합니다.
3. **전 세계적 사용자 경험 개선**: Global Accelerator는 AWS의 글로벌 네트워크를 활용하여 사용자 요청을 더 빠르게 처리할 수 있도록 도와줍니다.

### **기타 옵션 분석:**
- **A.** 지연 라우팅 정책을 사용하면 낮은 지연 시간의 리전으로 라우팅할 수 있지만, 장애 발생 시 자동으로 요청을 다른 리전으로 전환하는 기능은 제공하지 않습니다.
- **B.** 장애 조치 라우팅 정책은 장애가 발생한 리전을 대체하는 데 유용하지만, 사용자의 위치에 따른 지연 시간 최적화는 수행하지 않습니다.
- **D.** 지리적 위치 라우팅 정책은 사용자의 위치에 따라 리전을 결정하지만, 장애 조치 기능이 포함되어 있지 않습니다.

따라서, **C** 옵션이 요구 사항을 가장 효과적으로 충족하는 솔루션입니다.


## 질문 #368 **

한 회사가 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

EC2 인스턴스는 자동 확장 그룹에 있습니다. 애플리케이션이 때때로 느리고 응답하지 않습니다. Amazon CloudWatch 메트릭은 일부 EC2 인스턴스가 높은 CPU 부하를 겪고 있음을 보여줍니다.

SysOps 관리자는 모든 EC2 인스턴스의 CPU 메트릭을 자동으로 표시할 수 있는 CloudWatch 대시보드를 만들어야 합니다. 메트릭에는 자동 확장 그룹의 일부로 시작된 새 인스턴스가 포함되어야 합니다.

SysOps 관리자는 이러한 요구 사항을 가장 운영 효율적인 방식으로 충족하기 위해 무엇을 해야 합니까?

A. CloudWatch 대시보드를 만듭니다. Auto Scaling 그룹의 활동 알림을 사용하여 사용자 지정 AWS Lambda 함수를 호출합니다. Lambda 함수를 사용하여 CloudWatch 대시보드를 업데이트하여 새 인스턴스 ID에 대한 CPUUtilization 메트릭을 모니터링합니다.
B. CloudWatch 대시보드를 만듭니다. 각 EC2 인스턴스에서 사용자 지정 스크립트를 실행하여 CPU 사용률을 대시보드로 스트리밍합니다.
C. CloudWatch 메트릭 탐색기를 사용하여 aws:autoscaling:groupName 태그로 필터링하고 CPUUtilization 메트릭에 대한 시각화를 만듭니다. 시각화를 CloudWatch 대시보드에 추가합니다.
D. CloudWatch 메트릭 탐색기를 사용하여 인스턴스 상태를 필터링하고 CPUUtilization 메트릭에 대한 시각화를 만듭니다. 시각화를 CloudWatch 대시보드에 추가합니다.

SysOps 관리자가 Amazon EC2 인스턴스의 CPU 메트릭을 자동으로 표시하고, 자동 확장 그룹의 일부로 시작된 새 인스턴스도 포함하여 CloudWatch 대시보드를 만들어야 하는 경우, 가장 운영 효율적인 방식은 다음과 같습니다:

### **C. CloudWatch 메트릭 탐색기를 사용하여 aws:autoscaling:groupName 태그로 필터링하고 CPUUtilization 메트릭에 대한 시각화를 만듭니다. 시각화를 CloudWatch 대시보드에 추가합니다.**

#### **이유:**
1. **자동화된 필터링**: EC2 인스턴스가 자동 확장 그룹의 일환으로 시작될 때, `aws:autoscaling:groupName` 태그가 자동으로 할당됩니다. 이를 활용하여 모든 관련 인스턴스를 손쉽게 필터링할 수 있습니다.
2. **즉각적인 업데이트**: 새로운 인스턴스가 추가될 때마다 태그를 기반으로 자동으로 해당 인스턴스의 메트릭이 대시보드에 포함되므로, 수동으로 메트릭을 업데이트할 필요가 없습니다.
3. **운영 효율성**: 이 방법은 최소한의 추가 작업으로 필요한 모든 메트릭을 시각화하므로, 관리의 복잡성을 줄여줍니다.

### **기타 옵션 분석:**
- **A.** 사용자 지정 AWS Lambda 함수를 호출하여 대시보드를 업데이트하는 방법은 복잡하고, Lambda 함수의 관리 및 추가 비용이 발생할 수 있습니다.
- **B.** 각 EC2 인스턴스에서 사용자 지정 스크립트를 실행하는 것은 비효율적이며 관리 및 유지보수의 복잡성을 증가시킵니다.
- **D.** 인스턴스 상태를 필터링하는 방법은 유용하지만, 특정 Auto Scaling 그룹에 속한 인스턴스를 필터링하기 위해 추가적인 태그 기반 필터링이 필요할 수 있습니다. 

따라서, **C** 옵션이 요구 사항을 충족하는 가장 효과적이고 운영 효율적인 방법입니다.

## 질문 #369 *

한 회사에 ap-southeast-2 지역에 호스팅된 암호화된 Amazon S3 버킷이 있습니다. 

eu-west-2 지역의 사용자는 인터넷을 통해 S3 버킷에 액세스합니다. eu-west-2 지역의 사용자는 대용량 파일에 대해 S3 버킷으로의 전송과 S3 버킷에서의 전송이 더 빨라야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. S3 버킷 내의 S3 버킷 접두사 길이를 줄입니다.
B. S3 버킷의 서버 측 암호화를 AES에서 RSA로 변경합니다.
C. eu-west-2에서 동일한 이름을 가진 새 S3 버킷을 만듭니다. 액세스에는 새 S3 버킷 엔드포인트의 도메인 이름을 사용합니다.
D. S3 버킷에서 S3 Transfer Acceleration을 활성화합니다. 액세스에는 새 s3-accelerate 엔드포인트의 도메인 이름을 사용합니다.

eu-west-2 지역의 사용자가 ap-southeast-2 지역에 호스팅된 암호화된 Amazon S3 버킷에 더 빠르게 액세스할 수 있도록 하려면 다음 솔루션이 가장 적합합니다:

### **D. S3 버킷에서 S3 Transfer Acceleration을 활성화합니다. 액세스에는 새 s3-accelerate 엔드포인트의 도메인 이름을 사용합니다.**

#### **이유:**
1. **전송 속도 향상**: S3 Transfer Acceleration은 AWS의 글로벌 엣지 로케이션을 활용하여 데이터를 S3 버킷으로 업로드할 때 대역폭을 개선하고 지연 시간을 줄입니다. 사용자가 eu-west-2 지역에서 파일을 업로드할 때 이 서비스를 사용하면 전송 속도가 빨라집니다.
2. **편리함**: 기존의 S3 버킷을 그대로 사용하면서 Transfer Acceleration을 활성화하면 별도의 버킷을 생성하거나 복잡한 구성을 요구하지 않습니다.
3. **간편한 사용**: 새 s3-accelerate 엔드포인트를 사용하면, Transfer Acceleration 기능을 통해 더 나은 성능을 쉽게 이용할 수 있습니다.

### **기타 옵션 분석:**
- **A.** S3 버킷 내의 접두사 길이를 줄이는 것은 성능 향상에 영향을 미치지 않습니다.
- **B.** 서버 측 암호화를 AES에서 RSA로 변경하는 것은 데이터 전송 속도와 관계가 없습니다.
- **C.** eu-west-2에서 동일한 이름의 새로운 S3 버킷을 만드는 것은 지역간의 전송 지연을 줄이는 효과가 없으며, 추가적인 관리 및 데이터 동기화의 필요성을 초래합니다.

따라서, **D** 옵션이 대용량 파일 전송 시 속도를 높이는 가장 효과적인 솔루션입니다.


## 질문 #370 *****

한 회사에 대규모 온프레미스 테이프 백업 솔루션이 있습니다. 

이 회사는 AWS Storage Gateway를 사용하기 시작했습니다. 이 회사는 기존 온프레미스 하드웨어를 대체하기 위해 Tape Gateway를 만들었습니다. 이 회사의 백업 엔지니어는 AWS에 쓰기로 되어 있던 일부 백업 작업이 "공간 부족" 오류로 인해 실행되지 않는다는 것을 알아챘습니다.

이 회사는 이러한 오류가 다시 발생하지 않기를 원합니다. 또한 이 회사는 AWS에서 지속적으로 충분한 테이프를 사용하려고 합니다.

SysOps 관리자가 이러한 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. 매 시간 실행되는 AWS Lambda 함수를 만들고 사용 가능한 공간이 있는 테이프 수를 확인합니다. 사용 가능한 테이프가 특정 임계값 아래에 있으면 더 많이 프로비저닝합니다.
B. 온프레미스 시스템에 Amazon CloudWatch 에이전트를 설치합니다. 로그 파일을 CloudWatch 로그 그룹으로 푸시합니다. "공간 부족" 오류가 나타나면 더 많은 테이프를 생성하는 AWS Lambda 함수를 만듭니다. Lambda 함수를 시작하는 메트릭 필터와 메트릭 알람을 만듭니다.
C. 자체 테이프 세트가 있는 추가 테이프 게이트웨이를 만듭니다. 기본 테이프 게이트웨이와 연결된 테이프에 사용 가능한 공간이 없는 경우 백업 엔지니어에게 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 구성합니다.
D. Tape Gateway에서 테이프 자동 생성을 구성합니다. 자동 생성 설정에서 최소 테이프 수, 적절한 바코드 접두사 및 테이프 풀을 구성합니다.

이 회사의 요구 사항을 충족하는 가장 운영 효율적인 방법은 다음과 같습니다:

### **D. Tape Gateway에서 테이프 자동 생성을 구성합니다. 자동 생성 설정에서 최소 테이프 수, 적절한 바코드 접두사 및 테이프 풀을 구성합니다.**

#### **이유:**
1. **자동화**: 테이프 자동 생성을 구성하면 사용자가 수동으로 테이프를 관리할 필요 없이 AWS가 자동으로 테이프를 생성하여 필요한 용량을 유지합니다. 이로 인해 "공간 부족" 오류가 발생할 가능성이 줄어듭니다.
2. **효율성**: 이 솔루션은 운영 오버헤드를 최소화하며, 필요한 만큼의 테이프를 자동으로 프로비저닝하여 작업이 중단되지 않도록 보장합니다.
3. **유지 관리 용이성**: AWS Storage Gateway의 기본 기능을 활용하므로, 추가적인 모니터링이나 별도의 관리 도구를 설정할 필요가 없습니다. 설정 후에는 AWS가 자동으로 용량을 관리합니다.

### **기타 옵션 분석:**
- **A.** AWS Lambda 함수를 사용하여 사용 가능한 테이프 수를 확인하는 방법은 가능하지만, 자동으로 테이프를 생성하지 않으므로 공간 부족 오류를 예방하는 데 비효율적입니다.
- **B.** 온프레미스 시스템에 CloudWatch 에이전트를 설치하고 오류를 감지하는 방법은 수동적이며, 즉각적인 문제 해결을 제공하지 않습니다.
- **C.** 추가 테이프 게이트웨이를 만들고 SNS를 통해 알림을 설정하는 것은 좋지만, 여전히 수동 관리의 필요성이 존재하며 운영 효율성이 떨어집니다.

따라서, **D** 옵션이 요구 사항을 가장 잘 충족하는 솔루션입니다.

## 질문 #371 **

SysOps 관리자가 회사의 Amazon S3 버킷을 관리합니다. 

SysOps 관리자는 회사의 AWS 계정에서 S3 버킷에 5GB의 불완전한 멀티파트 업로드를 식별했습니다. SysOps 관리자는 S3 버킷에서 불완전한 멀티파트 업로드 객체의 수를 줄여야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

A. S3 버킷에서 S3 수명 주기 규칙을 생성하여 만료된 마커나 완료되지 않은 다중 파트 업로드를 삭제합니다.
B. Amazon S3에 파일을 업로드하는 사용자는 S3 TransferUtility를 사용해야 합니다.
C. 완료되지 않은 다중 파트 업로드가 포함된 S3 버킷에서 S3 버전 관리를 활성화합니다.
D. 완료되지 않은 멀티파트 업로드를 삭제하려면 S3 객체 람다 액세스 포인트를 생성합니다.

SysOps 관리자가 불완전한 멀티파트 업로드 객체의 수를 줄이기 위해 취할 수 있는 최적의 솔루션은 다음과 같습니다:

### **A. S3 버킷에서 S3 수명 주기 규칙을 생성하여 만료된 마커나 완료되지 않은 다중 파트 업로드를 삭제합니다.**

#### **이유:**
1. **자동화된 관리**: S3 수명 주기 규칙을 사용하면 불완전한 멀티파트 업로드를 자동으로 정리할 수 있습니다. 이 규칙을 설정하면 지정된 기간이 지난 후에 완료되지 않은 업로드를 자동으로 삭제하여 저장 공간을 절약할 수 있습니다.
2. **비용 절감**: 미완료된 멀티파트 업로드가 계속 남아있으면 비용이 증가할 수 있습니다. 수명 주기 규칙을 설정하여 이를 정리하면 비용을 줄일 수 있습니다.
3. **단순성**: 수명 주기 규칙은 관리자가 한 번만 설정하면 자동으로 적용되므로 지속적으로 모니터링할 필요가 없습니다.

### **기타 옵션 분석:**
- **B.** S3 TransferUtility를 사용하는 것은 업로드 프로세스를 간소화하지만, 불완전한 멀티파트 업로드를 삭제하는 것과는 관련이 없습니다.
- **C.** S3 버전 관리를 활성화하면 객체의 여러 버전을 관리할 수 있지만, 불완전한 멀티파트 업로드를 자동으로 정리하지는 않습니다.
- **D.** S3 객체 람다 액세스 포인트를 생성하여 멀티파트 업로드를 삭제하는 것은 가능하지만, 이는 불필요한 복잡성을 초래하고 자동화되지 않은 솔루션입니다.

따라서, **A** 옵션이 요구 사항을 가장 잘 충족하는 솔루션입니다. 

## 질문 #372

SysOps 관리자는 AWS CloudFormation 템플릿에서 리소스로 Amazon S3 버킷을 생성해야 합니다. 버킷 이름은 무작위로 생성해야 하며, 버킷은 암호화되어야 합니다. 템플릿의 다른 리소스는 버킷을 참조합니다. SysOps 관리자는

이러한 요구 사항을 충족하기 위해 어떤 CloudFormation 리소스 정의를 사용해야 합니까?
A. 
B. 
C. 
D. 



## 질문 #373 *

SysOps 관리자는 AWS Organizations 구조에서 많은 AWS 멤버 계정에 대한 정책을 관리합니다. 
다른 팀의 관리자는 멤버 계정의 계정 루트 사용자 자격 증명에 액세스할 수 있습니다. SysOps 관리자는 관리자를 포함한 모든 팀이 Amazon DynamoDB를 사용하지 못하도록 해야 합니다. 솔루션은 팀이 다른 AWS 서비스에 액세스하는 기능에 영향을 미쳐서는 안 됩니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 모든 구성원 계정에서 루트 사용자를 포함한 모든 사용자의 모든 DynamoDB 리소스에 대한 액세스를 거부하는 IAM 정책을 구성합니다.
B. 관리 계정에서 모든 DynamoDB 작업을 거부하기 위해 서비스 제어 정책(SCP)을 만듭니다. 조직의 루트에 SCP를 적용합니다.
C. 모든 구성원 계정에서 루트 사용자를 포함한 모든 사용자에게 AmazonDynamoDBFullAccess를 거부하는 IAM 정책을 구성합니다.
D. 관리 계정에서 기본 서비스 제어 정책(SCP)을 제거합니다. 모든 DynamoDB 작업을 거부하는 단일 명령문을 포함하는 대체 SCP를 만듭니다.

이러한 요구 사항을 충족하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### **B. 관리 계정에서 모든 DynamoDB 작업을 거부하기 위해 서비스 제어 정책(SCP)을 만듭니다. 조직의 루트에 SCP를 적용합니다.**

#### **이유:**
1. **조직 전체 관리**: 서비스 제어 정책(SCP)은 AWS Organizations 내에서 계정에 적용되는 정책으로, 멤버 계정에서 어떤 서비스와 작업을 사용할 수 있는지를 제어합니다. 이를 통해 관리자는 특정 서비스에 대한 액세스를 쉽게 제한할 수 있습니다.
2. **루트 사용자 보호**: SCP는 루트 사용자 계정에 대해서도 적용됩니다. 따라서 모든 팀의 관리자를 포함한 루트 사용자가 DynamoDB에 접근하지 못하도록 보장할 수 있습니다.
3. **다른 서비스에 대한 영향 없음**: SCP는 DynamoDB에 대한 액세스만 제한하고 다른 AWS 서비스에 대한 액세스에는 영향을 미치지 않으므로 요구 사항에 맞습니다.

### **기타 옵션 분석:**
- **A.** IAM 정책은 개별 계정 내에서 작동하지만, 관리 계정에서는 SCP를 통해 보다 효과적으로 관리할 수 있습니다. 루트 사용자와 다른 사용자에 대한 거부 정책을 별도로 구성하는 것은 관리와 유지보수 측면에서 비효율적입니다.
- **C.** IAM 정책을 구성하는 것도 가능하지만, 이는 개별 계정에 적용되므로 모든 계정에서 이를 수동으로 적용해야 하며, 관리가 복잡해집니다.
- **D.** 기본 SCP를 제거하는 것은 권장되지 않으며, 이는 잠재적인 보안 문제를 일으킬 수 있습니다. 또한, SCP를 대체하는 것은 혼란을 초래할 수 있습니다.

따라서, **B** 옵션이 요구 사항을 가장 잘 충족하는 솔루션입니다.

## 질문 #374

회사에는 필요한 것보다 더 많은 디스크 성능 용량이 있는 Amazon EC2 인스턴스를 배포하는 사용자가 있습니다. 

SysOps 관리자는 인스턴스와 연결된 모든 Amazon Elastic Block Store(Amazon EBS) 볼륨을 검토하고 IOPS 및 처리량을 기반으로 비용 최적화 권장 사항을 만들어야 합니다.

SysOps 관리자는 이러한 요구 사항을 가장 운영 효율적인 방식으로 충족하기 위해 무엇을 해야 합니까?

A. EC2 콘솔의 모니터링 그래프를 사용하여 EBS 볼륨의 메트릭을 확인합니다. 각 볼륨에서 프로비저닝된 공간에 대해 사용된 공간을 검토합니다. 사용률이 낮은 볼륨을 식별합니다.
B. EC2 콘솔에서 EC2 인스턴스를 중지합니다. Amazon EBS-optimized에 대한 EC2 인스턴스 유형을 변경합니다. EC2 인스턴스를 시작합니다.
C. AWS Compute Optimizer에 가입하세요. 메트릭을 수집할 충분한 시간을 두세요. EBS 볼륨에 대한 Compute Optimizer 결과를 검토하세요.
D. EC2 인스턴스에 fio 도구를 설치하고 .cfg 파일을 만들어 필요한 작업 부하를 근사합니다. 벤치마크 결과를 사용하여 프로비저닝된 EBS 볼륨이 가장 적합한 유형인지 측정합니다.


Amazon EBS 볼륨의 IOPS 및 처리량을 기반으로 비용 최적화 권장 사항을 생성하기 위해 SysOps 관리자는 다음 조치를 취하는 것이 가장 운영 효율적인 방법입니다:

### **C. AWS Compute Optimizer에 가입하세요. 메트릭을 수집할 충분한 시간을 두세요. EBS 볼륨에 대한 Compute Optimizer 결과를 검토하세요.**

#### **이유:**
1. **자동화된 분석**: AWS Compute Optimizer는 자동으로 EC2 인스턴스와 EBS 볼륨의 성능을 분석하고 최적화할 수 있는 권장 사항을 제공합니다. 이를 통해 수동으로 모니터링할 필요가 없으며, 데이터에 기반한 인사이트를 제공합니다.
2. **비용 효율성**: Compute Optimizer는 리소스의 사용률을 최적화하여 불필요한 비용을 줄일 수 있도록 도와줍니다. EBS 볼륨에 대한 최적의 성능과 비용을 평가하여 가장 적합한 EBS 유형을 권장합니다.
3. **시간 절약**: 수동으로 볼륨 메트릭을 검토하는 것보다 Compute Optimizer를 사용하는 것이 시간을 절약하고 더 정확한 분석을 제공합니다.

### **기타 옵션 분석:**
- **A.** EC2 콘솔의 모니터링 그래프를 사용하여 메트릭을 확인하는 것은 수동적이고 시간이 많이 소요됩니다. 이 방법은 메트릭을 개별적으로 분석해야 하므로 비효율적입니다.
- **B.** EBS-optimized 인스턴스 유형으로 변경하는 것은 성능을 개선할 수 있지만, 현재의 EBS 볼륨에 대한 분석 없이 무작정 변경하는 것은 권장되지 않습니다.
- **D.** fio 도구를 사용하여 벤치마킹하는 방법은 기술적이고 수동적인 접근 방식입니다. 또한, 시스템 구성에 대한 추가 작업이 필요하므로 더 많은 시간과 노력이 소요됩니다.

따라서, **C** 옵션이 EBS 볼륨을 최적화하는 데 가장 운영 효율적인 방법입니다.


## 질문 #375 **

SysOps 관리자는 노드 간에 파일 시스템을 공유해야 하는 많은 Windows Amazon EC2 인스턴스를 가지고 있습니다. 

SysOps 관리자는 Amazon Elastic File System(Amazon EFS) 파일 공유를 만듭니다. 파일 공유를 만든 후 SysOps 관리자는 파일 공유를 EC2 인스턴스에 마운트하는 데 문제가 있습니다.

EC2 인스턴스가 파일을 공유할 수 있도록 SysOps 관리자는 어떤 조치를 취해야 합니까?

A. EFS 파일 공유를 삭제합니다. EC2 인스턴스에 대한 Amazon FSx for Windows File Server 파일 공유를 만듭니다.
B. 올바른 IAM 자격 증명을 사용하여 EFS 파일 공유를 마운트합니다.
C. EC2 인스턴스에서 실행되는 Windows 운영 체제에서 NFSv4 지원을 구성합니다.
D. 보안 그룹과 네트워크 ACL을 통해 NFS에 대한 올바른 포트를 허용합니다.

Amazon EFS 파일 공유를 Windows Amazon EC2 인스턴스에 마운트하는 데 문제가 발생한 경우, SysOps 관리자는 다음과 같은 조치를 취해야 합니다:

### **D. 보안 그룹과 네트워크 ACL을 통해 NFS에 대한 올바른 포트를 허용합니다.**

#### **이유:**
1. **NFS 프로토콜**: Amazon EFS는 NFS(Network File System) 프로토콜을 사용하여 파일 공유를 제공합니다. Windows 인스턴스에서 EFS를 마운트하려면 NFSv4를 사용해야 하며, 이 포트(2049번 포트)가 네트워크에서 열려 있어야 합니다.
2. **보안 그룹 및 네트워크 ACL**: EFS에 접근하기 위해 EC2 인스턴스가 EFS 파일 시스템의 보안 그룹과 네트워크 ACL에서 NFS 트래픽을 허용하는 규칙이 필요합니다. 이를 통해 EC2 인스턴스가 EFS에 연결할 수 있습니다.

### **기타 옵션 분석:**
- **A.** Amazon FSx for Windows File Server는 Windows 기반 파일 공유에 적합하지만, 문제의 핵심은 EFS와의 마운트 문제이므로 이를 삭제하고 다른 파일 공유로 전환하는 것은 비효율적입니다.
- **B.** IAM 자격 증명은 EFS 파일 시스템에 대한 액세스를 관리하는 데 필요할 수 있지만, Windows EC2 인스턴스에서 EFS를 마운트할 때 NFS 프로토콜의 요구 사항과는 관련이 없습니다.
- **C.** Windows 운영 체제에서 NFSv4 지원을 구성하는 것은 일반적으로 필요하지 않습니다. AWS에서는 EFS를 Windows 인스턴스에서 사용할 수 있도록 적절한 구성을 제공합니다.

따라서, **D** 옵션이 EFS 파일 공유를 EC2 인스턴스에 마운트할 수 있도록 하는 가장 적절한 조치입니다.


## 질문 #376 *****

한 회사에 다중 계정 환경이 있습니다. 계정 A에는 Amazon EC2 인스턴스에 호스팅된 프로덕션 애플리케이션이 있습니다. 

이 애플리케이션은 계정 B에 호스팅된 Amazon DynamoDB 테이블의 데이터를 쿼리해야 합니다.

SysOps 관리자는 계정 A의 EC2 인스턴스에 계정 B의 DynamoDB 테이블에 대한 액세스 권한을 제공해야 합니다.

이러한 요구 사항을 충족하는 가장 안전한 솔루션은 무엇입니까?

A. EC2 인스턴스의 IAM 역할에 연결된 IAM 정책을 업데이트하여 계정 B의 DynamoDB 테이블에 dynamodb:Query 권한을 허용합니다. 계정 A에 정책을 추가하여 DynamoDB 서비스 주체가 PassRole 작업을 사용하여 역할을 계정 B에 전달할 수 있도록 합니다.
B. 계정 B에서 DynamoDB 테이블을 쿼리할 수 있는 권한이 있는 IAM 역할을 만듭니다. EC2 인스턴스의 IAM 역할을 계정에서 새로 만든 IAM 역할의 신뢰 정책에 추가합니다. EC2 인스턴스의 IAM 역할에 연결된 IAM 정책을 업데이트하여 계정 B에서 새로 만든 IAM 역할에 sts:AssumeRole 권한을 허용합니다.
C. EC2 인스턴스의 IAM 역할에 연결된 IAM 정책을 업데이트하여 계정 B의 DynamoDB 테이블에 dynamodb:Query 권한을 허용합니다. DynamoDB 테이블의 리소스 정책을 업데이트하여 EC2 인스턴스의 IAM 역할에서 쿼리 작업을 허용합니다.
D. 계정 B에서 DynamoDB 테이블을 쿼리할 수 있는 적절한 권한이 있는 정적 IAM 키를 만듭니다. 이러한 자격 증명을 EC2 인스턴스의 자격 증명 파일에 포함합니다. 애플리케이션이 테이블을 쿼리해야 할 때마다 자격 증명을 참조합니다.

계정 A의 EC2 인스턴스가 계정 B의 DynamoDB 테이블에 안전하게 액세스할 수 있도록 하려면, 다음과 같은 솔루션이 가장 안전합니다:

### **B. 계정 B에서 DynamoDB 테이블을 쿼리할 수 있는 권한이 있는 IAM 역할을 만듭니다. EC2 인스턴스의 IAM 역할을 계정에서 새로 만든 IAM 역할의 신뢰 정책에 추가합니다. EC2 인스턴스의 IAM 역할에 연결된 IAM 정책을 업데이트하여 계정 B에서 새로 만든 IAM 역할에 sts:AssumeRole 권한을 허용합니다.**

#### **이유:**
1. **최소 권한 원칙:** IAM 역할을 사용하여 EC2 인스턴스가 DynamoDB 테이블에 액세스하는 권한을 위임함으로써, 필요한 권한만 부여할 수 있습니다.
2. **신뢰 정책:** 계정 B에서 생성한 IAM 역할에 EC2 인스턴스의 IAM 역할을 신뢰할 수 있도록 추가하여, EC2 인스턴스가 이 역할을 안전하게 가정할 수 있도록 합니다.
3. **동적 자격 증명:** EC2 인스턴스가 IAM 역할을 사용하여 DynamoDB에 액세스할 때, 임시 자격 증명을 사용하므로 자격 증명이 노출될 위험이 줄어듭니다.

### **기타 옵션 분석:**
- **A.** 이 옵션은 EC2 인스턴스의 IAM 역할에 권한을 부여하지만, PassRole 작업을 사용하는 것이 불필요하고 복잡합니다.
- **C.** 이 접근 방식은 DynamoDB 테이블의 리소스 정책을 업데이트하여 IAM 역할에서 직접 액세스를 허용하므로 안전성이 떨어질 수 있습니다. 또한, IAM 역할을 사용하여 권한을 위임하는 방식이 더 적합합니다.
- **D.** 정적 IAM 키를 사용하는 것은 자격 증명이 유출될 위험이 크고, 비밀 관리와 관련된 문제를 야기할 수 있습니다. 이 방법은 권장되지 않습니다.

따라서, **B** 옵션이 가장 안전하고 관리가 용이한 솔루션입니다.


## 질문 #377 ****

한 회사가 마이크로서비스 기반 애플리케이션을 호스팅하기 위해 Amazon Elastic Kubernetes Service(Amazon ECS)에 Kubernetes 클러스터를 구현했습니다. 

이 회사는 다음 달에 애플리케이션 트래픽이 상당히 증가할 것으로 예상하고 많은 요청으로 인해 애플리케이션이 충돌하는 것을 방지하고자 합니다.

어떤 솔루션이 가장 적은 관리 오버헤드로 이러한 요구 사항을 충족할까요?

A. 두 번째 EKS 클러스터를 만듭니다. 두 클러스터 간의 작업 부하를 로드 밸런싱합니다.
B. Kubernetes Horizontal Pod Autoscaler를 구현합니다. 목표 CPU 사용률 백분율을 설정합니다.
C. 다음 달 동안 Amazon EKS에서 Amazon EC2로 애플리케이션을 마이그레이션합니다. 그 달이 끝나면 애플리케이션을 다시 Amazon EKS로 마이그레이션합니다.
D. Kubernetes Vertical Pod Autoscaler를 구현합니다. 목표 CPU 사용률 백분율을 설정합니다.

트래픽 증가에 따른 애플리케이션 충돌을 방지하기 위해 관리 오버헤드를 최소화하면서 요구 사항을 충족하는 솔루션은 다음과 같습니다:

### **B. Kubernetes Horizontal Pod Autoscaler를 구현합니다. 목표 CPU 사용률 백분율을 설정합니다.**
- **이유:** Kubernetes Horizontal Pod Autoscaler(HPA)는 자동으로 파드 수를 조정하여 애플리케이션의 CPU 사용량이나 메모리 사용량에 기반하여 수요에 맞게 확장합니다. 이를 통해 요청이 증가할 때 필요한 만큼 파드를 추가하여 충돌을 방지하고, 기본 클러스터와 관리 작업에 대한 오버헤드를 최소화합니다. 설정이 완료되면 HPA는 자동으로 작동하므로 관리 부담이 줄어듭니다.

### **기타 옵션 분석:**
- **A. 두 번째 EKS 클러스터를 만듭니다. 두 클러스터 간의 작업 부하를 로드 밸런싱합니다.**
  - 추가 클러스터를 만드는 것은 상당한 관리 오버헤드를 유발하며, 클러스터 간의 로드 밸런싱 구성 및 관리를 추가로 요구합니다.

- **C. 다음 달 동안 Amazon EKS에서 Amazon EC2로 애플리케이션을 마이그레이션합니다. 그 달이 끝나면 애플리케이션을 다시 Amazon EKS로 마이그레이션합니다.**
  - 마이그레이션 과정은 복잡하고 시간 소모적이며, 서비스 중단을 초래할 수 있어 비효율적입니다.

- **D. Kubernetes Vertical Pod Autoscaler를 구현합니다. 목표 CPU 사용률 백분율을 설정합니다.**
  - Vertical Pod Autoscaler(VPA)는 파드의 리소스 요청 및 제한을 조정하여 리소스 사용을 최적화합니다. 하지만 VPA는 파드가 재배포되어야 하므로 자동 확장이 필요할 때 HPA보다 관리 오버헤드가 더 클 수 있습니다.

결론적으로, **B** 옵션이 가장 적은 관리 오버헤드를 가지면서 애플리케이션의 트래픽 증가를 효과적으로 처리할 수 있는 솔루션입니다.

## 질문 #378

한 회사가 Amazon EC2 인스턴스에 새 애플리케이션을 배포합니다. 

애플리케이션 코드는 AWS CodeCommit 리포지토리에 저장됩니다. 이 회사는 AWS CodePipeline 파이프라인을 사용하여 CI/CD(Continuous Integration and Continuous Delivery) 프로세스를 통해 EC2 인스턴스에 코드를 배포합니다.

SysOps 관리자는 자격 증명의 우발적 유출을 방지하기 위해 EC2 인스턴스에서 중요한 데이터베이스 정보가 올바르게 구성되었는지 확인해야 합니다.

가장 안전한 방식으로 중요한 정보를 저장하고 검색하는 솔루션은 무엇입니까? (두 가지를 선택하세요.)

A. AWS Secrets Manager에 값을 저장합니다. 애플리케이션이 시작될 때 이러한 값을 검색하도록 코드를 업데이트합니다. 애플리케이션이 사용할 수 있는 환경 변수로 값을 저장합니다.
B. AWS Systems Manager Parameter Store에 값을 비밀 문자열로 저장합니다. 애플리케이션이 시작될 때 이러한 값을 검색하도록 코드를 업데이트합니다. 애플리케이션이 사용할 수 있는 환경 변수로 값을 저장합니다.
C. AWS Lambda 함수에 값을 저장합니다. 애플리케이션이 시작될 때 Lambda 함수를 호출하도록 코드를 업데이트합니다. 애플리케이션이 사용할 수 있는 환경 변수로 값을 주입하도록 Lambda 함수를 구성합니다.
D. EC2 인스턴스의 파일에 구성 정보를 저장합니다. 기본 드라이브가 AWS Key Management Service(AWS KMS)에 의해 암호화되었는지 확인합니다. 애플리케이션이 시작될 때 파일을 읽도록 애플리케이션을 업데이트합니다. 값을 환경 변수로 저장합니다.
E. 값을 Amazon S3 버킷의 텍스트 파일에 저장합니다. CI/CD 파이프라인에서 해당 파일을 애플리케이션이 읽을 수 있는 디스크의 적절한 위치에 있는 EC2 인스턴스로 복사합니다.

SysOps 관리자가 Amazon EC2 인스턴스에서 중요한 데이터베이스 정보를 안전하게 저장하고 검색하기 위해 선택할 수 있는 가장 안전한 방법은 다음과 같습니다:

### **A. AWS Secrets Manager에 값을 저장합니다. 애플리케이션이 시작될 때 이러한 값을 검색하도록 코드를 업데이트합니다. 애플리케이션이 사용할 수 있는 환경 변수로 값을 저장합니다.**
- **이유:** AWS Secrets Manager는 비밀번호, API 키 및 데이터베이스 자격 증명과 같은 비밀 정보를 안전하게 저장하고 관리할 수 있는 서비스입니다. 애플리케이션이 시작될 때 Secrets Manager에서 비밀을 검색하면, 민감한 데이터가 소스 코드나 환경 변수에 직접 노출되지 않도록 할 수 있습니다.

### **B. AWS Systems Manager Parameter Store에 값을 비밀 문자열로 저장합니다. 애플리케이션이 시작될 때 이러한 값을 검색하도록 코드를 업데이트합니다. 애플리케이션이 사용할 수 있는 환경 변수로 값을 저장합니다.**
- **이유:** AWS Systems Manager Parameter Store는 비밀 문자열을 안전하게 저장하고 관리할 수 있는 또 다른 방법입니다. 이를 사용하여 애플리케이션이 시작될 때 비밀 값을 검색하면 자격 증명의 우발적 유출을 방지할 수 있습니다. 

### **추가 옵션 분석:**
- **C. AWS Lambda 함수에 값을 저장합니다. 애플리케이션이 시작될 때 Lambda 함수를 호출하도록 코드를 업데이트합니다. 애플리케이션이 사용할 수 있는 환경 변수로 값을 주입하도록 Lambda 함수를 구성합니다.**
  - Lambda 함수에 값을 저장하는 것은 비밀 정보의 관리를 복잡하게 만들 수 있으며, Lambda 호출의 오버헤드가 발생할 수 있습니다.

- **D. EC2 인스턴스의 파일에 구성 정보를 저장합니다. 기본 드라이브가 AWS Key Management Service(AWS KMS)에 의해 암호화되었는지 확인합니다. 애플리케이션이 시작될 때 파일을 읽도록 애플리케이션을 업데이트합니다. 값을 환경 변수로 저장합니다.**
  - 이 방법은 여전히 파일 시스템에 비밀이 저장되는 것이므로, 다른 접근 방식보다 보안이 떨어질 수 있습니다.

- **E. 값을 Amazon S3 버킷의 텍스트 파일에 저장합니다. CI/CD 파이프라인에서 해당 파일을 애플리케이션이 읽을 수 있는 디스크의 적절한 위치에 있는 EC2 인스턴스로 복사합니다.**
  - S3에 비밀 정보를 저장하는 것은 권한 관리와 접근 보안이 더 복잡해질 수 있으며, 자격 증명의 우발적 유출 위험이 큽니다.

결론적으로, **A**와 **B** 옵션이 요구 사항을 충족하는 가장 안전한 해결책입니다.

## 질문 #379 ***

SysOps 관리자가 기본 형식을 사용하여 VPC 흐름 로그를 구성했습니다. 

SysOps 관리자가 Amazon CloudWatch Logs를 대상으로 지정했습니다. 이 솔루션은 몇 달 동안 성공적으로 작동했습니다. 그러나 추가 문제 해결 요구 사항으로 인해 SysOps 관리자는 흐름 로그에 tcp-flags 필드를 포함해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 새 흐름 로그를 만듭니다. 사용자 지정 로그 형식에 tcp-flags 필드를 포함합니다. 원래 흐름 로그를 삭제합니다.
B. CloudWatch Logs 로그 그룹에서 tcp-flags 필드와 type 필드를 포함하도록 필터를 수정합니다.
C. CloudWatch Metrics에서 tcp-flags 필드를 포함하도록 메트릭 구성을 수정합니다.
D. 기존 흐름 로그를 수정합니다. 사용자 정의 로그 형식에 tcp-flags 필드와 type 필드를 포함합니다. 구성을 저장합니다.

VPC 흐름 로그에 `tcp-flags` 필드를 포함하기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### **A. 새 흐름 로그를 만듭니다. 사용자 지정 로그 형식에 tcp-flags 필드를 포함합니다. 원래 흐름 로그를 삭제합니다.**
- **이유:** VPC 흐름 로그의 기본 형식을 사용하면 특정 필드를 포함하도록 로그 구성을 수정할 수 없습니다. 따라서 필요한 필드를 포함한 새 흐름 로그를 만들고, 원래 흐름 로그를 삭제하는 것이 필요합니다. 사용자 지정 로그 형식을 설정할 수 있으며, 이때 `tcp-flags` 필드를 포함하도록 구성해야 합니다.

### **추가 옵션 분석:**
- **B. CloudWatch Logs 로그 그룹에서 tcp-flags 필드와 type 필드를 포함하도록 필터를 수정합니다.**
  - 이 방법은 필터를 수정하는 것이지만, VPC 흐름 로그의 원래 로그 형식을 변경할 수 없기 때문에 `tcp-flags` 필드가 로그에 포함되지 않습니다.

- **C. CloudWatch Metrics에서 tcp-flags 필드를 포함하도록 메트릭 구성을 수정합니다.**
  - 메트릭은 흐름 로그의 구성에 따라 생성되므로, tcp-flags 필드를 포함시키는 것은 올바른 접근이 아닙니다.

- **D. 기존 흐름 로그를 수정합니다. 사용자 정의 로그 형식에 tcp-flags 필드와 type 필드를 포함합니다. 구성을 저장합니다.**
  - 기존 흐름 로그는 수정할 수 없으므로 이 방법은 효과적이지 않습니다.

결론적으로, **A** 옵션이 요구 사항을 충족하는 올바른 해결책입니다.


## 질문 #380 ***

SysOps 관리자가 Amazon CloudFront 배포의 캐시 적중률이 10% 미만임을 알아챘습니다. 

SysOps 관리자는 배포의 캐시 적중률을 높이고, 네트워크 성능을 개선하고, 오리진의 부하를 줄여야 합니다. SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. 필요한 AWS 지역에 대해 CloudFront Origin Shield를 활성화합니다.
B. 뷰어 프로토콜 정책을 변경하여 HTTPS만 사용합니다.
C. 두 번째 오리진을 추가합니다. 두 오리진을 모두 포함하는 오리진 그룹을 만듭니다. CloudFront 오리진 페일오버를 활성화합니다.
D. 캐시 동작 설정에서 개체의 자동 압축을 켭니다.
E. 캐시 동작 설정에서 CloudFront TTL 값을 늘립니다.

Amazon CloudFront의 캐시 적중률을 높이고, 네트워크 성능을 개선하며, 오리진의 부하를 줄이기 위해 SysOps 관리자가 취할 수 있는 조치 조합은 다음과 같습니다:

### **A. 필요한 AWS 지역에 대해 CloudFront Origin Shield를 활성화합니다.**
- **이유:** CloudFront Origin Shield는 캐시 적중률을 높이고 오리진의 부하를 줄이는 데 도움을 줄 수 있습니다. 이를 활성화하면 CloudFront가 캐시된 콘텐츠를 더욱 효율적으로 제공하고, 오리진으로의 요청을 줄일 수 있습니다.

### **E. 캐시 동작 설정에서 CloudFront TTL 값을 늘립니다.**
- **이유:** TTL(Time To Live) 값을 늘리면 CloudFront가 객체를 캐시하는 시간을 늘려, 같은 콘텐츠에 대한 요청이 오리진에 도달하는 빈도를 줄이고 캐시 적중률을 높일 수 있습니다. 

### **추가 옵션 분석:**
- **B. 뷰어 프로토콜 정책을 변경하여 HTTPS만 사용합니다.** 
  - HTTPS로의 전환은 보안성을 높이지만, 캐시 적중률에 직접적인 영향을 주지는 않습니다.
  
- **C. 두 번째 오리진을 추가합니다. 두 오리진을 모두 포함하는 오리진 그룹을 만듭니다. CloudFront 오리진 페일오버를 활성화합니다.**
  - 오리진 페일오버는 신뢰성 향상에 도움이 될 수 있으나, 캐시 적중률이나 네트워크 성능에 큰 영향을 미치지 않습니다.

- **D. 캐시 동작 설정에서 개체의 자동 압축을 켭니다.**
  - 자동 압축은 전송되는 데이터의 크기를 줄이는 데 도움을 줄 수 있지만, 캐시 적중률을 높이기보다는 대역폭 절약 측면에서 유용합니다.

결론적으로, **A**와 **E** 조치를 취하는 것이 가장 적절합니다.


## 질문 #381 *****

모든 Amazon EC2 인스턴스에 사용자 정의 애플리케이션을 설치해야 합니다. 

애플리케이션은 작고, 자주 업데이트되며, 자동으로 설치할 수 있습니다.

애플리케이션을 새 EC2 인스턴스에 어떻게 배포할 수 있습니까?

A. Amazon EC2 사용자 데이터를 사용하여 애플리케이션을 다운로드하고 설치하는 스크립트를 시작합니다.
B. Amazon API Gateway를 사용하여 AWS CloudFormation 템플릿에서 설치 실행 파일을 호출하는 사용자 지정 API를 만듭니다.
C. AWS Systems Manager를 사용하여 애플리케이션을 AMI에 주입합니다.
D. AWS CodePipeline을 구성하여 코드 변경 사항과 업데이트를 배포합니다.

모든 Amazon EC2 인스턴스에 사용자 정의 애플리케이션을 자동으로 설치하기 위한 가장 적절한 방법은 다음과 같습니다:

**A. Amazon EC2 사용자 데이터를 사용하여 애플리케이션을 다운로드하고 설치하는 스크립트를 시작합니다.**

이유는 다음과 같습니다:

- **EC2 사용자 데이터**는 인스턴스 시작 시 실행되는 스크립트를 포함할 수 있으며, 이를 통해 애플리케이션을 자동으로 다운로드하고 설치할 수 있습니다. 이 방법은 간단하고, 인스턴스가 시작될 때 자동으로 실행되므로 관리가 용이합니다.
- 애플리케이션이 작고 자주 업데이트되는 경우, 사용자 데이터를 통해 최신 버전을 다운로드하는 스크립트를 작성하면 쉽게 최신 상태를 유지할 수 있습니다.

다른 옵션들의 분석은 다음과 같습니다:

- **B. Amazon API Gateway**는 API를 통해 설치 파일을 호출할 수 있지만, 이 방법은 복잡하고 EC2 인스턴스 시작 시 자동으로 실행되지 않기 때문에 불편합니다.
- **C. AWS Systems Manager**를 사용하여 AMI에 애플리케이션을 주입하는 것은 가능하지만, 이는 새로운 인스턴스를 생성할 때마다 AMI를 업데이트해야 하므로 자동화의 이점을 잃게 됩니다.
- **D. AWS CodePipeline**은 지속적인 통합 및 배포(Continuous Integration and Deployment, CI/CD)에 유용하지만, EC2 인스턴스가 시작될 때 자동으로 애플리케이션을 설치하는 데는 비효율적입니다.

따라서, 가장 효율적이고 자동화된 방법은 **A**입니다.

## 질문 #382 ***

SysOps 관리자가 AWS 계정이 없는 사용자 그룹과 프라이빗 Amazon S3 버킷의 객체를 안전하게 공유하려고 합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 사용자의 IP 주소에서만 객체를 다운로드할 수 있도록 허용하는 S3 버킷 정책을 연결합니다.
B. 객체에 대한 액세스 권한이 있는 IAM 역할을 만듭니다. 사용자에게 역할을 맡으라고 지시합니다.
C. 객체에 액세스할 수 있는 IAM 사용자를 만듭니다. 사용자와 자격 증명을 공유합니다.
D. 객체에 대한 사전 서명된 URL을 생성합니다. URL을 사용자와 공유합니다.

프라이빗 Amazon S3 버킷의 객체를 AWS 계정이 없는 사용자 그룹과 안전하게 공유하기 위해 가장 운영 효율적인 솔루션은 다음과 같습니다:

**D. 객체에 대한 사전 서명된 URL을 생성합니다. URL을 사용자와 공유합니다.**

이유는 다음과 같습니다:

- **사전 서명된 URL**은 특정 시간 동안만 유효한 URL을 생성하여 외부 사용자에게 S3 객체에 대한 일시적인 액세스를 제공합니다. 이 방식은 AWS 계정이 없는 사용자에게도 쉽게 접근할 수 있는 방법을 제공하며, 사용자가 URL을 통해 직접 객체를 다운로드할 수 있도록 합니다.
- 이 방법은 관리가 간편하고, 별도의 IAM 사용자 또는 역할을 생성할 필요가 없으며, IAM 자격 증명을 공유할 위험을 줄일 수 있습니다.

다른 옵션들은 다음과 같습니다:

- **A**는 IP 주소 기반의 액세스 제어를 제공하지만, 사용자에게 URL을 공유하는 방식에 비해 더 복잡하고 사용자 친화적이지 않습니다.
- **B**와 **C**는 IAM 역할이나 사용자를 통해 접근 권한을 부여하지만, 이는 AWS 계정이 없는 사용자에게는 적합하지 않습니다. IAM 사용자와 자격 증명을 공유하는 것은 보안 리스크를 증가시킬 수 있습니다.

## 질문 #383

한 회사가 AWS에서 전자상거래 애플리케이션을 실행하고 있습니다.
 이 애플리케이션은 Amazon Aurora DB 클러스터에 열려 있지만 유휴 상태인 연결을 많이 유지합니다. 사용량이 가장 많은 시간에 데이터베이스는 다음과 같은 오류 메시지를 생성합니다. "연결이 너무 많습니다." 데이터베이스 클라이언트에도 오류가 발생합니다.

어떤 솔루션이 이러한 오류를 해결할 수 있을까요?
A. 데이터베이스에서 읽기 용량 단위(RCU)와 쓰기 용량 단위(WCU)를 늘립니다.
B. RDS 프록시 구성. RDS 프록시 엔드포인트로 애플리케이션을 업데이트합니다.
C. DB 인스턴스에 대해 향상된 네트워킹을 켭니다.
D. 버스트 가능 인스턴스 유형을 사용하도록 DB 클러스터를 수정합니다.

"연결이 너무 많습니다"라는 오류 메시지는 데이터베이스의 동시 연결 수가 허용된 최대 연결 수를 초과했음을 의미합니다. 이 문제를 해결하기 위한 가장 적절한 솔루션은 다음과 같습니다:

**B. RDS 프록시 구성. RDS 프록시 엔드포인트로 애플리케이션을 업데이트합니다.**

이유는 다음과 같습니다:

- **RDS 프록시**는 데이터베이스와 애플리케이션 간의 연결을 관리하여 연결 수를 효율적으로 유지하고 유휴 연결을 자동으로 정리합니다. 이를 통해 애플리케이션의 연결 수를 줄이고 성능을 향상시킬 수 있습니다.
- RDS 프록시는 애플리케이션이 데이터베이스에 연결할 때보다 적은 수의 데이터베이스 연결을 유지하므로, 최대 연결 수 초과로 인한 오류를 완화할 수 있습니다.

다른 옵션들은 다음과 같습니다:

- **A**는 Amazon Aurora의 읽기 및 쓰기 용량에 해당하는 RCU와 WCU를 증가시키지만, 이는 주로 DynamoDB에 해당되는 개념입니다.
- **C**는 향상된 네트워킹을 통해 성능을 향상시킬 수 있지만, 이 문제의 직접적인 원인인 연결 수 문제를 해결하지 않습니다.
- **D**는 버스트 가능 인스턴스 유형을 사용하여 스케일링 성능을 높일 수 있지만, 이 또한 연결 수 문제를 해결하지 않습니다.

## 질문 #384 *

SysOps 관리자가 사용자 지정 네트워크 ACL을 활용하는 퍼블릭 및 프라이빗 서브넷이 있는 VPC의 문제를 해결하고 있습니다. 

프라이빗 서브넷의 인스턴스는 인터넷에 액세스할 수 없습니다. 퍼블릭 서브넷에 연결된 인터넷 게이트웨이가 있습니다. 프라이빗 서브넷에는 퍼블릭 서브넷에 연결된 NAT 게이트웨이로 가는 경로가 있습니다. Amazon EC2 인스턴스는 VPC의 기본 보안 그룹과 연결되어 있습니다.

이 시나리오에서 문제의 원인은 무엇입니까?

A. 개인 서브넷에 모든 아웃바운드 트래픽을 거부하도록 설정된 네트워크 ACL이 있습니다.
B. VPC의 개인 서브넷에 NAT 게이트웨이가 배포되어 있지 않습니다.
C. VPC의 기본 보안 그룹은 EC2 인스턴스로의 모든 인바운드 트래픽을 차단합니다.
D. VPC의 기본 보안 그룹은 EC2 인스턴스의 모든 아웃바운드 트래픽을 차단합니다.

프라이빗 서브넷의 인스턴스가 인터넷에 액세스할 수 없는 문제의 원인은 다음과 같습니다:

**A. 개인 서브넷에 모든 아웃바운드 트래픽을 거부하도록 설정된 네트워크 ACL이 있습니다.**

이유는 다음과 같습니다:

- **네트워크 ACL**(Network Access Control List)은 서브넷에 대한 인바운드 및 아웃바운드 트래픽을 제어합니다. 만약 프라이빗 서브넷의 네트워크 ACL이 모든 아웃바운드 트래픽을 차단하도록 설정되어 있다면, 인스턴스는 NAT 게이트웨이를 통해 인터넷에 액세스할 수 없습니다.
- NAT 게이트웨이가 퍼블릭 서브넷에 연결되어 있다 하더라도, 프라이빗 서브넷의 네트워크 ACL이 아웃바운드 트래픽을 차단하면 프라이빗 서브넷의 인스턴스는 외부 인터넷에 접속할 수 없습니다.

다른 옵션들은 해당 문제를 직접적으로 발생시키지 않으며, 특히 기본 보안 그룹은 VPC의 보안 설정으로 인스턴스의 아웃바운드 트래픽을 차단하지 않습니다.

## 질문 #385 *

한 회사가 내부 데이터를 Amazon S3 버킷에 저장합니다. 

S3 버킷 내의 모든 기존 데이터는 Amazon S3 관리 암호화 키(SSE-S3)를 사용한 서버 측 암호화를 사용하여 보호됩니다. S3 버전 관리가 활성화되어 있습니다. SysOps 관리자는 재해 복구를 위해 내부 데이터를 다른 AWS 계정의 다른 S3 버킷으로 복제해야 합니다. 모든 기존 데이터는 소스 S3 버킷에서 대상 S3 버킷으로 복사됩니다.

어떤 복제 솔루션이 가장 운영적으로 효율적일까요?

A. 소스 버킷에 복제 규칙을 추가하고 대상 버킷을 지정합니다. 소스 버킷 소유자가 객체를 복제할 수 있도록 대상 버킷에 대한 버킷 정책을 만듭니다.
B. Amazon EventBridge로 AWS Batch 작업을 예약하여 소스 버킷에서 대상 버킷으로 새 객체를 복사합니다. 대상 계정에서 Batch Operations IAM 역할을 만듭니다.
C. 소스 버킷에 대한 Amazon S3 이벤트 알림을 구성하여 AWS Lambda 함수를 호출하여 새 객체를 대상 버킷에 복사합니다. Lambda 함수에 교차 계정 액세스 권한이 있는지 확인합니다.
D. Amazon EC2 인스턴스에서 예약된 스크립트를 실행하여 소스 버킷에서 대상 버킷으로 새 객체를 복사합니다. EC2 인스턴스의 역할에 교차 계정 액세스 권한을 할당합니다.

가장 운영적으로 효율적인 복제 솔루션은 다음과 같습니다:

**A. 소스 버킷에 복제 규칙을 추가하고 대상 버킷을 지정합니다. 소스 버킷 소유자가 객체를 복제할 수 있도록 대상 버킷에 대한 버킷 정책을 만듭니다.**

이 방법은 Amazon S3의 Cross-Region Replication (CRR) 또는 Same-Region Replication (SRR)을 사용하여 소스 버킷의 모든 기존 객체를 자동으로 복제하는 규칙을 설정하는 방식입니다. 

- **자동화**: 복제 규칙이 설정되면 객체가 업로드되거나 기존 객체가 수정될 때 자동으로 복제됩니다. 이를 통해 운영 효율성을 높일 수 있습니다.
- **보안**: 대상 버킷에 대한 적절한 권한을 설정함으로써 소스 버킷 소유자가 안전하게 객체를 복제할 수 있습니다.
- **버전 관리 지원**: S3 버전 관리가 활성화되어 있으므로, 모든 버전의 객체가 복제될 수 있습니다.

다른 옵션들은 수동으로 작업을 설정하거나 유지 관리가 필요하므로 운영 효율성이 떨어집니다.


## 질문 #386

한 회사에 Amazon EC2 인스턴스에서 실행되는 고성능 컴퓨팅(HPC) 애플리케이션이 있습니다. 이 애플리케이션은 노드 간에 최소 대기 시간과 최대 네트워크 처리량이 필요합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 EC2 인스턴스를 어떻게 배포해야 합니까?
A. 단일 가용성 영역에서 클러스터 배치 그룹을 사용합니다.
B. 여러 가용성 영역에 걸쳐 클러스터 배치 그룹을 사용합니다.
C. 단일 가용성 영역에서 파티션 배치 그룹을 사용합니다.
D. 여러 가용성 영역에 걸쳐 파티션 배치 그룹을 사용합니다.

고성능 컴퓨팅(HPC) 애플리케이션의 최소 대기 시간과 최대 네트워크 처리량 요구 사항을 충족하기 위해 EC2 인스턴스를 배포하려면:

**A. 단일 가용성 영역에서 클러스터 배치 그룹을 사용합니다.**

클러스터 배치 그룹은 동일한 가용성 영역 내에 있는 인스턴스 간의 저지연 및 높은 네트워크 처리량을 제공하는 데 최적화되어 있습니다. 이 배치 그룹은 HPC 애플리케이션의 요구 사항을 충족하는 데 적합하며, 인스턴스 간의 물리적 거리와 네트워크 지연을 최소화하여 성능을 극대화합니다. 

반면, 여러 가용성 영역에 걸쳐 클러스터 배치 그룹을 사용하면 대기 시간과 처리량이 저하될 수 있으므로, 요구 사항에 맞지 않습니다.

## 질문 #387

한 회사에는 자동 확장 그룹의 10개 Amazon EC2 온디맨드 인스턴스로 구성된 플릿에 호스팅된 상태 없는 애플리케이션이 있습니다. 
서비스 요구 사항을 충족하려면 최소 6개의 인스턴스가 필요합니다.

어떤 작업이 애플리케이션의 가동 시간을 가장 비용 효율적으로 유지할까요?

A. 6개 인스턴스의 온디맨드 용량을 갖춘 스팟 플릿을 사용하세요.
B. 최소 6개의 온디맨드 인스턴스, 최대 10개의 온디맨드 인스턴스로 자동 크기 조정 그룹을 업데이트합니다.
C. 최소 1개의 온디맨드 인스턴스, 최대 6개의 온디맨드 인스턴스로 자동 크기 조정 그룹을 업데이트합니다.
D. 대상 용량이 6개인 스팟 플릿을 사용하세요.

애플리케이션의 가동 시간을 가장 비용 효율적으로 유지하기 위한 최적의 선택은 다음과 같습니다:

**B. 최소 6개의 온디맨드 인스턴스, 최대 10개의 온디맨드 인스턴스로 자동 크기 조정 그룹을 업데이트합니다.**

이 방법은 최소 6개의 온디맨드 인스턴스를 보장하여 서비스 요구 사항을 충족하면서도, 최대 10개의 인스턴스까지 확장할 수 있는 유연성을 제공합니다. 온디맨드 인스턴스를 사용함으로써 가동 시간을 보장할 수 있으며, 안정성과 성능을 유지할 수 있습니다. 

스팟 인스턴스를 사용할 경우 비용을 절감할 수 있지만, 스팟 인스턴스는 가용성이 불확실하므로 가동 시간에 영향을 줄 수 있습니다. 따라서 서비스의 가용성이 가장 중요한 경우, 온디맨드 인스턴스 사용이 더 적합합니다.

## 질문 #388 ***

한 회사가 Auto Scaling 그룹에 있는 Linux 기반 Amazon EC2 인스턴스의 플릿에 배포되는 서비스를 개발했습니다. 

이 서비스는 애플리케이션 코드의 오류로 인해 가끔 예기치 않게 실패합니다. 이 회사의 엔지니어링 팀은 서비스 실패의 근본 원인을 해결하는 데 몇 주가 걸릴 수 있다고 판단합니다.

SysOps 관리자는 EC2 인스턴스 중 하나에서 서비스가 충돌하는 경우 복구를 자동화하는 솔루션을 만들어야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요? (두 가지를 선택하세요.)

A. EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. CloudWatch 에이전트를 구성하여 서비스를 모니터링합니다. 서비스 상태 검사가 실패하면 CloudWatch 작업을 다시 시작하도록 설정합니다.
B. EC2 인스턴스에 태그를 지정합니다. AWS Systems Manager Session Manager를 사용하여 태그가 지정된 EC2 인스턴스에 로그인하고 서비스를 다시 시작하는 AWS Lambda 함수를 만듭니다. Lambda 함수가 5분마다 실행되도록 예약합니다.
C. EC2 인스턴스에 태그를 지정합니다. AWS Systems Manager State Manager를 사용하여 AWS-RunShellScript 문서를 사용하는 연결을 만듭니다. 서비스가 실행 중인지 확인하고 서비스가 실행 중이 아니면 서비스를 시작하는 스크립트로 연결 명령을 구성합니다. 대상의 경우 EC2 인스턴스 태그를 지정합니다. 5분마다 연결이 실행되도록 예약합니다.
D. Auto Scaling 그룹의 시작 템플릿에 지정된 EC2 사용자 데이터를 업데이트하여 5분마다 cron 일정에 따라 실행되는 스크립트를 포함합니다. 서비스가 실행 중인지 확인하고 서비스가 실행 중이 아니면 서비스를 시작하도록 스크립트를 구성합니다. 업데이트된 시작 템플릿으로 Auto Scaling 그룹의 모든 EC2 인스턴스를 다시 배포합니다.
E. Auto Scaling 그룹의 시작 템플릿에 지정된 EC2 사용자 데이터를 업데이트하여 서비스가 시작 중에 실행되도록 합니다. 업데이트된 시작 템플릿으로 Auto Scaling 그룹의 모든 EC2 인스턴스를 다시 배포합니다.

서비스 충돌을 자동으로 복구하려면, 다음 두 가지 솔루션을 선택하는 것이 좋습니다:

1. **A. EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. CloudWatch 에이전트를 구성하여 서비스를 모니터링합니다. 서비스 상태 검사가 실패하면 CloudWatch 작업을 다시 시작하도록 설정합니다.**
   - 이 방법은 CloudWatch 에이전트를 통해 서비스 상태를 모니터링하고, 서비스가 충돌했을 때 자동으로 재시작할 수 있도록 설정함으로써 자동 복구를 가능하게 합니다.

2. **D. Auto Scaling 그룹의 시작 템플릿에 지정된 EC2 사용자 데이터를 업데이트하여 5분마다 cron 일정에 따라 실행되는 스크립트를 포함합니다. 서비스가 실행 중인지 확인하고 서비스가 실행 중이 아니면 서비스를 시작하도록 스크립트를 구성합니다. 업데이트된 시작 템플릿으로 Auto Scaling 그룹의 모든 EC2 인스턴스를 다시 배포합니다.**
   - 이 방법은 EC2 인스턴스가 실행될 때마다 서비스를 확인하고, 필요할 경우 서비스를 재시작하는 스크립트를 사용하여 서비스의 가용성을 보장합니다.

이 두 가지 솔루션을 조합하면 서비스 충돌 시 자동으로 복구할 수 있는 견고한 시스템을 구축할 수 있습니다.

## 질문 #389 *

회사의 웹 애플리케이션은 단일 AWS 지역의 Amazon EC2 인스턴스에서 실행됩니다. 

인프라는 가용성 영역(AZ) 장애가 발생하더라도 성능 저하 없이 애플리케이션을 계속 사용할 수 있도록 설계해야 합니다. 최적의 성능을 보장하기 위해 애플리케이션은 항상 최소 12개의 인스턴스를 유지해야 합니다.

가능한 가장 적은 실행 인스턴스로 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 각 AZ에 6개의 인스턴스가 있는 2개의 AZ
B. 각 AZ에 12개의 인스턴스가 있는 2개의 AZ
C. 각 AZ에 4개의 인스턴스가 있는 3개의 AZ
D. 각 AZ에 6개의 인스턴스가 있는 3개의 AZ

최소 12개의 인스턴스를 유지하면서 가용성 영역(AZ) 장애 시에도 성능 저하 없이 애플리케이션을 사용할 수 있도록 하려면, 각 AZ에 6개의 인스턴스를 배치하는 것이 이상적입니다. 이 방식은 가용성 영역 중 하나가 장애를 겪더라도 나머지 가용성 영역에서 총 12개의 인스턴스를 보장할 수 있습니다.

따라서 최적의 솔루션은:

**A. 각 AZ에 6개의 인스턴스가 있는 2개의 AZ**


## 질문 #390 ****

회사에서 Amazon Elastic Block Store(Amazon EBS) 볼륨의 디스크 사용률을 모니터링해야 합니다. 

EBS 볼륨은 Amazon EC2 Linux 인스턴스에 연결되어 있습니다. SysOps 관리자는 디스크 사용률이 80% 이상으로 증가하면 알림을 제공하는 Amazon CloudWatch 알람을 설정해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (세 가지를 선택하세요.)

A. CloudWatchAgentServerPolicy AWS 관리 정책을 포함하는 IAM 역할을 만듭니다. 역할을 인스턴스에 연결합니다.
B. CloudWatchApplicationInsightsReadOnlyAccess AWS 관리 정책을 포함하는 IAM 역할을 만듭니다. 역할을 인스턴스에 연결합니다.
C. AWS Systems Manager 또는 명령줄을 사용하여 CloudWatch 에이전트를 설치하고 시작합니다.
D. IAM 역할을 사용하여 CloudWatch 에이전트를 설치하고 시작합니다. CloudWatchAgentServerPolicy AWS 관리 정책을 역할에 연결합니다.
E. disk_used_percent CloudWatch 지표가 80%보다 클 경우 CloudWatch 알람이 ALARM 상태로 전환되도록 구성합니다.
F. disk_used CloudWatch 지표가 80%보다 크거나 disk_free CloudWatch 지표가 20%보다 작으면 CloudWatch 알람이 ALARM 상태로 전환되도록 구성합니다.

SysOps 관리자가 Amazon EBS 볼륨의 디스크 사용률을 모니터링하고, 디스크 사용률이 80% 이상일 때 알림을 설정하려면 다음 단계를 따를 수 있습니다:

1. **A.** `CloudWatchAgentServerPolicy` AWS 관리 정책을 포함하는 IAM 역할을 만들고, 역할을 인스턴스에 연결합니다.
2. **C.** AWS Systems Manager 또는 명령줄을 사용하여 CloudWatch 에이전트를 설치하고 시작합니다.
3. **E.** `disk_used_percent` CloudWatch 지표가 80%보다 클 경우 CloudWatch 알람이 ALARM 상태로 전환되도록 구성합니다.

이 조합이 디스크 사용률 모니터링을 위해 필요한 구성입니다.


## 질문 #391

전자상거래 회사는 쇼핑 웹사이트에서 인기 있는 제품 쿼리의 메모리 내 캐싱을 위해 Amazon ElastiCache for Redis 클러스터를 사용합니다. 
캐시 제거 정책은 TTL이 설정되었는지 여부에 관계없이 키를 무작위로 제거하는 것입니다. SysOps 관리자는 비용을 증가시키지 않고 캐시 적중률을 개선해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. ElastiCache 클러스터에 다른 노드를 추가합니다.
B. ElastiCache TTL 값을 늘립니다.
C. TTL이 설정된 키를 무작위로 추방하도록 추방 정책을 변경합니다.
D. 가장 자주 사용되지 않는 키를 추방하도록 추방 정책을 변경합니다.

Amazon ElastiCache for Redis에서 캐시 적중률을 개선하려면 무작위로 키를 제거하는 추방 정책을 더 효율적인 정책으로 변경하는 것이 중요합니다. 가장 자주 사용되지 않는 데이터를 제거하는 방식으로 추방 정책을 변경하면, 더 중요한 데이터가 캐시에 남아 캐시 적중률이 향상됩니다.

따라서 가장 적합한 솔루션은:
**D. 가장 자주 사용되지 않는 키를 추방하도록 추방 정책을 변경합니다.**

이렇게 하면 사용되지 않는 데이터가 우선적으로 제거되고, 자주 액세스되는 데이터가 캐시에 유지되어 성능이 개선됩니다.


## 질문 #392

한 회사가 Application Load Balancer(ALB) 뒤의 여러 Amazon EC2 인스턴스에 새로운 웹 애플리케이션을 배포했습니다. 

EC2 인스턴스는 Auto Scaling 그룹에서 실행됩니다. 사용자들은 자주 로그인하라는 메시지가 표시된다고 보고합니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. ALB를 원본으로 하여 Amazon CloudFront 배포를 구성합니다.
B. EC2 인스턴스의 대상 그룹에 대해 스티키 세션(세션 친화성)을 활성화합니다.
C. EC2 인스턴스를 분산된 배치 그룹으로 다시 배포합니다.
D. ALB를 네트워크 로드 밸런서로 교체합니다.

사용자들이 자주 로그인하라는 메시지를 받는 문제는 세션이 여러 인스턴스 간에 공유되지 않기 때문일 수 있습니다. 이를 해결하려면 **스티키 세션(세션 친화성)**을 활성화하여 사용자가 동일한 EC2 인스턴스에 연결되도록 할 수 있습니다. 

따라서 이 문제를 해결하는 방법은:
**B. EC2 인스턴스의 대상 그룹에 대해 스티키 세션(세션 친화성)을 활성화합니다.**

스티키 세션을 사용하면 사용자가 동일한 인스턴스에 유지되어 세션이 중단되지 않으며, 자주 로그인하는 문제를 방지할 수 있습니다.


## 질문 #393 ****

한 회사에는 Amazon S3 버킷에 대용량 데이터 객체를 업로드하는 과학자가 있습니다. 

과학자들은 객체를 멀티파트 업로드로 업로드합니다. 멀티파트 업로드는 종종 최종 클라이언트 연결 상태가 좋지 않아 실패합니다.

이 회사는 데이터와 관련된 스토리지 비용을 최적화하고자 합니다. SysOps 관리자는 불완전한 업로드에 대한 메트릭을 제시하는 솔루션을 구현해야 합니다. 또한 솔루션은 7일 후에 모든 불완전한 업로드를 자동으로 삭제해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. S3 Storage Lens 대시보드에서 Incomplete Multipart Upload Bytes 메트릭을 검토합니다. 7일 후에 모든 불완전한 멀티파트 업로드를 자동으로 삭제하는 S3 라이프사이클 정책을 만듭니다.
B. S3 Intelligent-Tiering을 구현하여 7일 후에 데이터를 저비용 스토리지 클래스로 옮깁니다. S3 Storage Lens 정책을 생성하여 7일 후에 모든 불완전한 멀티파트 업로드를 자동으로 삭제합니다.
C. S3 콘솔에 액세스합니다. 메트릭 탭을 검토하여 완료되지 않은 멀티파트 업로드가 사용하는 스토리지를 확인합니다. 7일 후에 완료되지 않은 멀티파트 업로드를 삭제하는 AWS Lambda 함수를 만듭니다.
D. S3 분석 스토리지 클래스 분석 도구를 사용하여 불완전한 멀티파트 업로드를 식별하고 측정합니다. 7일 후에 불완전한 멀티파트 업로드를 삭제하도록 멀티파트 업로드에 대한 제한을 적용하는 S3 버킷 정책을 구성합니다.


가장 비용 효율적인 솔루션은 다음과 같습니다:

**A. S3 Storage Lens 대시보드에서 Incomplete Multipart Upload Bytes 메트릭을 검토합니다. 7일 후에 모든 불완전한 멀티파트 업로드를 자동으로 삭제하는 S3 라이프사이클 정책을 만듭니다.**

이 솔루션은 다음을 제공합니다:

- **S3 Storage Lens**: 불완전한 멀티파트 업로드에 대한 메트릭을 확인하고 분석할 수 있습니다.
- **S3 라이프사이클 정책**: 불완전한 멀티파트 업로드를 7일 후에 자동으로 삭제하여 스토리지 비용을 절감할 수 있습니다.

이는 데이터 전송 실패 문제와 스토리지 최적화 요구를 해결하는 운영적으로 효율적인 방법입니다.

## 질문 #394 ***

한 회사가 세 개의 별도 AWS 리전에 프로비저닝된 Amazon S3 버킷에 데이터를 저장합니다. 

VPN을 사용하여 공용 인터넷을 통해 S3 버킷에서 데이터 센터로 데이터가 복사됩니다. SysOps 관리자는 가끔 전송이 평소보다 오래 걸리는 것을 알아차리고 문제가 회사 ISP 네트워크 내의 혼잡이라고 판단합니다. 관리자가

S3에서 데이터 센터로의 일관된 전송 시간을 보장하기 위해 취할 수 있는 가장 비용 효율적인 접근 방식은 무엇입니까?

A. 각 리전에 AWS Direct Connect 링크를 설정합니다. 각 링크에 개인 가상 인터페이스를 만듭니다.
B. 각 리전에 AWS Direct Connect 링크를 설정합니다. 각 링크에 퍼블릭 가상 인터페이스를 만듭니다.
C. 리전 중 하나에 AWS Direct Connect 링크를 설정합니다. 해당 링크에서 개인 가상 인터페이스를 만듭니다.
D. 리전 중 하나에 AWS Direct Connect 링크를 설정합니다. 해당 링크에서 퍼블릭 가상 인터페이스를 만듭니다.

회사가 S3에서 데이터 센터로의 전송 시간을 일관되게 보장하기 위해 취할 수 있는 가장 비용 효율적인 접근 방식은 **D. 리전 중 하나에 AWS Direct Connect 링크를 설정하고 해당 링크에서 퍼블릭 가상 인터페이스를 만드는 것**입니다.

이 접근 방식은 단일 리전에 Direct Connect를 설정하여 비용을 절감하고, 퍼블릭 가상 인터페이스를 사용하여 S3와 같은 AWS 퍼블릭 서비스에 직접 연결할 수 있게 합니다. 이렇게 하면 VPN을 사용할 때 발생할 수 있는 인터넷 혼잡 문제를 해결하고 안정적인 전송 시간을 보장할 수 있습니다.

## 질문 #395

한 회사에 프로덕션 시스템을 지원하는 Amazon EC2 인스턴스가 있습니다. 

EC2 인스턴스는 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 백업됩니다. EBS 볼륨의 드라이브가 100% 용량으로 채워져 EC2 인스턴스의 애플리케이션에 오류가 발생합니다.

어떤 솔루션이 가장 짧은 시간 내에 이러한 오류를 해결할 수 있을까요?

A. 추가 드라이브 공간을 추가하여 EBS 볼륨을 수정합니다. EC2 인스턴스에 로그인합니다. 파일 시스템별 명령을 사용하여 파일 시스템을 확장합니다.
B. 기존 EBS 볼륨의 스냅샷을 만듭니다. 스냅샷이 완료되면 EC2 인스턴스와 동일한 가용성 영역에서 스냅샷에서 더 큰 크기의 EBS 볼륨을 만듭니다. 새 EBS 볼륨을 EC2 인스턴스에 연결합니다. 파일 시스템을 마운트합니다.
C. EC2 인스턴스와 동일한 가용성 영역에 더 큰 크기의 새 EBS 볼륨을 만듭니다. EBS 볼륨을 EC2 인스턴스에 연결합니다. 기존 EBS 볼륨에서 새 EBS 볼륨으로 데이터를 복사합니다.
D. EC2 인스턴스를 중지합니다. EC2 인스턴스를 추가 드라이브 공간을 포함하는 더 큰 인스턴스 크기로 변경합니다. EC2 인스턴스를 시작합니다.


가장 빠른 해결책은 **A. 추가 드라이브 공간을 추가하여 EBS 볼륨을 수정**하는 것입니다. 이 방법은 기존 EBS 볼륨의 크기를 즉시 확장하고, EC2 인스턴스에 로그인하여 파일 시스템을 확장하는 파일 시스템별 명령을 사용하는 것입니다. 이 방식은 EC2 인스턴스를 중지하지 않고 수행할 수 있어, 애플리케이션의 다운타임을 최소화하고 오류를 빠르게 해결할 수 있습니다.


## 질문 #396

한 회사에 AWS Organizations의 조직에 있는 여러 멤버 계정이 있습니다. 

이 회사는 최근에 관리자가 계정 루트 사용자 자격 증명을 사용하고 있다는 사실을 발견했습니다. 이 회사는 관리자가 루트 사용자 자격 증명을 사용하여 Amazon EC2 인스턴스에서 어떤 작업도 수행하지 못하도록 해야 합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자는 무엇을 해야 합니까?


A. 각 멤버 계정에서 ID 기반 IAM 정책을 생성하여 루트 사용자가 EC2 인스턴스에서 작업을 수행하지 못하도록 합니다.
B. 조직의 관리 계정에서 모든 구성원 계정의 루트 사용자가 EC2 인스턴스에 수행하는 작업을 거부하는 서비스 제어 정책(SCP)을 만듭니다.
C. AWS Config를 사용하여 루트 사용자가 EC2 인스턴스에서 어떤 작업도 수행하지 못하도록 합니다.
D. 각 멤버 계정에서 Amazon Inspector를 사용하여 루트 사용자 로그인을 스캔하고 루트 사용자가 EC2 인스턴스에서 어떠한 작업도 수행하지 못하도록 합니다.

이 요구 사항을 충족하기 위해 **B. 조직의 관리 계정에서 모든 구성원 계정의 루트 사용자가 EC2 인스턴스에 수행하는 작업을 거부하는 서비스 제어 정책(SCP)을 만듭니다**가 가장 적합한 솔루션입니다.

### 이유:
- **서비스 제어 정책(SCP)**는 AWS Organizations에서 모든 계정에 걸쳐 AWS 서비스 사용을 제어하는 데 사용됩니다. SCP는 멤버 계정에 적용되며, 루트 사용자 포함 모든 사용자에게 적용됩니다. 이를 통해 조직의 모든 멤버 계정에서 **루트 사용자가 Amazon EC2 인스턴스에서 작업을 수행하는 것을 제한**할 수 있습니다.
- SCP는 **루트 사용자**의 활동을 제한할 수 있는 유일한 방법입니다. IAM 정책은 루트 사용자를 제한할 수 없으며, 각 계정에서 일일이 정책을 설정할 필요가 없는 점에서 SCP가 관리 효율성이 높습니다.

### 다른 옵션의 한계:
- **A. IAM 정책**은 루트 사용자에게 적용되지 않으므로, 루트 사용자의 활동을 제한할 수 없습니다.
- **C. AWS Config**는 리소스의 구성 변경을 모니터링하고 규정 준수를 추적하는 도구로, 루트 사용자 작업을 제한하는 데 직접적인 방법은 아닙니다.
- **D. Amazon Inspector**는 보안 취약성 및 컴플라이언스 문제를 스캔하는 도구로, 루트 사용자 작업을 제한하는 역할을 하지 않습니다.

따라서 **B**가 루트 사용자의 EC2 작업을 제한하는 가장 적절하고 효율적인 방법입니다.


## 질문 #397

한 회사가 Amazon EC2 인스턴스에서 호스팅되는 애플리케이션에서 벗어나고 있습니다. 

이 회사는 Amazon S3, Amazon API Gateway, AWS Lambda, Amazon CloudFront를 사용하는 서버리스 아키텍처를 구현하려고 합니다. 이 전환의 일환으로 이 회사는 EC2 인스턴스가 종료된 후 모든 EC2 인스턴스와 연결되지 않은 Elastic IP 주소를 가지고 있습니다.

SysOps 관리자는 EC2 인스턴스가 종료된 후 남아 있는 모든 연결되지 않은 Elastic IP 주소를 해제하는 프로세스를 자동화해야 합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족할까요?


A. AWS 계정에서 리소스가 변경될 때 자동으로 실행되도록 eip가 연결된 AWS Config 관리 규칙을 활성화합니다. 규칙에 대한 자동 수정을 구성합니다. 수정을 위한 AWS-ReleaseElasticIP AWS Systems Manager Automation 런북을 지정합니다. 수정 권한이 있는 적절한 역할을 지정합니다.

B. EC2 ReleaseAddress API 작업을 호출하고 Elastic IP 주소 AllocationId를 지정하는 사용자 지정 Lambda 함수를 만듭니다. Amazon EventBridge 규칙을 사용하여 Lambda 함수를 호출합니다. 이벤트 소스로 AWS 서비스를 지정하고 이벤트 유형으로 모든 이벤트를 지정하고 대상으로 AWS Trusted Advisor를 지정합니다.


C. Amazon EventBridge 규칙을 만듭니다. 이벤트 소스로 AWS 서비스를 지정하고, 이벤트 유형으로 Instance State-change Notification을 지정하고, 서비스로 Amazon EC2를 지정합니다. 알림에서 Elastic IP 주소를 추출하는 Lambda 함수를 호출합니다. AWS CloudFormation을 사용하여 AllocationId를 입력 매개변수로 지정하여 주소를 해제합니다.

D. EC2 ReleaseAddress API 작업을 호출하고 Elastic IP 주소 AllocationId를 지정하는 사용자 지정 Lambda 함수를 만듭니다. Amazon EventBridge 규칙을 사용하여 Lambda 함수를 호출합니다. 이벤트 소스로 AWS 서비스를 지정하고, 이벤트 유형으로 Instance State-change Notification을 지정하고, 서비스로 Amazon EC2를 지정합니다.

이 요구 사항을 가장 운영적으로 효율적으로 해결할 수 있는 솔루션은 **D. EC2 ReleaseAddress API 작업을 호출하고 Elastic IP 주소 AllocationId를 지정하는 사용자 지정 Lambda 함수를 만듭니다. Amazon EventBridge 규칙을 사용하여 Lambda 함수를 호출합니다. 이벤트 소스로 AWS 서비스를 지정하고, 이벤트 유형으로 Instance State-change Notification을 지정하고, 서비스로 Amazon EC2를 지정합니다**입니다.

### 이유:
- **Lambda 함수**는 특정 작업을 자동화하기에 적합하며, EC2 인스턴스가 종료되었을 때 연결되지 않은 Elastic IP를 자동으로 해제하는 작업을 수행할 수 있습니다.
- **Amazon EventBridge**는 인스턴스 상태 변경 이벤트(Instance State-change Notification)를 트리거로 사용하여 EC2 인스턴스가 종료될 때 Lambda 함수를 호출할 수 있습니다.
- Lambda 함수는 EC2의 **ReleaseAddress API**를 호출하여 Elastic IP를 해제할 수 있으며, 이 과정은 자동으로 수행되므로 운영 효율성이 매우 높습니다.
- **EventBridge**와 **Lambda**의 조합은 확장성이 뛰어나고, 관리 오버헤드가 적습니다.

### 다른 옵션의 한계:
- **A. AWS Config 관리 규칙과 Systems Manager Automation 런북**: 이 방법은 규칙 구성과 자동 수정을 필요로 하지만, Elastic IP 해제를 위한 추가적인 자동화 런북을 설정하는 것은 상대적으로 복잡할 수 있습니다. Lambda 함수와 EventBridge를 사용한 방식이 더 직관적이고 간단합니다.
- **B. Lambda와 Trusted Advisor**: Trusted Advisor는 Elastic IP 사용에 대한 권고를 제공하지만, 그 자체로는 자동화되지 않습니다. Lambda 함수와 EventBridge 규칙이 더 직접적이고 실시간으로 Elastic IP를 해제하는 데 적합합니다.
- **C. CloudFormation과 AllocationId**: CloudFormation은 인프라 관리를 자동화하는 데 좋지만, 이 경우에는 Lambda 함수가 더 단순하고 운영적으로 효율적입니다. CloudFormation 템플릿을 생성하여 Elastic IP를 해제하는 방식은 복잡도를 증가시킬 수 있습니다.

따라서 **D** 솔루션이 가장 간단하고, 운영 효율적이며, 요구 사항을 충족할 수 있는 적합한 방법입니다.

## 질문 #398

한 회사가 Amazon CloudFront를 사용하여 최종 사용자에게 정적 콘텐츠를 제공합니다. 

이 회사의 마케팅 팀은 최근 회사 웹사이트에 150개 이미지에 대한 업데이트를 배포했습니다. 그러나 웹사이트에 일부 새 이미지가 표시되지 않습니다.

SysOps 관리자가 CloudFront 배포의 캐시 설정을 검토합니다. 배포의 기본 TTL은 1주일(604,800초)로 설정되어 있습니다.

SysOps 관리자는 가장 운영 효율적인 방식으로 새 이미지로 캐시를 새로 고치려면 무엇을 해야 합니까?

A. 동일한 출처를 가진 새로운 CloudFront 배포를 만듭니다. 기본 TTL을 1분(60초)으로 설정합니다. Amazon Route 53 DNS 레코드를 전환하여 새 배포를 사용합니다.
B. 마케팅 팀에 새로운 이미지를 다른 위치에 업로드하도록 지시합니다. 새로운 이미지가 업로드되면 웹사이트를 업데이트하여 새로운 이미지를 찾습니다.
C. 마케팅팀의 업데이트에서 새 이미지를 즉시 만료시키기 위해 CloudFront 무효화 요청을 발행합니다.
D. 기존 CloudFront 배포를 업데이트하여 기본 TTL을 1분(60초)으로 재구성합니다. 새 구성을 제출하는 동안 지정된 경로의 객체를 무효화하는 플래그를 포함합니다.


이 문제를 가장 운영 효율적인 방식으로 해결하기 위한 최적의 솔루션은 **C. 마케팅팀의 업데이트에서 새 이미지를 즉시 만료시키기 위해 CloudFront 무효화 요청을 발행합니다**입니다.

### 설명:
- Amazon CloudFront는 기본적으로 객체를 캐시하며, 기본 TTL 설정에 따라 콘텐츠를 유지합니다. 캐시된 콘텐츠가 만료되지 않으면 업데이트된 콘텐츠가 즉시 반영되지 않습니다.
- **CloudFront 무효화 요청**을 통해 특정 파일이나 경로의 캐시를 강제로 새로 고침할 수 있습니다. 이를 통해 새 이미지가 즉시 사용자에게 제공될 수 있습니다.
- 무효화 요청은 **효율적이고 빠른** 해결책으로, 새 이미지를 표시하는 데 필요한 작업량을 최소화하며 다른 캐시 설정을 변경할 필요도 없습니다.

### 다른 옵션의 한계:
- **A. 새로운 CloudFront 배포를 만들고 DNS 레코드를 전환**: 이 방법은 지나치게 복잡하며, 배포를 새로 만드는 작업은 시간과 노력이 많이 필요합니다. 또한 기존 배포를 완전히 대체할 필요는 없습니다.
- **B. 마케팅팀에 새로운 이미지를 다른 위치에 업로드하도록 지시**: 이는 불필요한 작업을 증가시키며, 근본적인 캐싱 문제를 해결하지 못합니다.
- **D. 기존 CloudFront 배포의 TTL을 1분으로 재구성하고 무효화**: TTL을 줄이는 것은 불필요하며, 무효화 요청만으로도 문제를 해결할 수 있습니다. TTL을 낮추면 향후 캐시 효율성이 떨어질 수 있습니다.

따라서 가장 효율적인 해결책은 **C**입니다. CloudFront 무효화 요청으로 새 이미지가 즉시 반영되도록 할 수 있습니다.


## 질문 #399

SysOps 관리자는 회사의 재해 복구 절차를 담당합니다. 

이 회사는 프로덕션 계정에 소스 Amazon S3 버킷이 있으며, 소스에서 비프로덕션 계정의 대상 S3 버킷으로 객체를 복제하려고 합니다. SysOps 관리자는 S3 크로스 리전, 크로스 계정 복제를 구성하여 소스 S3 버킷을 대상 S3 버킷으로 복사합니다. SysOps 관리자가 대상 S3 버킷의 객체에 액세스하려고 하면 액세스 거부 오류가 발생합니다.

어떤 솔루션으로 이 문제를 해결할 수 있을까요?
A. 복제 구성을 수정하여 개체 소유권을 대상 S3 버킷 소유자로 변경합니다.
B. 복제 규칙이 소스 S3 버킷의 모든 객체에 적용되고 단일 접두사로 범위가 지정되지 않았는지 확인하세요.
C. S3 복제 시간 제어(S3 RTC)가 경과하면 요청을 다시 시도합니다.
D. 복제된 객체의 스토리지 클래스가 소스 S3 버킷과 대상 S3 버킷 사이에서 변경되지 않았는지 확인합니다.

이 문제를 해결하기 위한 가장 적합한 솔루션은 **A. 복제 구성을 수정하여 개체 소유권을 대상 S3 버킷 소유자로 변경합니다**입니다.

### 설명:
- Amazon S3의 복제 기능을 사용할 때, 기본적으로 복제된 객체는 소스 버킷의 소유자로 남습니다. 이 경우 대상 S3 버킷에서 복제된 객체에 대한 액세스 권한이 없기 때문에 **액세스 거부 오류**가 발생합니다.
- 복제 구성에서 **`Object Ownership`**을 `Bucket owner preferred`로 설정하면 복제된 객체의 소유권이 대상 버킷의 소유자로 변경되어, 해당 버킷에서 액세스할 수 있습니다.

### 다른 옵션의 한계:
- **B. 복제 규칙이 소스 S3 버킷의 모든 객체에 적용되고 단일 접두사로 범위가 지정되지 않았는지 확인하세요**: 이 옵션은 복제 규칙의 범위와 관련이 있지만, 객체에 대한 액세스 거부 문제를 해결하지는 않습니다.
- **C. S3 복제 시간 제어(S3 RTC)가 경과하면 요청을 다시 시도합니다**: 복제 시간이 문제가 아닌 경우, 이는 액세스 거부 문제를 해결하지 않습니다.
- **D. 복제된 객체의 스토리지 클래스가 소스 S3 버킷과 대상 S3 버킷 사이에서 변경되지 않았는지 확인합니다**: 스토리지 클래스는 액세스 권한과 직접적인 관련이 없으며, 이 문제를 해결하는 데 도움이 되지 않습니다.

따라서 **A** 옵션이 가장 적합한 솔루션입니다.

## 질문 #400

한 회사가 PostgreSQL Multi-AZ DB 클러스터용 Amazon RDS를 실행하고 있습니다. 

이 회사는 AWS CloudFormation 템플릿을 사용하여 기본 크기가 100GB인 데이터베이스를 개별적으로 만듭니다. 이 회사는 매주 월요일에 데이터베이스를 만들고 매주 금요일에 데이터베이스를 삭제합니다.

가끔씩 데이터베이스의 디스크 공간이 부족해져 Amazon CloudWatch 알람이 울립니다. SysOps 관리자는 앞으로 데이터베이스의 디스크 공간이 부족해지는 것을 방지해야 합니다.

어떤 솔루션이 애플리케이션에 최소한의 변경만 가해도 이러한 요구 사항을 충족할 수 있을까요?
A. Amazon Aurora PostgreSQL을 DB 엔진으로 사용하도록 CloudFormation 템플릿을 수정합니다.
B. CloudFormation 템플릿을 수정하여 Amazon DynamoDB를 데이터베이스로 사용합니다. 테이블 생성 중에 스토리지 자동 확장을 활성화합니다.
C. 기존 DB 인스턴스에서 스토리지 자동 크기 조정을 활성화하려면 Cloud Formation 템플릿을 수정합니다.
D. DB 인스턴스 스토리지 공간을 모니터링하기 위해 CloudWatch 알람을 만듭니다. VACUUM 명령을 호출하도록 알람을 구성합니다.

이 요구 사항을 충족하기 위한 가장 적합한 솔루션은 **C. 기존 DB 인스턴스에서 스토리지 자동 크기 조정을 활성화하려면 CloudFormation 템플릿을 수정합니다**입니다.

### 설명:
- **스토리지 자동 크기 조정**을 활성화하면 데이터베이스의 디스크 공간이 부족해지는 문제를 자동으로 해결할 수 있습니다. RDS는 필요에 따라 스토리지를 자동으로 확장하여, 지정된 최대 스토리지 크기까지 사용할 수 있습니다. 이를 통해 수동으로 스토리지를 조정할 필요가 없어져 관리가 간소화됩니다.
- CloudFormation 템플릿을 수정하는 것은 기존 인프라에 최소한의 변경으로 이루어질 수 있습니다.

### 다른 옵션의 한계:
- **A. Amazon Aurora PostgreSQL을 DB 엔진으로 사용하도록 CloudFormation 템플릿을 수정합니다**: Aurora는 좋은 성능을 제공하지만, 이 변경은 애플리케이션에 더 많은 변경이 필요할 수 있으며, 즉각적인 문제 해결이 아닙니다.
- **B. CloudFormation 템플릿을 수정하여 Amazon DynamoDB를 데이터베이스로 사용합니다**: 이 변경은 데이터베이스 엔진을 완전히 변경하므로, 애플리케이션의 많은 부분을 수정해야 할 수 있습니다.
- **D. DB 인스턴스 스토리지 공간을 모니터링하기 위해 CloudWatch 알람을 만듭니다. VACUUM 명령을 호출하도록 알람을 구성합니다**: VACUUM은 공간을 회수하는 데 도움이 되지만, 근본적인 디스크 공간 부족 문제를 해결하지는 않습니다. 또한, 알람이 울릴 때마다 수동으로 호출하는 것이 번거롭습니다.

따라서 **C** 옵션이 가장 적합한 솔루션입니다.



## 질문 #401

SysOps 관리자가 프로덕션 데이터베이스 사본을 마이그레이션 계정과 공유하려고 합니다. 

프로덕션 데이터베이스는 Amazon RDS DB 인스턴스에 호스팅되고 production-rds-key라는 별칭을 가진 AWS Key Management Service(AWS KMS) 키로 암호화됩니다. SysOps 관리자는 최소한의 관리 오버헤드로 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 프로덕션 계정에서 RDS DB 인스턴스의 스냅샷을 찍습니다. production-rds-key KMS 키의 KMS 키 정책을 수정하여 마이그레이션 계정의 루트 사용자에게 액세스 권한을 부여합니다. 스냅샷을 마이그레이션 계정과 공유합니다.
B. 마이그레이션 계정에서 RDS 읽기 복제본을 만듭니다. KMS 키 정책을 구성하여 production-rds-key KMS 키를 마이그레이션 계정으로 복제합니다.
C. 프로덕션 계정에서 RDS DB 인스턴스의 스냅샷을 찍습니다. 스냅샷을 마이그레이션 계정과 공유합니다. 마이그레이션 계정에서 동일한 별칭을 가진 새 KMS 키를 만듭니다.
D. 네이티브 데이터베이스 툴셋을 사용하여 RDS DB 인스턴스를 Amazon S3로 내보냅니다. 프로덕션 계정과 마이그레이션 계정 간의 교차 계정 액세스를 위한 S3 버킷과 S3 버킷 정책을 만듭니다. 네이티브 데이터베이스 툴셋을 사용하여 Amazon S3에서 새 RDS DB 인스턴스로 데이터베이스를 가져옵니다.


이 문제를 해결하기 위한 가장 적합한 솔루션은 **A. 프로덕션 계정에서 RDS DB 인스턴스의 스냅샷을 찍습니다. production-rds-key KMS 키의 KMS 키 정책을 수정하여 마이그레이션 계정의 루트 사용자에게 액세스 권한을 부여합니다. 스냅샷을 마이그레이션 계정과 공유합니다.**입니다.

### 설명:
1. **스냅샷 찍기**: 프로덕션 데이터베이스의 스냅샷을 생성하여 해당 시점의 데이터베이스 상태를 저장합니다. RDS 스냅샷은 안전하게 공유할 수 있는 방법입니다.
2. **KMS 키 정책 수정**: KMS 키 정책을 수정하여 마이그레이션 계정에 해당 KMS 키에 대한 액세스 권한을 부여하면 마이그레이션 계정에서 암호화된 스냅샷을 사용할 수 있습니다. 이를 통해 프로덕션 데이터베이스에 대한 보안을 유지하면서도 필요한 접근을 허용합니다.
3. **스냅샷 공유**: RDS 스냅샷을 마이그레이션 계정과 공유하여 해당 계정에서 스냅샷을 사용할 수 있도록 합니다.

### 다른 옵션의 한계:
- **B. 마이그레이션 계정에서 RDS 읽기 복제본을 만드는 것**: 읽기 복제본을 만들려면 프로덕션 계정의 데이터베이스 인스턴스에 대한 직접적인 액세스가 필요하므로, 적절한 권한을 설정하는 데 추가적인 복잡성이 발생합니다.
- **C. 스냅샷을 찍고 마이그레이션 계정에서 동일한 별칭을 가진 새 KMS 키를 만드는 것**: 새 KMS 키를 만드는 것은 관리 오버헤드를 증가시키고, 기존 KMS 키와의 연동성 문제를 발생시킬 수 있습니다.
- **D. 네이티브 데이터베이스 툴셋을 사용하여 RDS DB 인스턴스를 S3로 내보내고 가져오는 것**: 이 방법은 추가적인 설정과 관리가 필요하며, 더 복잡한 과정이 될 수 있습니다.

따라서 **A** 옵션이 최소한의 관리 오버헤드로 요구 사항을 충족하는 가장 적합한 솔루션입니다.


## 질문 #402

한 회사가 AWS에서 CI/CD(Continuous Integration and Continuous Delivery) 환경을 호스팅합니다. CI/CD 환경에는 Amazon EC2 인스턴스에 호스팅된 Jenkins 서버가 포함됩니다. 500GB General Purpose SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨이 EC2 인스턴스에 연결됩니다.

디스크 처리량 제한으로 인해 Jenkins 서버는 서버에서 빌드 속도가 느려지는 성능 문제를 보고합니다. EBS 볼륨은 야간 빌드 작업을 수행하는 동안 3,000 IOPS를 유지해야 합니다.

SysOps 관리자가 Amazon CloudWatch에서 서버의 기록을 검사합니다. BurstBalance 메트릭은 야간 빌드 중에 0 값을 가졌습니다. SysOps 관리자는 성능을 개선하고 지속적인 처리량 요구 사항을 충족해야 합니다.

이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?
A. gp2 EBS 볼륨 크기를 500GB에서 1,000GB로 두 배로 늘립니다.
B. 볼륨 유형을 gp2에서 General Purpose SSD(gp3)로 변경합니다.
C. 볼륨 유형을 gp2에서 처리량 최적화된 HDD(st1)로 변경합니다.
D. 볼륨 유형을 gp2에서 Provisioned IOPS SSD(io2)로 변경합니다.

이 문제를 가장 비용 효율적으로 해결하는 방법은 **B. 볼륨 유형을 gp2에서 General Purpose SSD(gp3)로 변경합니다**입니다.

### 설명:
**gp3 EBS 볼륨**은 **gp2**보다 성능을 더 유연하게 설정할 수 있습니다. **gp3** 볼륨은 **기본적으로 3,000 IOPS**를 제공하며, 필요할 경우 비용을 절감하면서도 IOPS와 처리량을 원하는 수준으로 프로비저닝할 수 있습니다. 또한, IOPS와 처리량을 각각 독립적으로 조정할 수 있어, 성능 요구 사항을 충족하는 데 적합합니다.

### 다른 옵션의 한계:
- **A. gp2 EBS 볼륨 크기를 500GB에서 1,000GB로 두 배로 늘립니다**: gp2 볼륨은 크기를 늘리면 IOPS도 증가하지만, 비용이 증가하고 필요한 3,000 IOPS에 도달하기 위해 용량을 더 많이 확보해야 하므로 비효율적입니다.
- **C. st1(처리량 최적화 HDD)로 변경**: st1은 주로 대규모 순차적 읽기/쓰기 작업에 적합하며, Jenkins와 같은 랜덤 액세스 워크로드에는 적합하지 않습니다.
- **D. io2로 변경**: io2는 높은 성능을 제공하지만, 비용이 매우 높아 Jenkins와 같은 워크로드에서 필요 이상으로 성능을 제공할 수 있습니다.

따라서 **gp3로의 변경**이 성능과 비용 측면에서 가장 적합한 선택입니다.

## 질문 #403

한 회사가 애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스 그룹에서 애플리케이션을 실행하고 있습니다. 

EC2 인스턴스는 3개의 가용성 영역에서 실행됩니다. 이 회사는 고객에게 애플리케이션에 대한 최대 2개의 정적 IP 주소를 제공해야 합니다.

SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?

A. Application Load Balancer 앞에 AWS Global Accelerator를 추가합니다.
B. 애플리케이션 로드 밸런서 뒤에 내부 네트워크 로드 밸런서를 추가합니다.
C. 두 개의 가용성 영역에만 애플리케이션 로드 밸런서를 구성합니다.
D. 두 개의 Elastic IP 주소를 생성하여 Application Load Balancer에 할당합니다.

이 요구 사항을 충족하는 가장 적합한 방법은 **A. Application Load Balancer 앞에 AWS Global Accelerator를 추가합니다**입니다.

### 설명:

**AWS Global Accelerator**는 전역 네트워크를 사용하여 사용자의 트래픽을 최적의 AWS 엔드포인트로 라우팅하고, 애플리케이션에 대한 고정된(정적) IP 주소를 제공합니다. 이를 통해 사용자는 Global Accelerator를 통해 최대 2개의 정적 IP 주소를 사용할 수 있으며, 트래픽은 Application Load Balancer(ALB)로 전달됩니다. Global Accelerator는 고가용성과 성능 최적화를 위해 트래픽을 최적의 경로로 전달하며, 이를 통해 ALB와 EC2 인스턴스가 있는 여러 가용성 영역 간에 트래픽을 분산시킬 수 있습니다.

### 다른 옵션의 한계:
- **B. 애플리케이션 로드 밸런서 뒤에 내부 네트워크 로드 밸런서를 추가합니다**: 네트워크 로드 밸런서를 추가하는 것은 이 문제를 해결하지 않으며, 네트워크 로드 밸런서는 주로 낮은 레이턴시의 TCP 트래픽 처리를 위해 사용됩니다.
- **C. 두 개의 가용성 영역에만 애플리케이션 로드 밸런서를 구성합니다**: 가용성 영역을 줄이면 애플리케이션의 고가용성이 저하됩니다. 3개의 가용성 영역을 사용하는 것이 더 안정적입니다.
- **D. 두 개의 Elastic IP 주소를 생성하여 Application Load Balancer에 할당합니다**: Application Load Balancer(ALB)는 Elastic IP 주소를 할당할 수 없습니다. Elastic IP 주소는 네트워크 로드 밸런서(NLB)에만 할당할 수 있습니다.

따라서 **A. AWS Global Accelerator**를 사용하는 것이 이 문제에 대한 최적의 솔루션입니다.

## 질문 #404

SysOps 관리자는 프로덕션 Auto Scaling 그룹이 Amazon EC2 인스턴스 2개로 축소되었다는 알림을 받습니다. Auto Scaling 그룹은 원래 최소 용량이 3개 인스턴스로 구성되었습니다. 그러나 SysOps 관리자는 구성이 이제 최소 용량이 2개 인스턴스임을 확인합니다.

어떤 AWS 서비스가 변경을 한 사람을 식별하는 데 도움이 될까요?
A. AWS 구성
B. 아마존 인스펙터
C. 아마존 메이시
D. Amazon Cloud Watch 로그

이 문제에서 변경을 한 사람을 식별하는 데 가장 적합한 서비스는 **A. AWS Config**입니다.

### 설명:
**AWS Config**는 AWS 리소스의 구성을 추적하고, 변경 사항에 대한 기록을 남기는 서비스입니다. Auto Scaling 그룹의 최소 용량 설정이 변경된 경우, AWS Config를 사용하면 누가 언제 이러한 변경을 했는지 확인할 수 있습니다. 이 서비스는 리소스 변경 내역을 저장하고, 특정 변경 사항의 원인을 분석하는 데 유용합니다.

### 다른 옵션의 한계:
- **B. 아마존 인스펙터**: 애플리케이션 보안 취약성 평가를 위한 서비스이며, Auto Scaling 그룹의 변경 사항을 추적하는 데는 적합하지 않습니다.
- **C. 아마존 메이시**: 민감한 데이터 보호와 관련된 서비스로, 리소스 변경 추적 기능은 제공하지 않습니다.
- **D. Amazon CloudWatch 로그**: 로그를 모니터링하는 데 사용할 수 있지만, 누가 Auto Scaling 그룹의 설정을 변경했는지를 직접 추적하는 기능은 없습니다.

따라서 **A. AWS Config**가 변경한 사람을 식별하는 데 가장 적합한 도구입니다.


## 질문 #405

한 회사가 Amazon S3 버킷에 민감한 재무 데이터를 저장하려고 합니다. 

이 회사는 버킷에 대한 공개 읽기 또는 쓰기 액세스를 허용하지 않는 회사 정책을 가지고 있습니다. SysOps 관리자는 공개 읽기 또는 쓰기 액세스를 허용하는 S3 권한을 자동으로 제거하는 솔루션을 만들어야 합니다.

SysOps 관리자는 이러한 요구 사항을 가장 운영적으로 효율적인 방식으로 충족하기 위해 어떤 AWS 서비스를 사용해야 합니까?

A. AWS 구성
B. AWS 보안 허브
C. AWS 신뢰할 수 있는 고문
D. 아마존 인스펙터

이 문제를 가장 효율적으로 해결할 수 있는 서비스는 **A. AWS Config**입니다.

### 설명:
**AWS Config**는 AWS 리소스의 구성을 추적하고 변경 사항을 기록하며, 미리 정의된 규칙에 따라 리소스가 적절하게 구성되었는지 평가하는 서비스입니다. Amazon S3 버킷의 공개 읽기 또는 쓰기 권한을 모니터링하고, 이러한 권한이 감지되면 자동으로 제거하는 규칙을 설정할 수 있습니다. 또한, AWS Config 규칙을 통해 위반 사항이 발생했을 때 자동으로 시정 작업을 실행할 수도 있습니다.

### 다른 옵션의 한계:
- **B. AWS 보안 허브**: 보안 허브는 AWS 환경 전반에 걸친 보안 상태를 평가하고 권고 사항을 제공하지만, S3 권한에 대한 자동 수정 기능은 제공하지 않습니다.
- **C. AWS 신뢰할 수 있는 고문**: 신뢰할 수 있는 고문은 보안 및 비용에 대한 권장 사항을 제공하지만, 자동으로 S3 버킷 권한을 수정하지는 않습니다.
- **D. 아마존 인스펙터**: 인스펙터는 애플리케이션의 보안 취약성을 검사하는 서비스로, S3 버킷 권한 관리와는 관련이 없습니다.

따라서 **A. AWS Config**가 회사의 요구 사항을 충족하는 가장 적합한 솔루션입니다.


## 질문 #406

SysOps 관리자는 특정 AWS 서비스에 액세스해야 하는 개발자를 위한 IAM 정책을 만들어야 합니다. 요구 사항에 따라 SysOps 관리자는 다음 정책을 만듭니다.


이 정책은 어떤 작업을 허용합니까? (두 가지를 선택하세요.)


A. AWS Storage Gateway를 생성합니다.
B. AWS Lambda 함수에 대한 IAM 역할을 생성합니다.
C. Amazon Simple Queue Service(Amazon SQS) 대기열을 삭제합니다.
D. AWS 로드 밸런서를 설명하세요.
E. AWS Lambda 함수를 호출합니다.



## 질문 #407

SysOps 관리자가 애플리케이션을 재구성하고 있습니다. 

SysOps 관리자는 데이터베이스가 퍼블릭 엔드포인트를 사용하는 퍼블릭 서브넷에서 퍼블릭 네트워크의 액세스를 제한하기 위해 프라이빗 서브넷으로 데이터베이스를 이동했습니다. 이 변경 후 데이터베이스에 대한 읽기 액세스가 필요한 AWS Lambda 함수는 데이터베이스에 연결할 수 없습니다. SysOps 관리자는 보안을 손상시키지 않고 이 문제를 해결해야 합니다.

이러한 요구 사항을 충족하는 솔루션은 무엇입니까?
A. Lambda 함수에 대한 AWS PrivateLink 인터페이스 엔드포인트를 만듭니다. 프라이빗 엔드포인트를 사용하여 데이터베이스에 연결합니다.
B. Lambda 함수를 데이터베이스 VPC에 연결합니다. 프라이빗 엔드포인트를 사용하여 데이터베이스에 연결합니다.
C. Lambda 함수에 데이터베이스에 대한 읽기 권한이 있는 IAM 역할을 연결합니다.
D. 데이터베이스를 퍼블릭 서브넷으로 이동합니다. 보안 그룹을 사용하여 안전한 액세스를 확보합니다.

이 문제를 해결하는 가장 적합한 솔루션은 **B. Lambda 함수를 데이터베이스 VPC에 연결합니다. 프라이빗 엔드포인트를 사용하여 데이터베이스에 연결합니다.**입니다.

### 설명:
1. **Lambda 함수를 VPC에 연결**: Lambda 함수가 데이터베이스가 위치한 프라이빗 서브넷 내의 VPC에 연결되어 있지 않으면 데이터베이스에 접근할 수 없습니다. Lambda 함수를 데이터베이스가 있는 VPC와 프라이빗 서브넷에 연결함으로써 Lambda가 데이터베이스에 직접 접근할 수 있게 됩니다. 이 방법은 보안을 손상시키지 않으면서도 Lambda가 데이터베이스와 안전하게 통신할 수 있게 합니다.

2. **프라이빗 엔드포인트 사용**: 데이터베이스에 퍼블릭 액세스를 허용하지 않기 위해 프라이빗 서브넷에서의 엔드포인트를 사용하여 Lambda 함수가 안전하게 연결되도록 할 수 있습니다.

### 다른 옵션의 한계:
- **A. PrivateLink 인터페이스 엔드포인트를 만드는 것**: AWS PrivateLink는 Lambda 함수가 데이터베이스에 접근할 수 있게 해줄 수 있지만, PrivateLink는 주로 다른 VPC 간 통신을 위한 서비스입니다. 이 시나리오에서는 Lambda와 데이터베이스가 같은 VPC에 있을 가능성이 크므로, VPC에 연결하는 방법이 더 적합합니다.
- **C. Lambda 함수에 IAM 역할을 연결하는 것**: IAM 역할은 Lambda가 데이터베이스에 접근할 권한을 설정하는 데 필요하지만, 네트워크 연결 문제를 해결하지는 못합니다.
- **D. 데이터베이스를 퍼블릭 서브넷으로 이동하는 것**: 데이터베이스를 퍼블릭 서브넷으로 다시 이동하는 것은 보안 측면에서 위험이 있습니다. 프라이빗 서브넷에서 데이터베이스를 유지하는 것이 더 안전합니다.

따라서 **B** 옵션이 보안을 유지하면서 Lambda 함수가 데이터베이스에 연결할 수 있도록 하는 적절한 솔루션입니다.


## 질문 #408

사용자는 상태 저장 웹 애플리케이션에서 일관된 강제 로그아웃을 보고하고 있습니다. 

로그아웃은 15분 애플리케이션 로그아웃 타이머가 만료되기 전에 발생합니다.

웹 애플리케이션은 자동 확장 그룹에 있는 Amazon EC2 인스턴스에서 호스팅됩니다. 인스턴스는 단일 대상 그룹이 있는 애플리케이션 로드 밸런서(ALB) 뒤에서 실행됩니다. ALB는 Amazon CloudFront 배포에서 원점으로 구성됩니다. 세션 선호도(스티키 세션)는 ALB 대상 그룹에서 이미 활성화되어 있으며 기간 기반 쿠키를 사용합니다. 웹 애플리케이션은 자체 애플리케이션 쿠키를 생성합니다.

SysOps 관리자는 로그아웃 문제를 해결하기 위해 어떤 작업 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. ALB 대상 그룹에서 가장 덜 처리된 요청 알고리즘을 변경합니다.
B. CloudFront 배포의 캐시 동작 설정에서 쿠키 전달을 구성합니다.
C. 기간 기반 쿠키의 이름을 AWSALB로 구성합니다.
D. 만료 쿠키 헤더를 사용하도록 ALB를 구성합니다.
E. ALB를 변형하여 애플리케이션 기반 쿠키를 사용합니다.  


사용자가 일관되게 강제 로그아웃되는 문제를 해결하기 위해 가장 적합한 작업 조합은 **B. CloudFront 배포의 캐시 동작 설정에서 쿠키 전달을 구성합니다**와 **E. ALB를 변형하여 애플리케이션 기반 쿠키를 사용합니다**입니다.

### 설명:

1. **B. CloudFront 배포의 캐시 동작 설정에서 쿠키 전달을 구성합니다**:
   - CloudFront가 ALB의 쿠키를 전달하지 않으면 클라이언트의 세션 상태가 제대로 유지되지 않을 수 있습니다. CloudFront가 웹 애플리케이션에서 설정한 쿠키를 원본(EC2 인스턴스)으로 올바르게 전달하도록 구성해야 세션이 지속됩니다.

2. **E. ALB를 변형하여 애플리케이션 기반 쿠키를 사용합니다**:
   - 현재 ALB는 기간 기반 쿠키를 사용하고 있으나, 웹 애플리케이션이 자체 쿠키를 생성하는 경우 **애플리케이션 기반 쿠키**를 사용하는 것이 더 적합할 수 있습니다. 이를 통해 ALB가 애플리케이션의 세션 쿠키를 처리하고 일관된 세션을 유지할 수 있습니다.

### 다른 옵션의 한계:
- **A. ALB 대상 그룹에서 가장 덜 처리된 요청 알고리즘을 변경합니다**: ALB가 "가장 덜 처리된 요청" 알고리즘을 사용해도 쿠키 기반 세션 문제와는 관련이 없습니다.
- **C. 기간 기반 쿠키의 이름을 AWSALB로 구성합니다**: 쿠키 이름을 변경하는 것은 문제 해결에 직접적으로 도움이 되지 않습니다. 문제는 쿠키 전달과 세션 유지와 관련되어 있습니다.
- **D. 만료 쿠키 헤더를 사용하도록 ALB를 구성합니다**: 쿠키 만료 설정은 세션의 지속 시간과 관련이 있지만, 현재 문제는 쿠키가 전달되지 않거나 올바르게 유지되지 않는 것과 관련이 있습니다.

따라서 **B**와 **E**가 가장 적합한 해결책입니다.


## 질문 #409

회사의 소셜 미디어 애플리케이션에는 엄격한 데이터 상주 요구 사항이 있습니다. 이 회사는 Amazon Route 53을 사용하여 애플리케이션에 DNS 서비스를 제공하려고 합니다.

SysOps 관리자는 정의된 AWS 지역 목록으로 요청을 라우팅하는 솔루션을 구현해야 합니다. 라우팅은 사용자의 위치를 ​​기반으로 해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. Route 53 지연 라우팅 정책을 구성합니다.
B. Route 53 다중값 답변 라우팅 정책을 구성합니다.
C. Route 53 지리적 위치 라우팅 정책을 구성합니다.
D. Route 53 IP 기반 라우팅 정책을 구성합니다.

엄격한 데이터 상주 요구 사항을 충족하고 사용자의 위치에 따라 요청을 라우팅하기 위해 가장 적합한 솔루션은 **C. Route 53 지리적 위치 라우팅 정책을 구성합니다.**입니다.

### 설명:
1. **지리적 위치 라우팅 정책**: 이 정책은 사용자의 요청을 특정 지역에 따라 라우팅할 수 있게 해줍니다. 예를 들어, 사용자가 특정 AWS 지역에 위치해 있다면, 그 지역에 있는 리소스로 요청을 보낼 수 있습니다. 이를 통해 데이터 상주 요구 사항을 준수하면서도 사용자에게 최적의 서비스를 제공할 수 있습니다.

2. **다른 옵션의 단점**:
   - **A (지연 라우팅 정책)**: 이 정책은 응답 시간에 기반하여 요청을 라우팅하지만, 위치에 따라 라우팅할 수는 없습니다.
   - **B (다중값 답변 라우팅 정책)**: 이 정책은 여러 IP 주소를 반환할 수 있지만, 위치 기반 라우팅 기능을 제공하지 않습니다.
   - **D (IP 기반 라우팅 정책)**: 이 정책은 사용자의 IP 주소에 따라 요청을 라우팅할 수 있지만, AWS의 지리적 위치 라우팅 정책에 비해 덜 직관적이고 관리가 복잡할 수 있습니다.

따라서 **C. Route 53 지리적 위치 라우팅 정책**이 가장 적합한 솔루션입니다.


## 질문 #410 ++++

한 회사에는 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에서 많은 파일을 읽고 쓰는 Linux Amazon EC2 Spot Instances 클러스터가 있습니다. 

EC2 인스턴스는 자주 시작되고 중지됩니다. EC2 인스턴스가 시작될 때 프로세스의 일부로 EBS 볼륨이 스냅샷에서 복원됩니다.

스냅샷에서 복원된 EBS 볼륨은 예상보다 낮은 초기 성능을 경험하고 있습니다. 회사의 워크로드에는 연결된 EBS 볼륨에서 프로비저닝된 IOPS의 거의 대부분이 필요합니다. EBS 볼륨의 성능이 너무 낮으면 EC2 인스턴스가 워크로드를 지원할 수 없습니다. SysOps 관리자는 EBS 볼륨이 스냅샷에서 복원될 때 예상 성능을 제공하도록 하는 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. 사용되는 스냅샷에 빠른 스냅샷 복원(FSR)을 구성합니다.
B. 각 스냅샷을 암호화되지 않은 EBS 볼륨으로 복원합니다. 성능이 안정화되면 EBS 볼륨을 암호화합니다.
C. 스냅샷을 복원하기 전에 EBS 볼륨을 XFS 파일 시스템으로 포맷합니다.
D. Linux 미리 읽기 버퍼를 1MiB로 늘립니다


Amazon EBS 볼륨이 스냅샷에서 복원될 때 초기 성능 저하 문제를 해결하기 위해 가장 적합한 솔루션은 **A. 사용되는 스냅샷에 빠른 스냅샷 복원(FSR)을 구성합니다.**입니다.

### 설명:
1. **빠른 스냅샷 복원(FSR)**: FSR은 EBS 볼륨이 스냅샷에서 복원될 때 성능을 향상시킬 수 있는 기능입니다. 이를 통해 복원 프로세스가 더 빨라지고, 초기 성능이 향상되어 연결된 EC2 인스턴스가 더 원활하게 작업을 수행할 수 있습니다.

2. **다른 옵션의 단점**:
   - **B**: 암호화되지 않은 EBS 볼륨으로 복원하는 것은 보안에 취약할 수 있으며, 성능을 직접적으로 개선하지 않습니다.
   - **C**: XFS 파일 시스템으로 포맷하는 것은 성능 향상에 직접적으로 기여하지 않습니다. 스냅샷에서 복원할 때 파일 시스템 형식이 성능에 큰 영향을 미치지 않습니다.
   - **D**: 미리 읽기 버퍼 크기를 늘리는 것은 성능을 개선할 수 있지만, 스냅샷에서 복원될 때의 초기 성능 문제를 직접적으로 해결하지 않습니다.

따라서 A 옵션이 스냅샷 복원 시 성능을 개선하는 데 가장 효과적인 방법입니다.


AWS에서의 빠른 스냅샷 복원(Quick Snapshot Restore)은 Amazon Elastic Block Store (EBS) 스냅샷을 기반으로 하여 EC2 인스턴스의 EBS 볼륨을 빠르게 복원하는 기능을 제공합니다. 이 기능은 주로 데이터 보호와 복구를 위한 용도로 사용되며, 스냅샷을 통해 생성된 볼륨을 사용하여 EC2 인스턴스의 상태를 빠르게 복원할 수 있습니다. 다음은 AWS에서 빠른 스냅샷 복원에 대한 주요 내용입니다.

### 1. **기능 개요**

- **스냅샷 생성**: EBS 볼륨의 스냅샷은 데이터를 Amazon S3에 백업합니다. 스냅샷을 생성할 때는 변경된 블록만 저장하여 공간을 절약합니다.
- **빠른 복원**: 스냅샷을 기반으로 새 EBS 볼륨을 생성할 때, 데이터의 복원을 위한 시간을 단축시킵니다. EBS 스냅샷을 사용하여 기존 인스턴스나 새 인스턴스를 위해 볼륨을 신속하게 생성할 수 있습니다.

### 2. **장점**

- **신속한 데이터 복구**: 스냅샷을 사용하여 EBS 볼륨을 빠르게 생성할 수 있으므로 장애가 발생한 경우 신속하게 데이터를 복원할 수 있습니다.
- **비용 효율성**: 스냅샷은 변경된 블록만 저장하기 때문에, 저장 공간을 효율적으로 사용할 수 있습니다.
- **자동화된 워크플로우**: AWS Lambda와 같은 서비스와 통합하여 자동화된 스냅샷 생성 및 복원을 구현할 수 있습니다.

### 3. **복원 과정**

빠른 스냅샷 복원 프로세스는 다음 단계로 이루어집니다.

1. **스냅샷 생성**: 기존 EBS 볼륨의 스냅샷을 생성합니다. 이 스냅샷은 S3에 저장됩니다.
2. **새 EBS 볼륨 생성**: 생성한 스냅샷을 기반으로 새로운 EBS 볼륨을 생성합니다. 이때 스냅샷의 데이터가 사용됩니다.
3. **EC2 인스턴스에 연결**: 생성된 EBS 볼륨을 EC2 인스턴스에 연결하여 데이터에 액세스할 수 있습니다.

### 4. **복원 성능 최적화**

- **가용성 및 성능**: AWS는 스냅샷을 기반으로 볼륨을 생성할 때 성능을 최적화하여 복원 시간을 최소화합니다. EBS의 **Provisioned IOPS** (IO1 또는 IO2 볼륨)와 같은 옵션을 사용하여 복원 성능을 더욱 향상시킬 수 있습니다.
- **Concurrent Snapshots**: 여러 스냅샷을 동시에 복원할 수 있어 복원 작업이 병렬로 수행되어 더욱 빠른 복원이 가능합니다.

### 5. **주의사항**

- **비용**: EBS 스냅샷 및 볼륨 사용에 대한 비용이 발생합니다. 스냅샷을 자주 생성하거나 많은 데이터를 저장하는 경우 비용이 증가할 수 있습니다.
- **복원 시 데이터 일관성**: EBS 스냅샷은 데이터 일관성을 보장하기 위해 반드시 애플리케이션이 일시 중지되거나 적절히 관리된 상태에서 생성해야 합니다.

### 요약

AWS의 빠른 스냅샷 복원 기능은 EBS 스냅샷을 통해 EC2 인스턴스의 데이터 복구를 신속하게 수행할 수 있는 방법입니다. 이를 통해 신속한 데이터 복구와 비용 효율성을 달성할 수 있으며, 자동화된 워크플로우를 통해 관리 부담을 줄일 수 있습니다.



## 질문 #411

한 회사가 최근 프로덕션에 애플리케이션을 배포했습니다. 

프로덕션 환경은 현재 애플리케이션의 웹 애플리케이션과 MariaDB 데이터베이스를 호스팅하는 단일 Amazon EC2 인스턴스에서 실행됩니다. 회사 정책에 따르면 모든 IT 프로덕션 환경은 고가용성이어야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. EC2 인스턴스에서 Amazon RDS for MariaDB Multi-AZ DB 인스턴스로 데이터베이스를 마이그레이션합니다. 여러 가용성 영역에 걸쳐 확장되는 자동 확장 그룹에 있는 EC2 인스턴스에서 애플리케이션을 실행합니다. 로드 밸런서 뒤에 EC2 인스턴스를 배치합니다.
B. EC2 인스턴스에서 Amazon RDS for MariaDB Multi-AZ DB 인스턴스로 데이터베이스를 마이그레이션합니다. AWS Application Migration Service를 사용하여 애플리케이션을 AWS Lambda 함수로 변환합니다. Lambda 함수에 대해 Multi-AZ 옵션을 지정합니다.
C. 데이터베이스를 다른 가용성 영역의 다른 EC2 인스턴스로 복사합니다. AWS Backup을 사용하여 애플리케이션 EC2 인스턴스와 데이터베이스 EC2 인스턴스의 Amazon Machine Images(AMI)를 만듭니다. 1분마다 상태 검사를 수행하는 AWS Lambda 함수를 만듭니다. 실패 시 AWS Backup이 만든 AMI에서 새 EC2 인스턴스를 시작하도록 Lambda 함수를 구성합니다.
D. 데이터베이스를 다른 EC2 인스턴스로 마이그레이션합니다. 여러 가용성 영역에 걸쳐 확장되는 자동 확장 그룹에 애플리케이션 EC2 인스턴스를 배치합니다. 데이터베이스 EC2 인스턴스에서 Amazon Machine Image(AMI)를 만듭니다. AMI를 사용하여 다른 가용성 영역에서 두 번째 데이터베이스 EC2 인스턴스를 시작합니다. 두 번째 데이터베이스 EC2 인스턴스를 중지 상태로 만듭니다. 두 번째 데이터베이스 EC2 인스턴스를 대기로 사용합니다.


고가용성 요구 사항을 충족하기 위해 SysOps 관리자가 수행해야 할 가장 적절한 조치는 **A. EC2 인스턴스에서 Amazon RDS for MariaDB Multi-AZ DB 인스턴스로 데이터베이스를 마이그레이션합니다. 여러 가용성 영역에 걸쳐 확장되는 자동 확장 그룹에 있는 EC2 인스턴스에서 애플리케이션을 실행합니다. 로드 밸런서 뒤에 EC2 인스턴스를 배치합니다.**입니다.

### **이유:**

1. **Amazon RDS for MariaDB Multi-AZ:** 
   - Multi-AZ 배포는 자동으로 장애 조치(failover)를 지원하여, 한 가용성 영역(AZ)에 문제가 발생할 경우 다른 AZ로 즉시 전환할 수 있게 해줍니다. 이를 통해 데이터베이스의 가용성을 높이고 유지 관리 작업 중에도 애플리케이션의 가용성을 유지할 수 있습니다.

2. **자동 확장 그룹:** 
   - 자동 확장 그룹을 사용하면 여러 AZ에 걸쳐 EC2 인스턴스를 실행하여 수요에 따라 인스턴스를 자동으로 추가하거나 제거할 수 있습니다. 이는 트래픽 증가에 대응하고, 인스턴스 중 하나가 실패할 경우 다른 인스턴스가 계속해서 서비스를 제공할 수 있도록 합니다.

3. **로드 밸런서:** 
   - 로드 밸런서를 사용하면 여러 EC2 인스턴스에 트래픽을 분산시켜 애플리케이션의 가용성을 높이고 성능을 개선합니다. 로드 밸런서는 인스턴스가 실패할 경우 트래픽을 다른 인스턴스로 자동으로 리디렉션하여 다운타임을 최소화합니다.

### **다른 옵션 분석:**

- **B. AWS Application Migration Service를 사용하여 애플리케이션을 AWS Lambda 함수로 변환합니다. Lambda 함수에 대해 Multi-AZ 옵션을 지정합니다.**
  - Lambda는 서버리스 환경에서 잘 작동하지만, 기존 웹 애플리케이션을 Lambda로 변환하는 것은 복잡할 수 있으며, 다수의 트래픽을 처리하는 데 제한이 있을 수 있습니다.

- **C. 데이터베이스를 다른 가용성 영역의 다른 EC2 인스턴스로 복사합니다. AWS Backup을 사용하여 애플리케이션 EC2 인스턴스와 데이터베이스 EC2 인스턴스의 AMI를 만듭니다.**
  - 이 방법은 비효율적이며, 장애 조치(failover) 자동화가 부족합니다. 데이터베이스의 고가용성을 보장하지 못합니다.

- **D. 데이터베이스를 다른 EC2 인스턴스로 마이그레이션합니다. 여러 가용성 영역에 걸쳐 확장되는 자동 확장 그룹에 애플리케이션 EC2 인스턴스를 배치합니다.**
  - EC2 인스턴스 간의 데이터베이스 복제는 더 복잡하고 수동 작업이 필요하며, 자동화된 장애 조치가 지원되지 않습니다.

결론적으로, **A** 옵션이 고가용성을 확보하는 가장 효과적인 방법입니다.



## 질문 #412

회사가 온프레미스와 AWS에서 워크로드를 실행하고 있습니다. 

SysOps 관리자는 AWS 서비스를 사용하여 온프레미스의 모든 서버에서 작업을 자동화해야 합니다. SysOps 관리자는 온프레미스 서버에 장기 자격 증명을 설치해서는 안 됩니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. AWS Systems Manager 권한을 포함하는 IAM 역할 및 인스턴스 프로필을 만듭니다. 역할을 온프레미스 서버에 연결합니다.
B. AWS Systems Manager에서 관리형 인스턴스 활성화를 만듭니다. 온프레미스 서버에 Systems Manager Agent(SSM Agent)를 설치합니다. 인스턴스 활성화의 활성화 코드와 ID로 서버를 등록합니다.
C. 적절한 AWS Systems Manager 권한을 포함하는 AWS 관리형 IAM 정책을 만듭니다. IAM 정책을 온프레미스 서버로 다운로드합니다.
D. IAM 사용자와 액세스 키를 만듭니다. 온프레미스 서버에 로그인하고 AWS CLI를 설치합니다. AWS CLI가 성공적으로 설치된 후 AWS 자격 증명 파일에서 액세스 키를 구성합니다.


온프레미스 서버에서 AWS 서비스를 사용하여 작업을 자동화하면서 장기 자격 증명을 설치하지 않으려면 **B. AWS Systems Manager에서 관리형 인스턴스 활성화를 만듭니다. 온프레미스 서버에 Systems Manager Agent(SSM Agent)를 설치합니다. 인스턴스 활성화의 활성화 코드와 ID로 서버를 등록합니다.**가 가장 적합한 해결책입니다.

### **이유:**

1. **SSM Agent 설치:** SSM Agent를 온프레미스 서버에 설치하면 AWS Systems Manager를 통해 해당 서버를 관리할 수 있습니다. 이 에이전트는 AWS와의 통신을 위한 필요한 기능을 제공합니다.

2. **관리형 인스턴스 활성화:** 관리형 인스턴스 활성화는 온프레미스 서버를 AWS Systems Manager에 등록할 수 있는 방법을 제공하며, 이 과정에서 장기 자격 증명을 설치할 필요가 없습니다.

3. **IAM 역할 필요 없음:** 이 접근 방식은 온프레미스 서버에 IAM 역할을 직접 연결할 필요가 없으므로 장기 자격 증명 문제를 피할 수 있습니다. 대신 활성화 코드를 사용하여 서버를 등록합니다.

### **다른 옵션 분석:**

- **A. AWS Systems Manager 권한을 포함하는 IAM 역할 및 인스턴스 프로필을 만듭니다. 역할을 온프레미스 서버에 연결합니다.**
  - 온프레미스 서버에 IAM 역할을 직접 연결할 수 없기 때문에 이 옵션은 적합하지 않습니다.

- **C. 적절한 AWS Systems Manager 권한을 포함하는 AWS 관리형 IAM 정책을 만듭니다. IAM 정책을 온프레미스 서버로 다운로드합니다.**
  - IAM 정책을 다운로드하는 것은 효과적이지 않으며, 서버에 장기 자격 증명을 설치해야 할 수 있습니다.

- **D. IAM 사용자와 액세스 키를 만듭니다. 온프레미스 서버에 로그인하고 AWS CLI를 설치합니다. AWS CLI가 성공적으로 설치된 후 AWS 자격 증명 파일에서 액세스 키를 구성합니다.**
  - 이 방법은 액세스 키를 사용해야 하므로, 장기 자격 증명을 설치해야 하는 단점이 있습니다.

결론적으로, **B** 옵션이 장기 자격 증명을 피하면서 온프레미스 서버를 AWS Systems Manager에 통합할 수 있는 가장 효과적인 방법입니다.

## 질문 #413

한 회사가 AWS에 애플리케이션을 배포했습니다. 

이 애플리케이션은 Auto Scaling 그룹에 있는 Linux Amazon EC2 인스턴스 플릿에서 실행됩니다. Auto Scaling 그룹은 시작 템플릿을 사용하도록 구성되어 있습니다. 시작 템플릿은 기본 스토리지에 General Purpose SSD(gp3) EBS 볼륨을 사용하는 Amazon Elastic Block Store(Amazon EBS) 지원 EC2 인스턴스를 시작합니다.

SysOps 관리자는 모든 EC2 인스턴스가 동일한 기본 파일을 공유할 수 있도록 하는 솔루션을 구현해야 합니다. 이 솔루션은 또한 데이터가 일관되도록 해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만듭니다. EFS 파일 시스템을 마운트하는 사용자 데이터를 포함하는 새로운 시작 템플릿 버전을 만듭니다. Auto Scaling 그룹을 업데이트하여 새로운 시작 템플릿 버전을 사용하여 새로운 EC2 인스턴스를 순환하고 이전 EC2 인스턴스를 종료합니다.
B. EBS 볼륨에서 다중 연결을 활성화합니다. EBS 볼륨을 마운트하는 사용자 데이터를 포함하는 새 시작 템플릿 버전을 만듭니다. 자동 확장 그룹을 업데이트하여 새 템플릿 버전을 사용하여 새 EC2 인스턴스를 순환하고 이전 EC2 인스턴스를 종료합니다.
C. Auto Scaling 그룹의 모든 EC2 인스턴스에 대해 EBS 볼륨 간 데이터를 동기화하는 Cron 작업을 만듭니다. 인스턴스 시작 중에 수명 주기 후크를 만들어 모든 EC2 인스턴스에서 Cron 작업을 구성합니다. 이전 EC2 인스턴스를 순환합니다.
D. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만드는 새로운 시작 템플릿 버전을 만듭니다. Auto Scaling 그룹을 업데이트하여 새로운 템플릿 버전을 사용하여 새로운 EC2 인스턴스를 순환하고 이전 EC2 인스턴스를 종료합니다.


모든 EC2 인스턴스가 동일한 기본 파일을 공유하고 데이터의 일관성을 보장하기 위한 가장 적합한 솔루션은 다음과 같습니다:

### **A. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만듭니다. EFS 파일 시스템을 마운트하는 사용자 데이터를 포함하는 새로운 시작 템플릿 버전을 만듭니다. Auto Scaling 그룹을 업데이트하여 새로운 시작 템플릿 버전을 사용하여 새로운 EC2 인스턴스를 순환하고 이전 EC2 인스턴스를 종료합니다.**

#### **이유:**

1. **공유 스토리지:** Amazon EFS는 여러 EC2 인스턴스에서 동시에 마운트할 수 있는 파일 시스템으로, 모든 인스턴스가 동일한 파일에 접근할 수 있도록 지원합니다. 이는 파일 기반 애플리케이션에 적합합니다.

2. **데이터 일관성:** EFS는 파일 시스템 수준에서 일관성을 보장하므로, 동시에 여러 인스턴스에서 파일에 대한 읽기 및 쓰기 작업이 안전하게 수행될 수 있습니다.

3. **확장성:** EFS는 자동으로 확장되므로, 데이터의 양이 증가해도 문제없이 사용할 수 있습니다.

4. **단순한 구현:** 사용자 데이터 스크립트를 사용하여 EFS 파일 시스템을 인스턴스에 마운트하는 방법은 간단하며, Auto Scaling 그룹의 인스턴스를 업데이트하는 데 필요한 작업이 적습니다.

### **다른 옵션 분석:**

- **B. EBS 볼륨에서 다중 연결을 활성화:**
  - EBS는 기본적으로 다중 연결을 지원하지 않으며, 여러 인스턴스에서 동시에 사용할 수 없기 때문에 이 옵션은 적합하지 않습니다.

- **C. EBS 볼륨 간 데이터 동기화 Cron 작업:**
  - 이 방법은 수동으로 데이터 동기화를 관리해야 하며, 데이터 일관성을 보장하는 데 어려움이 있습니다. 또한, 인스턴스가 종료되거나 새로 생성될 때마다 동기화가 필요하므로 복잡성이 증가합니다.

- **D. EFS 파일 시스템을 만드는 새로운 시작 템플릿 버전:**
  - 이 옵션은 유사하지만, A 옵션과의 차이점은 EFS 파일 시스템을 마운트하는 방법이 사용자 데이터 스크립트로 포함되어 있다는 점입니다. A 옵션이 더 명확하게 설명하고 있어 더 적합합니다.

결론적으로, **A**가 요구 사항을 가장 잘 충족하는 솔루션입니다.



## 질문 #414

한 회사에 AWS 계정 50개가 있고 각 계정에서 동일한 Amazon VPC를 만들고 싶어합니다.

회사가 앞으로 VPC에 적용하는 모든 변경 사항은 모든 VPC에 구현해야 합니다.

각 계정에서 VPC를 배포하고 업데이트하는 가장 운영 효율적인 방법은 무엇입니까?

A. VPC를 정의하는 AWS CloudFormation 템플릿을 만듭니다. 각 계정에서 AWS Management Console에 로그인합니다. 템플릿에서 스택을 만듭니다.
B. AWS CLI를 사용하여 VPC를 구성하는 셸 스크립트를 만듭니다. 텍스트 파일에서 셸 스크립트에 계정 목록을 제공합니다. 목록의 모든 계정에서 VPC를 만듭니다.
C. VPS를 구성하는 AWS Lambda 함수를 만듭니다. Amazon DynamoDB에 계정 정보를 저장합니다. Lambda에 DynamoDB 테이블에 대한 액세스 권한을 부여합니다. 목록에 있는 모든 계정에서 VPC를 만듭니다.
D. VPC를 정의하는 AWS CloudFormation 템플릿을 만듭니다. 템플릿을 기반으로 AWS CloudFormation StackSet을 만듭니다. 스택 세트를 사용하여 모든 계정에 템플릿을 배포합니다.


50개의 AWS 계정에서 동일한 Amazon VPC를 배포하고 업데이트하는 가장 운영 효율적인 방법은 다음과 같습니다:

### **D. VPC를 정의하는 AWS CloudFormation 템플릿을 만듭니다. 템플릿을 기반으로 AWS CloudFormation StackSet을 만듭니다. 스택 세트를 사용하여 모든 계정에 템플릿을 배포합니다.**

#### **이유:**

1. **자동화 및 효율성:** CloudFormation StackSets를 사용하면 한 번의 작업으로 여러 계정과 여러 리전에 VPC를 배포할 수 있습니다. 이는 50개 계정 각각에 대해 수동으로 스택을 만들 필요가 없으므로 시간과 노력을 절약합니다.

2. **일관성:** StackSets를 사용하면 모든 VPC가 동일한 템플릿에 의해 관리되므로, 구성 변경 사항이 모든 VPC에 일관되게 적용됩니다. 이는 관리의 일관성을 보장합니다.

3. **간편한 업데이트:** VPC에 변경 사항이 필요한 경우, CloudFormation 템플릿을 업데이트하고 StackSets를 통해 모든 계정에 대한 업데이트를 쉽게 배포할 수 있습니다.

4. **정책 관리:** IAM 역할 및 정책을 통해 각 계정에 대한 권한을 중앙에서 관리할 수 있어 보안이 강화됩니다.

### **다른 옵션 분석:**

- **A. AWS CloudFormation 템플릿을 만들고 각 계정에서 스택을 생성.**
  - 이 방법은 수동 작업이 필요하고, 모든 계정에서 동일한 작업을 반복해야 하므로 비효율적입니다.

- **B. AWS CLI를 사용하여 셸 스크립트 작성.**
  - 셸 스크립트를 사용하는 것은 자동화의 한 형태지만, VPC의 구성을 관리하기가 복잡해지고, 계정 간의 일관성을 보장하기 어렵습니다.

- **C. AWS Lambda 함수를 사용하여 VPC 구성.**
  - Lambda를 사용하여 VPC를 생성할 수 있지만, 각 계정에 대한 권한 관리와 구성이 복잡할 수 있습니다. DynamoDB를 통한 계정 정보 관리 또한 불필요하게 복잡해질 수 있습니다.

따라서 **D**가 가장 운영 효율적인 방법입니다.


## 질문 #415

한 회사가 프로덕션 VPC의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 애플리케이션에 대한 클라이언트 연결이 실패합니다. SysOps 관리자가 VPC 흐름 로그를 검사하고 다음 항목을 찾습니다.

2 11112222333 eni-<###> 192.0.2.15 203.0.113.25 10711 443 6 1 40 1418530010 1418530070 REJECT OK

이러한 연결 실패의 가능한 원인은 무엇입니까?

A. 보안 그룹 거부 규칙이 포트 443의 트래픽을 차단하고 있습니다.
B. EC2 인스턴스가 종료되었습니다.
C. 네트워크 ACL이 HTTPS 트래픽을 차단하고 있습니다.
D. VPC에 인터넷 게이트웨이가 연결되어 있지 않습니다.


VPC 흐름 로그에서 제공된 정보를 기반으로, 클라이언트 연결 실패의 원인은 다음과 같습니다:

```
2 11112222333 eni-<###> 192.0.2.15 203.0.113.25 10711 443 6 1 40 1418530010 1418530070 REJECT OK
```

이 로그는 다음과 같은 정보를 포함합니다:

- **REJECT**: 패킷이 거부되었음을 나타냅니다. 이는 보안 그룹이나 네트워크 ACL에서의 거부 규칙 때문일 수 있습니다.
- **소스 IP**: `203.0.113.25` (클라이언트 IP)
- **목적지 IP**: `192.0.2.15` (EC2 인스턴스 IP)
- **목적지 포트**: `443` (HTTPS)

이 정보를 통해 연결 실패의 가능한 원인을 분석하면:

### **A. 보안 그룹 거부 규칙이 포트 443의 트래픽을 차단하고 있습니다.**
- 이 경우, 클라이언트의 요청이 EC2 인스턴스로 들어오는 과정에서 보안 그룹이 해당 요청을 거부했을 가능성이 높습니다. 클라이언트가 포트 443으로 요청을 보내고 있지만, EC2 인스턴스에 설정된 보안 그룹에서 이를 차단하고 있는 것입니다.

### **C. 네트워크 ACL이 HTTPS 트래픽을 차단하고 있습니다.**
- 네트워크 ACL도 인바운드 및 아웃바운드 트래픽을 제어합니다. 만약 ACL이 포트 443에 대해 트래픽을 거부하고 있다면, 클라이언트가 HTTPS를 통해 접근할 수 없게 됩니다. 

### **다른 옵션 분석:**
- **B. EC2 인스턴스가 종료되었습니다.**
  - 만약 EC2 인스턴스가 종료되었다면, 클라이언트는 연결 시도 자체가 실패할 것이므로 "REJECT" 로그가 생성되지 않습니다. 이 경우에는 연결이 아예 이루어지지 않았을 것입니다.

- **D. VPC에 인터넷 게이트웨이가 연결되어 있지 않습니다.**
  - VPC에 인터넷 게이트웨이가 연결되지 않은 경우, EC2 인스턴스가 인터넷과 연결할 수 없지만, 클라이언트가 요청을 시도하면 "REJECT" 로그가 생성되지 않고 연결 시도가 아예 실패할 것입니다.

결론적으로, 가장 가능한 원인은 **A. 보안 그룹 거부 규칙이 포트 443의 트래픽을 차단하고 있습니다.** 이와 함께, **C. 네트워크 ACL이 HTTPS 트래픽을 차단하고 있습니다.** 또한 점검할 필요가 있습니다.


## 질문 #416

미디어 회사가 AWS에서 공개 뉴스 및 비디오 포털을 호스팅합니다. 

이 포털은 프로비저닝된 용량이 있는 Amazon DynamoDB 테이블을 사용하여 Amazon S3 버킷에 저장된 비디오 파일의 인덱스를 유지합니다. 최근 이벤트 동안 수백만 명의 방문자가 뉴스를 보기 위해 포털을 방문했습니다. 트래픽이 증가하면서 DynamoDB 테이블에서 읽기 요청이 제한되었습니다. 포털에 비디오를 표시할 수 없었습니다.

회사의 운영 팀은 수요를 충족하기 위해 일시적으로 프로비저닝된 용량을 수동으로 늘렸습니다. 이 회사는 테이블이 미래에 제한되기 전에 운영 팀에서 알림을 받기를 원합니다. 이 회사는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만들고 운영 팀의 이메일 주소를 SNS 토픽에 구독했습니다. 이 회사는 이러한

요구 사항을 충족하기 위해 다음에 무엇을 해야 합니까?

A. ConsumedReadCapacityUnits 메트릭을 사용하는 Amazon CloudWatch 알람을 만듭니다. 알람 임계값을 DynamoDB 테이블의 프로비저닝된 용량에 가까운 값으로 설정합니다. 알람을 구성하여 SNS 토픽에 알림을 게시합니다.
B. DynamoDB 테이블에서 자동 스케일링을 켭니다. 스케일링 이벤트 중에 SNS 토픽에 알림을 게시하도록 Amazon EventBridge 규칙을 구성합니다.
C. DynamoDB 테이블에 대해 Amazon CloudWatch Logs를 켭니다. DynamoDB의 THROTTLING_EXCEPTION 상태 코드와 패턴이 일치하도록 Amazon CloudWatch 메트릭 필터를 만듭니다. 메트릭에 대한 CloudWatch 알람을 만듭니다. 알림에 대한 SNS 주제를 선택합니다.
D. Amazon CloudWatch Logs에 로그를 저장하도록 애플리케이션을 구성합니다. DynamoDB의 THROTTLING_EXCEPTION 상태 코드와 패턴이 일치하도록 Amazon CloudWatch 메트릭 필터를 만듭니다. 메트릭에 대한 CloudWatch 알람을 만듭니다. 알림에 대한 SNS 주제를 선택합니다.


회사의 운영 팀이 DynamoDB 테이블에서 읽기 요청이 제한되기 전에 알림을 받기를 원하는 경우, 가장 적절한 방법은 다음과 같습니다:

### **A. ConsumedReadCapacityUnits 메트릭을 사용하는 Amazon CloudWatch 알람을 만듭니다. 알람 임계값을 DynamoDB 테이블의 프로비저닝된 용량에 가까운 값으로 설정합니다. 알람을 구성하여 SNS 토픽에 알림을 게시합니다.**

### **이유:**
- **ConsumedReadCapacityUnits 메트릭:** 이 메트릭은 DynamoDB 테이블에서 소모된 읽기 용량 단위를 모니터링합니다. 이 메트릭을 사용하면 운영 팀은 실제로 사용된 읽기 용량을 확인하고, 프로비저닝된 용량에 가까워지거나 이를 초과하기 시작할 때를 감지할 수 있습니다.
- **알람 설정:** 알람을 설정하여 사용량이 특정 임계값(예: 프로비저닝된 용량의 80% 또는 90%)에 도달하면 SNS 토픽에 알림을 게시하도록 구성하면, 운영 팀이 조치를 취할 수 있는 기회를 가질 수 있습니다.

### 다른 옵션 분석:
- **B. DynamoDB 테이블에서 자동 스케일링을 켭니다:** 자동 스케일링을 사용하면 DynamoDB가 수요에 맞춰 용량을 자동으로 조정하지만, 운영 팀에서 알림을 받기 위한 설정이 포함되지 않습니다. 자동 스케일링이 활성화되더라도, 초기 트래픽 증가에 대한 대응을 위한 알림은 필요합니다.
  
- **C. DynamoDB 테이블에 대해 Amazon CloudWatch Logs를 켭니다:** CloudWatch Logs와 메트릭 필터를 사용하는 방법은 다소 복잡하고, THROTTLING_EXCEPTION을 처리하는 대신 직접적으로 사용량을 모니터링하는 것이 더 간단합니다. 이 방법은 읽기 요청의 제한을 초과한 경우에만 알림을 제공합니다.
  
- **D. Amazon CloudWatch Logs에 로그를 저장하도록 애플리케이션을 구성:** 이 방법 역시 복잡성을 증가시키며, 로그를 통해 직접적으로 알림을 설정하기보다는 읽기 용량을 모니터링하는 것이 더 직관적이고 효율적입니다.

따라서 **A** 옵션이 요구 사항을 가장 잘 충족하는 방법입니다.


## 질문 #417

한 회사가 Auto Scaling 그룹의 일부인 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 

이 회사는 인스턴스의 CPU 사용률이 50%를 넘으면 Auto Scaling 그룹이 확장되기를 원합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 Auto Scaling 그룹을 어떻게 구성해야 합니까?

A. 이벤트에 따라 자동 크기 조정 그룹을 확장하도록 구성합니다.
B. 일정에 따라 크기를 조정하도록 자동 크기 조정 그룹을 구성합니다.
C. 수요에 따라 동적으로 확장되도록 자동 크기 조정 그룹을 구성합니다.
D. 예측적 확장을 사용하도록 자동 확장 그룹을 구성합니다.


회사가 Auto Scaling 그룹의 일부인 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행하고 있으며, CPU 사용률이 50%를 넘으면 Auto Scaling 그룹이 확장되기를 원한다면, 다음과 같이 구성해야 합니다:

### **C. 수요에 따라 동적으로 확장되도록 자동 크기 조정 그룹을 구성합니다.**

### **이유:**
- **동적 확장:** 수요에 따라 자동으로 EC2 인스턴스를 추가하거나 제거하는 방식으로, CPU 사용률과 같은 특정 메트릭을 모니터링하여 설정한 임계값(이 경우 50%)을 초과할 때 인스턴스를 자동으로 추가합니다. 이는 효율적인 리소스 사용과 비용 절감을 돕습니다.
- **메트릭 기반 확장:** Auto Scaling 그룹은 CloudWatch 메트릭을 사용하여 EC2 인스턴스의 성능을 모니터링하고, 정의된 임계값을 초과하면 자동으로 인스턴스를 추가하여 수요를 충족합니다.

### 다른 옵션 분석:
- **A. 이벤트에 따라 자동 크기 조정 그룹을 확장하도록 구성:** 이벤트 기반 확장은 특정 이벤트에 응답하여 인스턴스를 추가하는 것이며, CPU 사용률과 같은 메트릭에 기반한 것이 아닙니다.
- **B. 일정에 따라 크기를 조정하도록 자동 크기 조정 그룹을 구성:** 일정 기반 확장은 고정된 시간에 인스턴스를 추가하거나 제거하는 방식으로, 동적인 수요 변화에는 적합하지 않습니다.
- **D. 예측적 확장을 사용하도록 자동 확장 그룹을 구성:** 예측적 확장은 과거의 메트릭을 기반으로 미래의 수요를 예측하여 사전적으로 인스턴스를 추가하는 방식이지만, 현재의 요구 사항에서는 단순히 CPU 사용률을 기준으로 동적으로 확장하는 것이 더 적절합니다.

따라서 **C** 옵션이 요구 사항을 충족하는 가장 효과적인 방법입니다.


## 질문 #418 +++++

회사의 VPC에 기존 IPv4 구성이 있습니다. 

IPv4 구성에는 퍼블릭 서브넷, 프라이빗 서브넷, NAT 게이트웨이, 기본 경로 테이블 및 ACL이 포함됩니다.

회사는 IPv6 CIDR 블록을 VPC에 연결합니다. 회사는 각 기존 서브넷에 IPv6 할당을 추가하고 경로 테이블에 경로를 추가합니다. 회사는 모든 IPv6 트래픽을 허용하도록 ACL을 업데이트합니다.

퍼블릭 서브넷은 예상대로 작동하지만 프라이빗 서브넷은 인터넷 IPv6 연결을 허용하지 않습니다.

SysOps 관리자는 새 IPv6 서브넷에 대한 아웃바운드 전용 연결을 허용하기 위해 무엇을 해야 합니까?

A. 이탈 전용 인터넷 게이트웨이를 구성하고 VPC와 연결합니다. 프라이빗 서브넷과 연결된 경로 테이블에 기본 경로를 만듭니다. 이탈 전용 인터넷 게이트웨이를 가리키도록 기본 경로를 구성합니다.
B. NAT 게이트웨이에서 IPv6 NAT를 켭니다. 프라이빗 서브넷과 연관된 경로 테이블에 기본 경로를 만듭니다. 기본 경로가 NAT 게이트웨이를 가리키도록 구성합니다.
C. 새로운 IPv6 전용 NAT 게이트웨이를 구성합니다. 프라이빗 서브넷과 연관된 경로 테이블에 기본 경로를 만듭니다. IPv6 전용 NAT 게이트웨이를 가리키도록 기본 경로를 구성합니다.
D. 프라이빗 서브넷과 연관된 경로 테이블에 기본 경로를 만듭니다. 기본 경로가 기존 인터넷 게이트웨이를 가리키도록 구성합니다.

프라이빗 서브넷에서 인터넷 IPv6 연결을 허용하려면, AWS VPC의 IPv6 설정을 고려해야 합니다. 주어진 선택지에서 적절한 솔루션은 다음과 같습니다:

### **A. 이탈 전용 인터넷 게이트웨이를 구성하고 VPC와 연결합니다. 프라이빗 서브넷과 연결된 경로 테이블에 기본 경로를 만듭니다. 이탈 전용 인터넷 게이트웨이를 가리키도록 기본 경로를 구성합니다.**

### **이유:** egress-only internet gateway 
- **이탈 전용 인터넷 게이트웨이:** IPv6 주소가 있는 프라이빗 서브넷에서 인터넷에 대한 아웃바운드 전용 연결을 허용하기 위해서는 이탈 전용 인터넷 게이트웨이를 사용해야 합니다. 이는 IPv6 전용 리소스가 인터넷과 통신할 수 있도록 해줍니다.
- **경로 테이블 설정:** 프라이빗 서브넷과 연결된 경로 테이블에 이탈 전용 인터넷 게이트웨이를 가리키는 기본 경로를 추가하면, 프라이빗 서브넷에서 발생하는 IPv6 트래픽이 인터넷으로 나갈 수 있습니다.

### 다른 옵션의 분석:
- **B. NAT 게이트웨이에서 IPv6 NAT를 켭니다:** AWS NAT 게이트웨이는 IPv4 트래픽을 처리하기 위한 것이므로, IPv6 NAT는 지원되지 않습니다.
- **C. 새로운 IPv6 전용 NAT 게이트웨이를 구성:** AWS는 IPv6 전용 NAT 게이트웨이를 제공하지 않습니다. IPv6 트래픽을 위해 NAT 게이트웨이를 사용할 수 없습니다.
- **D. 프라이빗 서브넷과 연관된 경로 테이블에 기존 인터넷 게이트웨이를 가리키도록 구성:** 기존 인터넷 게이트웨이는 IPv4 전용이므로 IPv6 트래픽을 처리할 수 없습니다.

따라서 **A** 옵션이 프라이빗 서브넷에서 IPv6 아웃바운드 연결을 가능하게 하는 가장 적절한 솔루션입니다.


## 질문 #419

한 회사가 세 개의 Amazon EC2 인스턴스에서 작업자 프로세스를 실행합니다. 

인스턴스는 간단한 확장 정책을 사용하도록 구성된 자동 확장 그룹에 있습니다. 인스턴스는 Amazon Simple Queue Service(Amazon SQS) 대기열의 메시지를 처리합니다.

메시지가 증가하는 무작위 기간으로 인해 작업자 프로세스의 성능이 저하됩니다. SysOps 관리자는 증가한 메시지 수를 수용하기 위해 인스턴스를 확장해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?


A. CloudWatch를 사용하여 SQS 대기열에서 가장 오래된 메시지의 대략적인 나이를 계산하는 메트릭 수학 표현식을 만듭니다. 메트릭 수학 표현식에 대한 대상 추적 스케일링 정책을 만들어 자동 스케일링 그룹을 수정합니다.
B. CloudWatch를 사용하여 각 인스턴스의 SQS 대기열에 표시되는 대략적인 메시지 수를 계산하는 메트릭 수학 표현식을 만듭니다. 메트릭 수학 표현식에 대한 대상 추적 확장 정책을 만들어 자동 확장 그룹을 수정합니다.
C. 애플리케이션 로드 밸런서(ALB)를 만듭니다. ALB를 자동 확장 그룹에 연결합니다. ALBRequestCountPerTarget 메트릭에 대한 대상 추적 확장 정책을 만들어 자동 확장 그룹을 수정합니다.
D. 애플리케이션 로드 밸런서(ALB)를 만듭니다. ALB를 자동 확장 그룹에 연결합니다. 자동 확장 그룹에 대한 예약된 확장 정책을 만듭니다.

작업자 프로세스의 성능 저하를 해결하기 위해 인스턴스를 확장해야 할 때, 가장 적합한 솔루션은 다음과 같습니다:

### **B. CloudWatch를 사용하여 각 인스턴스의 SQS 대기열에 표시되는 대략적인 메시지 수를 계산하는 메트릭 수학 표현식을 만듭니다. 메트릭 수학 표현식에 대한 대상 추적 확장 정책을 만들어 자동 확장 그룹을 수정합니다.**

### **이유:**
- **SQS 메시지 수 기반 확장:** SQS 대기열의 메시지 수를 기준으로 인스턴스를 확장하는 것은 시스템이 실제로 처리해야 할 작업량을 반영합니다. 메시지가 증가하면 더 많은 인스턴스가 필요하다는 것을 의미하므로, 이 메트릭을 기반으로 한 자동 확장은 효율적입니다.
- **대상 추적 확장 정책:** 대상 추적 확장 정책을 사용하면, 메트릭이 설정된 임계값을 초과할 때 자동으로 인스턴스를 추가하는 방식으로, 자동 확장이 즉각적이고 효율적으로 수행될 수 있습니다.

### 다른 옵션의 분석:
- **A. 메트릭 수학 표현식으로 오래된 메시지 나이 계산:** 메시지가 오래된 나이를 기반으로 확장하는 것은 간접적이며, 메시지 수의 변화를 즉각적으로 반영하지 않기 때문에 성능 저하 문제를 빠르게 해결하지 못할 수 있습니다.
- **C. ALB를 사용한 요청 수 기반 확장:** ALB는 HTTP(S) 트래픽에 적합하며, SQS 메시지 처리와는 관계가 없기 때문에 이 시나리오에 적합하지 않습니다.
- **D. ALB와 예약된 확장 정책:** 예약된 확장은 특정 시간에만 인스턴스를 추가하는 방식으로, 무작위로 발생하는 메시지 증가에 적절히 대응할 수 없습니다.

따라서 **B** 옵션이 작업자 프로세스의 성능 저하 문제를 해결하고 자동으로 확장할 수 있는 가장 효과적인 방법입니다.

## 질문 #420

한 회사가 VPC의 퍼블릭 서브넷에 NAT 게이트웨이를 만들었습니다. 

VPC에는 Amazon EC2 인스턴스를 포함하는 프라이빗 서브넷도 있습니다. EC2 인스턴스는 NAT 게이트웨이를 사용하여 인터넷에 액세스하여 패치와 업데이트를 다운로드합니다. 이 회사는 NAT 게이트웨이의 탄력적 네트워크 인터페이스에 대한 VPC 흐름 로그를 구성했습니다. 이 회사는 출력을 Amazon CloudWatch Logs에 게시하고 있습니다.

SysOps 관리자는 프라이빗 서브넷의 EC2 인스턴스가 다운로드를 위해 통신하는 상위 5개 인터넷 대상을 식별해야 합니다.

SysOps 관리자는 가장 운영 효율적인 방식으로 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?
A. AWS CloudTrail Insights 이벤트를 활용하여 상위 5개 인터넷 목적지를 파악하세요.
B. Amazon CloudFront 표준 로그(액세스 로그)를 사용하여 상위 5개 인터넷 목적지를 식별합니다.
C. CloudWatch Logs Insights를 사용하여 상위 5개 인터넷 목적지를 파악하세요.
D. Amazon S3에 로그를 게시하도록 흐름 로그를 변경합니다. Amazon Athena를 사용하여 Amazon S3의 로그 파일을 쿼리합니다.

프라이빗 서브넷의 EC2 인스턴스가 다운로드를 위해 통신하는 상위 5개 인터넷 대상을 식별하기 위해 SysOps 관리자가 가장 운영 효율적인 방식으로 수행해야 할 작업은 다음과 같습니다:

### **C. CloudWatch Logs Insights를 사용하여 상위 5개 인터넷 목적지를 파악하세요.**

### **이유:**
- **운영 효율성:** CloudWatch Logs Insights는 로그 데이터를 쿼리하고 분석할 수 있는 강력한 도구로, VPC 흐름 로그와 같은 로그 데이터를 신속하게 분석하는 데 매우 유용합니다. 사용자는 쿼리를 작성하여 로그에서 필요한 정보를 빠르게 추출할 수 있습니다.
- **즉시 사용 가능:** NAT 게이트웨이에 대한 VPC 흐름 로그는 이미 CloudWatch Logs에 게시되고 있으므로, 추가적인 데이터 이동이나 변환 없이 CloudWatch Logs Insights에서 직접 쿼리를 실행하여 상위 5개 인터넷 대상을 쉽게 식별할 수 있습니다.

### 다른 옵션의 분석:
- **A. AWS CloudTrail Insights:** CloudTrail은 API 호출 로그를 기록하며, 네트워크 흐름 로그를 분석하는 데 적합하지 않습니다.
- **B. Amazon CloudFront 표준 로그:** CloudFront는 콘텐츠 전송 네트워크(CDN) 서비스로, NAT 게이트웨이와 직접적인 관련이 없으므로 이 경우 적합하지 않습니다.
- **D. Amazon S3 및 Athena:** S3에 로그를 게시하고 Athena를 사용하는 방법은 가능하지만, 이는 추가적인 설정과 데이터 이동을 포함하며, 이미 CloudWatch Logs에 있는 데이터를 효율적으로 분석하는 것보다 더 복잡합니다.

따라서 **C** 옵션이 가장 운영 효율적인 방식으로 요구 사항을 충족하는 방법입니다.



## 질문 #421

한 회사가 여러 AWS 계정에서 프로덕션 애플리케이션을 관리합니다. 

이 회사는 Amazon Linux 2를 실행하는 Amazon EC2 인스턴스에서 프로덕션 애플리케이션을 호스팅합니다. EC2 인스턴스는 여러 VPC에 분산되어 있습니다. 각 VPC는 ​​프라이빗 DNS에 자체 Amazon Route 53 프라이빗 호스팅 영역을 사용합니다.

계정 A의 VPC는 ​​계정 B의 다른 VPC와 연결된 프라이빗 호스팅 영역에서 프라이빗 DNS 레코드를 확인해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 계정 A에서 모든 EC2 인스턴스의 /etc/resolv.conf 파일을 업데이트하여 계정 B의 VPC에 대한 AWS 제공 기본 DNS 확인자를 가리키는 AWS Systems Manager 문서를 만듭니다.
B. 계정 A에서 계정 B의 개인 호스팅 영역을 계정 A의 개인 호스팅 영역과 연결하는 AWS CloudFormation 템플릿을 만듭니다.
C. 계정 A에서 AWS CLI를 사용하여 VPC 연결 권한을 만듭니다. 연결이 생성되면 계정 B에서 AWS CLI를 사용하여 계정 A의 VPC를 계정 B의 프라이빗 호스팅 영역과 연결합니다.
D. 계정 B에서 AWS CLI를 사용하여 VPC 연결 권한을 만듭니다. 연결이 생성되면 계정 A에서 AWS CLI를 사용하여 계정 B의 VPC를 계정 A의 프라이빗 호스팅 영역과 연결합니다.


계정 A의 VPC가 계정 B의 VPC와 연결된 프라이빗 호스팅 영역에서 프라이빗 DNS 레코드를 확인할 수 있도록 하려면, SysOps 관리자는 다음 단계를 수행해야 합니다:

### **B. 계정 A에서 계정 B의 개인 호스팅 영역을 계정 A의 개인 호스팅 영역과 연결하는 AWS CloudFormation 템플릿을 만듭니다.**

### **이유:**
- **프라이빗 호스팅 영역 연결:** Route 53 프라이빗 호스팅 영역을 서로 다른 AWS 계정의 VPC와 연결하려면 AWS Route 53의 기능을 사용하여 이러한 연결을 설정해야 합니다. CloudFormation 템플릿을 사용하면 이 작업을 자동화하고, 필요한 리소스를 쉽게 배포할 수 있습니다.
- **계정 간 연결:** 계정 A에서 계정 B의 프라이빗 호스팅 영역을 계정 A의 프라이빗 호스팅 영역과 연결함으로써, 계정 A의 EC2 인스턴스가 계정 B의 DNS 레코드에 접근할 수 있습니다.

### 다른 옵션의 분석:
- **A.** `/etc/resolv.conf` 파일을 수동으로 업데이트하는 것은 권장되지 않으며, DNS 확인 문제를 해결하는데 적절한 방법이 아닙니다.
- **C.** AWS CLI를 사용하여 VPC 연결 권한을 설정하는 것은 올바른 접근 방식이지만, 권한을 설정한 후 계정 B에서 계정 A의 프라이빗 호스팅 영역과 연결해야 하므로, 직접적으로 연결할 수 있는 방법은 아닙니다.
- **D.** 계정 B에서 권한을 생성하고 이후에 계정 A에서 연결을 설정하는 것도 가능하지만, **B** 옵션처럼 CloudFormation을 통해 연결을 설정하는 것이 더 효율적입니다.

따라서 **B** 옵션이 요구 사항을 충족하는 올바른 해결책입니다.


## 질문 #422

회사에서 IAM 사용자에게 다음 정책을 첨부했습니다.


다음 중 IAM 사용자에게 허용되는 작업은 무엇입니까?
A. us-east-1 지역의 Amazon RDS DescribeDBInstances 작업
B. testbucket이라는 버킷의 Amazon S3 PutObject 작업
C. us-east-1 지역의 Amazon EC2 DescribeInstances 작업
D. eu-west-1 지역의 Amazon EC2 AttachNetworkInterface 작업


A.


## 질문 #423

회사에 온프레미스 DNS 솔루션이 있으며 example.com의 Amazon Route 53 프라이빗 호스팅 영역에서 DNS 레코드를 확인하려고 합니다. 

이 회사는 온프레미스 네트워크와 VPC 간의 네트워크 연결을 위해 AWS Direct Connect 연결을 설정했습니다. SysOps 관리자는 온프레미스 서버가 example.com 도메인의 레코드를 쿼리할 수 있는지 확인해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 엔드포인트에 보안 그룹을 연결하여 온프레미스 DNS 서버에서 TCP/UDP 포트 53으로 인바운드 트래픽을 허용합니다.
B. Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 엔드포인트에 보안 그룹을 연결하여 TCP/UDP 포트 53에서 온프레미스 DNS 서버로의 아웃바운드 트래픽을 허용합니다.
C. Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 엔드포인트에 보안 그룹을 연결하여 온프레미스 DNS 서버에서 TCP/UDP 포트 53으로 인바운드 트래픽을 허용합니다.
D. Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 엔드포인트에 보안 그룹을 연결하여 TCP/UDP 포트 53에서 온프레미스 DNS 서버로의 아웃바운드 트래픽을 허용합니다.

온프레미스 DNS 서버가 Amazon Route 53 프라이빗 호스팅 영역의 DNS 레코드를 쿼리할 수 있도록 하려면, SysOps 관리자는 다음 단계를 수행해야 합니다:

### **A. Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 엔드포인트에 보안 그룹을 연결하여 온프레미스 DNS 서버에서 TCP/UDP 포트 53으로 인바운드 트래픽을 허용합니다.**

### **이유:**
- **인바운드 엔드포인트:** 온프레미스 DNS 서버가 VPC 내의 Route 53 프라이빗 호스팅 영역에 있는 DNS 레코드를 쿼리하려면, Route 53 Resolver의 인바운드 엔드포인트가 필요합니다. 이 엔드포인트는 외부에서 오는 DNS 쿼리를 수신할 수 있습니다.
- **보안 그룹 설정:** 보안 그룹을 사용하여 온프레미스 DNS 서버에서 오는 TCP 및 UDP 포트 53의 인바운드 트래픽을 허용해야 합니다. 이렇게 하면 온프레미스 DNS 서버가 Route 53 Resolver에 쿼리를 보낼 수 있습니다.

### 다른 옵션의 분석:
- **B.** 아웃바운드 트래픽을 허용하는 설정은 잘못되었습니다. 온프레미스 DNS 서버가 쿼리를 보내고자 할 때는 인바운드 엔드포인트가 필요합니다.
- **C 및 D.** 이들은 Route 53 Resolver의 아웃바운드 엔드포인트를 설정하는 옵션입니다. 아웃바운드 엔드포인트는 VPC에서 온프레미스 DNS 서버로 쿼리를 전달하는 데 사용되지만, 이번 요구 사항에서는 온프레미스 서버가 쿼리를 보내는 것이므로 적합하지 않습니다.

따라서 **A** 옵션이 요구 사항을 충족하는 올바른 해결책입니다.



## 질문 #424

한 회사가 AWS CloudFormation을 사용하여 애플리케이션 인프라를 배포합니다.

최근에 사용자가 실수로 CloudFormation 템플릿에서 데이터베이스의 속성을 변경하고 스택 업데이트를 수행하여 애플리케이션이 중단되었습니다. SysOps 관리자는 DevOps 팀이 인프라를 계속 배포할 수 있도록 배포 프로세스를 수정하는 방법을 결정해야 하지만 특정 리소스에 대한 우발적인 수정은 방지해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. CloudFormation 스택의 변경 사항에 따라 알림을 보내는 AWS Config 규칙을 설정합니다. 그런 다음 AWS Lambda 함수는 스택을 설명하여 보호된 리소스가 수정되었는지 확인하고 작업을 취소할 수 있습니다.
B. 모든 CloudFormation API 호출에 따라 시작할 규칙이 있는 Amazon EventBridge 이벤트를 설정합니다. 그런 다음 AWS Lambda 함수는 스택을 설명하여 보호된 리소스가 수정되었는지 확인하고 작업을 취소할 수 있습니다.
C. Update:* 작업으로 모든 리소스를 명시적으로 허용하고 보호된 리소스를 명시적으로 거부하는 스택 정책을 사용하여 CloudFormation 템플릿을 시작합니다.
D. 보호된 리소스의 특정 Amazon 리소스 이름(ARN)을 기반으로 하는 조건을 사용하여 CloudFormation 스택이 업데이트되지 않도록 하는 IAM 정책을 DevOps 팀 역할에 연결합니다.


우발적인 수정으로부터 특정 리소스를 보호하기 위한 가장 적절한 솔루션은 다음과 같습니다:

### **C. Update:* 작업으로 모든 리소스를 명시적으로 허용하고 보호된 리소스를 명시적으로 거부하는 스택 정책을 사용하여 CloudFormation 템플릿을 시작합니다.**
- 이 접근 방식은 CloudFormation 스택의 특정 리소스에 대해 명시적으로 업데이트를 거부하는 정책을 적용합니다. 이를 통해 DevOps 팀은 나머지 인프라를 계속 업데이트할 수 있지만, 보호된 리소스는 변경할 수 없도록 안전하게 유지됩니다. 이 방법은 CloudFormation 스택 정책을 사용하여 구현할 수 있습니다.

### 추가 설명:
- **A, B:** AWS Config 규칙이나 EventBridge를 통해 변경 사항을 감지하고 작업을 취소하는 방법은 효과적일 수 있지만, 이 방법은 사후 대응 방식이며, 즉각적인 보호가 제공되지 않습니다.
- **D:** IAM 정책을 사용하는 방법은 리소스 업데이트를 방지할 수 있지만, DevOps 팀이 인프라를 계속 배포하는 데 필요한 유연성을 제한할 수 있습니다.

따라서 **C** 옵션이 가장 적합한 해결책입니다.


## 질문 #425

SysOps 관리자는 us-west-2에 있는 회사의 기존 인프라에 대한 AWS CloudFormation 템플릿을 가지고 있습니다. 관리자는 이 템플릿을 사용하여 eu-west-1에서 새 스택을 시작하려고 하지만 스택이 일부만 배포되고 오류 메시지를 받은 다음 롤백됩니다.

이 템플릿이 배포에 실패하는 이유는 무엇입니까? (두 가지를 선택하세요.)
A. 템플릿은 eu-west-1에서 사용할 수 없는 IAM 사용자를 참조했습니다.
B. 템플릿은 eu-west-1에서 사용할 수 없는 Amazon Machine Image(AMI)를 참조했습니다.
C. 템플릿에는 리소스를 배포하는 데 필요한 적절한 수준의 권한이 없습니다.
D. 템플릿은 eu-west-1에 존재하지 않는 서비스를 요청했습니다.
E. CloudFormation 템플릿은 기존 서비스를 업데이트하는 데만 사용할 수 있습니다.


스택 배포 실패의 원인은 다음 두 가지일 수 있습니다:

### **B. 템플릿은 eu-west-1에서 사용할 수 없는 Amazon Machine Image(AMI)를 참조했습니다.**
- 특정 AWS 리전에서는 사용 가능한 AMI 목록이 다르기 때문에, 템플릿이 특정 리전에서 사용할 수 없는 AMI를 참조하는 경우 배포가 실패할 수 있습니다.

### **D. 템플릿은 eu-west-1에 존재하지 않는 서비스를 요청했습니다.**
- 각 AWS 리전은 특정 서비스 및 리소스를 지원하며, 템플릿에서 요청한 서비스가 eu-west-1 리전에서 사용할 수 없는 경우에도 배포가 실패할 수 있습니다.

이 두 가지가 오류 메시지를 유발하여 스택이 롤백되는 주요 원인입니다. 나머지 옵션들도 배포 실패와 관련이 있을 수 있지만, 주로 특정 리전에서의 리소스 가용성과 관련된 문제입니다.


## 질문 #426

애플리케이션은 파일 시스템 인터페이스를 통해 데이터에 액세스합니다. 애플리케이션은 여러 가용성 영역의 Amazon EC2 인스턴스에서 실행되며, 모두 동일한 데이터를 공유해야 합니다. 현재 데이터 양은 적지만, 회사는 애플리케이션 수명 동안 수십 테라바이트로 증가할 것으로 예상합니다.

이 요구 사항을 충족하는 가장 확장 가능한 스토리지 솔루션은 무엇입니까?

A. 대규모 Amazon EBS 볼륨을 여러 인스턴스에 연결하고 스냅샷을 예약합니다.

B. VPC에 Amazon EFS를 배포하고 여러 서브넷에 마운트 대상을 만듭니다.

C. EC2 인스턴스를 시작하고 SMB/CIFS 또는 NFS를 사용하여 데이터를 공유합니다.

D. Amazon EC2에 AWS Storage Gateway 캐시 볼륨을 배포합니다.


이 요구 사항을 충족하는 가장 확장 가능한 스토리지 솔루션은 다음과 같습니다:

### **B. VPC에 Amazon EFS를 배포하고 여러 서브넷에 마운트 대상을 만듭니다.**

**이유:**
- **Amazon EFS (Elastic File System)**는 여러 EC2 인스턴스에서 동시에 액세스할 수 있는 파일 시스템을 제공합니다. 이는 파일 시스템 인터페이스를 통해 데이터에 액세스하는 애플리케이션에 적합합니다.
- EFS는 자동으로 확장되며, 수십 테라바이트에 이르는 데이터의 증가를 처리할 수 있습니다.
- EFS는 다중 가용성 영역에 걸쳐 분산되어 있어 가용성과 내구성이 뛰어나며, 인스턴스가 서로 다른 AZ에 위치해 있어도 데이터 공유가 가능합니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

- **A. 대규모 Amazon EBS 볼륨**: EBS는 단일 EC2 인스턴스에 연결될 수 있으며, 여러 인스턴스에서 공유할 수 없으므로 데이터 공유 요구 사항에 부합하지 않습니다.
  
- **C. EC2 인스턴스를 시작하고 SMB/CIFS 또는 NFS를 사용하여 데이터 공유**: 이 방법은 관리 오버헤드가 크고, 확장성이 제한적입니다. 여러 인스턴스에서의 공유를 위해 추가적인 설정이 필요합니다.

- **D. AWS Storage Gateway 캐시 볼륨**: 이 솔루션은 온프레미스 환경과 클라우드 간의 데이터 전송을 위해 주로 사용되며, EC2 인스턴스 간의 파일 공유 요구 사항에 적합하지 않습니다.

## 질문 #427

한 회사가 프랑스에 위치한 AWS 리전에 전자상거래 애플리케이션을 배포하고 있습니다. 이 회사는 프랑스에 있는 사용자만 애플리케이션의 첫 번째 버전에 액세스할 수 있기를 원합니다. 이 회사는 다음 버전의 애플리케이션에 더 많은 국가를 추가할 계획입니다. SysOps 관리자는 Amazon Route 53에서 라우팅 정책을 구성해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. 지리적 근접성 라우팅 정책을 사용합니다. 레코드에서 위치로 프랑스를 선택합니다.
B. 지리적 위치 라우팅 정책을 사용합니다. 레코드에서 위치로 프랑스를 선택합니다.
C. IP 기반 라우팅 정책을 사용합니다. 기록에서 프랑스에 할당된 모든 IP 주소를 선택하세요.
D. 지리적 근접성 라우팅 정책을 사용합니다. 기록에서 프랑스에 할당된 모든 IP 주소를 선택하세요.


이 회사의 요구 사항을 충족하기 위해 가장 적합한 Amazon Route 53 라우팅 정책은 다음과 같습니다:

### **B. 지리적 위치 라우팅 정책을 사용합니다. 레코드에서 위치로 프랑스를 선택합니다.**

- **지리적 위치 라우팅 정책**은 사용자의 IP 주소를 기반으로 요청을 처리하여, 특정 국가 또는 지역에 있는 사용자에게 트래픽을 라우팅할 수 있습니다. 따라서 프랑스에 위치한 사용자만 애플리케이션의 첫 번째 버전에 액세스할 수 있도록 설정할 수 있습니다. 이 설정은 향후 다른 국가를 추가할 때도 유용하게 확장할 수 있습니다.

**지리적 근접성 라우팅 정책**은 일반적으로 두 리전 간의 지리적 거리와 응답 시간에 따라 트래픽을 라우팅하는 데 사용되며, 이 경우에는 요구 사항에 적합하지 않습니다.


## 질문 #428

SysOps 관리자가 IAM 자격 증명을 사용하여 DOC-EXAMPLE-BUCKET이라는 고객의 Amazon S3 버킷에 파일을 업로드하려고 합니다. SysOps 관리자가 AccessDenied 메시지를 받고 있습니다.

어떤 구성 변경 조합이 이 문제를 해결할 수 있을까요? (두 가지를 선택하세요.)
A. SysOps 관리자 사용자에게 이 IAM 정책을 추가합니다.
```yaml
{
   "verstion":"2012-10-17",
   "statement":[
      {
         "sid":"AllowAccess",
         "Effect":"Allow",
         "Action":"s3:PutObject",
         "Resource":"arn:aws:s3:::DOC-EXAMPLE-BUCKET"
      }
   ]
}
```
B. 고객 S3 버킷에 이 IAM 정책을 추가합니다
```yaml
{
   "verstion":"2012-10-17",
   "statement":[
      {
         "sid":"AllowAccess",
         "Effect":"Allow",
         "Principal":{"AWS":"ardn:aws:iam<number>:root"}
         "Action":"s3:PutObject",
         "Resource":"arn:aws:s3:::DOC-EXAMPLE-BUCKET"
      }
   ]
}
```

C. SysOps 관리자 사용자에게 이 IAM 정책을 추가합니다.

D. 고객 계정 루트 사용자에게 이 IAM 정책을 추가합니다.

E. 이 IAM 정책을 SysOps 관리자 계정 루트 사용자에게 추가합니다.




SysOps 관리자가 Amazon S3 버킷에 파일을 업로드할 수 있도록 하기 위해 필요한 구성 변경 조합은 다음과 같습니다:

### **A. SysOps 관리자 사용자에게 이 IAM 정책을 추가합니다.**

- SysOps 관리자의 IAM 사용자에게 S3 버킷에 대한 적절한 권한을 부여하는 IAM 정책을 추가하여 파일 업로드를 허용할 수 있습니다.

### **B. 고객 S3 버킷에 이 IAM 정책을 추가합니다.**

- 고객의 S3 버킷 정책에 SysOps 관리자가 해당 버킷에 파일을 업로드할 수 있는 권한을 추가하여 문제를 해결할 수 있습니다. 이 정책은 특정 IAM 사용자 또는 역할에게 필요한 권한을 명시적으로 부여합니다.

이 두 가지 구성 변경은 SysOps 관리자가 DOC-EXAMPLE-BUCKET이라는 S3 버킷에 파일을 성공적으로 업로드할 수 있도록 필요한 권한을 제공합니다.



## 질문 #429

한 회사가 AWS Organizations를 사용하여 여러 AWS 계정에서 여러 애플리케이션을 호스팅합니다. 여러 팀이 AWS 계정에서 애플리케이션의 인프라를 구축하고 유지 관리할 책임이 있습니다.

SysOps 관리자는 사용자 계정과 권한이 중앙에서 관리되도록 솔루션을 구현해야 합니다. 솔루션은 회사의 기존 온프레미스 Active Directory 환경과 통합되어야 합니다. SysOps 관리자는 이미 AWS IAM Identity Center(AWS Single Sign-On)를 활성화하고 AWS Direct Connect 연결을 설정했습니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?
A. Simple AD 도메인을 만들고 온프레미스 Active Directory 도메인과 포리스트 신뢰 관계를 설정합니다. Simple AD 도메인을 IAM Identity Center의 ID 소스로 설정합니다. 필요한 역할 기반 권한 집합을 만듭니다. 각 사용자 그룹을 그룹이 관리할 AWS 계정에 할당합니다.
B. 온프레미스 Active Directory 도메인에 가입된 Amazon EC2 인스턴스에서 Active Directory 도메인 컨트롤러를 만듭니다. Active Directory 도메인 컨트롤러를 IAM Identity Center의 ID 소스로 설정합니다. 필요한 역할 기반 권한 집합을 만듭니다. 각 사용자 그룹을 그룹이 관리할 AWS 계정에 할당합니다.
C. 온프레미스 Active Directory 도메인과 연결된 AD 커넥터를 만듭니다. AD 커넥터를 IAM Identity Center의 ID 소스로 설정합니다. 필요한 역할 기반 권한 집합을 만듭니다. 각 사용자 그룹을 그룹이 관리할 AWS 계정에 할당합니다.
D. IAM Identity Center의 ID 소스로 내장 SSO 디렉터리를 사용합니다. 온프레미스 Active Directory 도메인에서 사용자와 그룹을 복사합니다. 필요한 역할 기반 권한 집합을 만듭니다. 그룹이 관리할 AWS 계정에 각 사용자 그룹을 할당합니다.


이 회사의 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **C. 온프레미스 Active Directory 도메인과 연결된 AD 커넥터를 만듭니다. AD 커넥터를 IAM Identity Center의 ID 소스로 설정합니다. 필요한 역할 기반 권한 집합을 만듭니다. 각 사용자 그룹을 그룹이 관리할 AWS 계정에 할당합니다.**

#### 이유:
1. **AD 커넥터**:
   - AD 커넥터는 온프레미스 Active Directory와 AWS IAM Identity Center 간의 연결을 제공하여 사용자가 AWS 리소스에 SSO(Single Sign-On)를 통해 액세스할 수 있게 합니다. 이를 통해 관리자는 사용자 계정과 권한을 중앙에서 쉽게 관리할 수 있습니다.

2. **중앙 관리**:
   - 기존 온프레미스 Active Directory 환경을 활용함으로써, 사용자의 관리 및 인증 작업을 간소화하고 운영 효율성을 높일 수 있습니다.

3. **역할 기반 권한 설정**:
   - IAM Identity Center에서 역할 기반 권한 집합을 생성하여 각 사용자 그룹에 대한 액세스를 세밀하게 제어할 수 있습니다. 

4. **온프레미스 환경과의 통합**:
   - AD 커넥터를 통해 온프레미스 Active Directory 사용자 및 그룹을 AWS에 통합하여 유연하게 사용자 관리를 할 수 있습니다. 

이 방식은 유지 관리가 용이하고 운영 효율성이 높은 솔루션을 제공하여 여러 팀이 AWS 계정에서 애플리케이션을 효과적으로 관리할 수 있도록 지원합니다.


## 질문 #430

한 회사에서는 VPC 내에서 사용자 정의 리소스 이름 확인을 허용하기 위해 기존 Amazon Route 53 프라이빗 호스팅 영역을 새 VPC에 적용하려고 합니다. SysOps 관리자가 VPC를 만들고 적절한 리소스 레코드 세트를 프라이빗 호스팅 영역에 추가했습니다.

SysOps 관리자는 설정을 완료하기 위해 어떤 단계를 거쳐야 합니까?

A. Route 53 개인 호스팅 영역을 VPC와 연결합니다.
B. VPC의 기본 보안 그룹에서 Route 53 Resolver로의 트래픽을 허용하는 규칙을 만듭니다.
C. VPC 네트워크 ACL이 Route 53 Resolver로의 트래픽을 허용하는지 확인하세요.
D. 각 VPC 경로 테이블에 Route 53 Resolver로의 경로가 있는지 확인하세요.


SysOps 관리자가 VPC 내에서 사용자 정의 리소스 이름 확인을 허용하기 위해 기존 Amazon Route 53 프라이빗 호스팅 영역을 새 VPC에 적용하기 위해 설정을 완료하기 위해 필요한 단계는 다음과 같습니다:

### A. Route 53 개인 호스팅 영역을 VPC와 연결합니다.
- Route 53 프라이빗 호스팅 영역을 새 VPC와 연결해야 합니다. 이렇게 하면 해당 VPC 내에서 DNS 쿼리를 수행할 수 있게 되고, 프라이빗 호스팅 영역에 정의된 레코드에 대한 이름 해석이 가능해집니다.

이 단계를 수행한 후에는 VPC 내의 인스턴스가 Route 53 프라이빗 호스팅 영역에 정의된 도메인 이름을 통해 리소스를 참조할 수 있게 됩니다. 

### 추가 고려 사항:
- **보안 그룹 및 네트워크 ACL**: 프라이빗 호스팅 영역을 연결한 후, 보안 그룹과 네트워크 ACL 설정이 올바르게 구성되어 있어야 합니다. 이러한 설정이 올바른지 점검하여 Route 53 Resolver에 대한 트래픽이 허용되는지 확인하는 것이 중요합니다.
- 


## 질문 #431

한 회사에 온프레미스 리소스와 VPC에 호스팅된 리소스 간에 AWS 사이트 간 VPN 연결이 있습니다. SysOps 관리자가 VPC의 개인 서브넷에 개인 IP 주소만 있는 Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스는 Microsoft Windows Server를 실행합니다. EC2 인스턴스

의 보안 그룹에는 VPN 연결을 통해 온프레미스 네트워크에서 인바운드 트래픽을 허용하는 규칙이 있습니다. 온프레미스 환경에는 타사 네트워크 방화벽이 있습니다. 타사 네트워크 방화벽의 규칙은 VPN 연결을 통해 온프레미스 사용자 간에 원격 데스크톱 프로토콜(RDP) 트래픽이 흐르도록 허용합니다.

온프레미스 사용자는 EC2 인스턴스에 연결할 수 없고 시간 초과 오류가 발생합니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?
A. EC2 인스턴스에 대한 Amazon CloudWatch 로그를 생성하여 차단된 트래픽을 확인합니다.
B. 사이트 간 VPN 연결에 대한 Amazon CloudWatch 로그를 생성하여 차단된 트래픽을 확인합니다.
C. EC2 인스턴스의 탄력적 네트워크 인터페이스에 대한 VPC 흐름 로그를 생성하여 거부된 트래픽을 확인합니다.
D. 사용자에게 EC2 Instance Connect를 연결 방법으로 사용하도록 지시합니다.

SysOps 관리자가 온프레미스 사용자가 Amazon EC2 인스턴스에 연결할 수 없는 문제를 해결하기 위해 가장 적절한 조치는 다음과 같습니다:

### C. EC2 인스턴스의 탄력적 네트워크 인터페이스에 대한 VPC 흐름 로그를 생성하여 거부된 트래픽을 확인합니다.
- VPC 흐름 로그를 사용하면 EC2 인스턴스의 네트워크 인터페이스에 대해 들어오는 트래픽과 나가는 트래픽을 모니터링할 수 있습니다. 이를 통해 RDP 트래픽이 EC2 인스턴스에 도달하지 않는 이유(예: 보안 그룹이나 네트워크 ACL에서의 거부 등)를 확인할 수 있습니다.

이 외에도 다른 조치들도 필요할 수 있지만, VPC 흐름 로그는 구체적인 네트워크 트래픽을 진단하고 문제의 원인을 파악하는 데 유용합니다. 

### 추가적인 고려 사항:
- **온프레미스 방화벽 확인**: 온프레미스 네트워크 방화벽의 설정이 올바른지, VPN 연결을 통해 RDP 트래픽이 허용되는지 확인합니다.
- **VPN 연결 상태 확인**: AWS 사이트 간 VPN 연결이 정상적으로 작동하고 있는지도 점검해야 합니다.
- 


## 질문 #432

SysOps 관리자가 퍼블릭 서브넷에 웹 서버로 새 Amazon EC2 인스턴스를 설정했습니다. 이 인스턴스는 HTTP 포트 80과 HTTPS 포트 443을 사용합니다

. SysOps 관리자는 퍼블릭 리포지토리에서 운영 체제 업데이트와 소프트웨어를 다운로드하여 인터넷 연결을 확인했습니다. 그러나 SysOps 관리자는 인터넷의 웹 브라우저에서 인스턴스에 액세스할 수 없습니다.

SysOps 관리자는 이 문제를 해결하기 위해 어떤 단계 조합을 취해야 합니까? (세 가지를 선택하세요.)

A. 인스턴스 보안 그룹의 인바운드 규칙이 포트 80 및 443에서 트래픽을 허용하는지 확인하세요.
B. 인스턴스 보안 그룹의 아웃바운드 규칙이 포트 80 및 443에서 트래픽을 허용하는지 확인하세요.
C. 인스턴스의 서브넷과 연결된 네트워크 ACL의 인바운드 규칙에서 임시 포트 1024-65535가 허용되는지 확인하세요.
D. 인스턴스의 서브넷과 연결된 네트워크 ACL의 아웃바운드 규칙에서 임시 포트 1024~65535가 허용되는지 확인하세요.
E. 인스턴스에서 실행 중인 모든 방화벽에 대한 필터링 규칙이 포트 80 및 443에서 인바운드 트래픽을 허용하는지 확인하세요.
F. 인스턴스에 대해 AWS WAF가 켜져 있고 웹 트래픽을 차단하고 있는지 확인하세요.



SysOps 관리자가 퍼블릭 서브넷에 설정한 Amazon EC2 인스턴스에 대한 접근 문제를 해결하기 위해 취해야 할 단계 조합은 다음과 같습니다:

### A. 인스턴스 보안 그룹의 인바운드 규칙이 포트 80 및 443에서 트래픽을 허용하는지 확인하세요.
- 웹 서버가 HTTP(포트 80)와 HTTPS(포트 443)를 통해 외부 요청을 수신할 수 있도록 인바운드 규칙에서 해당 포트를 허용해야 합니다.

### D. 인스턴스의 서브넷과 연결된 네트워크 ACL의 아웃바운드 규칙에서 임시 포트 1024~65535가 허용되는지 확인하세요.
- 웹 브라우저와의 연결을 유지하기 위해서는 아웃바운드 규칙에서 임시 포트를 허용해야 합니다. 이는 클라이언트가 서버에 연결한 후 응답을 받을 수 있도록 해야 하기 때문입니다.

### E. 인스턴스에서 실행 중인 모든 방화벽에 대한 필터링 규칙이 포트 80 및 443에서 인바운드 트래픽을 허용하는지 확인하세요.
- 인스턴스 내부의 방화벽(예: iptables 등)이 포트 80과 443으로 들어오는 트래픽을 차단하고 있지 않은지 확인해야 합니다. 이 규칙이 설정되어 있지 않으면 인스턴스가 외부에서 요청을 받아들일 수 없습니다.

이 조합을 통해 EC2 인스턴스가 인터넷에서 접근 가능하도록 설정할 수 있습니다.



## 질문 #433

SysOps 관리자는 Linux Amazon EC2 인스턴스에서 실행되는 프로세스를 모니터링해야 합니다. 

프로세스가 중지되면 프로세스가 자동으로 다시 시작되어야 합니다. Amazon CloudWatch 에이전트는 모든 EC2 인스턴스에 이미 설치되어 있습니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?


A. 프로세스에 대한 CloudWatch 에이전트에 procstat 모니터링 구성을 추가합니다. 프로세스가 중지된 후 프로세스를 다시 시작하기 위해 AWS Systems Manager Automation 런북을 시작하는 Amazon EventBridge 이벤트 규칙을 만듭니다.
B. 프로세스에 대한 CloudWatch 에이전트에 StatsD 모니터링 구성을 추가합니다. 프로세스가 중지된 후 프로세스를 다시 시작하기 위해 AWS Systems Manager Automation 런북을 시작하는 CloudWatch 알람을 만듭니다.
C. 프로세스에 대한 CloudWatch 에이전트에 StatsD 모니터링 구성을 추가합니다. 프로세스가 중지된 후 프로세스를 다시 시작하기 위해 AWS Systems Manager Automation 런북을 시작하는 Amazon EventBridge 이벤트 규칙을 만듭니다.
D. 프로세스에 대한 CloudWatch 에이전트에 procstat 모니터링 구성을 추가합니다. 프로세스가 중지된 후 프로세스를 다시 시작하기 위해 AWS Systems Manager Automation 런북을 시작하는 CloudWatch 알람을 만듭니다.


SysOps 관리자가 Linux Amazon EC2 인스턴스에서 실행되는 프로세스를 모니터링하고, 프로세스가 중지되면 자동으로 다시 시작해야 하는 요구 사항을 충족하기 위해 선택할 수 있는 최적의 솔루션은 다음과 같습니다:

### A. 프로세스에 대한 CloudWatch 에이전트에 procstat 모니터링 구성을 추가합니다. 프로세스가 중지된 후 프로세스를 다시 시작하기 위해 AWS Systems Manager Automation 런북을 시작하는 Amazon EventBridge 이벤트 규칙을 만듭니다.

#### 이유:
- **procstat 모니터링**은 특정 프로세스의 상태를 모니터링하는 데 유용하며, 이를 통해 프로세스가 중지되었는지를 감지할 수 있습니다.
- **Amazon EventBridge 이벤트 규칙**을 사용하여 프로세스가 중지된 경우 트리거하여 **AWS Systems Manager Automation 런북**을 시작함으로써 프로세스를 자동으로 다시 시작할 수 있습니다.
- 이 접근 방식은 각 구성 요소를 잘 통합하여 프로세스의 중단을 효과적으로 감지하고 자동으로 처리할 수 있게 해줍니다.

다른 옵션들은 `StatsD`를 사용하는 대신 `procstat` 모니터링을 사용할 필요가 있으며, CloudWatch 알람을 사용한 접근 방식보다 EventBridge 규칙이 더 유연하고 신뢰성 있는 이벤트 기반 트리거링을 제공합니다.


## 질문 #434

한 회사에 MariaDB Multi-AZ 데이터베이스를 위한 Amazon RDS를 사용하는 애플리케이션이 있습니다. 
계획된 유지 관리 이벤트 중에 데이터베이스가 장애 조치를 경험할 때마다 애플리케이션이 몇 분 동안 사용할 수 없게 됩니다.

SysOps 관리자는 장애 조치 중에 애플리케이션의 다운타임을 줄이기 위해 무엇을 해야 합니까?


A. 여러 개의 작성자 인스턴스가 있는 MariaDB DB 클러스터용 RDS를 만듭니다. 유지 관리 이벤트 중에 다른 기본 노드에서 실패한 쿼리를 다시 시도하도록 애플리케이션을 구성합니다.
B. 장애 조치가 진행되는 동안 연결을 풀링하기 위해 RDS 유지 관리 창 설정을 구성합니다.
C. 데이터베이스에 대한 Amazon ElastiCache write-through 캐시를 구성합니다. 데이터베이스에 직접 연결하는 대신 캐시에 연결하도록 애플리케이션을 구성합니다.
D. 데이터베이스와 연결된 RDS 프록시를 만듭니다. 데이터베이스에 직접 연결하는 대신 프록시에 연결하도록 애플리케이션을 구성합니다.


장애 조치 중에 애플리케이션의 다운타임을 줄이기 위해 SysOps 관리자가 취할 수 있는 최선의 조치는 다음과 같습니다:

### D. 데이터베이스와 연결된 RDS 프록시를 만듭니다. 데이터베이스에 직접 연결하는 대신 프록시에 연결하도록 애플리케이션을 구성합니다.

#### 이유:
- **RDS 프록시**는 데이터베이스 연결을 관리하여 애플리케이션과 데이터베이스 간의 중단을 줄이는 데 도움이 됩니다. 장애 조치가 발생할 때 프록시는 자동으로 새로운 데이터베이스 인스턴스에 연결하므로 애플리케이션이 계속 작동할 수 있습니다.
- 이 솔루션은 프록시가 이전 연결을 자동으로 관리하기 때문에 애플리케이션의 코드 변경이 적거나 필요하지 않으며, 데이터베이스에 대한 연결 수를 줄여 주기 때문에 성능을 향상시키는 데도 도움이 됩니다.

다른 옵션들은 장애 조치 중에 연결의 지속성을 보장하는 데 필요한 신뢰성을 제공하지 않거나, 애플리케이션의 복잡성을 증가시킬 수 있습니다.


## 질문 #435

SysOps 관리자가 Amazon S3 버킷에서 수백만 개의 LIST 요청을 발견했습니다.

관리자는 어떤 서비스나 기능을 사용하여 요청이 어디에서 오는지 조사할 수 있습니까? (두 가지를 선택하세요.)

A. AWS CloudTrail 데이터 이벤트
B. 아마존 이벤트브릿지
C. AWS Health 대시보드
D. Amazon S3 서버 액세스 로깅
E. AWS 신뢰할 수 있는 고문


SysOps 관리자가 Amazon S3 버킷에서 수백만 개의 LIST 요청을 조사하기 위해 사용할 수 있는 서비스나 기능은 다음과 같습니다:

### A. AWS CloudTrail 데이터 이벤트
- AWS CloudTrail을 사용하면 S3 버킷에서 발생하는 모든 API 호출(예: LIST 요청)을 기록할 수 있습니다. 데이터 이벤트를 활성화하면 특정 S3 버킷에 대한 요청 로그를 확인할 수 있어 요청의 출처를 파악하는 데 유용합니다.

### D. Amazon S3 서버 액세스 로깅
- S3 서버 액세스 로깅을 활성화하면 버킷에 대한 모든 요청에 대한 로그를 기록할 수 있습니다. 이 로그에는 요청을 수행한 IP 주소, 요청 시간, 요청 유형(LIST 포함) 등의 정보가 포함되어 있어 요청이 어디에서 오는지 파악하는 데 도움이 됩니다.

이 두 가지 옵션(A와 D)을 사용하여 LIST 요청이 어디에서 오는지 조사할 수 있습니다.



## 질문 #436

SysOps 관리자가 Amazon CloudWatch Logs에 게시하도록 VPC 흐름 로그를 구성합니다. SysOps 관리자가 CloudWatch Logs의 로그를 검토하고 예상보다 트래픽이 적다는 것을 알아차립니다. SysOps 관리자가 VPC 흐름 로그를 사내에서 캡처한 로그와 비교한 후, SysOps 관리자는 VPC 흐름 로그가 불완전하다고 생각합니다.

트래픽 차이에 대한 가능한 이유는 다음 중 무엇입니까?
A. CloudWatch Logs 제한이 적용되었습니다.
B. CloudWatch IAM 역할은 VPC 흐름 로그 서비스와 신뢰 관계가 없습니다.
C. VPC 흐름 로그는 아직 생성 중입니다.
D. VPC 흐름 로그는 온프레미스 서버에서 VPC로의 트래픽을 캡처할 수 없습니다.


SysOps 관리자가 Amazon CloudWatch Logs에 게시된 VPC 흐름 로그를 검토하고 예상보다 트래픽이 적음을 발견한 경우, **D. VPC 흐름 로그는 온프레미스 서버에서 VPC로의 트래픽을 캡처할 수 없습니다.**가 가능한 이유입니다.

### 이유:
- **VPC 흐름 로그의 제한**: VPC 흐름 로그는 AWS VPC 내에서 발생하는 트래픽에 대한 정보만 캡처합니다. 즉, VPC 외부(온프레미스 서버)에서 VPC 내부로 전송되는 트래픽은 로그에 포함되지 않습니다. 이는 온프레미스 서버와 AWS VPC 간의 트래픽을 모니터링하고자 하는 경우에 영향을 미칠 수 있습니다. 

### 다른 옵션에 대한 설명:
- **A. CloudWatch Logs 제한이 적용되었습니다.**: CloudWatch Logs에는 로그 데이터에 대한 보관 및 데이터 전송 제한이 있지만, 이 제한은 VPC 흐름 로그의 수집 방식에 직접적으로 영향을 미치지 않습니다.

- **B. CloudWatch IAM 역할은 VPC 흐름 로그 서비스와 신뢰 관계가 없습니다.**: IAM 역할이 잘못 구성된 경우 로그가 CloudWatch Logs에 전송되지 않을 수 있지만, 이러한 경우 로그가 아예 생성되지 않거나 에러가 발생해야 합니다. 따라서 로그가 일부라도 생성되었다면 이 원인은 아닙니다.

- **C. VPC 흐름 로그는 아직 생성 중입니다.**: VPC 흐름 로그가 생성되는 데 약간의 시간이 걸릴 수 있지만, 로그가 생성되었고 일부 트래픽이 기록되고 있다면 이 원인도 아닙니다.

따라서 트래픽 차이에 대한 가장 가능성이 높은 이유는 **D. VPC 흐름 로그는 온프레미스 서버에서 VPC로의 트래픽을 캡처할 수 없습니다.**입니다.



## 질문 #437

회사의 SysOps 관리자가 AWS IAM Identity Center(AWS Single Sign-On)를 사용하여 Active Directory에 연결합니다. SysOps 관리자가 회사의 모든 사용자가 액세스해야 하는 새 계정을 만듭니다.

SysOps 관리자가 새 계정에 대한 권한을 부여하기 위해 Active Directory Domain Users 그룹을 사용하는 이유는 모든 사용자가 이미 그룹의 멤버이기 때문입니다. 사용자가 로그인을 시도하면 액세스가 거부됩니다.

어떤 조치를 취하면 이 액세스 문제가 해결됩니까?

A. 새 그룹을 만듭니다. 새 그룹에 사용자를 추가하여 액세스를 제공합니다.
B. Active Directory 도메인 컨트롤러의 시간을 수정합니다.
C. 계정을 제거합니다. IAM Identity Center와 통합된 조직에 계정을 다시 추가합니다.
D. IAM Identity Center에 읽기 액세스 권한이 있도록 Active Directory 그룹의 권한을 수정합니다.

SysOps 관리자가 AWS IAM Identity Center(AWS Single Sign-On)를 사용하여 Active Directory에 연결한 후, 새 계정에 대한 액세스 문제가 발생한 경우, 이 문제를 해결하기 위해 **D. IAM Identity Center에 읽기 액세스 권한이 있도록 Active Directory 그룹의 권한을 수정합니다**를 선택하는 것이 가장 적절합니다.

### 이유:
- **IAM Identity Center와 Active Directory 통합**: IAM Identity Center가 Active Directory와 통합되어 있을 때, IAM Identity Center는 Active Directory 그룹에 대한 읽기 권한이 있어야 합니다. 이를 통해 IAM Identity Center는 Active Directory의 사용자 그룹과 해당 권한을 인식할 수 있습니다. 읽기 권한이 없으면 IAM Identity Center가 그룹의 멤버를 확인할 수 없으므로 액세스가 거부됩니다.

### 다른 옵션에 대한 설명:
- **A. 새 그룹을 만듭니다. 새 그룹에 사용자를 추가하여 액세스를 제공합니다.**: 이 옵션은 추가적인 그룹을 만들고 사용자를 그곳에 추가하는 방법이지만, 문제의 본질은 Active Directory 그룹의 권한이 잘못 설정된 것에 있으므로 근본적인 해결책이 아닙니다.
  
- **B. Active Directory 도메인 컨트롤러의 시간을 수정합니다.**: 시간이 맞지 않는 경우 인증 문제가 발생할 수 있지만, 사용자 그룹의 권한 문제와는 관련이 없습니다.
  
- **C. 계정을 제거합니다. IAM Identity Center와 통합된 조직에 계정을 다시 추가합니다.**: 계정을 제거하고 다시 추가하는 것은 불필요한 작업이며, 권한 문제는 해결되지 않을 가능성이 큽니다.

따라서 액세스 문제를 해결하기 위해 가장 적절한 조치는 **D. IAM Identity Center에 읽기 액세스 권한이 있도록 Active Directory 그룹의 권한을 수정합니다**입니다.




## 질문 #438

SysOps 관리자는 Amazon S3 웹사이트를 가지고 있으며 단일 Amazon CloudFront 배포에 대한 액세스를 제한하려고 합니다. 웹사이트 방문자는 CloudFront를 우회하거나 버킷에서 직접 S3 웹사이트를 볼 수 없어야 합니다.

어떤 AWS 서비스 또는 기능이 이러한 요구 사항을 충족할까요?
A. S3 버킷 ACL
B. AWS 방화벽 관리자
C. Amazon Route 53 개인 호스팅 영역
D. 원본 접근 ID(OAI)

SysOps 관리자가 Amazon S3 웹사이트에 대한 액세스를 제한하고 방문자가 CloudFront를 우회하거나 S3 웹사이트를 직접 볼 수 없도록 하려면 **원본 접근 ID(OAI)**를 사용하는 것이 가장 적합합니다. 

### 이유:
- **원본 접근 ID(OAI)**: OAI는 CloudFront가 S3 버킷에 대한 요청을 할 때 사용하는 특별한 IAM 역할입니다. 이를 통해 CloudFront는 S3 버킷에 대한 액세스를 인증할 수 있으며, OAI를 사용하여 S3 버킷의 퍼블릭 액세스를 비활성화하면 CloudFront를 통해서만 버킷의 콘텐츠에 접근할 수 있습니다.

이렇게 설정하면 S3 웹사이트는 CloudFront를 통해서만 접근 가능하게 되며, 사용자는 CloudFront를 우회하거나 S3 웹사이트를 직접 볼 수 없습니다. 

### 다른 옵션에 대한 설명:
- **S3 버킷 ACL**: S3 버킷의 액세스 제어 목록은 기본적인 퍼미션 설정을 제공하지만, CloudFront 배포와의 통합에서 OAI만큼 강력한 보안을 제공하지 않습니다.
- **AWS 방화벽 관리자**: AWS 방화벽 관리자는 네트워크 보호와 관련된 서비스이며, S3와 CloudFront의 연결에 대한 직접적인 액세스 제한을 제공하지 않습니다.
- **Amazon Route 53 개인 호스팅 영역**: Route 53 개인 호스팅 영역은 도메인 이름 해석에 관한 것이며, S3 웹사이트 액세스를 제한하는 데 직접적인 관련이 없습니다.

따라서 정답은 **D. 원본 접근 ID(OAI)**입니다.


## 질문 #439

SysOps 관리자는 회사의 AWS 계정 보안을 담당합니다. 이 회사에는 사용자가 다중 요소 인증(MFA) 장치를 사용하여 인증된 경우에만 Amazon EC2 인스턴스를 중지하거나 종료할 수 있는 정책이 있습니다. SysOps 관리자는

이 요구 사항을 충족하기 위해 어떤 정책을 적용해야 합니까?
A. 
B. 
C. 
D. 

이러한 요구 사항을 충족하기 위해 SysOps 관리자가 적용해야 할 IAM 정책의 예는 다음과 같습니다. 이 정책은 사용자가 MFA를 사용하여 인증된 경우에만 EC2 인스턴스를 중지하거나 종료할 수 있도록 합니다.

### IAM 정책 예시

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:StopInstances",
                "ec2:TerminateInstances"
            ],
            "Resource": "*",
            "Condition": {
                "Bool": {
                    "aws:MultiFactorAuthPresent": "true"
                }
            }
        }
    ]
}
```

### 정책 설명:
- **Effect**: `"Allow"` - 이 정책은 특정 작업을 허용합니다.
- **Action**: `"ec2:StopInstances"` 및 `"ec2:TerminateInstances"` - 사용자가 EC2 인스턴스를 중지하거나 종료하는 작업을 정의합니다.
- **Resource**: `"*"` - 모든 EC2 인스턴스에 대해 이 작업을 허용합니다. 필요한 경우 특정 리소스 ARN으로 제한할 수 있습니다.
- **Condition**: `{"Bool": {"aws:MultiFactorAuthPresent": "true"}}` - 사용자가 MFA를 사용하여 인증했는지 확인하는 조건입니다. 이 조건이 true인 경우에만 사용자가 EC2 인스턴스를 중지하거나 종료할 수 있습니다.

이 정책을 IAM 사용자 또는 그룹에 할당하면, 사용자는 MFA를 사용하여 인증할 때만 EC2 인스턴스를 중지하거나 종료할 수 있습니다.


## 질문 #440

글로벌 기업이 전 세계 누구나 ​​모바일 폰에서 비디오를 업로드할 수 있도록 허용하고자 합니다. 

이 회사의 모바일 앱은 추가 처리를 위해 공개 인터넷을 통해 비디오를 us-east-1 지역의 Amazon S3 버킷에 업로드합니다. us-east

-1에서 멀리 떨어진 위치에서 사용자가 업로드하는 비디오는 us-east-1에서 가까운 위치에서 사용자가 업로드하는 비디오보다 업로드 속도가 느립니다. 많은 경우 느린 업로드로 인해 먼 위치의 사용자가 업로드를 취소합니다.

먼 위치의 사용자의 업로드 속도를 개선할 수 있는 솔루션은 무엇입니까?

A. S3 버킷에서 S3 Transfer Acceleration을 활성화합니다. 모바일 앱을 변경하여 업로드에 S3 Transfer Acceleration 엔드포인트를 사용합니다.
B. 전 세계 여러 AWS 리전에서 S3 버킷에 대한 S3 액세스 포인트를 만듭니다. 모바일 앱을 변경하여 업로드에 S3 액세스 포인트 엔드포인트를 사용합니다.
C. S3 버킷에서 S3 Select를 사용합니다. 모바일 앱을 변경하여 업로드에 S3 Select 글로벌 엔드포인트를 사용합니다.
D. 전 세계 여러 AWS 리전에 새로운 퍼블릭 네트워크 로드 밸런서(NLB)를 만듭니다. S3 버킷을 NLB의 대상으로 지정합니다. 모바일 앱을 변경하여 업로드에 가장 가까운 NLB를 사용합니다.

전 세계 여러 위치에서 비디오를 업로드할 때 느린 업로드 속도를 개선하기 위한 가장 적절한 솔루션은 다음과 같습니다:

### A. S3 버킷에서 S3 Transfer Acceleration을 활성화합니다. 모바일 앱을 변경하여 업로드에 S3 Transfer Acceleration 엔드포인트를 사용합니다.

### 이유:
- **S3 Transfer Acceleration**: 이 기능은 사용자가 S3 버킷에 데이터를 업로드할 때 Amazon CloudFront의 엣지 로케이션을 사용하여 전송 속도를 향상시킵니다. 사용자는 가장 가까운 엣지 로케이션으로 데이터를 전송하고, 이 후 S3 버킷으로 데이터를 전송하는 방식으로 업로드 속도를 개선합니다.
- **쉬운 구현**: 모바일 앱의 업로드 코드에서 엔드포인트를 변경하는 것만으로 간편하게 구현할 수 있으며, 추가적인 인프라를 설정할 필요가 없습니다.
- **효율적인 데이터 전송**: 전 세계 어디서나 비디오를 업로드하는 사용자에게 더 나은 경험을 제공하여, 업로드 취소를 줄일 수 있습니다.

### 다른 옵션들에 대한 설명:
- **B. S3 액세스 포인트를 사용**: S3 액세스 포인트는 다양한 AWS 리전에서 S3 버킷에 대한 사용자 지정 엔드포인트를 제공하지만, Transfer Acceleration만큼 업로드 속도를 직접 개선하지는 않습니다.

- **C. S3 Select를 사용**: S3 Select는 S3에 저장된 데이터에서 특정 데이터만 쿼리할 수 있도록 도와주지만, 업로드 속도와는 관련이 없습니다.

- **D. 퍼블릭 NLB를 사용**: NLB를 사용하여 S3 버킷에 대한 로드 밸런싱을 수행하는 것은 복잡하고, S3의 기본 사용 사례와 맞지 않습니다. 이 방식은 S3의 내부 작동 방식을 변경하지 않으며, 업로드 속도를 개선하는 데 효과적이지 않습니다.

따라서 **A**가 가장 적절한 솔루션입니다.


## 질문 #441 *****
한 회사에서 AWS Certificate Manager(ACM)를 사용하여 퍼블릭 SSL/TLS 인증서를 관리하고 있습니다. SysOps 관리자는 인증서가 만료까지 14일 미만일 때 이메일 알림을 보내야 합니다.

어떤 솔루션이 가장 적은 운영 오버헤드로 이 요구 사항을 충족할까요?
A. 모든 ACM 인증서에 대한 인증서 만료를 모니터링하기 위해 Amazon CloudWatch 사용자 지정 메트릭을 만듭니다. aws.cloudwatch의 이벤트 소스가 있는 Amazon EventBridge 규칙을 만듭니다. DaysToExpiry 메트릭이 14보다 작으면 대상 Amazon Simple Notification Service(Amazon SNS) 토픽에 이벤트를 보내도록 규칙을 구성합니다. 적절한 이메일 주소를 SNS 토픽에 구독합니다.
B. aws.acm의 이벤트 소스가 있는 Amazon EventBridge 규칙을 만듭니다. 모든 ACM 인증서에 대한 DaysToExpiry 메트릭을 평가하도록 규칙을 구성합니다. DaysToExpiry가 14보다 작으면 대상 Amazon Simple Notification Service(Amazon SNS) 토픽에 이벤트를 보내도록 규칙을 구성합니다. 적절한 이메일 주소를 SNS 토픽에 구독합니다.
C. 모든 ACM 인증서에 대한 DaysToExpiry 메트릭을 표시하는 Amazon CloudWatch 대시보드를 만듭니다. DaysToExpiry가 14보다 작으면 해당 이메일 주소로 이메일 메시지를 보냅니다. 미리 정의된 CLI 명령을 실행하여 Amazon Simple Notification Service(Amazon SNS) 주제에 게시하여 이메일 메시지를 보냅니다.
D. aws.acm의 이벤트 소스가 있는 Amazon EventBridge 규칙을 만듭니다. 모든 ACM 인증서에 대한 DaysToExpiry 메트릭을 평가하도록 규칙을 구성합니다. 미리 정의된 이메일 템플릿을 사용하는 대상 SMS ID를 구성합니다. DaysToExpiry가 14보다 작으면 대상 SMS ID에 이벤트를 보내도록 규칙을 구성합니다.


이 요구 사항을 충족하기 위해 가장 적은 운영 오버헤드로 사용할 수 있는 솔루션은 다음과 같습니다:

### B. aws.acm의 이벤트 소스가 있는 Amazon EventBridge 규칙을 만듭니다. 모든 ACM 인증서에 대한 DaysToExpiry 메트릭을 평가하도록 규칙을 구성합니다. DaysToExpiry가 14보다 작으면 대상 Amazon Simple Notification Service(Amazon SNS) 토픽에 이벤트를 보내도록 규칙을 구성합니다. 적절한 이메일 주소를 SNS 토픽에 구독합니다.

### 이유:
- **EventBridge 규칙 사용**: Amazon EventBridge를 사용하여 ACM 인증서의 만료 상태를 모니터링할 수 있으며, 특정 조건(예: DaysToExpiry가 14일 미만일 때)에 따라 알림을 설정할 수 있습니다.
- **SNS로 알림 발송**: SNS를 통해 이메일 알림을 쉽게 설정할 수 있으며, 사용자에게 필요한 알림을 적시에 보낼 수 있습니다.
- **운영 오버헤드 최소화**: AWS 서비스가 서로 통합되어 작동하므로, 추가적인 관리 작업 없이 자동으로 모니터링 및 알림을 수행할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. 모든 ACM 인증서에 대한 인증서 만료를 모니터링하기 위해 Amazon CloudWatch 사용자 지정 메트릭을 만듭니다.** 
  - 사용자 지정 메트릭을 만드는 것은 더 복잡하고 운영 오버헤드가 더 큽니다. EventBridge를 직접 사용하는 것이 더 효율적입니다.

- **C. 모든 ACM 인증서에 대한 DaysToExpiry 메트릭을 표시하는 Amazon CloudWatch 대시보드를 만듭니다.** 
  - 대시보드에서 수동으로 모니터링하는 것은 운영 오버헤드가 클 수 있으며, 자동 알림을 제공하지 않습니다.

- **D. 미리 정의된 이메일 템플릿을 사용하는 대상 SMS ID를 구성합니다.**
  - SMS는 이메일 알림과 같은 유용한 알림 방식이 아니며, 또한 EventBridge를 활용하는 것이 더 효율적입니다.

따라서 **B**가 가장 적절한 솔루션입니다.



## 질문 #442

SysOps 관리자가 AWS Lambda 함수를 호출하는 Amazon EventBridge 규칙을 프로비저닝하는 AWS CloudFormation 템플릿을 생성했습니다. 

Lambda 함수는 Amazon CloudWatch 로그 그룹에 이벤트 세부 정보를 쓰도록 설계되었습니다. 이 함수는 Amazon CloudWatch Logs에 이벤트를 쓸 수 있는 권한이 있습니다. 그러나 SysOps 관리자는 Lambda 함수가 실행 중이 아니라는 것을 발견했습니다.

SysOps 관리자는 어떻게 문제를 해결해야 합니까?


A. CloudFormation 스택을 업데이트하여 EventBridge가 함수를 호출하는 데 필요한 IAM 권한이 있는 AWS::IAM::Role 리소스를 포함합니다. 역할을 EventBridge 규칙에 할당합니다.
B. CloudFormation 스택을 업데이트하여 함수에 필요한 IAM 권한이 있는 AWS::IAM::Role 리소스를 포함합니다. 역할을 함수 실행 역할로 할당합니다.
C. AWS::Lambda::Permission 리소스로 CloudFormation 스택을 업데이트하여 events.amazonaws.com이 함수를 호출할 수 있는 권한이 있는지 확인합니다.
D. Lambda.amazonaws.com이 함수를 호출할 수 있는 권한이 있는지 확인하기 위해 AWS::Lambda::Permission 리소스로 CloudFormation 스택을 업데이트합니다.


AWS Lambda 함수가 Amazon EventBridge 규칙에 의해 호출되지 않는 문제를 해결하기 위해 SysOps 관리자가 취해야 할 적절한 조치는 다음과 같습니다:

### C. AWS::Lambda::Permission 리소스로 CloudFormation 스택을 업데이트하여 events.amazonaws.com이 함수를 호출할 수 있는 권한이 있는지 확인합니다.
- EventBridge가 Lambda 함수를 호출할 수 있도록 허용하기 위해서는 `AWS::Lambda::Permission` 리소스를 사용하여 `events.amazonaws.com`에 대한 권한을 추가해야 합니다. 이 권한이 없으면 EventBridge가 Lambda 함수를 호출할 수 없습니다.

### 다른 옵션들에 대한 설명:
- **A. CloudFormation 스택을 업데이트하여 EventBridge가 함수를 호출하는 데 필요한 IAM 권한이 있는 AWS::IAM::Role 리소스를 포함합니다. 역할을 EventBridge 규칙에 할당합니다.**
  - EventBridge 규칙이 Lambda 함수를 호출하기 위해 IAM 역할을 필요로 하지 않습니다. Lambda 함수의 호출 권한은 `AWS::Lambda::Permission` 리소스를 통해 관리됩니다.

- **B. CloudFormation 스택을 업데이트하여 함수에 필요한 IAM 권한이 있는 AWS::IAM::Role 리소스를 포함합니다. 역할을 함수 실행 역할로 할당합니다.**
  - Lambda 함수에 대한 실행 역할은 이미 설정되어 있을 가능성이 있으며, 이 옵션은 EventBridge와 관련된 문제를 해결하지 않습니다.

- **D. Lambda.amazonaws.com이 함수를 호출할 수 있는 권한이 있는지 확인하기 위해 AWS::Lambda::Permission 리소스로 CloudFormation 스택을 업데이트합니다.**
  - 이 옵션은 잘못된 대상입니다. `Lambda.amazonaws.com`은 Lambda 함수가 호출할 수 있는 서비스이고, EventBridge에 대한 호출 권한은 `events.amazonaws.com`에 대한 권한을 추가해야 합니다.

따라서 **C**가 올바른 답변입니다.


## 질문 #443

한 회사에 CPU 사용률이 높은 Amazon EC2 인스턴스가 있습니다. 
EC2 인스턴스는 t3.large 인스턴스이며 테스트 웹 애플리케이션을 실행하고 있습니다. 이 회사는 웹 애플리케이션이 컴퓨팅 최적화된 대형 인스턴스에서 더 잘 작동할 것이라는 것을 알게 되었습니다.

SysOps 관리자는 이 변경을 위해 무엇을 해야 합니까?

A. AWS VM Import/Export를 사용하여 EC2 인스턴스를 컴퓨팅 최적화 인스턴스로 마이그레이션합니다.
B. EC2 인스턴스에서 하이버네이션을 활성화합니다. 인스턴스 유형을 컴퓨팅 최적화 인스턴스로 변경합니다. EC2 인스턴스에서 하이버네이션을 비활성화합니다.
C. EC2 인스턴스를 중지합니다. 인스턴스 유형을 컴퓨팅 최적화 인스턴스로 변경합니다. EC2 인스턴스를 시작합니다.
D. EC2 인스턴스가 실행되는 동안 인스턴스 유형을 컴퓨팅 최적화 인스턴스로 변경합니다.


CPU 사용률이 높은 Amazon EC2 인스턴스를 컴퓨팅 최적화 인스턴스로 변경하기 위해서는 다음 단계를 따라야 합니다. 이 경우 올바른 선택은:

### C. EC2 인스턴스를 중지합니다. 인스턴스 유형을 컴퓨팅 최적화 인스턴스로 변경합니다. EC2 인스턴스를 시작합니다.
- EC2 인스턴스의 유형을 변경하려면 먼저 인스턴스를 중지해야 하며, 중지된 후에 인스턴스의 유형을 변경할 수 있습니다. 변경 후 인스턴스를 다시 시작하면 새로운 인스턴스 유형으로 실행됩니다.

### 다른 옵션들에 대한 설명:
- **A. AWS VM Import/Export를 사용하여 EC2 인스턴스를 컴퓨팅 최적화 인스턴스로 마이그레이션합니다.**
  - VM Import/Export는 물리적 서버를 Amazon EC2로 마이그레이션하는 데 사용되며, 기존 EC2 인스턴스를 다른 인스턴스 유형으로 변경하는 데 사용되지 않습니다.

- **B. EC2 인스턴스에서 하이버네이션을 활성화합니다. 인스턴스 유형을 컴퓨팅 최적화 인스턴스로 변경합니다. EC2 인스턴스에서 하이버네이션을 비활성화합니다.**
  - 하이버네이션은 EC2 인스턴스를 종료하고 상태를 저장하는 기능이지만, 인스턴스 유형을 변경하기 위해서는 하이버네이션을 사용할 필요가 없습니다.

- **D. EC2 인스턴스가 실행되는 동안 인스턴스 유형을 컴퓨팅 최적화 인스턴스로 변경합니다.**
  - 실행 중인 인스턴스의 유형을 직접 변경할 수는 없으며, 반드시 인스턴스를 중지한 후 변경해야 합니다.

결론적으로, **C**가 올바른 답변입니다.


## 질문 #444

개발팀이 15분 전에 새로운 AWS Lambda 함수를 생성하고 배포했습니다. 
함수가 여러 번 호출되었지만 Amazon CloudWatch Logs에는 로그 메시지가 표시되지 않습니다.

이것의 한 가지 원인은 무엇입니까?
A. 개발자는 이 Lambda 함수에 대한 로그 메시지를 활성화하지 않았습니다.
B. Lambda 함수의 역할에는 CloudWatch Logs 항목을 생성할 수 있는 권한이 포함되지 않습니다.
C. Lambda 함수는 첫 번째 로그 명령문에 도달하기 전에 예외를 발생시킵니다.
D. Lambda 함수는 로컬 로그 파일을 생성하며, 이 로그 파일은 표시되기 전에 먼저 CloudWatch Logs에 전송되어야 합니다.


AWS Lambda 함수가 호출되었음에도 불구하고 Amazon CloudWatch Logs에 로그 메시지가 표시되지 않는 이유는 여러 가지가 있을 수 있습니다. 제시된 옵션 중에서 가장 가능성이 높은 원인은 다음과 같습니다:

### B. Lambda 함수의 역할에는 CloudWatch Logs 항목을 생성할 수 있는 권한이 포함되지 않습니다.
- AWS Lambda 함수가 CloudWatch Logs에 로그를 기록하기 위해서는 해당 함수에 연결된 IAM 역할에 `logs:CreateLogGroup`, `logs:CreateLogStream`, 및 `logs:PutLogEvents` 권한이 포함되어 있어야 합니다. 만약 이 권한이 없다면, 함수는 로그를 생성할 수 없으므로 CloudWatch Logs에 로그가 나타나지 않게 됩니다.

### 다른 옵션들에 대한 설명:
- **A. 개발자는 이 Lambda 함수에 대한 로그 메시지를 활성화하지 않았습니다.**
  - AWS Lambda는 기본적으로 CloudWatch Logs에 로그를 기록하도록 설정되어 있으므로 별도로 로그 메시지를 활성화해야 하는 것은 아닙니다.

- **C. Lambda 함수는 첫 번째 로그 명령문에 도달하기 전에 예외를 발생시킵니다.**
  - Lambda 함수가 예외를 발생시키면 로그는 생성되지만, 예외 발생 이전에 로그 메시지가 없을 뿐입니다. 예외와 관련된 로그는 CloudWatch Logs에 기록됩니다.

- **D. Lambda 함수는 로컬 로그 파일을 생성하며, 이 로그 파일은 표시되기 전에 먼저 CloudWatch Logs에 전송되어야 합니다.**
  - AWS Lambda는 로컬 로그 파일을 생성하지 않으며, 로그는 자동으로 CloudWatch Logs로 전송됩니다.

결론적으로, **B**가 가장 적절한 원인입니다.

## 질문 #445

한 회사에서 새로 만든 Amazon CloudWatch 알람이 INSUFFICIENT_DATA 상태에서 전환되지 않는 것을 관찰했습니다. 

이 알람은 퍼블릭 서브넷에 배포된 Amazon EC2 인스턴스의 mem_used_percent 메트릭을 추적하기 위해 만들어졌습니다.

EC2 인스턴스를 검토한 결과 통합 CloudWatch 에이전트가 설치되어 실행 중인 것으로 나타났습니다. 그러나 이 메트릭은 CloudWatch에서 사용할 수 없습니다. SysOps 관리자는 이 문제를 해결하기 위한 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. EC2 인스턴스에 대한 CloudWatch 상세 모니터링 활성화
B. CloudWatch 권한이 포함된 IAM 인스턴스 프로필을 만듭니다. EC2 인스턴스에 인스턴스 프로필을 추가합니다.
C. EC2 인스턴스를 프라이빗 서브넷으로 마이그레이션
D. 액세스 키 ID와 비밀 액세스 키가 있는 IAM 사용자를 만듭니다. 해당 자격 증명을 사용하도록 통합 CloudWatch 에이전트 구성 파일을 업데이트합니다.


EC2 인스턴스에서 `mem_used_percent` 메트릭이 CloudWatch에 표시되지 않거나 알람이 **INSUFFICIENT_DATA** 상태인 경우, 이 문제를 해결하기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### B. CloudWatch 권한이 포함된 IAM 인스턴스 프로필을 만듭니다. EC2 인스턴스에 인스턴스 프로필을 추가합니다.
- CloudWatch 에이전트가 메트릭을 성공적으로 전송하려면 IAM 역할이 필요합니다. 이 역할에는 CloudWatch에 로그를 쓰고 메트릭을 전송하는 데 필요한 권한이 포함되어 있어야 합니다. 따라서 CloudWatch에 적절한 권한을 가진 IAM 인스턴스 프로필을 생성하고 이를 EC2 인스턴스에 연결하면 문제가 해결될 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. EC2 인스턴스에 대한 CloudWatch 상세 모니터링 활성화**
  - 상세 모니터링은 기본적인 EC2 인스턴스 메트릭(예: CPU 사용률, 디스크 I/O 등)에 적용됩니다. 메모리와 같은 사용자 정의 메트릭에는 영향이 없습니다.

- **C. EC2 인스턴스를 프라이빗 서브넷으로 마이그레이션**
  - 퍼블릭 서브넷에 있든 프라이빗 서브넷에 있든, 메트릭 데이터는 CloudWatch에 전달될 수 있습니다. 이 옵션은 문제 해결과 관련이 없습니다.

- **D. 액세스 키 ID와 비밀 액세스 키가 있는 IAM 사용자를 만듭니다. 해당 자격 증명을 사용하도록 통합 CloudWatch 에이전트 구성 파일을 업데이트합니다.**
  - IAM 사용자로 인증을 구성하는 것은 권장되지 않으며, 인스턴스 프로필을 사용하는 것이 더 안전하고 관리하기 쉬운 방법입니다. 

따라서, **B**가 가장 적절한 솔루션입니다.


## 질문 #446

어떤 회사가 중요한 파일을 Amazon S3에 객체로 업로드하고 있습니다. 업로드 중에 객체가 손상되면 회사에 알려야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 객체 업로드 중에 요청 본문으로 Content-Disposition 값을 전달합니다.
B. 객체 업로드 중에 요청 헤더로 Content-MD5 값을 전달합니다.
C. 객체 업로드 중에 x-amz-object-lock-mode를 요청 헤더로 전달합니다.
D. 객체 업로드 중에 요청 본문으로 x-amz-server-side-encryption-customer-algorithm을 전달합니다.


Amazon S3에 객체를 업로드할 때, 업로드 중에 객체가 손상되는 것을 감지하고 알리기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### B. 객체 업로드 중에 요청 헤더로 Content-MD5 값을 전달합니다.
- **Content-MD5** 헤더는 객체 업로드 요청에서 제공되는 MD5 해시 값을 나타냅니다. S3는 이 값을 사용하여 업로드된 객체의 무결성을 확인합니다. 서버는 요청 본문에서 제공된 Content-MD5 값을 계산하고, 계산된 해시 값이 요청에 포함된 MD5 해시와 일치하지 않으면 업로드를 실패시키고 오류를 반환합니다. 이를 통해 객체 손상을 감지할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. 객체 업로드 중에 요청 본문으로 Content-Disposition 값을 전달합니다.**
  - Content-Disposition은 객체의 표시 방식에 관한 정보를 정의하지만, 무결성과는 관련이 없습니다.

- **C. 객체 업로드 중에 x-amz-object-lock-mode를 요청 헤더로 전달합니다.**
  - Object Lock 기능은 객체에 대한 변경을 방지하는 데 사용되지만, 업로드 중 무결성을 확인하는 데는 도움이 되지 않습니다.

- **D. 객체 업로드 중에 요청 본문으로 x-amz-server-side-encryption-customer-algorithm을 전달합니다.**
  - 이 헤더는 서버 측 암호화에 대한 정보를 제공하지만, 객체의 무결성을 보장하는 데는 관련이 없습니다.

따라서, **B**가 이 요구 사항을 충족하는 가장 적절한 조치입니다.



## 질문 #447

SysOps 관리자는 Application Load Balancer(ALB)에 대해 각 대상 그룹 구성원에게 전송되고 수신되는 바이트 수를 보여주는 보고서를 만들어야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. ALB에 대한 액세스 로깅을 활성화합니다. 로그를 Amazon S3 버킷에 저장합니다.
B. 대상 그룹의 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다.
C. Amazon Athena를 사용하여 ALB 로그를 쿼리합니다. 테이블을 쿼리합니다. received_bytes 및 sent_bytes 필드를 사용하여 대상 포트 필드로 그룹화된 총 바이트를 계산합니다.
D. Amazon Athena를 사용하여 ALB 로그를 쿼리합니다. 테이블을 쿼리합니다. received_bytes 및 sent_bytes 필드를 사용하여 클라이언트 포트 필드로 그룹화된 총 바이트를 계산합니다.
E. ALB에 대한 ProcessedBytes 메트릭의 Sum 통계를 보여주는 Amazon CloudWatch 대시보드를 만듭니다.

SysOps 관리자가 Application Load Balancer (ALB)에 대해 각 대상 그룹 구성원에게 전송되고 수신되는 바이트 수를 보여주는 보고서를 만들기 위해 취해야 할 단계 조합은 다음과 같습니다:

### A와 C:
1. **A. ALB에 대한 액세스 로깅을 활성화합니다. 로그를 Amazon S3 버킷에 저장합니다.**
   - ALB의 액세스 로깅을 활성화하면 모든 요청에 대한 로그가 Amazon S3에 저장됩니다. 이 로그에는 각 요청에 대한 수신 및 전송 바이트 수(`received_bytes`, `sent_bytes`) 정보가 포함됩니다.

2. **C. Amazon Athena를 사용하여 ALB 로그를 쿼리합니다. 테이블을 쿼리합니다. received_bytes 및 sent_bytes 필드를 사용하여 대상 포트 필드로 그룹화된 총 바이트를 계산합니다.**
   - Athena를 사용하여 S3에 저장된 ALB 로그를 쿼리하면, 각 대상 그룹의 구성원에게 전송 및 수신된 바이트 수를 집계할 수 있습니다. 대상 포트 필드를 기준으로 그룹화하면 각 대상 그룹별로 바이트 수를 계산할 수 있습니다.

### 이유:
- **B**는 Amazon CloudWatch 에이전트를 인스턴스에 설치하는 것으로, ALB의 바이트 수를 직접 수집하는 데 필요하지 않습니다. ALB 로그를 통해 필요한 정보를 얻을 수 있습니다.
- **D**는 클라이언트 포트 필드로 그룹화하여 각 대상 그룹의 바이트 수를 계산하는 것이 아니라, 클라이언트 요청을 기반으로 한 데이터입니다. 요구 사항에 부합하지 않습니다.
- **E**는 ProcessedBytes 메트릭을 보여주지만, 이는 전체 ALB의 메트릭으로, 개별 대상 그룹 구성원의 수신 및 전송 바이트 수를 제공하지 않습니다.

따라서, **A와 C**의 조합이 요구 사항을 가장 잘 충족하는 솔루션입니다.


## 질문 #448

한 회사가 Amazon Linux 2 Amazon Machine Image(AMI)를 기반으로 하는 수천 개의 Amazon EC2 인스턴스를 실행합니다. SysOps 관리자는 EC2 인스턴스 중 하나에서 대화형 세션이 필요한 모든 사용자의 명령과 출력을 기록하는 솔루션을 구현해야 합니다. 솔루션은 내구성 있는 스토리지 위치에 데이터를 기록해야 합니다. 또한 솔루션은 로그 데이터를 기반으로 하는 자동화된 알림 및 알람을 제공해야 합니다.

어떤 솔루션이 이러한 요구 사항을 가장 높은 운영 효율성으로 충족할까요?

A. 각 EC2 인스턴스에서 명령 세션 로깅을 구성합니다. 통합 Amazon CloudWatch 에이전트를 구성하여 세션 로그를 Amazon CloudWatch Logs로 보냅니다. Amazon Athena를 사용하여 쿼리 필터와 알림을 설정합니다.
B. 모든 사용자가 EC2 인스턴스에 대한 명령줄 액세스가 필요할 때 중앙 배스천 호스트를 사용하도록 요구합니다. 배스천 호스트에서 통합 Amazon CloudWatch 에이전트를 구성하여 세션 로그를 Amazon CloudWatch Logs로 보냅니다. CloudWatch Logs에서 관련 보안 결과에 대한 메트릭 필터와 메트릭 알람을 설정합니다.
C. 모든 사용자가 EC2 인스턴스에 대한 명령줄 액세스가 필요할 때 AWS Systems Manager Session Manager를 사용하도록 요구합니다. Session Manager를 구성하여 세션 로그를 Amazon CloudWatch Logs로 스트리밍합니다. CloudWatch Logs에서 관련 보안 결과에 대한 메트릭 필터와 메트릭 알람을 설정합니다.
D. 각 EC2 인스턴스에서 명령 세션 로깅을 구성합니다. 모든 사용자가 EC2 인스턴스에 대한 명령줄 액세스가 필요할 때 AWS Systems Manager Run Command 문서를 사용하도록 요구합니다. 통합 Amazon CloudWatch 에이전트를 구성하여 세션 로그를 Amazon CloudWatch Logs로 보냅니다. Amazon Athena 쿼리 결과에 따라 CloudWatch 알람을 설정합니다.


회사가 Amazon EC2 인스턴스에서 대화형 세션의 모든 사용자 명령과 출력을 기록해야 하는 경우, 가장 높은 운영 효율성을 제공하는 솔루션은 **C. 모든 사용자가 EC2 인스턴스에 대한 명령줄 액세스가 필요할 때 AWS Systems Manager Session Manager를 사용하도록 요구합니다. Session Manager를 구성하여 세션 로그를 Amazon CloudWatch Logs로 스트리밍합니다. CloudWatch Logs에서 관련 보안 결과에 대한 메트릭 필터와 메트릭 알람을 설정합니다.**입니다.

### 이유:
1. **중앙 관리**:
   - AWS Systems Manager Session Manager를 사용하면 여러 EC2 인스턴스에 대한 세션을 중앙에서 관리할 수 있습니다. 이는 운영 효율성을 높여줍니다.

2. **자동 로그 기록**:
   - Session Manager는 사용자 세션의 로그를 자동으로 Amazon CloudWatch Logs로 전송할 수 있습니다. 이렇게 하면 로그 저장 및 관리가 간편해집니다.

3. **확장성**:
   - 수천 개의 인스턴스에서 작업할 때, Session Manager는 기존 인프라와 통합되어 유연성과 확장성을 제공합니다. 모든 인스턴스에 동일한 구성으로 쉽게 배포할 수 있습니다.

4. **자동화된 알림 및 모니터링**:
   - CloudWatch Logs에서 메트릭 필터 및 알람을 설정하면 특정 조건에 따라 알림을 받을 수 있습니다. 이를 통해 보안 이벤트나 사용자 활동에 대한 모니터링을 강화할 수 있습니다.

### 다른 옵션에 대한 설명:
- **A**: 각 EC2 인스턴스에서 세션 로깅을 개별적으로 구성해야 하므로 관리 오버헤드가 증가합니다.
- **B**: 중앙 배스천 호스트를 사용하는 것은 추가적인 인프라 관리가 필요하며, 세션 로깅을 위한 복잡성이 증가합니다.
- **D**: AWS Systems Manager Run Command 문서를 사용하는 것은 추가적인 구성 단계를 요구하며, Session Manager에 비해 대화형 세션 관리에서 효율성이 떨어집니다.

결론적으로, **C** 옵션이 가장 적합하며, 운영 효율성, 관리 용이성 및 보안 요구 사항을 모두 충족합니다.



## 질문 #449

AWS Organizations를 사용하는 한 회사가 최근 AWS Control Tower를 구현했습니다. 이 회사는 이제 ID 관리를 중앙화해야 합니다. SysOps 관리자는 AWS IAM Identity Center를 외부 SAML 2.0 ID 공급자(IdP)와 페더레이션하여 회사의 모든 계정과 클라우드 애플리케이션에 대한 액세스를 중앙에서 관리해야 합니다.

SysOps 관리자가 외부 IdP에 연결하려면 SysOps 관리자가 어떤 전제 조건을 갖춰야 합니까? (두 가지를 선택하세요.)
A. IAM ID 센터 SAML 메타데이터 사본
B. 공개 X 509 인증서를 포함하는 IdP 메타데이터
C. IdP의 IP 주소
D. 관리 계정에 대한 루트 액세스
E. 조직의 회원 계정에 대한 관리 권한

AWS IAM Identity Center를 외부 SAML 2.0 ID 공급자(IdP)와 페더레이션하기 위해 SysOps 관리자가 갖춰야 할 전제 조건은 다음과 같습니다:

SAML(Security Assertion Markup Language, 샘엘)은 인증 정보 제공자(identity provider)와 서비스 제공자(service provider) 간의 인증 및 인가 데이터를 교환하기 위한 XML 기반의 개방형 표준 데이터 포맷이다.

### 정답: 
- **A. IAM ID 센터 SAML 메타데이터 사본**
- **B. 공개 X 509 인증서를 포함하는 IdP 메타데이터**

### 설명:
1. **A. IAM ID 센터 SAML 메타데이터 사본**:
   - IAM Identity Center는 SAML 메타데이터를 사용하여 IdP와의 통신을 설정합니다. SysOps 관리자는 IAM ID 센터의 SAML 메타데이터를 준비해야 합니다. 이 메타데이터는 IdP와 연결하기 위해 필요합니다.

2. **B. 공개 X 509 인증서를 포함하는 IdP 메타데이터**:
   - SAML 2.0 IdP에서 제공하는 공개 X.509 인증서는 SAML 응답을 서명하는 데 사용됩니다. SysOps 관리자는 이 인증서를 포함하여 IdP와의 신뢰 관계를 설정해야 합니다. 이를 통해 AWS IAM Identity Center는 IdP에서 오는 SAML 응답의 유효성을 확인할 수 있습니다.

### 다른 선택지에 대한 설명:
- **C. IdP의 IP 주소**:
   - IdP의 IP 주소는 SAML 페더레이션 구성에 필요하지 않습니다. SAML은 IP 주소에 의존하지 않기 때문에 이 정보는 필수적이지 않습니다.

- **D. 관리 계정에 대한 루트 액세스**:
   - 루트 액세스는 필요한 권한이 아닙니다. SysOps 관리자는 필요한 IAM 권한만 있으면 됩니다. 루트 권한은 사용을 최소화해야 하며, 일반적으로 필요하지 않습니다.

- **E. 조직의 회원 계정에 대한 관리 권한**:
   - 회원 계정에 대한 관리 권한이 필요한 것은 아니며, IAM Identity Center는 관리 계정에서 설정되므로 관리 계정에 대한 적절한 권한만 필요합니다.

결론적으로, **A**와 **B**가 외부 SAML 2.0 ID 공급자에 연결하기 위한 주요 전제 조건입니다.

## 질문 #450

한 회사가 최근 서버 인프라를 Amazon EC2 인스턴스로 이전했습니다. 이 회사는 Amazon CloudWatch Logs를 사용하여 인스턴스 로그를 추적하려고 합니다.

SysOps 관리자는 AWS 모범 사례를 준수하여 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?
A. AWS Management Console에서 인스턴스에 대한 CloudWatch를 구성합니다. AWS가 인스턴스에 대한 에이전트를 자동으로 설치하고 구성할 때까지 기다립니다.
B. 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 IAM 역할을 연결합니다.
C. 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 IAM 사용자를 연결합니다.
D. 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 필요한 보안 그룹을 연결합니다.

AWS 모범 사례를 준수하여 Amazon EC2 인스턴스의 로그를 Amazon CloudWatch Logs에 추적하기 위해 SysOps 관리자가 수행해야 할 가장 적합한 방법은 **B** 옵션입니다:

### B. 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 IAM 역할을 연결합니다.

### 이유:
- **CloudWatch 에이전트 설치 및 구성**: CloudWatch 에이전트는 EC2 인스턴스에서 로그 파일을 수집하고 CloudWatch Logs로 전송하는 데 필요합니다. 이 에이전트를 설치하고 구성하는 것은 AWS 모범 사례 중 하나입니다.
- **IAM 역할 사용**: EC2 인스턴스에 IAM 역할을 연결하여 CloudWatch에 로그를 쓸 수 있는 권한을 부여하는 것이 가장 안전한 방법입니다. IAM 역할은 인스턴스가 AWS 리소스에 접근할 수 있도록 허용하며, IAM 사용자를 연결하는 것보다 더 안전합니다.

### 다른 선택지에 대한 설명:
- **A. AWS Management Console에서 인스턴스에 대한 CloudWatch를 구성합니다. AWS가 인스턴스에 대한 에이전트를 자동으로 설치하고 구성할 때까지 기다립니다.**
  - 이 방법은 수동 개입 없이 에이전트를 자동으로 설치하는 것을 기대하지만, 이는 신뢰할 수 있는 방법이 아닙니다. 직접 설치하고 구성하는 것이 더 안전하고 확실합니다.

- **C. 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 IAM 사용자를 연결합니다.**
  - IAM 사용자는 EC2 인스턴스가 CloudWatch에 접근하는 데 사용되는 권한을 제공하지 않으며, 대신 IAM 역할을 사용하는 것이 바람직합니다.

- **D. 인스턴스에 CloudWatch 에이전트를 설치하고 구성합니다. 인스턴스가 CloudWatch에 로그를 쓸 수 있도록 필요한 보안 그룹을 연결합니다.**
  - 보안 그룹은 네트워크 레벨에서 접근을 제어하는 것이며, CloudWatch Logs에 로그를 쓸 수 있도록 하는 데 필요하지 않습니다. IAM 역할을 사용하는 것이 중요합니다.

따라서, **B** 옵션이 AWS 모범 사례를 준수하며 인스턴스 로그를 CloudWatch에 추적하기 위한 가장 적합한 솔루션입니다.

## 질문 #451

한 회사가 AWS CloudFormation을 사용하여 인프라를 배포합니다. 이 회사는 최근에 애플리케이션을 폐기했습니다. 클라우드 운영 엔지니어가 CloudFormation 스택 삭제를 시작했는데, 스택이 DELETE_FAILED 상태에 갇혔습니다.

SysOps 관리자가 스택이 보안 그룹을 배포했음을 발견했습니다. 보안 그룹은 환경의 다른 보안 그룹에서 참조합니다. SysOps 관리자는 다른 애플리케이션에 영향을 미치지 않고 스택을 삭제해야 합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이러한 요구 사항을 충족할까요?
A. 다른 이름을 가진 새 보안 그룹을 만듭니다. 새 보안 그룹에 동일한 규칙을 적용합니다. 새 보안 그룹을 참조하는 다른 모든 보안 그룹을 바꿉니다. 스택을 삭제합니다.
B. 보안 그룹을 삭제하기 위해 CloudFormation 변경 세트를 만듭니다. 변경 세트를 배포합니다.
C. 스택을 다시 삭제합니다. 보안 그룹이 유지되도록 지정합니다.
D. CloudFormation 드리프트 감지를 수행합니다. 스택을 삭제합니다.

AWS CloudFormation 스택 삭제가 `DELETE_FAILED` 상태에 갇혔고, 이 문제를 해결하기 위해 운영적으로 효율적인 방법으로 보안 그룹을 삭제해야 하는 경우, 가장 적합한 솔루션은 **C** 옵션입니다:

### C. 스택을 다시 삭제합니다. 보안 그룹이 유지되도록 지정합니다.

### 이유:
- **스택 삭제 시 보안 그룹을 유지**하는 옵션을 사용하면, 현재 보안 그룹의 의존성을 해결한 후 스택을 안전하게 삭제할 수 있습니다. 이를 통해 보안 그룹이 참조되는 다른 애플리케이션에 영향을 미치지 않게 됩니다.
- 이 접근 방식은 수동으로 다른 보안 그룹을 업데이트하거나 새 보안 그룹을 만드는 과정을 피할 수 있으므로 운영적으로 더 효율적입니다.

### 다른 선택지에 대한 설명:
- **A. 다른 이름을 가진 새 보안 그룹을 만듭니다. 새 보안 그룹에 동일한 규칙을 적용합니다. 새 보안 그룹을 참조하는 다른 모든 보안 그룹을 바꿉니다. 스택을 삭제합니다.**
  - 이 방법은 시간과 노력을 많이 소모하며, 여러 보안 그룹을 수정해야 하므로 운영 오버헤드가 높습니다.

- **B. 보안 그룹을 삭제하기 위해 CloudFormation 변경 세트를 만듭니다. 변경 세트를 배포합니다.**
  - 이 방법은 스택의 DELETE_FAILED 상태를 해결하지 못할 수 있으며, 보안 그룹의 의존성이 해소되지 않으면 여전히 문제가 발생할 수 있습니다.

- **D. CloudFormation 드리프트 감지를 수행합니다. 스택을 삭제합니다.**
  - 드리프트 감지는 리소스의 현재 상태와 CloudFormation 스택 템플릿의 상태 간의 불일치를 식별하지만, 삭제 과정에서 보안 그룹을 유지하는 옵션을 제공하지 않으므로 문제를 해결할 수 없습니다.

따라서, **C** 옵션이 가장 운영적으로 효율적이며 다른 애플리케이션에 영향을 미치지 않고 스택을 삭제하는 데 가장 적합한 솔루션입니다.


## 질문 #452

회사는 최종 사용자에게 웹사이트의 가용성을 모니터링해야 합니다. 

회사는 웹사이트 가동 시간이 99% 미만으로 감소하면 Amazon Simple Notification Service(Amazon SNS) 알림을 제공하는 솔루션이 필요합니다. 모니터링은 웹사이트의 사용자 경험에 대한 정확한 보기를 제공해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. CloudWatch Logs 로그 그룹에 게시된 웹사이트 로그를 기반으로 하는 Amazon CloudWatch 알람을 만듭니다. HTTP 4xx 오류와 5xx 오류 수가 지정된 임계값을 초과하면 SNS 알림을 게시하도록 알람을 구성합니다.
B. CloudWatch에서 웹사이트의 게시된 메트릭을 기반으로 하는 Amazon CloudWatch 알람을 만듭니다. 이상 탐지를 기반으로 하는 SNS 알림을 게시하도록 알람을 구성합니다.
C. Amazon CloudWatch Synthetics 하트비트 모니터링 카나리아를 만듭니다. 최종 사용자를 위해 카나리아를 웹사이트 URL과 연결합니다. 카나리아에 대한 CloudWatch 알람을 만듭니다. SuccessPercent 메트릭 값이 99% 미만이면 SNS 알림을 게시하도록 알람을 구성합니다.
D. Amazon CloudWatch Synthetics 끊어진 링크 검사기 모니터링 카나리아를 만듭니다. 최종 사용자를 위해 카나리아를 웹사이트 URL과 연결합니다. 카나리아에 대한 CloudWatch 알람을 만듭니다. SuccessPercent 메트릭 값이 99% 미만이면 SNS 알림을 게시하도록 알람을 구성합니다.

회사가 최종 사용자에게 웹사이트의 가용성을 모니터링하고, 가용성이 99% 미만으로 감소하면 Amazon Simple Notification Service(Amazon SNS) 알림을 제공해야 하는 경우, **C** 옵션이 가장 적합한 솔루션입니다:

### C. Amazon CloudWatch Synthetics 하트비트 모니터링 카나리아를 만듭니다. 최종 사용자를 위해 카나리아를 웹사이트 URL과 연결합니다. 카나리아에 대한 CloudWatch 알람을 만듭니다. SuccessPercent 메트릭 값이 99% 미만이면 SNS 알림을 게시하도록 알람을 구성합니다.

### 이유:
- **Amazon CloudWatch Synthetics**는 웹사이트의 가용성과 성능을 모니터링하기 위해 "카나리아"를 생성하여 실제 사용자 경험을 시뮬레이션합니다.
- **SuccessPercent** 메트릭을 모니터링하여 웹사이트의 가용성을 측정하고, 가용성이 99% 미만으로 감소할 경우 SNS를 통해 즉시 알림을 받을 수 있습니다. 이 방법은 사용자 경험에 대한 정확한 보기를 제공합니다.
- CloudWatch Synthetics는 정기적으로 웹사이트를 점검하므로, 가용성 감소를 실시간으로 감지할 수 있습니다.

### 다른 선택지에 대한 설명:
- **A. CloudWatch Logs 로그 그룹에 게시된 웹사이트 로그를 기반으로 하는 Amazon CloudWatch 알람을 만듭니다. HTTP 4xx 오류와 5xx 오류 수가 지정된 임계값을 초과하면 SNS 알림을 게시하도록 알람을 구성합니다.**
  - 이 방법은 오류를 기반으로 하므로 웹사이트의 실제 가용성을 정확히 반영하지 않을 수 있습니다. 사용자 경험에 대한 정보를 제공하지 않습니다.

- **B. CloudWatch에서 웹사이트의 게시된 메트릭을 기반으로 하는 Amazon CloudWatch 알람을 만듭니다. 이상 탐지를 기반으로 하는 SNS 알림을 게시하도록 알람을 구성합니다.**
  - 이 방법은 이상 탐지 기반이지만, 웹사이트의 실제 가용성을 측정하는 데 적합하지 않을 수 있습니다.

- **D. Amazon CloudWatch Synthetics 끊어진 링크 검사기 모니터링 카나리아를 만듭니다. 최종 사용자를 위해 카나리아를 웹사이트 URL과 연결합니다. 카나리아에 대한 CloudWatch 알람을 만듭니다. SuccessPercent 메트릭 값이 99% 미만이면 SNS 알림을 게시하도록 알람을 구성합니다.**
  - 이 방법도 카나리아를 사용하지만, 끊어진 링크 검사기는 특정 링크의 상태만을 확인하는 데 초점을 맞추므로 전체 웹사이트의 가용성을 모니터링하는 데 최적화되어 있지 않습니다.

따라서 **C** 옵션이 웹사이트 가용성을 모니터링하고 SNS 알림을 제공하는 데 가장 적합한 솔루션입니다.

## 질문 #453

회사는 AWS 계정에서 지출을 추적해야 합니다. 회사는 현재 비용과 예상 비용이 특정 임계값을 초과할 때 알림을 받아야 합니다.

어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할까요?
A. 새 IAM 역할을 만듭니다. AWSPurchaseOrdersServiceRolePolicy AWS 관리 정책을 역할에 연결합니다. 정기적으로 AWS Cost Explorer를 확인하여 현재 비용과 예상 비용을 모니터링합니다.
B. AWS 비용 및 사용 보고서를 만듭니다. 새 사용 파일이 생성될 때 실행되는 AWS Step Functions 상태 머신을 만듭니다. 상태 머신을 구성하여 데이터를 Amazon Forecast에 전달하고 AWS Lambda 함수를 호출합니다. Lambda 함수를 구성하여 데이터를 구문 분석하고 비용이 임계값을 초과하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 보냅니다.
C. AWS 비용 및 사용 보고서를 만듭니다. 현재 비용과 예상 비용을 서비스별로 분리합니다. 매월 Amazon Simple Notification Service(Amazon SNS) 주제로 보고서를 보내도록 예약합니다.
D. AWS Budgets에서 반복 비용 예산을 만듭니다. 실제 비용에 대한 알림을 만듭니다. 예상 비용에 대한 두 번째 알림을 만듭니다. 알림을 수신하도록 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.


회사가 AWS 계정에서 지출을 추적하고 현재 비용과 예상 비용이 특정 임계값을 초과할 때 알림을 받기 위한 가장 적은 운영 오버헤드 솔루션은 **D**입니다:

### D. AWS Budgets에서 반복 비용 예산을 만듭니다. 실제 비용에 대한 알림을 만듭니다. 예상 비용에 대한 두 번째 알림을 만듭니다. 알림을 수신하도록 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.

### 이유:
- **AWS Budgets**는 사용자가 비용 및 사용량 예산을 설정하고 이를 모니터링할 수 있도록 하는 서비스입니다. 이 서비스는 사용자가 설정한 임계값을 초과하는 경우 알림을 보낼 수 있습니다.
- 실제 비용과 예상 비용에 대해 별도의 알림을 구성함으로써, 회사는 두 가지 측면에서 비용을 효율적으로 추적할 수 있습니다.
- AWS Budgets는 간편하게 설정할 수 있으며, 예산을 초과할 경우 즉시 알림을 받을 수 있는 기능을 제공하여 운영 오버헤드를 최소화합니다.

### 다른 선택지에 대한 설명:
- **A. 새 IAM 역할을 만듭니다. AWSPurchaseOrdersServiceRolePolicy AWS 관리 정책을 역할에 연결합니다. 정기적으로 AWS Cost Explorer를 확인하여 현재 비용과 예상 비용을 모니터링합니다.**
  - 이 방법은 수동적이며 자동 알림을 제공하지 않습니다. 비용을 수동으로 확인해야 하므로 운영 오버헤드가 증가합니다.

- **B. AWS 비용 및 사용 보고서를 만듭니다. 새 사용 파일이 생성될 때 실행되는 AWS Step Functions 상태 머신을 만듭니다. 상태 머신을 구성하여 데이터를 Amazon Forecast에 전달하고 AWS Lambda 함수를 호출합니다. Lambda 함수를 구성하여 데이터를 구문 분석하고 비용이 임계값을 초과하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 알림을 보냅니다.**
  - 이 접근 방식은 매우 복잡하며 여러 서비스를 통합해야 하므로 운영 오버헤드가 높습니다. 불필요하게 복잡한 솔루션입니다.

- **C. AWS 비용 및 사용 보고서를 만듭니다. 현재 비용과 예상 비용을 서비스별로 분리합니다. 매월 Amazon Simple Notification Service(Amazon SNS) 주제로 보고서를 보내도록 예약합니다.**
  - 이 방법은 정기적인 보고서를 제공하지만, 임계값 초과 알림을 실시간으로 받을 수 없습니다. 사용자가 보고서를 주기적으로 수동으로 확인해야 하므로 운영 오버헤드가 증가합니다.

따라서 **D** 옵션이 요구 사항을 충족하고 운영 오버헤드를 최소화하는 가장 적합한 솔루션입니다.


## 질문 #454

한 회사가 AWS 클라우드에서 다중 계정 구조를 사용합니다. 

이 회사의 환경에는 공통 리소스를 위한 공유 계정이 포함됩니다. 이 환경에는 새로운 애플리케이션 개발을 위한 개발 계정도 포함됩니다. 이 회사는 DNS 관리를 위해 Amazon Route 53을 사용합니다. 이 회사는 공유 계정에서 모든 Route 53 호스팅 영역을 관리합니다.

SysOps 관리자는 개발 계정에 배포된 애플리케이션에 대한 새 SSL/TLS 인증서를 얻어야 합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자는 무엇을 해야 합니까?
A. 공유 계정에서 새로운 AWS Key Management Service(AWS KMS) 키를 만듭니다. 개발 계정의 루트 주체에게 읽기 액세스 권한을 부여하도록 키 정책을 구성합니다.
B. 공유 계정에서 AWS Certificate Manager(ACM)를 사용하여 새 인증서를 요청합니다. 공유 계정에서 Route 53을 사용하여 관련 호스팅 영역에서 검증 레코드 세트를 만듭니다.
C. 개발 계정에서 AWS Certificate Manager(ACM)를 사용하여 새 인증서를 요청합니다. 공유 계정에서 Route 53을 사용하여 관련 호스팅 영역에서 검증 레코드 세트를 만듭니다.
D. 개발 계정에서 새로운 AWS Key Management Service(AWS KMS) 키를 만듭니다. 공유 계정의 루트 주체에 대한 읽기 액세스 권한을 부여하도록 키 정책을 구성합니다. 공유 계정에서 Route 53을 사용하여 KMS 키의 Amazon Resource Name(ARN)을 참조하는 검증 레코드 세트를 만듭니다.

이 시나리오에서 SysOps 관리자가 개발 계정에 배포된 애플리케이션에 대한 SSL/TLS 인증서를 얻기 위해 선택해야 할 최적의 솔루션은 **B**입니다:

### B. 공유 계정에서 AWS Certificate Manager(ACM)를 사용하여 새 인증서를 요청합니다. 공유 계정에서 Route 53을 사용하여 관련 호스팅 영역에서 검증 레코드 세트를 만듭니다.

### 이유:
- **AWS Certificate Manager (ACM)**는 SSL/TLS 인증서를 쉽게 요청하고 관리할 수 있는 서비스입니다. 공유 계정에서 ACM을 사용하여 인증서를 요청하면, 해당 인증서를 Route 53에서 관리하는 호스팅 영역과 연결할 수 있습니다.
- Route 53 호스팅 영역이 공유 계정에 있기 때문에, 검증 레코드 세트를 Route 53에서 생성하여 도메인 소유권을 검증하는 것이 가능합니다. 이는 ACM 인증서 요청 프로세스의 필수 단계입니다.

### 다른 선택지에 대한 설명:
- **A. 공유 계정에서 새로운 AWS Key Management Service(AWS KMS) 키를 만듭니다. 개발 계정의 루트 주체에게 읽기 액세스 권한을 부여하도록 키 정책을 구성합니다.**
  - KMS 키를 만드는 것은 SSL/TLS 인증서를 요청하는 데 필요하지 않습니다. KMS는 암호화 및 키 관리를 위한 서비스이지 인증서 관리와는 관련이 없습니다.

- **C. 개발 계정에서 AWS Certificate Manager(ACM)를 사용하여 새 인증서를 요청합니다. 공유 계정에서 Route 53을 사용하여 관련 호스팅 영역에서 검증 레코드 세트를 만듭니다.**
  - 개발 계정에서 ACM을 사용해 인증서를 요청하는 것은 불가능합니다. Route 53 호스팅 영역이 공유 계정에 있기 때문에, 검증 레코드를 추가할 수 없습니다. 인증서 요청과 검증은 동일한 계정에서 처리해야 합니다.

- **D. 개발 계정에서 새로운 AWS Key Management Service(AWS KMS) 키를 만듭니다. 공유 계정의 루트 주체에 대한 읽기 액세스 권한을 부여하도록 키 정책을 구성합니다. 공유 계정에서 Route 53을 사용하여 KMS 키의 Amazon Resource Name(ARN)을 참조하는 검증 레코드 세트를 만듭니다.**
  - KMS 키는 SSL/TLS 인증서와는 직접적인 관련이 없습니다. 인증서 검증을 위해 KMS 키 ARN을 사용하는 것은 적절하지 않으며, 검증 레코드는 ACM과 Route 53의 도메인 소유권 확인 프로세스에 따라 생성되어야 합니다.

따라서 **B** 옵션이 이 요구 사항을 충족하는 가장 적절한 솔루션입니다.



## 질문 #455

회사의 SysOps 관리자가 애플리케이션 구성 요소 간 통신 문제를 해결하고 있습니다. 회사는 VPC 흐름 로그를 Amazon CloudWatch Logs에 게시하도록 구성했습니다. 그러나 CloudWatch Logs에 로그가 없습니다. VPC

흐름 로그가 CloudWatch Logs에 게시되는 것을 막는 요인은 무엇일까요?
A. 흐름 로그에 대한 IAM 역할에 연결된 IAM 정책에 로그 CreateLogGroup 권한이 없습니다.
B. 흐름 로그에 대한 IAM 역할에 연결된 IAM 정책에 로그 CreateExportTask 권한이 없습니다.
C. VPC는 IPv6 주소로 구성되었습니다.
D. VPC는 AWS 계정의 다른 VPC와 피어링됩니다.

VPC 흐름 로그가 Amazon CloudWatch Logs에 게시되지 않는 원인으로 가장 적절한 선택지는 **A**입니다: 

### A. 흐름 로그에 대한 IAM 역할에 연결된 IAM 정책에 로그 CreateLogGroup 권한이 없습니다.
- **이유**: VPC 흐름 로그를 CloudWatch Logs에 게시하려면 IAM 역할이 CloudWatch Logs에 로그 그룹을 생성하고 로그 스트림을 작성할 수 있는 권한을 가져야 합니다. 이 권한이 없으면 VPC 흐름 로그가 로그 그룹에 게시되지 않기 때문에 로그가 생성되지 않습니다.

### 다른 선택지에 대한 설명:
- **B. 흐름 로그에 대한 IAM 역할에 연결된 IAM 정책에 로그 CreateExportTask 권한이 없습니다.**
  - `CreateExportTask` 권한은 흐름 로그를 CloudWatch Logs로 내보내는 작업에 필요한 것이지만, 이 권한이 없더라도 로그가 생성되지 않지는 않습니다. 흐름 로그 자체를 게시하는 데는 필요하지 않습니다.

- **C. VPC는 IPv6 주소로 구성되었습니다.**
  - VPC가 IPv6 주소로 구성되어 있다고 해서 VPC 흐름 로그가 CloudWatch Logs에 게시되지 않는 것은 아닙니다. IPv6 지원은 흐름 로그에 영향을 주지 않습니다.

- **D. VPC는 AWS 계정의 다른 VPC와 피어링됩니다.**
  - VPC 간의 피어링은 흐름 로그에 영향을 주지 않습니다. 흐름 로그는 VPC의 트래픽을 모니터링하는 기능이므로, 다른 VPC와의 연결 여부는 관계가 없습니다.

따라서, **A**가 가장 적절한 원인입니다. IAM 역할의 정책을 검토하여 `CreateLogGroup` 및 기타 필요한 권한이 포함되어 있는지 확인하는 것이 중요합니다.


## 질문 #456

한 회사가 3개의 가용성 영역에 걸쳐 3개의 Amazon EC2 인스턴스에 새 애플리케이션을 배포합니다. 이 회사는 네트워크 로드 밸런서(NLB)를 사용하여 트래픽을 EC2 인스턴스로 라우팅합니다. SysOps 관리자는 EC2 인스턴스가 NLB에서만 트래픽을 허용하도록 솔루션을 구현해야 합니다. SysOps 관리자는

최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?
A. NLB와 연결된 보안 그룹에서만 트래픽을 허용하도록 EC2 인스턴스와 연결된 보안 그룹을 구성합니다.
B. NLB와 연결된 탄력적 네트워크 인터페이스에서만 트래픽을 허용하도록 EC2 인스턴스와 연결된 보안 그룹을 구성합니다.
C. 네트워크 ACL 만들기 네트워크 ACL을 애플리케이션 서브넷과 연결합니다. NLB의 CIDR 범위에서만 인바운드 트래픽을 허용하도록 네트워크 ACL을 구성합니다.
D. 별도의 EC2 인스턴스에 설치된 타사 방화벽 솔루션을 사용합니다. NLB가 배포된 서브넷에서만 애플리케이션의 EC2 인스턴스로의 트래픽을 허용하는 방화벽 규칙을 구성합니다.


이 요구 사항을 충족하기 위한 최소한의 운영 오버헤드 솔루션은 다음과 같습니다:

**C. 네트워크 ACL 만들기 네트워크 ACL을 애플리케이션 서브넷과 연결합니다. NLB의 CIDR 범위에서만 인바운드 트래픽을 허용하도록 네트워크 ACL을 구성합니다.**

이 접근 방식의 장점은 다음과 같습니다:

1. **네트워크 수준 제어**: 네트워크 ACL을 사용하여 인바운드 및 아웃바운드 트래픽을 제어할 수 있으며, NLB에서 허용된 CIDR 범위만 인바운드 트래픽을 수신할 수 있도록 설정할 수 있습니다.
2. **운영 오버헤드 최소화**: 네트워크 ACL은 기본적으로 VPC 수준에서 관리되므로 EC2 인스턴스와 관련된 보안 그룹을 개별적으로 관리할 필요가 없습니다.
3. **가용성 영역에 걸친 일관된 정책**: 네트워크 ACL은 VPC의 서브넷에 연결되어 있으며, 모든 가용성 영역에서 동일한 정책을 적용할 수 있습니다.

이 솔루션은 효과적이고 관리가 용이하여 EC2 인스턴스가 NLB에서만 트래픽을 수신하도록 보장합니다.


옵션 **A**인 "NLB와 연결된 보안 그룹에서만 트래픽을 허용하도록 EC2 인스턴스와 연결된 보안 그룹을 구성합니다."가 정답이 아닌 이유는 다음과 같습니다:

1. **보안 그룹의 작동 방식**: AWS 보안 그룹은 상태가 있는 방화벽으로, 인바운드 및 아웃바운드 규칙을 사용하여 트래픽을 제어합니다. NLB가 사용하는 보안 그룹은 트래픽이 NLB에서 EC2 인스턴스로 전달될 수 있도록 구성되어야 합니다. 그러나 보안 그룹은 다른 보안 그룹에서 오는 트래픽을 필터링할 수 없습니다. 즉, EC2 인스턴스에 연결된 보안 그룹이 NLB의 보안 그룹에서만 트래픽을 허용하도록 설정해도, NLB의 보안 그룹과 EC2 인스턴스의 보안 그룹 간의 관계로 인해 직접적인 연결이 이루어지지 않습니다.

2. **추가적인 설정 필요성**: EC2 인스턴스의 보안 그룹에서 NLB의 보안 그룹을 참조하는 것은 NLB의 IP 주소와 보안 그룹 규칙을 허용하도록 설정해야 하며, 이는 관리 오버헤드를 증가시킬 수 있습니다. 특히, NLB의 IP 주소가 동적으로 변경될 수 있기 때문에 추가적인 관리 작업이 필요합니다.

3. **비용 및 복잡성**: 이 접근 방식은 EC2 인스턴스의 보안 그룹 설정을 지속적으로 관리해야 하므로, 복잡성을 증가시키고 운영 오버헤드를 높일 수 있습니다.

따라서, **C** 옵션인 "네트워크 ACL 만들기 네트워크 ACL을 애플리케이션 서브넷과 연결합니다. NLB의 CIDR 범위에서만 인바운드 트래픽을 허용하도록 네트워크 ACL을 구성합니다."가 보다 간단하고 운영 오버헤드가 적은 솔루션으로 권장됩니다. 네트워크 ACL을 사용하면 가용성 영역 전반에 걸쳐 EC2 인스턴스에 대한 인바운드 트래픽을 쉽게 제어할 수 있습니다.


## 질문 #457 +++++

ServiceNow를 사용하는 회사에는 민감한 워크로드가 실행되는 AWS 계정이 있습니다. 필요한 보안 그룹이 있습니다. 회사는 보안 그룹에서 규칙이 변경될 때마다 ServiceNow에서 인시던트를 생성하는 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 노력으로 이 요구 사항을 충족할까요?

A. 보안 그룹이 변경될 때 ALARM 상태로 전환되는 Amazon CloudWatch 알람을 만듭니다. ServiceNow에 연결하여 인시던트를 생성하는 AWS Lambda 함수를 호출하도록 알람을 구성합니다.

B. AWS Security Hub를 활성화합니다. ServiceNow에 연결하여 인시던트를 생성하는 AWS Lambda 함수를 만듭니다. 보안 그룹 변경을 감지하는 Amazon EventBridge 규칙을 만듭니다. 이벤트 유형을 Security Hub Findings - Custom Action으로 구성합니다. Lambda 함수를 호출하도록 EventBridge 규칙을 구성합니다.

C. 보안 그룹 변경을 감지하기 위한 Amazon EventBridge 규칙을 만듭니다. 이벤트 유형을 CloudTrail을 통한 AWS API 호출로 구성합니다. ServiceNow에서 인시던트를 생성하기 위해 AWS-CreateServiceNowIncidentAWS Systems Manager Automation 런북을 실행하도록 EventBridge 규칙을 구성합니다.

D. ServiceNow에 지속적으로 연결된 Amazon EC2 인스턴스를 시작하여 보안 그룹 변경을 감지합니다. AWS CloudTrail 로그를 EC2 인스턴스로 내보냅니다. 30분마다 예약된 cron 작업을 실행하여 CloudTrail 로그에서 보안 그룹 변경을 검색하는 bash 스크립트를 작성합니다. 변경이 감지되면 ServiceNow에서 인시던트를 생성하도록 EC2 인스턴스를 구성합니다.


이 요구 사항을 충족하기 위한 최소한의 운영 노력 솔루션은 다음과 같습니다:

**C. 보안 그룹 변경을 감지하기 위한 Amazon EventBridge 규칙을 만듭니다. 이벤트 유형을 CloudTrail을 통한 AWS API 호출로 구성합니다. ServiceNow에서 인시던트를 생성하기 위해 AWS Systems Manager Automation 런북을 실행하도록 EventBridge 규칙을 구성합니다.**

이 접근 방식의 장점은 다음과 같습니다:

1. **자동화**: EventBridge 규칙을 사용하여 CloudTrail에서 보안 그룹 변경 이벤트를 자동으로 감지할 수 있습니다.
2. **운영 오버헤드 감소**: AWS Systems Manager Automation 런북을 사용하여 인시던트를 생성하는 작업을 자동화하므로 추가적인 관리 작업이 필요 없습니다.
3. **적시 대응**: 보안 그룹이 변경될 때마다 즉시 인시던트를 생성하여 민감한 워크로드에 대한 보안을 강화할 수 있습니다.

이 솔루션은 관리의 복잡성을 최소화하면서도 필요한 기능을 충족합니다.


고객은 ServiceNow를 AWS Systems Manager OpsCenter에서 운영 항목을 추적하기 위한 단일 위치로 사용할 수 있습니다. 이제 ServiceNow 사용자는 ServiceNow에서 기존 워크플로를 사용하면서 AWS 리소스와 관련된 운영 항목을 보고 조사하고 해결할 수 있습니다. 또한 ServiceNow의 AWS Systems Manager Automation 런북을 사용하여 알려진 문제를 해결할 수 있습니다. AWS Systems Manager OpsCenter를 사용하면 운영자가 중앙에서 AWS 리소스와 관련된 운영 항목을 추적하고 해결할 수 있으므로 문제 해결 시간을 단축할 수 있습니다.



## 질문 #458

회사는 AWS 계정에서 Amazon DynamoDB 테이블에 대한 태그 지정 요구 사항을 시행해야 합니다. SysOps 관리자는 적절한 태그가 없는 모든 DynamoDB 테이블을 식별하고 수정하는 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요?
A. 모든 DynamoDB 테이블을 평가하고 수정하기 위한 사용자 지정 AWS Lambda 함수를 만듭니다. Lambda 함수를 호출하기 위한 Amazon EventBridge 예약 규칙을 만듭니다.
B. 모든 DynamoDB 테이블을 평가하고 수정하기 위한 사용자 지정 AWS Lambda 함수를 만듭니다. Lambda 함수를 호출하기 위한 AWS Config 사용자 지정 규칙을 만듭니다.
C. 필수 태그 AWS Config 관리 규칙을 사용하여 모든 DynamoDB 테이블의 적절한 태그를 평가합니다. AWS
Systems Manager Automation 사용자 지정 런북을 사용하는 자동 수정 작업을 구성합니다.
D. 모든 DynamoDB 테이블의 적절한 태그를 평가하기 위해 Amazon EventBridge 관리 규칙을 만듭니다.
수정을 위해 AWS Systems Manager Automation 사용자 지정 런북을 실행하도록 EventBridge 규칙을 구성합니다.


이 요구 사항을 충족하기 위한 솔루션 중에서 최소한의 운영 오버헤드를 제공하는 옵션은 다음과 같습니다:

**C. 필수 태그 AWS Config 관리 규칙을 사용하여 모든 DynamoDB 테이블의 적절한 태그를 평가합니다. AWS Systems Manager Automation 사용자 지정 런북을 사용하는 자동 수정 작업을 구성합니다.**

이 접근 방식의 장점은 다음과 같습니다:

1. **자동화된 평가**: AWS Config 관리 규칙을 사용하면 DynamoDB 테이블의 태그를 자동으로 평가하고, 태그가 누락된 테이블을 식별할 수 있습니다.
2. **자동 수정**: AWS Systems Manager Automation 런북을 사용하여 적절한 태그가 없는 테이블을 자동으로 수정할 수 있으므로 수동 개입이 필요하지 않습니다.
3. **운영 오버헤드 감소**: AWS Config 및 Systems Manager를 사용하면 지속적으로 모니터링하고 수정할 수 있으므로 관리 부담이 줄어듭니다.

이러한 방식으로 태그 지정 요구 사항을 효과적으로 시행할 수 있습니다.


## 질문 #459

한 회사가 새로운 웹 애플리케이션으로의 트래픽을 증가시킬 마케팅 캠페인을 준비하고 있습니다. 이 애플리케이션은 애플리케이션 로직에 Amazon API Gateway와 AWS Lambda를 사용합니다. 이 애플리케이션은 하나의 Aurora Replica가 있는 Amazon Aurora MySQL DB 클러스터에 관련 사용자 데이터를 저장합니다. 이 애플리케이션에 대한 데이터베이스 쿼리는 5% 쓰기, 95% 읽기입니다.

트래픽이 증가할 때 SysOps 관리자는 데이터베이스를 확장하기 위해 무엇을 해야 합니까?
A. Aurora Replicas의 평균 CPU 사용률에 따라 클러스터에 Aurora Replicas를 추가하거나 제거하도록 Aurora Auto Scaling을 구성합니다.
B. Aurora Replicas의 평균 CPU 사용률에 따라 Aurora Replicas의 크기를 늘리거나 줄이도록 Aurora Auto Scaling을 구성합니다.
C. AWS Auto Scaling을 구성하여 Aurora 클러스터를 모니터링합니다. AWS Auto Scaling을 구성하여 기본 인스턴스의 평균 CPU 사용률을 기준으로 클러스터에서 Aurora 복제본을 추가하거나 제거합니다.
D. AWS Auto Scaling을 구성하여 Aurora 클러스터를 모니터링합니다. AWS Auto Scaling을 구성하여 기존 Aurora Replica의 평균 CPU 사용률을 기반으로 클러스터에서 Aurora Replica를 추가하거나 제거합니다.



이 시나리오에서 트래픽 증가로 인한 데이터베이스 쿼리의 읽기 비율이 95%임을 고려할 때, Amazon Aurora Replicas를 활용하여 읽기 성능을 개선하는 것이 중요합니다. Aurora Replicas는 읽기 요청을 분산시켜 데이터베이스의 성능을 향상시킬 수 있습니다.

따라서, SysOps 관리자가 데이터베이스를 확장하기 위해 수행해야 할 조치는 다음과 같습니다:

**A. Aurora Replicas의 평균 CPU 사용률에 따라 클러스터에 Aurora Replicas를 추가하거나 제거하도록 Aurora Auto Scaling을 구성합니다.**

이 옵션은 Aurora Auto Scaling을 사용하여 트래픽 증가에 따라 Aurora Replicas의 수를 자동으로 조절하여 읽기 성능을 유지하고 향상시킵니다. 이는 읽기 요청의 분산을 통해 데이터베이스의 전체적인 응답성을 개선하는 데 도움을 줄 수 있습니다.


## 질문 #460

한 회사가 Amazon S3를 사용하여 공개된 임시 정적 웹사이트를 설정하고 있습니다. SysOps 관리자가 기본 설정을 사용하여 S3 버킷을 만듭니다. SysOps 관리자가 S3 버킷 속성을 업데이트하여 정적 웹사이트 호스팅을 구성합니다. 그런 다음 SysOps 관리자가 인덱스 html 및 오류 html에 대한 콘텐츠가 포함된 객체를 업로드합니다. SysOps

관리자가 웹사이트 URL로 이동하면 SysOps 관리자는 HTTP 상태 코드 403: 금지됨(액세스 거부) 오류를 수신합니다.

SysOps 관리자는 이 오류를 해결하기 위해 무엇을 해야 합니까?
A. Amazon Route 53 DNS 항목을 만듭니다. 항목을 S3 버킷으로 지정합니다.
B. Block Public Access 설정을 꺼서 S3 버킷 권한을 편집합니다. S3 버킷에서 GetObject 액세스를 허용하는 버킷 정책을 만듭니다.
C. 인덱스 HTML 및 오류 HTML 파일에 대한 읽기 권한을 편집합니다.
D. Block Public Access 설정을 꺼서 S3 버킷 권한을 편집합니다. S3 버킷에서 PutObject 액세스를 허용하는 버킷 정책을 만듭니다.

HTTP 상태 코드 403: 금지됨(액세스 거부) 오류는 S3 버킷의 권한 설정 때문에 발생하는 경우가 많습니다. SysOps 관리자가 정적 웹사이트를 호스팅하기 위해 S3 버킷을 설정했으나, 해당 버킷의 공개 액세스가 차단되어 있거나 객체에 대한 읽기 권한이 부족할 수 있습니다.

이 문제를 해결하기 위해 SysOps 관리자는 다음과 같은 단계를 수행해야 합니다:

**B. Block Public Access 설정을 꺼서 S3 버킷 권한을 편집합니다. S3 버킷에서 GetObject 액세스를 허용하는 버킷 정책을 만듭니다.**

이 옵션은 S3 버킷이 퍼블릭 액세스를 허용하도록 설정하고, 인덱스 및 오류 HTML 파일에 대한 읽기 권한을 부여하여 웹사이트 URL에 접근할 수 있도록 합니다.

## 질문 #461

한 회사에 AWS 클라우드와 온프레미스에 리소스가 있는 내부 하이브리드 애플리케이션이 있습니다. 사용자는 애플리케이션을 사용할 수 없는 경우가 있다고 보고합니다. 이 회사는 AWS 사이트 간 VPN 연결의 터널 상태를 모니터링하기 위해 Amazon CloudWatch 알람을 구성했습니다.

SysOps 관리자는 VPN 터널이 다운될 때 내부 티켓팅 도구에서 높은 우선순위 티켓을 만드는 솔루션을 구현해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?
A. CloudWatch 알람에 대한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. 티케팅 도구의 엔드포인트를 SNS 토픽에 구독합니다.
B. CloudWatch 알람의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 만듭니다. 메시지를 티켓으로 변환하고 티켓을 티켓팅 도구의 엔드포인트에 게시하도록 대기열을 구성합니다.
C. AWS Lambda 함수를 만듭니다. CloudWatch 알람을 구성하여 Lambda 함수를 직접 호출하여 티켓팅 도구에서 개별 티켓을 만듭니다.
D. VPN 터널을 직접 모니터링하는 Amazon EventBridge 규칙을 만듭니다. 티켓팅 도구의 엔드포인트를 규칙의 대상으로 구성합니다.

SysOps 관리자가 AWS CloudWatch 알람을 사용하여 VPN 터널의 상태를 모니터링하고, 터널이 다운될 때 내부 티켓팅 도구에서 높은 우선순위 티켓을 생성하기 위한 가장 적합한 솔루션은 **AWS Lambda 함수를 사용하여 CloudWatch 알람을 구성하는 것입니다.** 이 방법은 CloudWatch 알람이 트리거되었을 때 Lambda 함수를 직접 호출하여 티켓팅 도구에서 티켓을 생성할 수 있습니다.

따라서 요구 사항을 충족하는 올바른 옵션은:

**C. AWS Lambda 함수를 만듭니다. CloudWatch 알람을 구성하여 Lambda 함수를 직접 호출하여 티켓팅 도구에서 개별 티켓을 만듭니다.**

이 방식은 VPN 터널의 상태를 실시간으로 감지하고 자동으로 티켓을 생성하는 데 유연성과 즉각성을 제공합니다.


## 질문 #462

SysOps 관리자가 실패한 AWS CloudFormation 스택 생성 문제를 해결하고 있습니다. SysOps 관리자가 문제를 식별하기 전에 스택과 해당 리소스가 삭제됩니다. 향후 배포를 위해 SysOps 관리자는 CloudFormation에서 성공적으로 생성한 모든 리소스를 보존해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?
A. 스택 생성 중에 DisableRollback 매개변수 값을 False로 설정합니다.
B. 스택 생성 중에 OnFailure 매개변수 값을 DO_NOTHING으로 설정합니다.
C. 스택 생성 중에 DO_NOTHING의 롤백 트리거가 있는 롤백 구성을 지정하세요.
D. 스택 생성 중에 OnFailure 매개변수 값을 ROLLBACK으로 설정합니다.


AWS CloudFormation 스택 생성 중에 리소스를 삭제하지 않고 보존하려면 **OnFailure 매개변수 값을 DO_NOTHING으로 설정하는 것이 가장 적절한 방법**입니다. 이렇게 하면 스택 생성 중에 오류가 발생해도 기존 리소스가 삭제되지 않고 그대로 유지됩니다.

따라서 요구 사항을 충족하기 위한 올바른 옵션은:

**B. 스택 생성 중에 OnFailure 매개변수 값을 DO_NOTHING으로 설정합니다.**

이 설정을 사용하면 실패한 경우에도 리소스가 보존되어 향후 배포나 문제 해결에 도움이 됩니다.


## 질문 #463 +++

회사는 인스턴스가 시작될 때 Amazon EC2 인스턴스에 특정 소프트웨어를 설치하는 솔루션을 구현해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

A. EC2 인스턴스를 시작할 때 필요한 소프트웨어로 부트스트랩하기 위해 AWS Systems Manager State Manager 연결을 구성합니다.
B. Amazon CloudWatch 에이전트를 사용하여 EC2 InstanceStart 이벤트를 감지하고 필요한 소프트웨어를 주입합니다. InstanceRole IAM 역할을 수정하여 StartTask API 작업에 대한 권한을 추가합니다.
C. Amazon Inspector를 사용하여 EC2 시작 이벤트를 감지합니다. EC2 시작 이벤트에 대한 라이프사이클 후크의 일부로 필요한 소프트웨어를 설치하도록 Amazon Inspector를 구성합니다.
D. AWS Security Hub 수정 작업을 사용하여 시작 시 필요한 소프트웨어를 설치합니다.


Amazon EC2 인스턴스가 시작될 때 특정 소프트웨어를 자동으로 설치하는 가장 효과적인 방법은 **AWS Systems Manager의 부트스트랩 기능을 활용하는 것입니다**. 이를 통해 인스턴스가 시작될 때 필요한 소프트웨어를 자동으로 설치할 수 있습니다. 

따라서 가장 적절한 솔루션은:

**A. EC2 인스턴스를 시작할 때 필요한 소프트웨어로 부트스트랩하기 위해 AWS Systems Manager State Manager 연결을 구성합니다.**

이 접근 방식은 인스턴스가 시작될 때 자동으로 지정된 작업을 수행하도록 설정할 수 있어, 관리와 자동화가 용이합니다.

## 질문 #464

한 회사에서 Amazon CloudWatch 알람을 사용하여 Amazon Elastic Kubernetes Service(Amazon EKS) 워크로드를 모니터링하고 있습니다. 

알람은 임계값 정의를 통해 시작되며 EKS 클러스터가 더 효율적으로 작동하는 데 도움이 되지 않습니다.

SysOps 관리자는 이상을 식별하고 이상을 해결하는 방법에 대한 권장 사항을 생성하는 솔루션을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?
A. CloudWatch 이상 감지를 사용하여 이상을 식별하고 권장 사항을 제공합니다.
B. Amazon DevOps Guru와 함께 CloudWatch Container Insights를 사용하여 이상을 식별하고 권장 사항을 제공합니다.
C. CloudWatch Container Insights를 사용하여 이상을 식별하고 권장 사항을 제공합니다.
D. CloudWatch Container Insights와 함께 CloudWatch 이상 감지 기능을 사용하여 이상을 식별하고 권장 사항을 제공합니다.


이 시나리오에서 EKS 클러스터의 이상을 식별하고 그에 대한 권장 사항을 제공하는 가장 적절한 솔루션은 **Amazon DevOps Guru와 함께 CloudWatch Container Insights를 사용하는 것입니다**. 

Amazon DevOps Guru는 머신 러닝을 활용하여 애플리케이션의 이상 징후를 식별하고 그에 대한 통찰력을 제공하는 서비스입니다. CloudWatch Container Insights는 EKS 클러스터와 같은 컨테이너화된 애플리케이션의 성능과 운영 상태를 모니터링하는 데 유용합니다. 이 두 서비스를 결합함으로써, SysOps 관리자는 EKS 워크로드의 이상을 보다 효과적으로 식별하고 해결할 수 있습니다.

따라서 가장 적절한 답변은:

**B. Amazon DevOps Guru와 함께 CloudWatch Container Insights를 사용하여 이상을 식별하고 권장 사항을 제공합니다.**
