https://free-braindumps.com/amazon/free-soa-c02-braindumps.html?p=60#answerQ54
https://www.secexams.com/exams/Amazon/aws-certified-developer-associate-dva-c02/view/?utm_source=mail


## 질문 #1
한 회사에는 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 실행되는 지옥의 웹 애플리케이션이 있습니다. 

인스턴스는 단일 가용성 영역의 Amazon EC2 자동 확장 그룹에서 실행됩니다. SysOps 관리자는 애플리케이션을 고가용성으로 만들어야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

A. 최대 사용 시 필요한 용량을 충족시키기 위해 자동 크기 조정 그룹의 최대 인스턴스 수를 늘립니다.

B. 최대 사용 시 필요한 용량을 충족시키기 위해 자동 크기 조정 그룹의 최소 인스턴스 수를 늘립니다.

C. 동일한 AWS 지역의 두 번째 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다. 가장 많이 투표된

D. 두 번째 AWS 지역의 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다.

정답: C. 동일한 AWS 지역의 두 번째 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다.

이유:
고가용성을 보장하려면 애플리케이션이 여러 가용성 영역(AZ)에 걸쳐 배포되어야 합니다. 이렇게 하면 한 가용성 영역에서 장애가 발생해도 애플리케이션은 다른 가용성 영역에서 계속 실행될 수 있습니다.

자동 크기 조정 그룹에 두 번째 가용성 영역을 추가하면, 여러 가용성 영역에 걸쳐 인스턴스를 배포할 수 있어 가용성과 내구성이 크게 향상됩니다.
AWS 지역 내 여러 가용성 영역을 사용하는 것이 고가용성 아키텍처를 구현하는 표준 방법입니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A와 B: 최대 또는 최소 인스턴스 수를 늘리는 것은 단일 가용성 영역 내에서만 작동하므로, 고가용성을 보장하지 못합니다. 장애가 발생하면 해당 영역의 모든 인스턴스가 중단될 수 있습니다.
D: 두 번째 AWS 지역으로 확장하는 것은 비용이 증가할 뿐만 아니라, 응답 지연 시간이 증가할 수 있습니다. 또한 동일한 AWS 지역 내 여러 가용성 영역을 사용하면 더 효율적이고 표준적인 고가용성 구성을 제공할 수 있습니다.


## 질문 #2
한 회사가 Auto Scaling 그룹에서 실행되는 여러 Amazon EC2 인스턴스에 웹사이트를 호스팅합니다. 

사용자는 매주 주말 오후 6시부터 오후 11시 사이의 피크 타임에 느린 응답을 보고합니다. SysOps 관리자는 이러한 피크 타임에 성능을 개선하기 위한 솔루션을 구현해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 피크 시간 전에 원하는 용량을 늘리기 위해 AWS Lambda 함수를 호출하는 예약된 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
B. 피크 시간 전후에 원하는 용량을 변경하기 위한 반복 옵션을 사용하여 예약된 확장 작업을 구성합니다. 가장 많이 투표된
C. 메모리 사용률이 70%를 넘을 경우 더 많은 인스턴스를 추가하는 대상 추적 확장 정책을 만듭니다.
D. 자동 크기 조정 그룹의 쿨다운 기간을 구성하여 피크 시간 전후에 원하는 용량을 수정합니다.

정답: B. 피크 시간 전후에 원하는 용량을 변경하기 위한 반복 옵션을 사용하여 예약된 확장 작업을 구성합니다.

이유:
예약된 확장 작업을 통해 피크 시간 전에 인스턴스 용량을 미리 늘리고, 피크 시간이 끝난 후 용량을 줄일 수 있습니다. 이렇게 하면 사용량 패턴에 따라 EC2 인스턴스의 수를 자동으로 조정할 수 있어 피크 타임 동안의 성능을 보장하면서도 비용을 효율적으로 관리할 수 있습니다.
반복 옵션을 사용하면 매주 주말 오후 6시부터 오후 11시 사이에 자동으로 확장 및 축소 작업을 실행할 수 있습니다. 이는 시스템을 수동으로 관리할 필요 없이 성능을 개선하는 운영 효율적인 방법입니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: Lambda 함수와 EventBridge 규칙을 사용하는 것은 가능하지만, 예약된 확장 작업을 구성하는 것보다 복잡하며 운영 효율성이 떨어집니다.
C: 대상 추적 확장 정책은 실시간으로 확장하지만, 피크 시간에 대한 사전 대비 없이 메모리 사용률이 높아졌을 때만 반응할 수 있어 즉각적인 성능 개선이 어렵습니다.
D: 쿨다운 기간은 인스턴스 수를 확장 또는 축소한 후에 추가 작업을 지연시키기 위한 설정으로, 피크 시간 전에 미리 확장하는 데는 적합하지 않습니다.


## 질문 #3
한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹사이트를 운영하고 있습니다. 

이 회사는 Amazon CloudFront 배포를 구성하고 ALB를 원점으로 설정했습니다. 이 회사는 모든 트래픽을 CloudFront 배포를 통해 보내기 위해 Amazon Route 53 CNAME 레코드를 만들었습니다. 의도치 않은 부작용으로 모바일 사용자에게 이제 데스크톱 버전의 웹사이트가 제공됩니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치를 취해야 합니까?

A. CloudFront 배포 동작을 구성하여 User-Agent 헤더를 전달합니다.
B. CloudFront 배포 오리진 설정을 구성합니다. 오리진 사용자 지정 헤더 목록에 User-Agent 헤더를 추가합니다.
C. ALB에서 IPv6를 활성화합니다. CloudFront 배포 원본 설정을 업데이트하여 dualstack 엔드포인트를 사용합니다.
D. CloudFront 배포에서 IPv6를 활성화합니다. Route 53 레코드를 업데이트하여 dualstack 엔드포인트를 사용합니다.


이 문제는 모바일 사용자가 데스크톱 버전의 웹사이트를 받는 문제와 관련이 있습니다. 
이를 해결하기 위해서는 CloudFront가 User-Agent 헤더를 올바르게 전달하여 원본 서버가 사용자의 디바이스 유형(모바일, 데스크톱)에 따라 적절한 버전을 제공할 수 있도록 해야 합니다.

정답: A. CloudFront 배포 동작을 구성하여 User-Agent 헤더를 전달합니다.
이유:
User-Agent 헤더는 사용자가 모바일 기기인지 데스크톱 기기인지 등을 서버에 전달하는 중요한 정보입니다. CloudFront가 기본적으로 일부 헤더를 캐시하여 성능을 최적화하는데, User-Agent 헤더가 전달되지 않으면 원본 서버는 디바이스를 구분할 수 없고, 디바이스에 맞는 적절한 콘텐츠를 제공하지 못할 수 있습니다.
CloudFront 배포에서 User-Agent 헤더를 전달하면, 원본 서버(이 경우 Application Load Balancer 뒤의 Amazon EC2 인스턴스)는 각 디바이스 유형에 맞는 콘텐츠를 적절하게 반환할 수 있습니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

B: 오리진 사용자 지정 헤더 목록에 User-Agent를 추가하는 것은 일반적으로 캐시 구성을 제어하는 데 사용되지 않으며, 단순히 오리진으로 헤더를 추가하는 것만으로는 문제를 해결할 수 없습니다.
C와 D: IPv6를 활성화하는 것은 네트워크 수준에서 트래픽을 처리하는 방식일 뿐, 모바일과 데스크톱 사용자 간의 웹사이트 버전 문제와는 직접적인 관련이 없습니다.

## 질문 #4
SysOps 관리자가 AWS 계정에서 AWS CloudTrail을 활성화했습니다.

CloudTrail이 비활성화된 경우 즉시 다시 활성화해야 합니다.
SysOps 관리자는 사용자 지정 코드를 작성하지 않고도 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. AWS 계정을 AWS Organizations에 추가합니다. 관리 계정에서 CloudTrail을 활성화합니다.
B. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용합니다. 가장 많이 투표된
C. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. CloudTrail을 활성화하기 위해 AWS Lambda 함수를 호출하도록 규칙을 구성합니다.
D. AWS Systems Manager Automation 문서를 실행하고 CloudTrail을 활성화하기 위한 일정 패턴을 사용하여 Amazon EventBridge(Amazon CloudWatch Event) 시간별 규칙을 만듭니다.


SysOps 관리자가 AWS CloudTrail이 비활성화될 때 자동으로 다시 활성화되도록 하려면, 사용자 지정 코드를 작성하지 않고 AWS에서 제공하는 자동화된 솔루션을 사용할 수 있습니다.

정답: B. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용합니다.
이유:
AWS Config는 AWS 리소스 구성을 추적하고 모니터링하는 서비스로, CloudTrail과 같은 리소스의 구성이 변경되었을 때 규칙을 트리거할 수 있습니다.
AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용하면 CloudTrail이 비활성화되었을 때 자동으로 다시 활성화됩니다. 이 자동화된 작업은 사용자 정의 코드 없이도 CloudTrail 구성을 보장할 수 있는 매우 효율적인 방법입니다.
이 방법은 AWS에서 제공하는 기본 기능을 활용하므로 관리가 쉽고 확장 가능합니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: AWS Organizations의 관리 계정에서 CloudTrail을 활성화할 수 있지만, 이 방법은 비활성화된 CloudTrail을 자동으로 다시 활성화하는 요구 사항을 충족하지 않습니다.
C: Lambda 함수를 사용하는 방법도 가능하지만, 사용자 지정 코드를 작성해야 하므로 더 복잡하고 운영 오버헤드가 증가합니다.
D: EventBridge 시간별 규칙을 사용하면 주기적으로 CloudTrail을 활성화할 수 있지만, CloudTrail이 비활성화된 시점을 즉시 감지하여 다시 활성화하는 데는 적합하지 않습니다. Config 규칙을 사용하는 것이 더 효율적입니다.

## 질문 #5
한 회사가 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 웹사이트를 호스팅합니다. 

이 회사는 Amazon Route 53으로 DNS를 관리하고 도메인의 존 에이펙스를 웹사이트로 가리키고 싶어합니다.
이러한 요구 사항을 충족하려면 어떤 유형의 레코드를 사용해야 합니까?

A. 도메인의 존 정점에 대한 AAAA 레코드
B. 도메인의 영역 정점에 대한 A 레코드
C. 도메인의 존 정점에 대한 CNAME 레코드
D. 도메인의 존 정점에 대한 별칭 레코드

도메인의 존 에이펙스(Apex, 즉 example.com와 같은 최상위 도메인)를 Application Load Balancer(ALB)에 연결하려면, CNAME 레코드는 사용할 수 없습니다. 대신 Amazon Route 53에서 제공하는 별칭(Alìas) 레코드를 사용하는 것이 적합합니다.

정답: D. 도메인의 존 정점에 대한 별칭 레코드
이유:
**별칭 레코드(Alìas Record)**는 Route 53에서 제공하는 기능으로, 특정 AWS 리소스(예: Application Load Balancer, CloudFront 배포, S3 버킷 등)로 도메인을 연결할 수 있습니다.
도메인의 존 에이펙스에는 CNAME 레코드를 사용할 수 없으므로, 별칭 레코드가 가장 적합한 선택입니다. 별칭 레코드는 또한 A 레코드와 유사하게 작동하여 IP 주소로의 변환을 처리합니다.
별칭 레코드는 Route 53이 제공하는 자동화된 기능을 활용해 트래픽 라우팅을 효율적으로 관리하며, 비용도 발생하지 않습니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: AAAA 레코드는 IPv6 주소를 가리키는 레코드입니다. ALB와 같은 AWS 리소스와 연결하는 데 일반적으로 사용되지 않습니다.
B: A 레코드는 IP 주소를 직접 가리키는 레코드로, AWS 리소스와 동적으로 연결할 수 없습니다.
C: CNAME 레코드는 존 정점(최상위 도메인)에 사용할 수 없으며, 하위 도메인(예: www.example.com)에서만 사용할 수 있습니다.

## 질문 #6
회사는 S3 버킷에 업로드된 모든 객체가 암호화되도록 해야 합니다.

다음 중 어떤 조치가 이 요구 사항을 충족할까요? (두 가지를 선택하세요.)

A. S3 버킷에 저장된 암호화되지 않은 객체로부터 보호하기 위해 AWS Shield를 구현합니다.
B. 암호화되지 않은 객체가 S3 버킷에 업로드되는 것을 거부하기 위해 객체 액세스 제어 목록(ACL)을 구현합니다.
C. Amazon S3 기본 암호화를 구현하여 업로드되는 모든 객체가 저장되기 전에 암호화되도록 합니다.
D. Amazon Inspector를 구현하여 S3 버킷에 업로드된 객체가 암호화되었는지 검사합니다.
E. 암호화되지 않은 객체가 버킷에 업로드되는 것을 거부하기 위해 S3 버킷 정책을 구현합니다.

Amazon S3 버킷에 업로드된 모든 객체가 암호화되도록 보장하기 위해서는 두 가지 방법을 사용할 수 있습니다: S3 기본 암호화와 버킷 정책을 통한 암호화 강제 적용입니다.

정답:
C. Amazon S3 기본 암호화를 구현하여 업로드되는 모든 객체가 저장되기 전에 암호화되도록 합니다.
E. 암호화되지 않은 객체가 버킷에 업로드되는 것을 거부하기 위해 S3 버킷 정책을 구현합니다.
이유:
C: Amazon S3 기본 암호화를 설정하면 모든 객체가 업로드될 때 자동으로 암호화됩니다. 기본 암호화는 객체가 저장되기 전에 암호화되므로, 사용자가 별도의 암호화 설정을 하지 않더라도 모든 객체가 보호됩니다.
E: S3 버킷 정책을 통해 특정 조건을 강제할 수 있습니다. 예를 들어, 객체가 업로드될 때 반드시 암호화 헤더가 포함되도록 요구하는 정책을 설정할 수 있으며, 이를 따르지 않는 업로드는 자동으로 거부됩니다. 이 방식은 S3 기본 암호화와 함께 사용될 때 더욱 효과적입니다.

다른 옵션들은 적합하지 않은 이유:
A: AWS Shield는 DDoS(분산 서비스 거부) 공격으로부터 보호하기 위한 서비스이며, 객체 암호화와는 관련이 없습니다.
B: 객체 ACL은 객체에 대한 읽기 및 쓰기 권한을 제어하는 것이며, 암호화 여부와 관련이 없습니다.
D: Amazon Inspector는 EC2 인스턴스, 컨테이너 이미지 등의 취약성을 검사하는 서비스로, S3 버킷 객체의 암호화 여부를 검사하는 기능은 제공하지 않습니다.


## 질문 #7
한 회사에는 Auto Scaling 그룹의 Amazon EC2 인스턴스에 호스팅된 상태 저장 웹 애플리케이션이 있습니다. 

인스턴스는 단일 대상 그룹이 있는 Application Load Balancer(ALB) 뒤에서 실행됩니다. ALB는 Amazon CloudFront 배포에서 원점으로 구성됩니다. 사용자는 웹 애플리케이션에서 무작위 로그아웃을 보고합니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. ALB 대상 그룹에서 가장 덜 처리된 요청 알고리즘으로 변경합니다.
B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.
C. CloudFront 배포 캐시 동작에서 헤더 전달을 구성합니다.
D. ALB 리스너 규칙에서 그룹 수준의 고정성을 활성화합니다.
E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.

무작위 로그아웃 문제는 세션이 EC2 인스턴스 간에 적절하게 유지되지 않기 때문에 발생할 수 있습니다. 특히 상태 저장 애플리케이션에서 세션 관리가 중요한데, 이는 스티키 세션(Sticky Session) 또는 세션 고정성을 통해 해결할 수 있습니다. 또한, CloudFront가 세션 관련 정보를 캐시하지 않도록 해야 합니다.

정답:
B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.
E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.

이유:
B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.

웹 애플리케이션이 세션 쿠키를 사용하여 사용자를 인증하고 세션을 유지한다면, CloudFront가 쿠키를 전달하지 않으면 세션 상태가 손실될 수 있습니다. CloudFront 배포에서 쿠키 전달을 구성하면, CloudFront가 세션 관련 정보를 제대로 처리하고 사용자에게 무작위 로그아웃 문제가 발생하지 않도록 할 수 있습니다.
E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.

스티키 세션(세션 고정성)을 활성화하면 사용자가 동일한 EC2 인스턴스에 지속적으로 연결됩니다. 이는 상태 저장 애플리케이션에서 사용자의 세션 상태를 유지하는 데 필수적입니다. 스티키 세션을 활성화하면 특정 사용자가 같은 인스턴스로 계속 연결되므로 세션이 유지됩니다.
다른 옵션들은 적합하지 않은 이유:
A: 덜 처리된 요청 알고리즘으로 변경하는 것은 트래픽을 분산시키는 방법일 뿐, 세션 관련 문제 해결과는 관련이 없습니다.
C: 헤더 전달은 쿠키 전달보다 덜 중요하며, 헤더가 세션 문제에 직접적인 영향을 미치지 않을 수 있습니다.
D: 그룹 수준의 고정성은 특정 리스너 규칙에 의존하는 것이며, 대상 그룹의 세션 고정성 관리와는 무관합니다. ALB 대상 그룹의 스티키 세션 설정이 더 적합한 해결책입니다.

## 질문 #8
한 회사가 AWS Lambda에서 서버리스 애플리케이션을 실행하고 있습니다. 

이 애플리케이션은 Amazon RDS for MySQL DB 인스턴스에 데이터를 저장합니다. 사용량이 꾸준히 증가했고, 최근 Lambda 함수가 데이터베이스에 연결을 시도할 때 "연결이 너무 많음" 오류가 많이 발생했습니다. 이 회사는 이미 가능한 최대 max_connections 값을 사용하도록 데이터베이스를 구성했습니다.
SysOps 관리자는 이러한 오류를 해결하기 위해 무엇을 해야 합니까?

A. 데이터베이스의 읽기 복제본을 만듭니다. Amazon Route 53을 사용하여 두 데이터베이스를 모두 포함하는 가중 DNS 레코드를 만듭니다.
B. Amazon RDS Proxy를 사용하여 프록시를 만듭니다. Lambda 함수에서 연결 문자열을 업데이트합니다.
C. 데이터베이스가 사용하는 매개변수 그룹의 max_connect_errors 매개변수 값을 늘립니다.
D. Lambda 함수의 예약된 동시성을 더 높은 값으로 업데이트합니다.

Lambda 함수가 데이터베이스에 연결을 시도할 때 "연결이 너무 많음" 오류가 발생하는 문제는 데이터베이스 연결 수가 제한된 상황에서 흔히 발생하는 문제입니다. 이 문제를 해결하기 위해 Amazon RDS Proxy를 사용하는 것이 가장 적합한 방법입니다.

정답:
B. Amazon RDS Proxy를 사용하여 프록시를 만듭니다. Lambda 함수에서 연결 문자열을 업데이트합니다.

이유:
Amazon RDS Proxy는 데이터베이스 연결을 관리하여 여러 Lambda 함수가 데이터베이스에 동시에 연결하는 문제를 완화시켜줍니다. 프록시는 연결을 풀링(pooling)하여 Lambda 함수가 데이터베이스와 직접 연결하지 않고 프록시를 통해 연결을 관리함으로써 데이터베이스에 대한 연결 수를 줄일 수 있습니다. 이렇게 하면 데이터베이스에 대한 연결이 최적화되고, "연결이 너무 많음" 오류를 방지할 수 있습니다.
다른 옵션들이 적합하지 않은 이유:

A: 읽기 복제본을 만들고 Route 53 가중 DNS 레코드를 설정하는 것은 읽기 요청 분산에 적합하지만, 이 문제는 연결 수에 관련된 문제이므로 해결책이 되지 않습니다.
C: max_connect_errors 매개변수는 데이터베이스의 연결 시도 오류 허용 한도를 제어하는 매개변수로, 연결 수 제한 문제를 해결하지는 못합니다.
D: Lambda 함수의 동시성을 증가시키는 것은 Lambda 함수가 실행되는 빈도나 동시성을 조절하는 것이며, 이는 데이터베이스 연결 수 문제와 직접적으로 관련이 없습니다. 오히려 더 많은 동시성이 더 많은 연결을 생성할 수 있어 문제가 악화될 수 있습니다.
RDS Proxy는 연결 관리 문제를 해결하는 가장 적절한 방법입니다.

## 질문 #9
SysOps 관리자가 10개의 Amazon EC2 인스턴스에 애플리케이션을 배포하고 있습니다. 

애플리케이션은 고가용성이어야 합니다. 인스턴스는 별도의 기본 하드웨어에 배치되어야 합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 단일 AWS 지역의 클러스터 배치 그룹으로 인스턴스를 시작합니다.
B. 여러 AWS 지역의 파티션 배치 그룹으로 인스턴스를 시작합니다.
C. 여러 AWS 지역에 분산된 배치 그룹으로 인스턴스를 시작합니다.
D. 단일 AWS 지역의 분산된 배치 그룹으로 인스턴스를 시작합니다.

애플리케이션이 고가용성을 요구하고, 인스턴스가 별도의 기본 하드웨어에 배치되어야 한다면, 분산된 배치 그룹을 사용하는 것이 적합합니다. 분산된 배치 그룹은 인스턴스가 서로 다른 물리적 하드웨어에 배치되도록 보장하며, 장애를 격리하는 데 효과적입니다.

정답:
D. 단일 AWS 지역의 분산된 배치 그룹으로 인스턴스를 시작합니다.

이유:
분산된 배치 그룹은 EC2 인스턴스를 서로 다른 물리적 하드웨어에 배치하여 단일 하드웨어 장애가 여러 인스턴스에 영향을 미치지 않도록 설계되었습니다. 따라서 고가용성을 보장하면서 인스턴스가 서로 다른 기본 하드웨어에 배치됩니다.
이 옵션은 단일 AWS 지역에서 고가용성을 유지하기 위한 적절한 선택입니다.

다른 옵션들이 적합하지 않은 이유:
A. 클러스터 배치 그룹은 저지연 네트워크 통신을 위해 인스턴스를 물리적으로 가까운 위치에 배치하는 방식으로, 하드웨어 중복성과 고가용성 요구사항에는 적합하지 않습니다.
B. 여러 AWS 지역의 파티션 배치 그룹은 지역 간 배포를 의미하지만, 파티션 배치 그룹은 특정 리소스 간의 장애 격리에 중점을 둡니다. 또한 다수의 지역을 사용할 필요는 없습니다.
C. 여러 AWS 지역에 분산된 배치 그룹은 고가용성을 위해 지역 간 배포를 의미하지만, 다중 지역 배포는 복잡성을 증가시키며 질문에서 요구하는 것은 단일 지역 내에서의 고가용성입니다.
따라서 단일 AWS 지역의 분산된 배치 그룹이 요구 사항을 충족하는 가장 적합한 선택입니다.

## 질문 #10
SysOps 관리자가 여러 Amazon EC2 인스턴스가 생성되는 AWS CloudFormation 템플릿의 문제를 해결하고 있습니다. 

템플릿은 us-east-1에서 작동하지만 us-west-2에서는
AMI [ami-12345678]이 존재하지 않음 이라는 오류 코드와 함께 실패합니다.
관리자는 AWS CloudFormation 템플릿이 모든 지역에서 작동하는지 어떻게 확인해야 합니까?

A. 소스 지역의 Amazon Machine Image(AMI)를 대상 지역에 복사하고 동일한 ID를 할당합니다.
B. AWS CloudFormation 템플릿을 편집하여 정규화된 AMI ID의 일부로 지역 코드를 지정합니다.
C. AWS::EC2::AMI::ImageID 컨트롤을 사용하여 AWS CloudFormation 템플릿을 편집하여 사용자에게 모든 AMI의 드롭다운 목록을 제공합니다.
D. "매핑" 섹션에 AMI ID를 포함하여 AWS CloudFormation 템플릿을 수정합니다. 적절한 AMI ID에 대한 템플릿 내의 적절한 매핑을 참조하세요.

이 문제는 특정 지역에서 사용 가능한 AMI가 다르기 때문에 발생합니다. 각 AWS 리전에서 고유한 AMI ID가 있으므로, 모든 지역에서 AWS CloudFormation 템플릿이 작동하도록 하려면 지역별로 다른 AMI ID를 지정할 수 있는 방법을 사용해야 합니다. 이를 위해 AWS CloudFormation 템플릿의 매핑 섹션을 사용하여 지역마다 올바른 AMI ID를 참조하게 할 수 있습니다.

정답:
D. "매핑" 섹션에 AMI ID를 포함하여 AWS CloudFormation 템플릿을 수정합니다. 적절한 AMI ID에 대한 템플릿 내의 적절한 매핑을 참조하세요.
이유:
매핑(Mappings) 섹션은 AWS CloudFormation에서 리전 또는 다른 조건에 따라 값을 달리 지정할 수 있게 해줍니다. 각 리전에 맞는 AMI ID를 매핑에 정의하고, Fn::FindInMap 함수로 적절한 값을 참조하도록 수정하면 템플릿이 여러 리전에서 작동하도록 할 수 있습니다.

예시 매핑 코드:
```yaml

Mappings:
  RegionMap:
    us-east-1:
      AMI: ami-12345678
    us-west-2:
      AMI: ami-87654321

Resources:
  MyEC2Instance:
    Type: "AWS::EC2::Instance"
    Properties:
      ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", AMI]
```

다른 옵션들이 적합하지 않은 이유:
A: 소스 지역의 AMI를 복사하고 동일한 ID를 할당하는 것은 불가능합니다. AWS에서는 AMI를 복사할 수 있지만, 복사된 AMI는 다른 리전에서 새로운 ID를 갖게 되므로 동일한 ID를 사용할 수 없습니다.
B: CloudFormation 템플릿에서 지역 코드에 따라 정규화된 AMI ID를 지정하는 방식은 존재하지 않습니다. AMI ID는 리전별로 고유합니다.
C: AWS::EC2::AMI::ImageID라는 리소스 타입은 존재하지 않으며, 사용자에게 AMI 목록을 제공하는 기능도 없습니다.
따라서 매핑을 통해 리전별 AMI ID를 설정하는 D 옵션이 가장 적합한 해결책입니다.


## 질문 #11
SysOps 관리자가 여러 Amazon EC2 인스턴스에서 공유 스토리지를 제공하기 위해 Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝하고 있습니다. 

인스턴스는 모두 여러 가용 영역에 걸쳐 동일한 VPC에 있습니다. 각 가용 영역에는 두 개의 인스턴스가 있습니다. SysOps 관리자는 가능한 가장 낮은 지연 시간으로 각 인스턴스에서 파일 시스템에 액세스할 수 있도록 해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. VPC에서 EFS 파일 시스템에 대한 마운트 대상을 만듭니다. 마운트 대상을 사용하여 각 인스턴스에서 파일 시스템을 마운트합니다.
B. VPC의 한 가용성 영역에 EFS 파일 시스템에 대한 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 파일 시스템을 마운트합니다. 다른 인스턴스와 디렉토리를 공유합니다.
C. 각 인스턴스에 대한 마운트 대상을 만듭니다. 각 마운트 대상을 사용하여 각 인스턴스에 EFS 파일 시스템을 마운트합니다.
D. VPC의 각 가용성 영역에 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 EFS 파일 시스템을 마운트합니다.


주어진 요구 사항에 따라 Amazon Elastic File System (EFS) 파일 시스템에 대한 최적의 솔루션을 선택해야 합니다. 이 경우, 모든 Amazon EC2 인스턴스가 여러 가용 영역에 걸쳐 동일한 VPC에 있으므로 각 인스턴스에서 가능한 가장 낮은 지연 시간으로 EFS에 액세스할 수 있도록 해야 합니다.

정답: D.VPC의 각 가용성 영역에 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 EFS 파일 시스템을 마운트합니다.

이유:
- EFS는 여러 가용 영역에 걸쳐서 고가용성과 내구성을 제공할 수 있습니다.
- 각 가용 영역에 마운트 대상을 만들면, 해당 가용 영역의 인스턴스가 EFS 파일 시스템에 직접적으로 연결되어 가장 낮은 지연 시간으로 액세스할 수 있습니다.
- 마운트 대상을 각 가용 영역에 설정하면, 네트워크 지연을 최소화하고 각 인스턴스가 EFS 파일 시스템에 효과적으로 접근할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
- **A**: 모든 인스턴스가 단일 마운트 대상을 사용할 경우, 네트워크 지연이 발생할 수 있습니다.
- **B**: 한 가용 영역에만 마운트 대상을 두면 다른 가용 영역의 인스턴스에서 높은 지연 시간으로 EFS에 액세스해야 합니다.
- **C**: 각 인스턴스에 대해 별도의 마운트 대상을 만드는 것은 비효율적이며, EFS의 이점을 제대로 활용하지 못합니다.


## 질문 #12
SysOps 관리자가 AWS CloudFormation 템플릿을 사용하여 VPC를 성공적으로 배포했습니다. 

SysOps 관리자는 AWS Organizations를 통해 관리되는 여러 계정에 동일한 템플릿을 배포하려고 합니다.
어떤 솔루션이 가장 적은 운영 오버헤드로 이 요구 사항을 충족할까요?

A. 관리 계정에서 OrganizationAccountAccessRole IAM 역할을 맡습니다. 각 계정에 템플릿을 배포합니다.
B. 각 계정에서 역할을 맡을 AWS Lambda 함수를 만듭니다. AWS CloudFormation CreateStack API 호출을 사용하여 템플릿을 배포합니다.
C. 계정 목록을 쿼리하기 위한 AWS Lambda 함수를 만듭니다. AWS CloudFormation CreateStack API 호출을 사용하여 템플릿을 배포합니다.
D. 관리 계정의 AWS CloudFormation StackSets를 사용하여 각 계정에 템플릿을 배포합니다.


주어진 시나리오에서 SysOps 관리자가 AWS CloudFormation 템플릿을 여러 AWS Organizations 계정에 배포하려고 할 때, 가장 적은 운영 오버헤드로 이 요구 사항을 충족할 수 있는 솔루션은 다음과 같습니다.

정답: D. 관리 계정의 AWS CloudFormation StackSets를 사용하여 각 계정에 템플릿을 배포합니다.

이유:
- **AWS CloudFormation StackSets**를 사용하면 여러 AWS 계정 및 리전에서 CloudFormation 스택을 동시에 관리하고 배포할 수 있습니다. 
- StackSets를 사용하면 단일 템플릿을 기반으로 여러 계정에 변경 사항을 쉽게 적용할 수 있으며, 중앙에서 관리하므로 운영 오버헤드가 줄어듭니다.
- 또한, StackSets는 IAM 권한과 관련하여 각 계정에 적절한 역할을 자동으로 처리할 수 있어 관리가 용이합니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
- A: 역할을 맡아 개별적으로 템플릿을 배포하는 것은 운영 오버헤드가 크고 관리가 복잡합니다.
- B: 각 계정에서 Lambda 함수를 만들어야 하며, 관리해야 할 코드가 많아져 운영 오버헤드가 증가합니다.
- C: 계정 목록을 쿼리하는 Lambda 함수를 만드는 것은 여전히 복잡성을 증가시키고, 여러 계정에 대해 수동으로 API 호출을 해야 하므로 비효율적입니다.

## 질문 #13
한 회사에서 계산을 위해 20개의 Amazon EC2 인스턴스로 구성된 플릿을 관리하기 위해 분산 컴퓨팅 소프트웨어를 실행하고 있습니다. 

플릿에는 계산을 실행하기 위한 2개의 제어 노드와 18개의 작업 노드가 포함되어 있습니다. 제어 노드는 자동으로 작업 노드를 시작할 수 있습니다.
현재 모든 노드는 주문형으로 실행됩니다. 제어 노드는 주 7일, 하루 24시간 이용 가능해야 합니다. 작업 노드는 매일 4시간씩 실행됩니다. SysOps 관리자는 이 솔루션의 비용을 최적화해야 합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하세요.)

A. 제어 노드에 대한 EC2 인스턴스 절약 플랜을 구매합니다. 가장 많이 투표된
B. 제어 노드에 전용 호스트를 사용합니다.
C. 작업 노드에 예약 인스턴스를 사용합니다.
D. 제어 노드에 Spot Instances를 사용합니다. Spot 가용성이 없는 경우 On-Demand Instances를 사용합니다.
E. 작업 노드에 Spot 인스턴스를 사용합니다. Spot 가용성이 없는 경우 On-Demand 인스턴스를 사용합니다. 가장 많이 투표된

이 시나리오에서 비용을 최적화하기 위한 두 가지 주요 선택지는 다음과 같습니다:

 A. **제어 노드에 대한 EC2 인스턴스 절약 플랜을 구매합니다.**
- **이유**: 제어 노드는 24/7 가동되어야 하기 때문에, 주문형(On-Demand) 인스턴스를 계속 사용하면 비용이 많이 듭니다. 대신 **EC2 절약 플랜(Savings Plan)**을 구매하면 특정 인스턴스 유형에 대해 장기적으로 비용을 절감할 수 있습니다. 절약 플랜은 특정 인스턴스 유형에 고정되지 않고, 다른 인스턴스 유형이나 AWS 서비스에도 적용될 수 있기 때문에 유연성이 높습니다. 이 플랜은 항상 가동해야 하는 제어 노드에 적합한 선택입니다.

 E. **작업 노드에 Spot 인스턴스를 사용합니다. Spot 가용성이 없는 경우 On-Demand 인스턴스를 사용합니다.**
- **이유**: 작업 노드는 매일 4시간만 사용되기 때문에 **Spot 인스턴스**를 활용하여 비용을 크게 절감할 수 있습니다. Spot 인스턴스는 미사용 EC2 용량을 저렴하게 제공하며, 짧은 시간 동안의 작업에 적합합니다. Spot 인스턴스가 가용하지 않을 때는 **On-Demand 인스턴스**를 사용하여 작업을 보장할 수 있습니다. 이는 작업 노드의 가동 시간을 충분히 고려하면서 비용 절감을 극대화할 수 있는 전략입니다.


 다른 옵션에 대한 설명:

- **B. 제어 노드에 전용 호스트를 사용합니다.**
  - **이유**: 전용 호스트는 비용이 매우 높으며, 제어 노드에 꼭 필요하지 않습니다. 이 옵션은 보안이나 라이선스 요구 사항이 있을 때 사용되며, 비용 절감에 적합하지 않습니다.

- **C. 작업 노드에 예약 인스턴스를 사용합니다.**
  - **이유**: 예약 인스턴스는 작업 노드에 적합하지 않습니다. 예약 인스턴스는 장기간 일정한 시간 동안 사용될 때 적합한 옵션인데, 작업 노드는 하루 4시간씩만 사용되므로 Spot 인스턴스가 더 저렴한 선택입니다.

- **D. 제어 노드에 Spot 인스턴스를 사용합니다. Spot 가용성이 없는 경우 On-Demand 인스턴스를 사용합니다.**
  - **이유**: 제어 노드는 24/7 항상 가동되어야 하므로 **Spot 인스턴스**처럼 일시적으로 가용하지 않을 수 있는 인스턴스 유형은 적합하지 않습니다. 제어 노드는 항상 안정적으로 가동될 필요가 있기 때문에, 이 옵션은 권장되지 않습니다.

---

결론적으로, **A**(제어 노드에 절약 플랜)와 **E**(작업 노드에 Spot 인스턴스) 조합이 이 시나리오에서 비용을 최적화하는 데 가장 적합한 선택입니다.


## 질문 #14
회사는 Amazon S3 버킷에서 매 시간 데이터 파일을 수신해야 합니다. 

S3 이벤트 알림은 파일이 도착할 때마다 AWS Lambda 함수를 호출합니다. 이 함수는 애플리케이션에서 사용할 수 있도록 데이터를 처리합니다.
애플리케이션 팀은 때때로 파일이 도착하지 않는다는 것을 알아차립니다. 애플리케이션 팀은 파일이 도착하지 않을 때마다 알림을 받고 싶어합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 지난 1시간 동안 생성된 객체로 제한된 범위로 S3 버킷에 S3 수명 주기 규칙을 추가합니다. 전환된 객체 수가 0일 때 수명 주기 전환에 의해 호출되는 다른 S3 이벤트 알림을 구성합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하여 애플리케이션 팀에 알립니다.
B. Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Lambda 함수를 호출하도록 다른 S3 이벤트 알림을 구성합니다. 대기열의 ApproximateAgeOfOldestMessage 메트릭이 1시간보다 클 때 애플리케이션 팀에 알리기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다.
C. Lambda 함수의 Invocations 메트릭이 1시간 동안 0일 때 애플리케이션 팀에 경고하기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다. 누락된 데이터를 위반으로 처리하도록 알람을 구성합니다. 가장 많이 투표된
D. S3 버킷에서 가장 최신 파일의 타임스탬프를 가져오는 새 Lambda 함수를 만듭니다. 타임스탬프가 1시간 전이면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하여 애플리케이션 팀에 알립니다. 매시간 새 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.

가장 운영 효율적인 솔루션은 옵션 C입니다.

C. Lambda 함수의 Invocations 메트릭이 1시간 동안 0일 때 애플리케이션 팀에 경고하기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다. 누락된 데이터를 위반으로 처리하도록 알람을 구성합니다.

이 솔루션은 다음과 같은 이유로 적합합니다:

운영 효율성: Lambda 함수의 Invocations 메트릭을 사용해 파일이 도착하지 않을 때 알림을 받을 수 있습니다. Lambda 함수가 호출되지 않으면 알림이 생성되므로 추가적인 커스텀 코드를 작성할 필요가 없습니다.

간단한 구성: AWS Lambda와 CloudWatch는 이미 설정된 메트릭을 기반으로 경고를 설정할 수 있으므로 추가적인 구성이나 복잡한 시스템 모니터링을 필요로 하지 않습니다.

자동화된 알림: Lambda가 호출되지 않는 상황을 바로 감지하여 SNS를 통해 알림을 받을 수 있습니다.
다른 옵션들에 비해 이 방법이 가장 직관적이고 관리하기 쉬운 방식입니다.


## 질문 #15
한 회사가 최근에 다른 회사와 그 회사의 모든 AWS 계정을 인수했습니다. 재무 분석가는 이러한 계정의 비용 데이터가 필요합니다.

SysOps 관리자는 Cost Explorer를 사용하여 비용 및 사용 보고서를 생성합니다. SysOps 관리자는 "No Tagkey"가 월 비용의 20%를 차지한다는 것을 알아챘습니다.
SysOps 관리자는 "No Tagkey" 리소스에 태그를 지정하기 위해 무엇을 해야 합니까?

A. AWS Organizations에 계정을 추가합니다. 서비스 제어 정책(SCP)을 사용하여 태그가 지정되지 않은 모든 리소스에 태그를 지정합니다.
B. AWS Config 규칙을 사용하여 태그가 지정되지 않은 리소스를 찾습니다. 리소스를 종료하기 위한 수정 작업을 설정합니다.
C. 비용 탐색기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다.
D. 태그 편집기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다. 가장 많이 투표된

정답은 **D. 태그 편집기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다**입니다.

**태그 편집기(Tag Editor)**는 AWS Management Console에서 제공하는 도구로, 여러 AWS 리소스를 한 번에 태그할 수 있습니다. SysOps 관리자는 태그가 지정되지 않은 리소스를 검색하고, 해당 리소스에 태그를 적용하여 "No Tagkey" 문제를 해결할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 서비스 제어 정책(SCP)은 태그를 지정하도록 강제할 수 없으며, AWS Organizations는 리소스를 직접 태그 지정하는 데 사용되지 않습니다.
- **B**: AWS Config 규칙을 사용하면 태그가 없는 리소스를 감지할 수 있지만, 리소스를 종료하는 것은 적절한 조치가 아닙니다.
- **C**: 비용 탐색기는 비용과 사용량 데이터를 분석할 수 있지만, 리소스에 직접 태그를 지정하는 기능은 제공하지 않습니다.

따라서, 가장 효율적인 방법은 태그 편집기를 사용하는 것이므로 **D**가 맞습니다.


## 질문 #16
AWS 관리형 VPN 연결을 설정하는 동안 SysOps 관리자가 AWS에서 고객 게이트웨이 리소스를 만듭니다. 

고객 게이트웨이 장치는 NAT 게이트웨이가 앞에 있는 데이터 센터에 있습니다.
고객 게이트웨이 리소스를 만드는 데 어떤 주소를 사용해야 합니까?

A. 고객 게이트웨이 장치의 개인 IP 주소
B. 고객 게이트웨이 장비 앞의 NAT 장비의 MAC 주소
C. 고객 게이트웨이 장치의 공용 IP 주소
D. 고객 게이트웨이 장치 앞에 있는 NAT 장치의 공용 IP 주소 가장 많이 투표된

정답은 **D. 고객 게이트웨이 장치 앞에 있는 NAT 장치의 공용 IP 주소**입니다.

AWS 관리형 VPN 연결에서 **고객 게이트웨이**는 AWS와 고객의 온프레미스 네트워크 간의 터널을 설정하는 데 사용됩니다. 고객 게이트웨이가 NAT 장치 뒤에 있을 경우, AWS는 고객 게이트웨이에 대한 직접적인 접근이 불가능하기 때문에 **NAT 장치의 공용 IP 주소**를 사용하여 VPN 터널을 설정해야 합니다.

다른 선택지에 대한 설명:
- **A**: 고객 게이트웨이 장치의 개인 IP 주소는 AWS에서 접근할 수 없으므로 사용할 수 없습니다.
- **B**: MAC 주소는 VPN 설정에 필요하지 않습니다.
- **C**: NAT 장치가 앞에 있으므로 고객 게이트웨이 장치의 공용 IP 주소가 아니라, NAT 장치의 공용 IP 주소를 사용해야 합니다.

따라서, **D**가 정답입니다.

## 질문 #17
한 회사에 매일 밤 여러 번 성능 문제가 발생하는 웹 애플리케이션이 있습니다. 

근본 원인 분석 결과 Amazon EC2 Linux 인스턴스에서 5분 동안 지속되는 CPU 사용률의 갑작스러운 증가가 나타났습니다. SysOps 관리자는 CPU를 더 많이 사용하는 서비스 또는 프로세스의 프로세스 ID(PID)를 찾아야 합니다. SysOps
관리자는 최소한의 노력으로 프로세스 사용률 정보를 수집하기 위해 무엇을 해야 합니까?

A. Amazon CloudWatch 에이전트 procstat 플러그인을 구성하여 CPU 프로세스 메트릭을 캡처합니다. 가장 많이 투표된
B. PID를 캡처하고 알림을 보내기 위해 1분마다 실행되도록 AWS Lambda 함수를 구성합니다.
C. 매일 밤 .pem 키를 사용하여 EC2 인스턴스에 로그인합니다. 그런 다음 top 명령을 실행합니다.
D. 기본 Amazon CloudWatch CPU 사용률 지표를 사용하여 CloudWatch에서 PID를 캡처합니다.

정답은 **A. Amazon CloudWatch 에이전트 procstat 플러그인을 구성하여 CPU 프로세스 메트릭을 캡처합니다**입니다.

**procstat 플러그인**은 Amazon CloudWatch 에이전트에서 제공하는 기능으로, 개별 프로세스의 CPU, 메모리 등의 성능 지표를 수집할 수 있습니다. 이를 통해 특정 프로세스의 CPU 사용률과 관련된 상세한 데이터를 얻고, 문제의 근본 원인을 쉽게 파악할 수 있습니다.

다른 선택지에 대한 설명:
- **B**: AWS Lambda 함수는 일반적으로 이벤트 기반 작업에 사용되며, PID 정보를 수집하기 위해 매 분마다 Lambda를 실행하는 것은 비효율적입니다.
- **C**: 매일 밤 EC2에 로그인하고 수동으로 `top` 명령을 실행하는 것은 자동화가 부족하고, 장기적으로 비효율적인 방법입니다.
- **D**: 기본 CloudWatch CPU 사용률 지표는 EC2 인스턴스 수준에서만 제공되며, 개별 프로세스(PID) 수준의 정보를 제공하지 않습니다.

따라서, **A**가 최선의 선택입니다.


## 질문 #18
SysOps 관리자가 하나의 Amazon Elastic Block Store(Amazon EBS) 볼륨이 연결된 단일 Amazon EC2 인스턴스에서 스냅샷을 캡처하도록 AWS Backup을 구성했습니다. 

첫 번째 스냅샷에서 EBS 볼륨에는 10GiB의 데이터가 있습니다. 두 번째 스냅샷에서 EBS 볼륨에는 여전히 10GiB의 데이터가 있지만 4GiB
가 변경되었습니다. 세 번째 스냅샷에서 2GiB의 데이터가 볼륨에 추가되어 총 12GiB가 되었습니다.
이러한 스냅샷을 저장하는 데 필요한 총 스토리지는 얼마입니까?

1. 12기가바이트
2. 16기가바이트 가장 많이 투표된
3. 26기가바이트
4. 32기가바이트

정답은 **B. 16기가바이트**입니다.

스냅샷은 Amazon EBS 볼륨의 **증분 백업**을 수행합니다. 즉, 첫 번째 스냅샷은 전체 데이터를 저장하지만, 이후 스냅샷은 변경된 데이터만 저장합니다. 이 경우, 스토리지 계산은 다음과 같이 이루어집니다:

1. **첫 번째 스냅샷**: 전체 데이터인 10GiB가 저장됩니다.
2. **두 번째 스냅샷**: 변경된 데이터 4GiB만 저장됩니다.
3. **세 번째 스냅샷**: 추가된 2GiB의 데이터만 저장됩니다.

따라서, 총 저장되는 데이터는 **10GiB + 4GiB + 2GiB = 16GiB**입니다.

따라서, 정답은 **B. 16기가바이트**입니다.

## 질문 #19
한 팀이 AWS Organizations의 조직 구성원인 AWS 계정을 관리하고 있습니다. 

조직은 통합 청구 기능을 활성화했습니다. 계정은 여러 애플리케이션을 호스팅합니다.
SysOps 관리자가 환경을 반영하기 위해 계정 내 리소스에 태그를 적용했습니다. 팀에는 환경별 요금 내역 보고서가 필요합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 태그 편집기에서 리소스 그룹을 필터링, 매핑하고 분류합니다.
B. 조직의 서비스 제어 정책(SCP)이 비용 할당 태그에 대한 액세스를 허용하는지 확인합니다.
C. Cost Explorer에 액세스하는 데 사용되는 IAM 자격 증명에 태그별로 비용을 그룹화할 수 있는 권한이 있는지 확인하세요.
D. 조직의 관리 계정에서 비용 할당을 위한 태그 키를 활성화합니다. 가장 많이 투표된

정답은 **D. 조직의 관리 계정에서 비용 할당을 위한 태그 키를 활성화합니다**입니다.

AWS에서는 **비용 할당 태그**를 사용하여 비용을 태그별로 세분화하고 분석할 수 있습니다. SysOps 관리자는 태그를 사용하여 환경별 비용 보고서를 생성하려면, 먼저 AWS Organizations 관리 계정에서 비용 할당을 위한 태그 키를 활성화해야 합니다. 이렇게 하면 해당 태그를 사용해 리소스 비용을 Cost Explorer에서 그룹화하고 분석할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 태그 편집기는 리소스를 태그별로 그룹화하는 데 사용될 수 있지만, 비용 분석을 위해서는 Cost Explorer와 비용 할당 태그가 필요합니다.
- **B**: SCP는 태그 액세스와 직접적인 관련이 없으며, 비용 할당 태그 활성화에 필요하지 않습니다.
- **C**: IAM 권한이 중요하지만, 우선적으로 비용 할당 태그를 활성화해야 태그별 비용을 그룹화할 수 있습니다.

따라서, **D**가 정답입니다.

## 질문 #20
한 회사에서 AWS CloudFormation 템플릿을 사용하여 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스를 프로비저닝합니다. 

SysOps 관리자는 EC2 인스턴스가 시작되기 전에 DB 인스턴스가 생성되도록 템플릿을 업데이트해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 템플릿에 대기 조건을 추가합니다. EC2 인스턴스가 시작된 후 신호를 보내도록 EC2 인스턴스 사용자 데이터 스크립트를 업데이트합니다.
B. EC2 인스턴스 리소스에 DependsOn 특성을 추가하고 RDS 리소스의 논리적 이름을 제공합니다. 가장 많이 투표된
C. 템플릿에서 리소스 순서를 변경하여 RDS 리소스가 EC2 인스턴스 리소스보다 앞에 나열되도록 합니다.
D. 여러 템플릿을 만듭니다. AWS CloudFormation StackSets를 사용하여 두 번째 스택이 생성되기 전에 한 스택이 완료될 때까지 기다립니다.

정답은 **B. EC2 인스턴스 리소스에 DependsOn 특성을 추가하고 RDS 리소스의 논리적 이름을 제공합니다**입니다.

AWS CloudFormation에서는 **DependsOn 특성**을 사용하여 리소스 간의 종속성을 정의할 수 있습니다. 이를 통해 특정 리소스가 다른 리소스가 완전히 생성된 후에 시작되도록 할 수 있습니다. 이 경우, EC2 인스턴스 리소스에 DependsOn 특성을 추가하여 RDS DB 인스턴스가 먼저 생성된 후 EC2 인스턴스가 시작되도록 지정할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 대기 조건과 신호는 리소스가 특정 상태에 도달했을 때까지 기다리도록 하는 방법이지만, 이 경우보다 간단하게 DependsOn을 사용하는 것이 더 적합합니다.
- **C**: 템플릿에서 리소스 순서를 변경하는 것은 리소스 생성 순서에 영향을 미치지 않습니다. CloudFormation은 리소스의 논리적 순서가 아닌 종속성을 기반으로 리소스를 생성합니다.
- **D**: 여러 템플릿을 만드는 것은 불필요하게 복잡한 방법이며, 하나의 템플릿 내에서 해결할 수 있습니다.

따라서, **B**가 가장 적절한 선택입니다.

## 질문 #21
한 회사가 Amazon S3에 정적 웹사이트를 호스팅합니다. 

이 웹사이트는 기본 TTL이 86,400초인 Amazon CloudFront 배포판에서 제공됩니다.
이 회사는 최근 웹사이트의 업데이트된 버전을 Amazon S3에 업로드했습니다. 그러나 사용자는 사이트를 새로 고칠 때 여전히 이전 콘텐츠를 봅니다. SysOps 관리자는 가능한 한 빨리 사용자에게 새 버전의 웹사이트를 표시해야 합니다.
이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. CloudFront 배포를 가리키는 DNS CNAME 레코드의 TTL 값을 조정합니다.

B. CloudFront 배포에서 이전 S3 객체에 대한 무효화를 생성합니다. 가장 많이 투표된

C. 새 CloudFront 배포를 만듭니다. DNS 레코드를 업데이트하여 새 CloudFront 배포를 가리킵니다.

D. 웹사이트의 DNS 레코드를 업데이트하여 S3 버킷을 가리키도록 합니다.


정답은 **B. CloudFront 배포에서 이전 S3 객체에 대한 무효화를 생성합니다**입니다.

Amazon CloudFront는 기본적으로 객체를 캐시하여 성능을 최적화합니다. 웹사이트를 업데이트한 후에도 사용자가 여전히 이전 콘텐츠를 보는 이유는 캐시된 콘텐츠가 만료되지 않았기 때문입니다. CloudFront에서 **무효화(invalidation)**를 생성하면 캐시된 객체를 제거하여 사용자에게 최신 콘텐츠를 제공할 수 있습니다. 

다른 선택지에 대한 설명:
- **A**: DNS CNAME 레코드의 TTL 값은 CloudFront 캐시와 관련이 없으며, 이를 조정해도 캐시된 콘텐츠 문제는 해결되지 않습니다.
- **C**: 새 CloudFront 배포를 만드는 것은 불필요하게 복잡한 작업입니다. 무효화를 통해 문제를 해결할 수 있습니다.
- **D**: S3 버킷을 직접 가리키도록 DNS를 업데이트하면 CloudFront의 캐싱 및 성능 이점을 잃게 됩니다. 이는 최선의 방법이 아닙니다.

따라서, **B**가 가장 적절한 솔루션입니다.


## 질문 #22
SysOps 관리자는 AWS CloudFormation을 사용하여 회사의 클라우드 인프라를 관리할 책임이 있습니다. 

SysOps 관리자는 여러 AWS 서비스로 구성된 단일 리소스를 만들어야 합니다. 리소스는 CloudFormation 콘솔을 통한 생성 및 삭제를 지원해야 합니다. SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 CloudFormation 리소스 유형을 만들어야 합니까?

A. cfn-init 헬퍼 스크립트가 있는 AWS::EC2::Instance
B. AWS::OpsWorks::인스턴스
C. AWS::SSM::문서
D. 사용자 정의::MyCustomType 가장 많이 투표된

정답은 **D. 사용자 정의::MyCustomType**입니다.

AWS CloudFormation에서 **사용자 정의 리소스**를 사용하면 여러 AWS 서비스로 구성된 복잡한 리소스를 만들 수 있습니다. 사용자 정의 리소스를 사용하면 CloudFormation 콘솔을 통해 리소스를 생성하고 삭제할 수 있으며, 필요에 따라 특정 로직이나 기능을 구현할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: `AWS::EC2::Instance`는 단일 EC2 인스턴스를 생성하는 리소스이며, 여러 AWS 서비스로 구성된 단일 리소스를 지원하지 않습니다.
- **B**: `AWS::OpsWorks::Instance`는 OpsWorks 서비스를 사용하는 인스턴스를 생성하는 리소스이지만, 여러 서비스로 구성된 리소스를 직접 지원하지는 않습니다.
- **C**: `AWS::SSM::Document`는 AWS Systems Manager에서 사용할 수 있는 문서 리소스를 생성하지만, CloudFormation 콘솔을 통한 리소스 생성 및 삭제의 요구 사항을 충족하지 않습니다.

따라서, 여러 AWS 서비스로 구성된 단일 리소스를 만들고 관리하기 위해서는 **D. 사용자 정의::MyCustomType**을 사용하는 것이 가장 적절합니다.

## 질문 #23
새로운 웹사이트는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 

Amazon Route 53은 DNS 레코드를 관리하는 데 사용됩니다.
웹사이트의 정점 도메인 이름(예: `company.com`)을 Application Load Balancer로 가리키기 위해 Route 53에 어떤 유형의 레코드를 설정해야 합니까?

1. CNAME
2. SOA
3. 텍스트
4. 별칭 가장 많이 투표된

정답은 **D. 별칭**입니다.

Amazon Route 53에서 **별칭 레코드**는 Route 53에서 제공하는 특별한 레코드 유형으로, Amazon Web Services(AWS) 리소스를 직접 가리킬 수 있습니다. Application Load Balancer(ALB)와 같은 AWS 리소스에 대해 별칭 레코드를 설정하면, ALB의 DNS 이름을 Route 53에서 가리킬 수 있으며, 사용자가 ALB를 통해 웹사이트에 접근할 수 있습니다. 

별칭 레코드는 루트 도메인(예: `company.com`)에서도 사용할 수 있어 CNAME 레코드보다 더 유용합니다. CNAME 레코드는 루트 도메인에 사용할 수 없기 때문입니다.

다른 선택지에 대한 설명:
- **A. CNAME**: CNAME 레코드는 서브도메인에 사용할 수 있지만, 루트 도메인에는 사용할 수 없습니다.
- **B. SOA**: SOA 레코드는 도메인 존의 시작을 나타내는 레코드로, DNS를 관리하는 데 필요하지만, ALB를 가리키기 위한 레코드는 아닙니다.
- **C. 텍스트**: TXT 레코드는 도메인에 대한 텍스트 정보를 저장하는 데 사용되며, ALB와는 관련이 없습니다.

따라서, 웹사이트의 정점 도메인 이름을 Application Load Balancer로 가리키기 위해서는 **D. 별칭** 레코드를 설정하는 것이 정답입니다.

## 질문 #24
한 회사가 AWS Trusted Advisor를 사용하여 보안 및 규정 준수를 구현하고 있습니다. 

회사의 SysOps 팀은 액세스할 수 있는 Trusted Advisor 검사 목록을 검증하고 있습니다.
사용 가능한 Trusted Advisor 검사의 양에 영향을 미치는 요소는 무엇입니까?

A. 최소한 하나의 Amazon EC2 인스턴스가 실행 상태인지 여부
B. AWS 지원 계획 가장 많이 투표된
C. AWS Organizations 서비스 제어 정책(SCP)
D. AWS 계정 루트 사용자가 다중 요소 인증(MFA)을 활성화했는지 여부

정답은 **B. AWS 지원 계획**입니다.

AWS Trusted Advisor의 기능은 고객이 선택한 **AWS 지원 계획**에 따라 다릅니다. 기본적인 지원 계획에서는 제한된 검사만 사용할 수 있지만, **Developer**, **Business**, 또는 **Enterprise** 지원 계획을 이용하면 더 많은 검사 및 권장 사항에 접근할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: EC2 인스턴스의 실행 여부는 Trusted Advisor의 검사 수에 직접적인 영향을 미치지 않습니다.
- **C**: 서비스 제어 정책(SCP)은 AWS Organizations 내에서 계정의 권한을 관리하는 데 사용되지만, Trusted Advisor 검사 목록에 직접적인 영향을 주지는 않습니다.
- **D**: MFA 활성화 여부는 보안 측면에서 중요하지만, Trusted Advisor 검사 수와는 관련이 없습니다.

따라서, Trusted Advisor에서 사용할 수 있는 검사의 양에 영향을 미치는 요소는 **B. AWS 지원 계획**입니다.

## 질문 #25
SysOps 관리자가 MariaDB DB 인스턴스용 Amazon RDS에서 문제를 조사하고 있습니다. 

SysOps 관리자는 자세한 대기 이벤트로 분류된 데이터베이스 부하를 표시하려고 합니다.
SysOps 관리자는 어떻게 이 목표를 달성할 수 있습니까?

A. Amazon CloudWatch 대시보드를 만듭니다.
B. Amazon RDS 성능 통찰력을 활성화합니다. 가장 많이 투표된
C. 향상된 모니터링을 활성화하고 구성합니다.
D. Amazon CloudWatch Logs에서 데이터베이스 로그를 검토합니다.

정답은 **C. 향상된 모니터링을 활성화하고 구성합니다**입니다.

**향상된 모니터링**을 활성화하면 Amazon RDS에서 MariaDB DB 인스턴스의 상세한 대기 이벤트 및 메트릭을 수집할 수 있습니다. 이 기능을 사용하면 데이터베이스의 CPU, 메모리, I/O 및 대기 이벤트와 같은 여러 지표를 실시간으로 모니터링하고, DB 인스턴스의 성능 문제를 더 잘 이해할 수 있습니다.

다른 선택지에 대한 설명:
- **A. Amazon CloudWatch 대시보드를 만듭니다**: CloudWatch 대시보드는 여러 메트릭을 시각화하는 데 유용하지만, 대기 이벤트와 같은 상세한 성능 메트릭은 향상된 모니터링을 통해 얻는 것이 더 정확합니다.
- **B. Amazon RDS 성능 통찰력을 활성화합니다**: 성능 통찰력은 데이터베이스 성능을 분석하는 데 유용하지만, 대기 이벤트에 대한 세부 정보를 직접적으로 제공하지는 않습니다.
- **D. Amazon CloudWatch Logs에서 데이터베이스 로그를 검토합니다**: CloudWatch Logs는 로그 정보를 제공하지만, 대기 이벤트에 대한 실시간 모니터링 및 메트릭을 제공하지 않습니다.

따라서, MariaDB DB 인스턴스에서 자세한 대기 이벤트를 확인하기 위해서는 **C. 향상된 모니터링을 활성화하고 구성하는 것**이 가장 적절한 방법입니다.

## 질문 #26
한 회사가 여러 가용성 영역에 분산된 Amazon EC2 인스턴스 세트에서 애플리케이션을 호스팅할 계획입니다. 

애플리케이션은 매초 수백만 건의 요청으로 확장할 수 있어야 합니다.
SysOps 관리자는 트래픽을 EC2 인스턴스로 분산하는 솔루션을 설계해야 합니다. 솔루션은 각 가용성 영역에 단일 정적 IP 주소를 사용하면서 갑작스럽고 불안정한 트래픽 패턴을 처리하도록 최적화되어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. Amazon Simple Queue Service(Amazon SQS) 대기열
B. 애플리케이션 로드 밸런서
C. AWS 글로벌 엑셀러레이터
D. 네트워크 로드 밸런서 가장 많이 투표된

정답은 **D. 네트워크 로드 밸런서**입니다.

**네트워크 로드 밸런서(NLB)**는 고속 TCP 및 UDP 트래픽을 처리할 수 있으며, 각 가용성 영역(AZ)에 단일 정적 IP 주소를 제공하는 기능을 가지고 있습니다. 이는 트래픽이 EC2 인스턴스로 효과적으로 분산되도록 하며, 갑작스럽고 불안정한 트래픽 패턴을 처리하는 데 최적화되어 있습니다. 

다른 선택지에 대한 설명:
- **A. Amazon Simple Queue Service (Amazon SQS) 대기열**: SQS는 메시지 큐 서비스로, 메시지를 비동기적으로 처리하는 데 적합하지만, 실시간 트래픽 분산에는 적합하지 않습니다.
- **B. 애플리케이션 로드 밸런서**: 애플리케이션 로드 밸런서는 HTTP/HTTPS 트래픽을 처리하는 데 최적화되어 있지만, 단일 정적 IP 주소를 제공하는 기능은 없으며, TCP 트래픽 처리에 있어 NLB보다 성능이 떨어질 수 있습니다.
- **C. AWS 글로벌 엑셀러레이터**: 글로벌 엑셀러레이터는 전 세계에 분산된 애플리케이션의 성능을 향상시키기 위한 서비스이지만, EC2 인스턴스 간의 트래픽 분산에는 직접적인 영향을 주지 않습니다.

따라서, **D. 네트워크 로드 밸런서**가 이러한 요구 사항을 충족하는 최적의 솔루션입니다.

## 질문 #27
SysOps 관리자가 AWS CloudFormation StackSets를 사용하여 동일한 AWS 계정의 두 AWS 리전에 AWS 리소스를 만들고 있습니다. 

한 리전에서 스택 작업이 실패하고 스택 인스턴스 상태가 OUTDATED로 반환됩니다.
이 실패의 원인은 무엇입니까?

A. CloudFormation 템플릿이 로컬 디스크에서 변경되어 CloudFormation에 제출되지 않았습니다.
B. CloudFormation 템플릿은 고유하지 않은 글로벌 리소스를 만들려고 합니다. 가장 많이 투표된
C. 스택이 아직 해당 지역에 배포되지 않았습니다.
D. SysOps 관리자가 CloudFormation API의 이전 버전을 사용하고 있습니다.

정답은 **B. CloudFormation 템플릿은 고유하지 않은 글로벌 리소스를 만들려고 합니다**입니다.

AWS CloudFormation StackSets는 여러 AWS 리전 또는 계정에 리소스를 배포할 수 있는 기능을 제공하지만, 글로벌 리소스(예: IAM, Route 53, S3 등)는 특정 리전에 종속되지 않으며, 이를 여러 리전에서 동시에 생성하려고 하면 충돌이 발생할 수 있습니다. 이러한 이유로 인해 스택 작업이 실패하고 상태가 OUTDATED로 반환될 수 있습니다.

다른 선택지에 대한 설명:
- **A**: CloudFormation 템플릿이 로컬 디스크에서 변경된 경우, 이는 작업 실패의 원인이 되지 않습니다. 스택 인스턴스의 상태는 템플릿 변경과는 무관하게 업데이트되며, 실패한 스택 인스턴스는 OUTDATED 상태로 표시됩니다.
- **C**: 스택이 아직 해당 지역에 배포되지 않았다면, 스택 인스턴스 상태가 OUTDATED가 아닌 PENDING 상태일 것입니다.
- **D**: CloudFormation API의 이전 버전을 사용하고 있다고 해서 특정 리전에서 스택 작업이 실패하는 것은 아닙니다. 

따라서, **B**가 스택 작업 실패의 올바른 원인입니다.

## 질문 #28
SysOps 관리자는 Amazon S3를 구성하여 간단한 비생산 웹페이지를 호스팅해야 합니다.

SysOps 관리자는 AWS Management Console에서 빈 S3 버킷을 만들었습니다. S3 버킷에는 기본 구성이 있습니다.
SysOps 관리자는 이 프로세스를 완료하기 위해 어떤 작업 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. "객체에 대한 요청 리디렉션" 기능을 사용하여 버킷 루트 URL을 가리키도록 S3 버킷을 구성합니다.
B. "모든 퍼블릭 액세스 차단" 설정을 끕니다. <Permission>WEBSITE</Permission>가 포함된 버킷 ACL을 사용하여 퍼블릭 액세스를 허용합니다.
C. "모든 퍼블릭 액세스 차단" 설정을 끕니다. AuthenticatedUsers 수혜자에게 액세스를 허용하는 버킷 ACL을 사용하여 퍼블릭 액세스를 허용합니다.
D. "모든 퍼블릭 액세스 차단" 설정을 끕니다. "Principal"을 허용하는 버킷 정책을 설정합니다: s3:GetObject 작업. 가장 많이 투표된
E. index.html 문서를 만듭니다. 정적 웹사이트 호스팅을 구성하고 인덱스 문서를 S3 버킷에 업로드합니다. 가장 많이 투표된


정답은 **D. "모든 퍼블릭 액세스 차단" 설정을 끕니다. "Principal"을 허용하는 버킷 정책을 설정합니다: s3:GetObject 작업.**와 **E. index.html 문서를 만듭니다. 정적 웹사이트 호스팅을 구성하고 인덱스 문서를 S3 버킷에 업로드합니다.**입니다.

## 선택 이유:
1. **D**: S3 버킷에 대해 "모든 퍼블릭 액세스 차단" 설정을 끄고, **버킷 정책**을 설정하여 공개적으로 객체에 접근할 수 있도록 허용해야 합니다. 이 정책은 `s3:GetObject` 작업을 허용하여 사용자가 S3 버킷의 콘텐츠를 접근할 수 있게 합니다.

2. **E**: 정적 웹사이트 호스팅을 활성화하려면 `index.html` 문서를 생성하고 이를 S3 버킷에 업로드해야 합니다. 그런 다음 S3에서 정적 웹사이트 호스팅을 설정하여 `index.html`을 기본 문서로 지정해야 합니다.

## 다른 선택지:
- **A**: "객체에 대한 요청 리디렉션" 기능은 정적 웹사이트를 호스팅하는 데 필요하지 않으며, 기본 구성이 필요합니다.
- **B**: "모든 퍼블릭 액세스 차단"을 끄는 것은 맞지만, **버킷 ACL**로 퍼블릭 액세스를 설정하는 것은 최선의 방법이 아닙니다. **버킷 정책**을 사용하는 것이 더 권장됩니다.
- **C**: AuthenticatedUsers 수혜자에게 액세스를 허용하는 것은 비생산 웹페이지의 목적에 부합하지 않으며, 퍼블릭 액세스를 완전히 허용하지 않습니다.

따라서, 올바른 조합은 **D**와 **E**입니다.

## 질문 #29
한 회사에서는 point-in-time 복구, 백트래킹, 자동 백업이 활성화된 Amazon Aurora MySQL DB 클러스터를 사용하고 있습니다. 

SysOps 관리자는 DB 클러스터를 이전 72시간 내의 특정 복구 지점으로 롤백할 수 있어야 합니다. 복원은 동일한 프로덕션 DB 클러스터에서 완료해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?


A. Aurora Replica를 생성합니다. 복제본을 홍보하여 ​​기본 DB 인스턴스를 대체합니다.
B. 기존 DB 클러스터에 자동 백업을 복원하는 AWS Lambda 함수를 생성합니다.
C. 백트래킹을 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 되돌립니다. 가장 많이 투표된
D. 지정 시점 복구를 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 복원합니다.

정답은 **C. 백트래킹을 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 되돌립니다**입니다.

## 선택 이유:
- **C. 백트래킹**: Amazon Aurora MySQL의 백트래킹 기능을 사용하면 DB 클러스터를 특정 시점으로 쉽게 되돌릴 수 있습니다. 이 기능은 72시간 이내의 복구 지점으로 롤백할 수 있는 기능을 제공합니다. 백트래킹은 실제 데이터를 변경하지 않고 특정 시점으로 데이터베이스를 되돌리는 매우 유용한 방법입니다.

## 다른 선택지:
- **A. Aurora Replica를 생성합니다. 복제본을 홍보하여 기본 DB 인스턴스를 대체합니다**: 이 방법은 클러스터의 복제를 제공할 수 있지만, 특정 복구 지점으로 롤백하는 것은 아닙니다.
  
- **B. 기존 DB 클러스터에 자동 백업을 복원하는 AWS Lambda 함수를 생성합니다**: 자동 백업을 복원할 수 있지만, 이 경우 기존 DB 클러스터에서 직접 복원할 수는 없습니다. 새로운 DB 클러스터를 생성하게 됩니다.
  
- **D. 지정 시점 복구를 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 복원합니다**: 지정 시점 복구는 새로운 DB 인스턴스를 생성하며, 기존 클러스터를 직접 복원하는 것이 아니기 때문에 요구 사항에 맞지 않습니다.

따라서, **C**가 요구 사항을 충족하는 최적의 솔루션입니다.

## 질문 #30
Amazon EC2 콘솔에서 작업하는 사용자가 Amazon EC2 Windows 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨의 크기를 늘렸습니다. 

변경 사항은 파일 시스템에 반영되지 않습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 운영 체제 수준 도구로 파일 시스템을 확장하여 새로운 저장 용량을 활용합니다. 가장 많이 투표된
B. EBS 볼륨을 EC2 인스턴스에 다시 연결합니다.
C. EBS 볼륨에 연결된 EC2 인스턴스를 재부팅합니다.
D. EBS 볼륨의 스냅샷을 찍습니다. 원래 볼륨을 스냅샷에서 생성된 볼륨으로 바꿉니다.


정답은 **A. 운영 체제 수준 도구로 파일 시스템을 확장하여 새로운 저장 용량을 활용합니다**입니다.

## 선택 이유:
- **A. 운영 체제 수준 도구로 파일 시스템을 확장**: Amazon EBS 볼륨의 크기를 늘린 후, 운영 체제의 파일 시스템도 해당 변경 사항을 인식하도록 확장해야 합니다. Windows에서는 Disk Management 도구를 사용하여 볼륨의 크기를 늘리거나 `diskpart` 명령어를 사용하여 크기를 조정할 수 있습니다. 이 단계를 수행해야만 새로 할당된 저장 용량을 사용할 수 있습니다.

## 다른 선택지:
- **B. EBS 볼륨을 EC2 인스턴스에 다시 연결합니다**: EBS 볼륨의 크기를 늘린 후에는 다시 연결할 필요가 없습니다. 이미 연결되어 있으므로 이 작업은 불필요합니다.
  
- **C. EBS 볼륨에 연결된 EC2 인스턴스를 재부팅합니다**: 인스턴스를 재부팅해도 파일 시스템의 크기는 자동으로 조정되지 않으며, 실제로는 운영 체제 수준에서 파일 시스템을 수동으로 확장해야 합니다.
  
- **D. EBS 볼륨의 스냅샷을 찍고 원래 볼륨을 스냅샷에서 생성된 볼륨으로 바꾼다**: 이 방법은 불필요한 작업입니다. EBS 볼륨 크기를 변경한 후 파일 시스템을 확장하는 것만으로도 충분합니다.

따라서, **A**가 문제를 해결하기 위한 올바른 방법입니다.


## 질문 #31
SysOps 관리자가 Amazon EC2 인스턴스를 사용하여 애플리케이션을 호스팅하고 있습니다. 

SysOps 관리자는 애플리케이션이 Amazon DynamoDB 테이블에 액세스할 수 있는 권한을 부여해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. DynamoDB 테이블에 액세스하기 위한 액세스 키를 만듭니다. 액세스 키를 EC2 인스턴스 프로필에 할당합니다.
B. DynamoDB 테이블에 액세스하기 위한 EC2 키 쌍을 만듭니다. 키 쌍을 EC2 인스턴스 프로필에 할당합니다.
C. DynamoDB 테이블에 액세스하기 위한 IAM 사용자를 만듭니다. EC2 인스턴스 프로필에 IAM 사용자를 할당합니다.
D. DynamoDB 테이블에 액세스하기 위한 IAM 역할을 만듭니다. EC2 인스턴스 프로필에 IAM 역할을 할당합니다. 가장 많이 투표된

정답은 **D. DynamoDB 테이블에 액세스하기 위한 IAM 역할을 만듭니다. EC2 인스턴스 프로필에 IAM 역할을 할당합니다**입니다.

## 선택 이유:
- **D. IAM 역할을 사용하여 EC2 인스턴스에 권한 부여**: IAM 역할은 AWS 서비스에 대한 권한을 관리하는 안전한 방법입니다. EC2 인스턴스에 IAM 역할을 할당하면, 해당 인스턴스에서 실행되는 애플리케이션이 IAM 역할에 부여된 권한을 사용하여 DynamoDB 테이블에 액세스할 수 있습니다. 이 방법은 보안성을 높이고, 액세스 키를 관리할 필요 없이 자동으로 자격 증명을 관리합니다.

## 다른 선택지:
- **A. 액세스 키를 만듭니다**: 액세스 키를 사용하면 보안 문제가 발생할 수 있습니다. 또한 EC2 인스턴스에 액세스 키를 직접 할당하는 것은 안전하지 않습니다.
  
- **B. EC2 키 쌍을 만듭니다**: 키 쌍은 EC2 인스턴스에 대한 SSH 액세스를 위한 것이지, DynamoDB에 대한 액세스 권한을 부여하지 않습니다.

- **C. IAM 사용자를 만듭니다**: IAM 사용자를 생성하는 것은 가능하지만, EC2 인스턴스에 IAM 사용자 권한을 직접 할당하는 것은 권장되지 않습니다. 대신 IAM 역할을 사용하는 것이 더 안전하고 관리하기 쉽습니다.

따라서, **D**가 가장 적절한 솔루션입니다.



## 질문 #32
SysOps 관리자가 Amazon S3 버킷의 객체를 실수로 덮어쓰거나 삭제하지 못하도록 보호하려고 합니다. 

현재가 아닌 객체는 90일 동안 보관한 다음 영구적으로 삭제해야 합니다. 객체는 원래 S3 버킷과 동일한 AWS 리전에 있어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. S3 버킷에 대한 Amazon Data Lifecycle Manager(Amazon DLM) 수명 주기 정책을 만듭니다. 90일 후에 비현재 객체를 삭제하는 규칙을 수명 주기 정책에 추가합니다.
B. S3 버킷에 대한 AWS 백업 정책을 만듭니다. 90일 후에 비현재 객체를 만료하는 라이프사이클을 포함하는 백업 규칙을 만듭니다.
C. S3 버킷에서 S3 크로스 리전 복제를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다.
D. S3 버킷에서 S3 버전 관리를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다. 가장 많이 투표된

가장 적합한 솔루션은 **D. S3 버킷에서 S3 버전 관리를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다.**

이유:

1. **S3 버전 관리 활성화**:  
   S3 버전 관리를 활성화하면 객체가 실수로 덮어써지거나 삭제되는 것을 방지할 수 있습니다. 버전 관리가 활성화된 버킷에서는 객체가 수정되거나 삭제될 때 이전 버전이 보존되며, 이를 통해 의도하지 않은 수정이나 삭제를 복구할 수 있습니다.

2. **라이프사이클 정책**:  
   라이프사이클 정책을 사용하면 S3 버킷에서 **비현재(non-current) 객체**를 90일 동안 유지하고 이후에 자동으로 삭제할 수 있습니다. 이는 객체가 덮어쓰여지거나 삭제된 후에도 이전 버전을 90일 동안 유지하면서 비용을 절감하고, 수동 작업 없이 자동으로 오래된 객체를 삭제할 수 있습니다.


다른 선택지에 대한 설명:

- **A. S3 버킷에 대한 Amazon Data Lifecycle Manager(Amazon DLM) 수명 주기 정책**:
  - **Amazon DLM**은 EBS 볼륨의 스냅샷 관리에 주로 사용되며, S3 객체 관리에는 적합하지 않습니다.

- **B. S3 버킷에 대한 AWS 백업 정책**:
  - **AWS 백업**은 다양한 AWS 리소스의 백업 및 복구를 관리하는 서비스이지만, S3 객체에 대한 백업과 수명 주기 관리는 S3 라이프사이클 정책과 버전 관리로 처리하는 것이 더 적합합니다.

- **C. S3 버킷에서 S3 크로스 리전 복제를 활성화**:
  - 크로스 리전 복제는 객체를 다른 AWS 리전으로 복제하는 기능입니다. 그러나 이 시나리오에서는 동일한 리전 내에서 객체를 관리해야 하며, 이 방식은 요구사항과 일치하지 않습니다.

결론적으로, **D 옵션**은 S3 버전 관리를 통해 실수로 객체가 삭제되거나 덮어쓰여지는 것을 방지하고, 라이프사이클 정책을 통해 90일 후에 비현재 객체를 삭제하는 요구 사항을 충족합니다.


## 질문 #33
한 회사에 고객이 웹사이트에서 레코드를 검색하는 데 사용하는 애플리케이션이 있습니다. 

애플리케이션의 데이터는 Amazon Aurora DB 클러스터에 저장됩니다. 애플리케이션의 사용은 계절과 요일에 따라 다릅니다.
웹사이트의 인기가 증가하고 있으며, 활동이 가장 많은 기간에 DB 클러스터에 부하가 증가하여 웹사이트 성능이 저하되고 있습니다. 애플리케이션 로그에 따르면 성능 문제는 사용자가 정보를 검색할 때 발생합니다. 동일한 검색을 여러 번 수행하는 경우는 드뭅니다.
SysOps 관리자는 리소스 효율성을 극대화하는 솔루션을 사용하여 플랫폼의 성능을 개선해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. DB 클러스터 앞에 Amazon ElastiCache for Redis 클러스터를 배포합니다. 애플리케이션이 데이터베이스에 새 쿼리를 발행하기 전에 캐시를 확인하도록 애플리케이션을 수정합니다. 모든 쿼리의 결과를 캐시에 추가합니다.
B. DB 클러스터에 Aurora Replica를 배포합니다. 검색 작업에 리더 엔드포인트를 사용하도록 애플리케이션을 수정합니다. Aurora Auto Scaling을 사용하여 부하에 따라 복제본 수를 확장합니다. 가장 많이 투표된
C. DB 클러스터를 지원하는 스토리지 볼륨에서 프로비저닝된 IOPS를 사용하여 애플리케이션의 최대 부하를 지원할 수 있을 만큼 성능을 ​​향상시킵니다.
D. DB 클러스터의 인스턴스 크기를 애플리케이션의 최대 부하를 지원하기에 충분한 크기로 늘립니다. Aurora Auto Scaling을 사용하여 부하에 따라 인스턴스 크기를 조정합니다.

이 문제에서 성능 저하의 주요 원인은 데이터베이스에 대한 읽기 부하입니다. 애플리케이션 로그에 따르면, 사용자가 정보를 검색할 때 성능 문제가 발생하고, 동일한 검색이 여러 번 발생하지는 않습니다. 따라서 효율적으로 데이터를 캐싱하거나 읽기 성능을 확장할 수 있는 방법이 필요합니다.

가장 적합한 솔루션은 **B. DB 클러스터에 Aurora Replica를 배포합니다. 검색 작업에 리더 엔드포인트를 사용하도록 애플리케이션을 수정합니다. Aurora Auto Scaling을 사용하여 부하에 따라 복제본 수를 확장합니다.**

이유:

1. **Aurora Replica를 사용한 읽기 성능 확장**:
   - Aurora는 읽기 작업을 처리하기 위해 **읽기 전용 복제본(Replica)**을 추가할 수 있습니다. 복제본을 추가하면 읽기 요청을 이 복제본으로 분산시켜 DB 클러스터의 **읽기 부하를 완화**할 수 있습니다. 이는 사용자가 데이터를 검색할 때 성능 문제를 해결하는 데 매우 효과적입니다.
   
2. **Aurora Auto Scaling**:
   - Aurora는 **Auto Scaling**을 지원하므로, 복제본의 수를 자동으로 확장하거나 축소하여 애플리케이션의 부하에 맞춰 DB 성능을 최적화할 수 있습니다. 계절성과 요일에 따라 애플리케이션의 부하가 달라진다면 Auto Scaling이 유연한 확장 및 축소 기능을 제공합니다.
   
3. **리더 엔드포인트 사용**:
   - 애플리케이션에서 **리더 엔드포인트**를 사용하도록 수정하면 여러 Aurora 복제본으로 읽기 요청을 자동으로 라우팅할 수 있습니다. 이를 통해 데이터베이스의 부하를 분산시키고 성능을 개선할 수 있습니다.

---

다른 선택지에 대한 설명:

- **A. ElastiCache for Redis를 사용한 캐시 적용**:
  - ElastiCache는 자주 사용되는 데이터에 대해 캐시를 제공하여 성능을 개선할 수 있지만, 문제의 근본 원인이 동일한 쿼리가 자주 반복되지 않는 것이라서 이 옵션은 효율성이 떨어질 수 있습니다. 따라서 이 상황에서는 캐시보다는 Aurora 복제본을 사용하여 읽기 성능을 확장하는 것이 더 적합합니다.

- **C. 프로비저닝된 IOPS 사용**:
  - 프로비저닝된 IOPS는 주로 **쓰기 성능**을 향상시키기 위해 사용됩니다. 이 시나리오에서 성능 문제는 **읽기 작업**에 의해 발생하므로, 프로비저닝된 IOPS를 사용하는 것은 적절하지 않습니다.

- **D. 인스턴스 크기 증가 및 Auto Scaling**:
  - Aurora의 인스턴스 크기를 늘리는 것은 일시적으로 성능을 향상시킬 수 있지만, 부하가 변동하는 상황에서는 인스턴스 크기를 증가시키는 것만으로는 장기적인 해결책이 아닙니다. 복제본을 추가하여 읽기 작업을 분산하는 것이 더 효율적이고 비용 절감에도 유리합니다.


따라서 **B 옵션**은 부하를 효과적으로 분산시키고, Aurora의 자동 확장 기능을 통해 유동적인 트래픽 변화에 대응할 수 있으므로 가장 적합한 솔루션입니다.

## 질문 #34
한 회사가 AWS Organizations를 사용하여 여러 AWS 계정을 관리합니다. 

회사 정책에 따라 특정 AWS 지역만 고객 데이터를 저장하고 처리하는 데 사용할 수 있습니다. SysOps 관리자는 회사의 모든 사람이 승인되지 않은 지역에서 Amazon EC2 인스턴스를 프로비저닝하는 것을 방지해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 모든 리전에서 AWS CloudTrail을 구성하여 모든 API 활동을 기록합니다. 모든 승인되지 않은 리전에서 ec2:RunInstances 이벤트에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. AWS Lambda를 사용하여 시작된 EC2 인스턴스를 종료합니다.

B. 각 AWS 계정에서 Region 조건을 사용하여 모든 승인되지 않은 Region에서 ec2:RunInstances 작업을 거부하는 관리형 IAM 정책을 만듭니다. 이 정책을 각 AWS 계정의 모든 IAM 그룹에 연결합니다.

C. 각 AWS 계정에서 Region 조건을 사용하여 모든 승인되지 않은 Region에서 ec2:RunInstances 작업을 거부하는 IAM 권한 경계 정책을 만듭니다. 각 AWS 계정의 모든 IAM 사용자에게 권한 경계 정책을 연결합니다.

D. AWS Organizations에서 서비스 제어 정책(SCP)을 만들어 모든 승인되지 않은 Regions에서 ec2:RunInstances 작업을 거부합니다. 이 정책을 조직의 루트 수준에 연결합니다. 가장 많이 투표된


이 시나리오에서 회사의 모든 AWS 계정이 승인되지 않은 지역에서 Amazon EC2 인스턴스를 프로비저닝하는 것을 방지하기 위한 가장 운영 효율적인 솔루션은 
**D. AWS Organizations에서 서비스 제어 정책(SCP)을 만들어 모든 승인되지 않은 Regions에서 ec2:RunInstances 작업을 거부합니다. 이 정책을 조직의 루트 수준에 연결합니다.**

### 이유:

1. **서비스 제어 정책(SCP)**:
   - SCP는 AWS Organizations의 핵심 기능으로, 조직의 모든 계정에 적용할 수 있는 권한 정책입니다. SCP를 사용하면 특정 AWS 서비스 및 API 작업에 대한 액세스를 전역적으로 제어할 수 있습니다. 이 경우 EC2 인스턴스를 특정 지역에서만 실행할 수 있도록 제한하는 SCP를 설정할 수 있습니다.

2. **조직의 루트 수준에서 적용**:
   - SCP는 조직의 루트 수준에서 설정할 수 있으며, 모든 하위 계정에 일관되게 적용됩니다. 이렇게 하면 각 계정의 IAM 정책을 따로 관리할 필요 없이, 중앙 집중식으로 관리할 수 있어 운영 효율성이 높아집니다.

3. **정책 관리의 용이성**:
   - SCP를 사용하면 새로운 계정을 추가할 때마다 정책을 별도로 적용할 필요 없이 조직 내 모든 계정에 자동으로 적용됩니다. 이를 통해 정책 관리의 복잡성을 줄일 수 있습니다.

---

### 다른 선택지에 대한 설명:

- **A. 모든 리전에서 AWS CloudTrail을 구성하여 모든 API 활동을 기록**:
  - CloudTrail은 API 호출을 기록하는 도구로, 이를 통해 비승인 지역에서 인스턴스가 생성된 경우 로그를 통해 확인할 수는 있지만, 이를 막는 방법이 아닙니다. Lambda 함수를 통해 인스턴스를 종료하는 것도 운영적으로 복잡하고 실시간으로 방지할 수는 없습니다.

- **B. 각 AWS 계정에서 Region 조건을 사용하여 IAM 정책을 만들기**:
  - IAM 정책은 특정 계정에만 적용되며, 정책을 각 계정의 모든 IAM 그룹에 수동으로 연결해야 합니다. 여러 계정을 관리하는 환경에서는 관리가 복잡해질 수 있습니다.

- **C. IAM 권한 경계 정책 만들기**:
  - 권한 경계는 IAM 정책의 최대 권한을 정의하는 것이지만, 모든 계정에서 이를 관리해야 하며 SCP처럼 중앙 집중적으로 관리하기 어려워집니다.

---

결론적으로, **D 옵션**은 AWS Organizations의 SCP를 사용하여 모든 계정에서 승인되지 않은 지역에서 EC2 인스턴스를 실행하는 것을 효과적으로 차단할 수 있으며, 운영 효율성을 극대화하는 가장 적합한 솔루션입니다.


## 질문 #35
회사의 공개 웹사이트는 Amazon CloudFront 배포판 뒤에 있는 us-east-1 지역의 Amazon S3 버킷에 호스팅됩니다. 

회사는 웹사이트가 DDoS 공격으로부터 보호되도록 하려고 합니다. SysOps 관리자는 회사가 DDoS 보호가 적용되는 속도 제한을 제어할 수 있는 솔루션을 배포해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 기본 작업 허용을 사용하여 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다. 가장 많이 투표된
B. us-east-1에서 allow default action을 사용하여 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 S3 버킷과 연결합니다.
C. 블록 기본 작업으로 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 허용하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다.
D. us-east-1에서 block default action을 사용하여 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 허용하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 S3 버킷과 연결합니다.

가장 적합한 솔루션은 **A. 기본 작업 허용을 사용하여 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다.**

### 이유:

1. **CloudFront 배포와 AWS WAF의 통합**:
   - **Amazon CloudFront**는 DDoS 공격에 대한 첫 번째 방어선으로 사용될 수 있습니다. CloudFront는 전역적으로 분산된 엣지 네트워크를 통해 콘텐츠를 캐싱하고 전송하기 때문에 DDoS 공격으로부터 자연스럽게 보호합니다.
   - **AWS WAF(웹 애플리케이션 방화벽)**를 CloudFront와 함께 사용하면 웹사이트에 대한 트래픽을 제어하고 보호할 수 있습니다. CloudFront 배포에 AWS WAF 웹 ACL을 연결하면 DDoS 공격 시 특정 트래픽을 필터링하고 차단할 수 있습니다.

2. **속도 기반 규칙**:
   - **속도 기반 규칙**을 사용하면 IP 주소당 요청 수를 제한할 수 있습니다. DDoS 공격은 대량의 요청을 생성하므로, 속도 기반 규칙을 통해 일정량 이상의 요청을 감지하여 차단하는 것이 매우 효과적입니다.

3. **기본 작업 허용**:
   - 기본 작업을 "허용"으로 설정하면 일반적인 트래픽은 계속 허용되고, 속도 기반 규칙에 따라 과도한 트래픽만 차단됩니다. 이는 정상적인 사용자에게 영향을 최소화하면서 DDoS 공격을 방어할 수 있는 방식입니다.

---

### 다른 선택지에 대한 설명:

- **B. AWS WAF 웹 ACL을 S3 버킷에 연결**:
  - AWS WAF는 직접 S3 버킷과 통합되지 않으므로, WAF 웹 ACL을 S3 버킷과 연결하는 것은 불가능합니다. WAF는 CloudFront나 Application Load Balancer(ALB)와 같은 프런트엔드 서비스와 통합되어야 합니다.

- **C. 블록 기본 작업으로 글로벌 범위의 AWS WAF 웹 ACL을 배포**:
  - 기본 작업을 "차단"으로 설정하면 대부분의 트래픽이 차단되며, 이로 인해 정상적인 트래픽까지도 차단될 가능성이 있습니다. 이 옵션은 서비스 가용성에 부정적인 영향을 미칠 수 있습니다.

- **D. AWS WAF 웹 ACL을 us-east-1에 배포하고 S3 버킷과 연결**:
  - AWS WAF는 S3 버킷과 직접 연결할 수 없으며, CloudFront를 통해 웹 트래픽을 처리해야 합니다. 그리고 글로벌 배포가 아닌 리전에 종속된 배포는 CloudFront를 보호하는 데 적합하지 않습니다.

---

결론적으로, **A 옵션**은 CloudFront와 AWS WAF의 글로벌 범위 웹 ACL을 사용해 트래픽을 보호하고, 속도 기반 규칙을 통해 DDoS 공격으로부터 웹사이트를 효과적으로 방어할 수 있는 최적의 솔루션입니다.


## 질문 #36
SysOps 관리자가 AWS SDK를 사용하여 여러 유지 관리 작업을 수행하는 Python 스크립트를 개발했습니다.

스크립트는 매일 밤 자동으로 실행되어야 합니다.
이 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. Python 스크립트를 AWS Lambda 함수로 변환합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 매일 밤 함수를 호출합니다. 가장 많이 투표된
B. Python 스크립트를 AWS Lambda 함수로 변환합니다. AWS CloudTrail을 사용하여 매일 밤 함수를 호출합니다.
C. Python 스크립트를 Amazon EC2 인스턴스에 배포합니다. Amazon EventBride(Amazon CloudWatch Events)를 사용하여 인스턴스가 매일 밤 시작 및 중지되도록 예약합니다.
D. Python 스크립트를 Amazon EC2 인스턴스에 배포합니다. AWS Systems Manager를 사용하여 매일 밤 인스턴스가 시작되고 중지되도록 예약합니다.

가장 적합한 솔루션은 **A. Python 스크립트를 AWS Lambda 함수로 변환합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 매일 밤 함수를 호출합니다.**

### 이유:

1. **AWS Lambda 함수**:
   - Lambda는 서버리스 방식으로 코드를 실행할 수 있는 서비스로, EC2 인스턴스를 프로비저닝하거나 관리할 필요 없이 코드를 실행할 수 있습니다. Python 스크립트를 Lambda 함수로 변환하면 인프라를 관리할 필요 없이 유지 관리 작업을 자동화할 수 있습니다.
   
2. **Amazon EventBridge(Amazon CloudWatch Events)**:
   - EventBridge는 지정된 일정에 따라 이벤트를 트리거할 수 있는 서비스로, 이를 사용하여 매일 밤 Lambda 함수를 호출하는 규칙을 생성할 수 있습니다. 이 방식은 매우 운영 효율적이고 관리가 간단합니다.

3. **운영 비용 효율성**:
   - Lambda는 사용한 만큼만 비용을 지불하는 모델로, EC2 인스턴스를 항상 실행하거나 관리할 필요 없이 Python 스크립트를 실행할 수 있어 비용 효율적입니다. 

---

### 다른 선택지에 대한 설명:

- **B. Lambda 함수와 CloudTrail 사용**:
  - **AWS CloudTrail**은 API 호출을 로깅하는 서비스로, Lambda 함수를 호출하는 데 적합하지 않습니다. 이를 대신 **EventBridge**를 사용해 매일 밤 자동 호출하는 것이 적절합니다.

- **C. Python 스크립트를 Amazon EC2 인스턴스에 배포**:
  - EC2 인스턴스를 사용하면 스크립트를 실행할 수는 있지만, EC2 인스턴스를 시작하고 종료하는 등의 작업이 필요하고, 인스턴스 관리 및 유지 보수 비용이 발생할 수 있습니다. Lambda를 사용하는 것이 더 운영 효율적입니다.

- **D. EC2 인스턴스와 AWS Systems Manager 사용**:
  - Systems Manager를 사용해 EC2 인스턴스를 제어하는 방식은 EC2 인스턴스를 지속적으로 관리해야 하고, Lambda를 사용하는 것에 비해 비용 및 운영 관리 측면에서 덜 효율적입니다.

---

결론적으로 **A 옵션**은 서버리스로 운영할 수 있으며, 유지 관리가 필요 없고 비용 효율적인 솔루션이므로 가장 적합한 선택입니다.

## 질문 #37
SysOps 관리자는 AWS Lambda 함수에 오류가 발생하면 소프트웨어 개발자에게 즉시 알리는 솔루션을 만들어야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?


A. 각 개발자에 대한 이메일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. Errors 메트릭과 Lambda 함수 이름을 차원으로 사용하여 Amazon CloudWatch 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다. 가장 많이 투표된
B. 각 개발자에 대한 모바일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. LambdaError를 이벤트 패턴으로, SNS 토픽 이름을 리소스로 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다.
C. Amazon Simple Email Service(Amazon SES)에서 각 개발자 이메일 주소를 확인합니다. LambdaError 메트릭과 개발자 이메일 주소를 차원으로 사용하여 Amazon CloudWatch 규칙을 만듭니다. 규칙 상태가 ALARM에 도달하면 Amazon SES를 통해 이메일을 보내도록 규칙을 구성합니다.
D. Amazon Simple Email Service(Amazon SES)에서 각 개발자 모바일 폰을 확인합니다. 이벤트 패턴으로 Error를 사용하고 리소스로 Lambda 함수 이름을 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 규칙 상태가 ALARM에 도달하면 Amazon SES를 통해 푸시 알림을 보내도록 규칙을 구성합니다.



가장 적합한 솔루션은 **A. 각 개발자에 대한 이메일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. Errors 메트릭과 Lambda 함수 이름을 차원으로 사용하여 Amazon CloudWatch 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다.**

### 이유:

1. **CloudWatch 알람과 Lambda의 통합**:
   - Lambda 함수의 오류를 감지하는 가장 좋은 방법은 **Amazon CloudWatch**의 **Errors 메트릭**을 사용하는 것입니다. Lambda는 오류가 발생할 때마다 CloudWatch에 메트릭을 전송하므로 이를 통해 오류를 즉시 모니터링할 수 있습니다.

2. **SNS 토픽을 통한 알림**:
   - **Amazon SNS**는 다양한 구독자에게 이메일 또는 SMS를 통해 알림을 보낼 수 있는 서비스입니다. 각 개발자에게 이메일 구독을 추가하면 CloudWatch 알람이 발생할 때 즉시 이메일 알림을 받을 수 있습니다.

3. **운영 효율성**:
   - 이 솔루션은 CloudWatch와 SNS의 기본 통합을 활용하여 Lambda 오류를 실시간으로 모니터링하고, 개발자에게 즉시 알림을 보내는 운영 효율적인 방법입니다. 추가적인 커스텀 설정 없이도 빠르게 알림을 설정할 수 있습니다.

---

### 다른 선택지에 대한 설명:

- **B. SNS 및 EventBridge 알람 사용**:
   - **EventBridge**는 주로 이벤트 중심의 아키텍처를 위한 서비스로, Lambda 오류 알림과 같은 단순한 모니터링에는 **CloudWatch 알람**이 더 적합합니다. 또한, Lambda 함수의 오류를 모니터링하려면 **Errors 메트릭**이 더 직접적입니다.

- **C. Amazon SES를 사용하여 이메일 전송**:
   - **Amazon SES**는 이메일을 보내는 서비스이지만, Lambda 오류 알림에는 SNS를 사용하는 것이 더 적합합니다. SES는 대량 이메일 전송에 유용하지만, 알림 설정에 SNS를 사용하는 것이 더 일반적이고 설정도 간단합니다.

- **D. Amazon SES를 통해 푸시 알림**:
   - **SES**는 주로 이메일 전송용이므로, 모바일 푸시 알림을 보내기에는 부적합합니다. 푸시 알림에는 **SNS**가 더 적합하며, EventBridge는 복잡한 이벤트를 처리할 때 유리하지만 이 경우 CloudWatch를 사용하는 것이 더 적합합니다.

---

결론적으로 **A 옵션**이 가장 적합한 솔루션입니다. Lambda 함수 오류를 CloudWatch에서 감지하고 SNS를 통해 즉시 알림을 보내는 운영적으로 효율적이고 간단한 방법입니다.




## 질문 #38
한 회사에는 민감한 정보가 들어 있는 개인 Amazon S3 버킷이 있습니다. 

SysOps 관리자는 버킷의 객체에 액세스하려는 시도로 인해 발생하는 인증 실패의 IP 주소 로그를 보관해야 합니다. 로그는 90일 동안 덮어쓰거나 삭제할 수 없도록 저장해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. AWS CloudTrail 트레일을 만듭니다. Amazon CloudWatch Logs에 저장할 로그 파일을 구성합니다. 보관 기간이 90일인 로그 그룹을 구성합니다.
B. AWS CloudTrail 트레일을 만듭니다. 로그 파일을 다른 S3 버킷에 저장하도록 구성합니다. CloudTrail 로그 파일 무결성 검증을 90일 동안 켭니다.
C. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 Amazon CloudWatch Logs에 저장되도록 구성합니다. 보관 기간이 90일인 로그 그룹을 구성합니다.
D. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 두 번째 S3 버킷에 저장되도록 구성합니다. 두 번째 S3 버킷에서 S3 객체 잠금을 켜고 기본 보관 기간을 90일로 구성합니다. 가장 많이 투표된

가장 적합한 솔루션은 **D. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 두 번째 S3 버킷에 저장되도록 구성합니다. 두 번째 S3 버킷에서 S3 객체 잠금을 켜고 기본 보관 기간을 90일로 구성합니다.**

### 이유:

1. **S3 액세스 로깅**:
   - S3 버킷에 대한 액세스 로깅을 활성화하면, 버킷의 객체에 대한 요청(성공과 실패)을 로그 파일로 기록할 수 있습니다. 이러한 로그에는 IP 주소와 같은 중요한 정보가 포함됩니다.

2. **두 번째 S3 버킷에 로그 저장**:
   - 민감한 정보가 포함된 S3 버킷의 액세스 로그를 별도의 S3 버킷에 저장하면, 로그 데이터를 더 안전하게 관리할 수 있습니다. 로그가 원본 버킷과 분리되어 보관되므로 추가 보안 계층을 제공합니다.

3. **S3 객체 잠금 및 WORM(Write Once, Read Many)**:
   - **S3 객체 잠금**을 사용하면 로그 파일을 덮어쓰거나 삭제할 수 없도록 보호할 수 있습니다. 이를 통해 **90일 동안 로그 파일을 보호**하고 데이터 무결성을 유지할 수 있습니다. 이는 규정 준수 및 감사 요구 사항에 적합한 방식입니다.

4. **보관 기간 설정**:
   - S3 객체 잠금을 사용하여 **기본 보관 기간을 90일**로 설정하면, 로그 파일이 그 기간 동안 보호되며 그 이후에는 자동으로 삭제하거나 관리할 수 있습니다.

---

### 다른 선택지에 대한 설명:

- **A. CloudTrail 트레일과 CloudWatch Logs 사용**:
   - CloudTrail을 통해 인증 실패 로그를 수집하는 것은 가능하지만, 로그를 90일 동안 덮어쓰거나 삭제되지 않도록 보장하려면 CloudWatch Logs가 적절하지 않습니다. CloudWatch에서는 로그 그룹을 설정할 수 있지만, 로그 무결성 보장은 제공되지 않습니다.

- **B. CloudTrail 로그 파일을 다른 S3 버킷에 저장**:
   - CloudTrail 로그 파일의 무결성 검증을 활성화하는 것은 로그 파일이 변조되지 않았음을 확인하는 데 도움이 될 수 있지만, **객체 잠금**을 사용해 삭제 방지 및 보존을 보장하는 D 옵션이 더 적합합니다.

- **C. S3 액세스 로그를 CloudWatch Logs에 저장**:
   - CloudWatch Logs에 액세스 로그를 저장할 수 있지만, CloudWatch에서 데이터 무결성을 보장하는 방법은 제한적입니다. 로그를 90일 동안 삭제하지 못하도록 보장하려면 S3 객체 잠금이 더 적합합니다.

---

결론적으로, **D 옵션**은 **S3 객체 잠금을 사용해** 로그 파일이 90일 동안 보호되도록 하고, 로그 무결성 및 데이터 보존을 확실하게 관리할 수 있는 솔루션이므로 요구 사항을 가장 잘 충족합니다.

## 질문 #39
SysOps 관리자가 NAT 인스턴스를 NAT 게이트웨이로 마이그레이션합니다. 

마이그레이션 후 프라이빗 서브넷의 Amazon EC2 인스턴스에 호스팅된 애플리케이션은 인터넷에 액세스할 수 없습니다.
다음 중 이 문제의 가능한 이유는 무엇입니까? (두 가지를 선택하세요.)

A. 해당 애플리케이션은 NAT 게이트웨이가 지원하지 않는 프로토콜을 사용하고 있습니다. 가장 많이 투표된
B. NAT 게이트웨이가 보안 그룹에 없습니다.
C. NAT 게이트웨이가 지원되지 않는 가용성 영역에 있습니다.
D. NAT 게이트웨이가 사용 가능한 상태가 아닙니다. 가장 많이 투표된
E. 포트 포워딩 설정으로 인해 인터넷에서 내부 서비스에 접근할 수 없습니다.

이 문제의 가능한 원인으로는 **A. 해당 애플리케이션은 NAT 게이트웨이가 지원하지 않는 프로토콜을 사용하고 있습니다.**와 **D. NAT 게이트웨이가 사용 가능한 상태가 아닙니다.**가 가장 적합합니다.

### 이유:

1. **A. NAT 게이트웨이가 지원하지 않는 프로토콜 사용**:
   - **NAT 게이트웨이**는 TCP, UDP, ICMP 프로토콜을 지원합니다. 그러나 만약 애플리케이션이 다른 프로토콜(예: GRE 또는 IPSec)을 사용하고 있다면 NAT 게이트웨이에서는 이를 지원하지 않기 때문에 인터넷 액세스 문제가 발생할 수 있습니다.

2. **D. NAT 게이트웨이가 사용 가능한 상태가 아님**:
   - NAT 게이트웨이가 생성된 후에 사용 가능한 상태가 아닐 수 있습니다. NAT 게이트웨이가 준비되지 않거나 문제가 발생하면 인터넷 연결이 되지 않으므로, 이 상태를 확인하는 것이 중요합니다. NAT 게이트웨이의 상태가 `Available`이 아닌 경우 연결할 수 없습니다.

---

### 다른 선택지에 대한 설명:

- **B. NAT 게이트웨이가 보안 그룹에 없습니다**:
   - NAT 게이트웨이는 **보안 그룹을 사용하지 않습니다**. 대신, 라우팅 테이블을 통해 트래픽을 관리합니다. 따라서 보안 그룹의 부재는 이 문제와 관련이 없습니다.

- **C. NAT 게이트웨이가 지원되지 않는 가용성 영역에 있습니다**:
   - NAT 게이트웨이는 특정 가용성 영역(AZ) 내에서 생성되지만, 잘못된 AZ에 있더라도 연결에 실패하지는 않습니다. 가용성 영역 선택이 잘못된 경우를 제외하고는 문제가 발생하지 않습니다. 다만 프라이빗 서브넷과 같은 AZ에 NAT 게이트웨이가 있어야 최적의 연결 성능을 얻을 수 있습니다.

- **E. 포트 포워딩 설정으로 인해 인터넷에서 내부 서비스에 접근할 수 없습니다**:
   - NAT 게이트웨이는 **프라이빗 서브넷에서 인터넷으로 나가는 트래픽을 처리**하는 것이 주된 역할입니다. 반대로 외부에서 프라이빗 서브넷 내부로 들어오는 트래픽을 처리하지 않으므로, 포트 포워딩 설정은 이 문제와 관련이 없습니다.

---

### 결론:
가장 적절한 답변은 **A와 D**입니다. NAT 게이트웨이가 지원하지 않는 프로토콜을 사용할 가능성과 NAT 게이트웨이가 사용 가능한 상태가 아닌 것이 문제의 원인일 수 있습니다.


## 질문 #40
한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

SysOps 관리자가 수요 증가를 처리하기 위해 Auto Scaling 그룹과 Application Load Balancer(ALB)를 만듭니다. 하지만 EC2 인스턴스가 상태 검사에 실패합니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 자동 확장 그룹이 모든 AWS 지역을 사용하도록 구성되었는지 확인합니다.
B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인합니다. 가장 많이 투표된
C. ALB에서 리스너 우선순위를 확인합니다. 필요한 경우 우선순위를 변경합니다.
D. Auto Scaling 그룹의 최대 인스턴스 수를 확인합니다. 필요한 경우 숫자를 변경합니다.


이 문제를 해결하기 위해 가장 적절한 조치는 **B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인합니다**입니다.

### 이유:

1. **B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인합니다**:
   - **Application Load Balancer(ALB)**는 상태 검사에서 지정된 포트와 프로토콜을 사용하여 EC2 인스턴스의 애플리케이션 상태를 확인합니다. 만약 애플리케이션이 ALB 리스너가 기대하는 포트(예: HTTP 80, HTTPS 443)에서 실행되지 않거나 잘못된 프로토콜로 구성된 경우, 상태 검사에 실패할 수 있습니다. 따라서 ALB와 애플리케이션 간의 통신이 제대로 설정되었는지 확인하는 것이 중요합니다.

### 다른 선택지에 대한 설명:

- **A. 자동 확장 그룹이 모든 AWS 지역을 사용하도록 구성되었는지 확인합니다**:
   - Auto Scaling 그룹은 특정 가용성 영역(AZ)과 연결됩니다. 지역 간의 구성을 확인하는 것은 이 문제와 관련이 없습니다. 상태 검사 실패 문제는 주로 인스턴스와 ALB 간의 통신 문제에 기인합니다.

- **C. ALB에서 리스너 우선순위를 확인합니다**:
   - 리스너 우선순위는 특정 규칙을 기반으로 트래픽을 라우팅할 때 사용됩니다. 상태 검사 실패와는 관련이 없습니다. 이 문제는 애플리케이션의 상태와 상태 검사 설정 문제일 가능성이 높습니다.

- **D. Auto Scaling 그룹의 최대 인스턴스 수를 확인합니다**:
   - Auto Scaling 그룹의 인스턴스 수는 트래픽 증가 시 더 많은 인스턴스를 추가할 수 있도록 설정하는 옵션입니다. 상태 검사 실패와는 관련이 없으며, 애플리케이션이 제대로 실행되지 않으면 인스턴스 수가 많아도 문제가 해결되지 않습니다.

### 결론:
**B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인**하는 것이 상태 검사 실패 문제를 해결하는 핵심 단계입니다.



## 질문 #41
SysOps 관리자가 AWS Service Catalog 포트폴리오를 생성하고 회사의 두 번째 AWS 계정과 포트폴리오를 공유했습니다. 

두 번째 계정은 다른 관리자가 제어합니다.
두 번째 계정의 관리자는 어떤 작업을 수행할 수 있습니까?

A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가합니다. 가장 많이 투표된
B. 가져온 포트폴리오에 새로운 제품을 추가합니다.
C. 가져온 포트폴리오에 포함된 제품에 대한 출시 역할을 변경합니다.
D. 가져온 포트폴리오의 제품을 맞춤화합니다.


두 번째 계정의 관리자가 할 수 있는 작업으로 가장 적절한 답변은 **A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가합니다**입니다.

### 이유:

- **A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가합니다**:
  - AWS Service Catalog를 통해 포트폴리오를 다른 계정과 공유하면, 해당 계정의 관리자는 공유된 포트폴리오에서 제품을 로컬 포트폴리오에 추가할 수 있습니다. 이렇게 하면 그 계정에서 제품을 사용하고 배포할 수 있습니다.

### 다른 선택지에 대한 설명:

- **B. 가져온 포트폴리오에 새로운 제품을 추가합니다**:
  - 포트폴리오에 제품을 추가하는 권한은 원래 포트폴리오를 소유한 관리자의 권한입니다. 두 번째 계정의 관리자는 가져온 포트폴리오에 제품을 추가할 수 없습니다.

- **C. 가져온 포트폴리오에 포함된 제품에 대한 출시 역할을 변경합니다**:
  - 출시 역할(Launch Role)을 설정하고 변경하는 권한은 원래 포트폴리오의 소유자에게만 있습니다. 두 번째 계정의 관리자는 공유된 포트폴리오의 출시 역할을 변경할 수 없습니다.

- **D. 가져온 포트폴리오의 제품을 맞춤화합니다**:
  - 두 번째 계정의 관리자는 포트폴리오의 제품을 직접 맞춤화할 수 없습니다. 제품의 템플릿과 설정은 원래 포트폴리오 소유자에 의해 정의되며, 관리자가 제공하는 설정에 따라 배포될 수 있습니다.

### 결론:
두 번째 계정의 관리자가 할 수 있는 작업은 **A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가**하는 것입니다.




## 질문 #42
한 회사가 애플리케이션을 AWS로 마이그레이션했습니다. 

이 회사는 여러 인스턴스 패밀리의 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다.
초기 테스트 중에 SysOps 관리자가 선택한 EC2 인스턴스에서 성능 문제를 식별합니다. 이 회사는 엄격한 예산 할당 정책을 가지고 있으므로
SysOps 관리자는 워크로드에 맞는 성능 특성을 가진 올바른 리소스 유형을 사용해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 즉각적인 비용 절감을 위해 지역별 예약 인스턴스(RI)를 구매합니다. Cost Explorer에서 EC2 적정 크기 조정 권장 사항을 검토하고 조치를 취합니다. 적정 크기 조정 후 RI를 최적의 인스턴스 패밀리로 교환합니다.
B. 기존 인스턴스에 대한 영역별 예약 인스턴스(RI)를 구매합니다. AWS Billing and Cost Management 콘솔에서 RI 활용도를 모니터링합니다. 활용도를 최적화하기 위해 인스턴스 크기를 조정합니다.
C. AWS Compute Optimizer 권장 사항을 검토하고 조치를 취합니다. 컴퓨팅 리소스를 실행하는 데 필요한 비용을 줄이기 위해 Compute Savings Plans를 구매합니다. 가장 많이 투표된
D. AWS 비용 및 사용 보고서에서 리소스 활용도 지표를 검토합니다. EC2 인스턴스를 적정 크기로 조정합니다. 적정 크기의 리소스에 대한 주문형 용량 예약을 만듭니다.

가장 적절한 솔루션은 **C. AWS Compute Optimizer 권장 사항을 검토하고 조치를 취합니다. 컴퓨팅 리소스를 실행하는 데 필요한 비용을 줄이기 위해 Compute Savings Plans를 구매합니다**입니다.

### 이유:

1. **C. AWS Compute Optimizer 권장 사항을 검토하고 조치를 취합니다**:
   - AWS Compute Optimizer는 EC2 인스턴스의 CPU, 메모리, 네트워크 사용량을 분석하여 성능을 최적화할 수 있는 권장 사항을 제공합니다. 이를 통해 워크로드에 맞는 성능 특성을 가진 EC2 인스턴스를 선택할 수 있습니다. Compute Optimizer는 비용 절감과 성능 향상을 위해 최적의 리소스 선택을 도와줍니다.
   - 또한, **Compute Savings Plans**는 특정 인스턴스 패밀리나 리전과 무관하게 다양한 EC2 인스턴스를 유연하게 사용할 수 있으면서도 비용 절감을 할 수 있는 옵션입니다.

### 다른 선택지에 대한 설명:

- **A. 즉각적인 비용 절감을 위해 지역별 예약 인스턴스(RI)를 구매합니다. Cost Explorer에서 EC2 적정 크기 조정 권장 사항을 검토하고 조치를 취합니다. 적정 크기 조정 후 RI를 최적의 인스턴스 패밀리로 교환합니다**:
   - 예약 인스턴스(RI)는 특정 인스턴스 타입에 대한 약정으로 비용을 절감할 수 있지만, 워크로드에 적합한 인스턴스를 선택하기 전에 RI를 구매하는 것은 성급한 결정입니다. RI는 특정 인스턴스에 종속적이기 때문에, Compute Optimizer와 같은 도구로 워크로드 분석 후에 결정을 내리는 것이 바람직합니다.

- **B. 기존 인스턴스에 대한 영역별 예약 인스턴스(RI)를 구매합니다. AWS Billing and Cost Management 콘솔에서 RI 활용도를 모니터링합니다. 활용도를 최적화하기 위해 인스턴스 크기를 조정합니다**:
   - 이 옵션은 이미 인스턴스 크기가 최적화되었다는 가정 하에 RI를 구매하는 방안입니다. 그러나 성능 문제가 발생한 상황에서는 먼저 적정 인스턴스 타입을 찾아야 하므로, 예약 인스턴스 구매는 성능 최적화 후에 고려하는 것이 맞습니다.

- **D. AWS 비용 및 사용 보고서에서 리소스 활용도 지표를 검토합니다. EC2 인스턴스를 적정 크기로 조정합니다. 적정 크기의 리소스에 대한 주문형 용량 예약을 만듭니다**:
   - 비용 및 사용 보고서는 리소스 활용도를 분석하는 데 도움을 줄 수 있지만, Compute Optimizer는 더 정교한 분석을 제공하여 성능과 비용 효율성을 극대화할 수 있습니다. 주문형 용량 예약은 특정 용량을 확보하는 방식이므로, 성능 최적화와 비용 절감을 위해서는 Compute Optimizer와 Savings Plans가 더 적합한 옵션입니다.

### 결론:
AWS Compute Optimizer는 성능 최적화와 비용 절감을 동시에 달성할 수 있는 강력한 도구이며, Compute Savings Plans는 다양한 EC2 인스턴스에 유연하게 적용할 수 있어 예산에 맞춘 비용 절감이 가능합니다.


## 질문 #43
SysOps 관리자는 회사의 인프라를 코드로 배포하는 업무를 맡고 있습니다. 

SysOps 관리자는 여러 환경에서 재사용할 수 있는 단일 템플릿을 작성하려고 합니다. SysOps 관리자는 AWS CloudFormation을 사용하여 솔루션을 만드는 방법은 무엇입니까?

A. CloudFormation 템플릿에서 Amazon EC2 사용자 데이터를 사용합니다.
B. 중첩된 스택을 사용하여 리소스를 프로비저닝합니다.
C. CloudFormation 템플릿에서 매개변수를 사용합니다. 가장 많이 투표된
D. 스택 정책을 사용하여 리소스를 프로비저닝합니다.

가장 적절한 솔루션은 **C. CloudFormation 템플릿에서 매개변수를 사용합니다**입니다.

### 이유:

**C. CloudFormation 템플릿에서 매개변수를 사용합니다**:
- **매개변수(Parameter)**를 사용하면 CloudFormation 템플릿을 다양한 환경에서 재사용할 수 있게 됩니다. 매개변수는 스택을 배포할 때 사용자로부터 입력을 받아 템플릿 내의 값(예: 인스턴스 타입, 리전, VPC ID 등)을 동적으로 변경할 수 있습니다. 이를 통해 동일한 템플릿을 여러 환경에서 유연하게 적용할 수 있으며, 환경마다 설정을 다르게 제공할 수 있습니다.

### 다른 선택지에 대한 설명:

- **A. CloudFormation 템플릿에서 Amazon EC2 사용자 데이터를 사용합니다**:
   - EC2 사용자 데이터(User Data)는 EC2 인스턴스에서 초기 설정을 자동으로 실행하는 데 사용됩니다. 이는 인스턴스 수준의 설정일 뿐, 전체 인프라를 재사용 가능한 방식으로 정의하는 데는 적합하지 않습니다.

- **B. 중첩된 스택을 사용하여 리소스를 프로비저닝합니다**:
   - **중첩된 스택(Nested Stacks)**는 리소스를 모듈식으로 관리하기 위한 방법으로, 여러 CloudFormation 템플릿을 계층 구조로 나누어 관리할 수 있게 합니다. 이는 복잡한 환경에서 재사용성을 높이지만, 템플릿을 여러 환경에서 재사용하기 위한 매개변수 설정과는 다른 방식입니다.

- **D. 스택 정책을 사용하여 리소스를 프로비저닝합니다**:
   - **스택 정책(Stack Policies)**는 CloudFormation 스택이 업데이트될 때 리소스를 보호하거나 제한하는 기능입니다. 이는 재사용 가능한 템플릿과는 관련이 없으며, 리소스의 변경이나 삭제를 방지하는 역할을 합니다.

### 결론:
**CloudFormation 매개변수**를 사용하면 템플릿의 유연성과 재사용성을 높일 수 있어 여러 환경에서 쉽게 사용할 수 있습니다. 이 방식은 다양한 인프라 구성에 적합한 값을 동적으로 입력받아 재사용 가능한 템플릿을 작성하는 데 이상적입니다.


## 질문 #44
SysOps 관리자는 Amazon EC2 인스턴스의 대규모 플릿을 담당하며, 다가올 하드웨어 유지 관리로 인해 인스턴스가 영향을 받을지 여부를 알아야 합니다.

어떤 옵션이 가장 적은 관리 오버헤드로 이 정보를 제공할까요?

A. 타사 모니터링 솔루션을 배포하여 실시간 EC2 인스턴스 모니터링을 제공합니다.
B. AWS Management Console을 사용하여 시스템 상태 검사에 실패한 모든 인스턴스를 나열합니다.
C. AWS CloudTrail에서 StopInstances API 호출을 모니터링합니다.
D. AWS 개인 건강 대시보드를 검토합니다. 가장 많이 투표된


가장 적절한 솔루션은 **D. AWS 개인 건강 대시보드를 검토합니다**입니다.

### 이유:

**D. AWS 개인 건강 대시보드를 검토합니다**:
- **AWS 개인 건강 대시보드**는 사용자의 AWS 계정에서 실행 중인 리소스에 영향을 미칠 수 있는 이벤트(예: 하드웨어 유지 관리, 서비스 장애)를 자동으로 모니터링하고 알림을 제공합니다. 이 대시보드는 EC2 인스턴스가 유지 관리로 인해 영향을 받을 때 자동으로 알림을 제공하여, SysOps 관리자가 대규모 플릿에 대해 빠르게 대응할 수 있도록 돕습니다. 관리 오버헤드가 매우 적고 AWS에서 제공하는 기본 기능이므로 별도의 설정 없이 쉽게 확인할 수 있습니다.

### 다른 선택지에 대한 설명:

- **A. 타사 모니터링 솔루션을 배포하여 실시간 EC2 인스턴스 모니터링을 제공합니다**:
   - 타사 솔루션은 추가적인 관리 오버헤드가 발생하며, AWS의 기본 유지 관리 알림이나 상태 정보를 확인하는 데 꼭 필요한 것은 아닙니다. AWS에서 제공하는 도구로 충분히 해결할 수 있는 문제입니다.

- **B. AWS Management Console을 사용하여 시스템 상태 검사에 실패한 모든 인스턴스를 나열합니다**:
   - 시스템 상태 검사는 EC2 인스턴스가 실행 중인 상태에서 발생하는 문제를 확인할 수 있지만, 유지 관리 알림을 사전에 받는 것과는 다릅니다. 이는 관리 오버헤드가 높고, 유지 관리 계획을 미리 확인할 수 없습니다.

- **C. AWS CloudTrail에서 StopInstances API 호출을 모니터링합니다**:
   - CloudTrail은 API 활동을 기록하는 서비스로, 이미 발생한 이벤트를 모니터링하는 데 적합합니다. 하지만 하드웨어 유지 관리로 인한 영향을 사전에 알리는 데는 적합하지 않으며, 필요한 정보를 제공하지 않습니다.

### 결론:
**AWS 개인 건강 대시보드**는 자동으로 유지 관리와 관련된 정보를 제공하므로, 관리 오버헤드가 적고 가장 적절한 해결책입니다.



## 질문 #45
SysOps 관리자가 AWS CloudFormation 템플릿을 사용하여 리소스를 배포하려고 합니다. 

템플릿에 정의된 Amazon EC2 인스턴스가 시작되지 않고 InsufficientInstanceCapacity 오류가 발생합니다.
SysOps 관리자는 이 오류를 해결하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. EC2 인스턴스에 대해 별도의 AWS CloudFormation 템플릿을 만듭니다.
B. EC2 인스턴스에 대한 가용성 영역을 지정하지 않도록 AWS CloudFormation 템플릿을 수정합니다. 가장 많이 투표된
C. AWS CloudFormation 템플릿을 수정하여 다른 EC2 인스턴스 유형을 사용합니다. 가장 많이 투표된
D. EC2 인스턴스에 다른 Amazon Machine Image(AMI)를 사용합니다.
E. 템플릿에서 스택을 생성하기 전에 AWS CLI의 validate-template 명령을 사용합니다.

**InsufficientInstanceCapacity** 오류는 AWS 리전이나 가용성 영역 내에서 요청한 EC2 인스턴스 유형에 대한 가용 용량이 부족할 때 발생합니다. 이 문제를 해결하기 위한 적절한 조치는 다음과 같습니다:

### 올바른 선택:

**B. EC2 인스턴스에 대한 가용성 영역을 지정하지 않도록 AWS CloudFormation 템플릿을 수정합니다.**
- 가용성 영역을 지정하지 않으면 AWS가 사용 가능한 가용성 영역에서 인스턴스를 자동으로 배포할 수 있어, 특정 가용성 영역의 용량 부족 문제를 우회할 수 있습니다.

**C. AWS CloudFormation 템플릿을 수정하여 다른 EC2 인스턴스 유형을 사용합니다.**
- 다른 EC2 인스턴스 유형을 사용하면 현재의 인스턴스 유형에 비해 더 많은 용량이 있는 인스턴스 유형으로 변경할 수 있어 문제를 해결할 수 있습니다.

### 다른 선택지에 대한 설명:

- **A. EC2 인스턴스에 대해 별도의 AWS CloudFormation 템플릿을 만듭니다.**
  - 별도의 템플릿을 만드는 것은 이 문제를 해결하는 데 도움이 되지 않습니다. InsufficientInstanceCapacity 오류는 인스턴스의 가용성 문제이므로 템플릿의 구조와는 관련이 없습니다.

- **D. EC2 인스턴스에 다른 Amazon Machine Image(AMI)를 사용합니다.**
  - AMI를 변경하는 것은 직접적으로 인스턴스 용량 문제와 관련이 없으며, InsufficientInstanceCapacity 오류를 해결하지 못합니다.

- **E. 템플릿에서 스택을 생성하기 전에 AWS CLI의 validate-template 명령을 사용합니다.**
  - 템플릿의 유효성을 검증하는 것은 좋은 습관이지만, 이 오류는 템플릿의 유효성 문제와는 관계가 없고, 인스턴스의 가용성과 관련된 문제입니다.

### 결론:
**B**와 **C**가 InsufficientInstanceCapacity 오류를 해결하는 데 적절한 조치입니다.



## 질문 #46
한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 

이 회사는 Amazon Route 53을 사용하여 트래픽을 라우팅합니다.
이 회사는 또한 Amazon S3 버킷에 구성된 정적 웹사이트를 가지고 있습니다.

SysOps 관리자는 정적 웹사이트를 웹 애플리케이션의 백업으로 사용해야 합니다. 정적 웹사이트로의 장애 조치는 완전히 자동화되어야 합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하십시오.)

A. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다.
B. 상태 검사에 실패하면 기본 웹사이트에서 보조 웹사이트로 전환하는 AWS Lambda 함수를 생성합니다.
C. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다. 가장 많이 투표된
D. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다.
E. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다. 가장 많이 투표된

이 시나리오에서 정적 웹사이트를 웹 애플리케이션의 백업으로 사용하고, 이를 완전히 자동화된 방식으로 장애 조치해야 하는 경우, 다음과 같은 조합이 적절합니다:

### 올바른 선택:

**C. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다.**
- 이 단계는 ALB에 대한 기본 경로를 설정하고, ALB에 문제가 발생할 경우 Route 53이 자동으로 상태 검사를 통해 이를 감지하여 장애 조치를 수행하도록 합니다.

**E. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다.**
- 이 단계는 ALB에 장애가 발생했을 때 Route 53이 정적 웹사이트로 자동으로 트래픽을 전환할 수 있도록 합니다.

### 다른 선택지에 대한 설명:

- **A. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다.**
  - 이 작업은 필요하지만, 상태 검사를 Route 53과 연결하는 것을 잊어서는 안 됩니다. 단독으로는 자동화된 장애 조치를 보장하지 않습니다.

- **B. 상태 검사에 실패하면 기본 웹사이트에서 보조 웹사이트로 전환하는 AWS Lambda 함수를 생성합니다.**
  - Lambda 함수를 사용한 장애 조치는 가능하지만, Route 53의 상태 검사와 기본적으로 연계되는 장애 조치 정책이 더 간단하고 효과적입니다.

- **D. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다.**
  - 이 옵션은 보조 레코드를 추가하는 것을 고려할 수 있지만, 실제로 ALB가 기본 레코드이므로 추가적인 설정이 필요합니다.

### 결론:
**C**와 **E**가 완전히 자동화된 장애 조치를 설정하는 데 가장 적합한 조합입니다. 이를 통해 ALB에서 장애가 발생했을 때 자동으로 정적 웹사이트로 트래픽이 전환될 수 있습니다.



## 질문 #47
데이터 분석 애플리케이션이 Amazon EC2 인스턴스에서 실행 중입니다. 

SysOps 관리자는 Amazon CloudWatch 에이전트가 수집한 메트릭에 사용자 지정 차원을 추가해야 합니다.
SysOps 관리자는 이 요구 사항을 어떻게 충족할 수 있습니까?

A. Amazon CloudWatch 에이전트를 사용하여 차원을 추출하고 메트릭을 수집하는 사용자 지정 셸 스크립트를 만듭니다.
B. 필요한 사용자 정의 차원을 평가하고 해당 지표를 Amazon Simple Notification Service(Amazon SNS)로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
C. AWS CloudTrail에서 지표를 수집하고 해당 지표를 Amazon CloudWatch Logs 그룹으로 전송하는 AWS Lambda 함수를 생성합니다.
D. Amazon CloudWatch 에이전트 구성 파일에 append_dimensions 필드를 만들어 메트릭을 수집합니다. 가장 많이 투표된

Amazon CloudWatch 에이전트에 사용자 정의 차원을 추가하여 메트릭을 수집하는 방법으로는 다음과 같은 옵션이 적합합니다:

### 올바른 선택:

**D. Amazon CloudWatch 에이전트 구성 파일에 append_dimensions 필드를 만들어 메트릭을 수집합니다.**
- 이 방법을 사용하면 CloudWatch 에이전트의 구성 파일에서 `append_dimensions` 필드를 설정하여 수집된 메트릭에 사용자 정의 차원을 추가할 수 있습니다. 이렇게 하면 특정 차원이 메트릭과 함께 자동으로 전송됩니다.

### 다른 선택지에 대한 설명:

- **A. Amazon CloudWatch 에이전트를 사용하여 차원을 추출하고 메트릭을 수집하는 사용자 지정 셸 스크립트를 만듭니다.**
  - 이 방법은 가능하지만, 복잡성과 유지 관리의 어려움이 있습니다. CloudWatch 에이전트의 기본 기능을 활용하는 것보다 비효율적입니다.

- **B. 필요한 사용자 정의 차원을 평가하고 해당 지표를 Amazon Simple Notification Service(Amazon SNS)로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.**
  - 이 방법은 차원 수집과 직접적인 연관이 없습니다. 메트릭 수집은 CloudWatch 에이전트의 기능을 통해 이루어져야 합니다.

- **C. AWS CloudTrail에서 지표를 수집하고 해당 지표를 Amazon CloudWatch Logs 그룹으로 전송하는 AWS Lambda 함수를 생성합니다.**
  - 이 방법은 CloudTrail의 기능과 관련이 있지만, 메트릭의 사용자 정의 차원을 추가하는 데 적합하지 않습니다. CloudTrail은 주로 API 호출 로그를 수집하는 데 사용됩니다.

### 결론:
**D** 선택이 가장 적합하며, CloudWatch 에이전트의 구성 파일을 통해 사용자 정의 차원을 쉽게 추가하고 메트릭을 수집할 수 있습니다.



## 질문 #48
한 회사가 Amazon S3 버킷에 데이터를 저장합니다. 

회사는 데이터를 분류하고 S3 파일에서 민감한 개인 정보를 찾아야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. S3 파일에서 민감한 개인 정보를 검색하고 이를 비준수로 표시하는 AWS Config 규칙을 생성합니다.
B. Amazon Rekognition을 사용하여 민감한 개인 정보를 분류하기 위한 S3 이벤트 기반 인공 지능/머신 러닝(AI/ML) 파이프라인을 생성합니다.
C. Amazon GuardDuty를 활성화합니다. Amazon S3 내부의 모든 데이터를 모니터링하도록 S3 보호를 구성합니다.
D. Amazon Macie를 활성화합니다. 관리되는 데이터 식별자를 사용하는 검색 작업을 만듭니다. 가장 많이 투표된

이 문제에서 요구하는 솔루션은 **민감한 개인 정보를 검색하고 이를 분류하는** 것입니다. 이와 관련하여 가장 적합한 선택지는 **D. Amazon Macie를 활성화합니다. 관리되는 데이터 식별자를 사용하는 검색 작업을 만듭니다.**입니다. 

### 선택지 D: Amazon Macie
- **이유**: Amazon Macie는 S3에 저장된 데이터를 자동으로 분석하고, 민감한 정보(예: 개인 식별 정보, 신용 카드 번호 등)를 식별하는 데 최적화되어 있습니다. Macie는 관리되는 데이터 식별자를 사용하여 검색 작업을 수행할 수 있으며, 이로써 민감한 데이터를 쉽게 찾아내고 분류할 수 있습니다. 이 서비스는 특히 개인정보 보호 및 규정 준수를 관리하는 데 유용합니다.

### 다른 선택지 설명

- **A. S3 파일에서 민감한 개인 정보를 검색하고 이를 비준수로 표시하는 AWS Config 규칙을 생성합니다.**
  - AWS Config는 리소스의 구성 변경을 추적하고 규정 준수 여부를 확인하는 서비스입니다. 하지만 S3 파일에서 민감한 정보를 검색하는 기능은 제공하지 않습니다. AWS Config는 규정 준수를 확인할 수는 있지만, 데이터를 분석하고 분류하는 데는 적합하지 않습니다.

- **B. Amazon Rekognition을 사용하여 민감한 개인 정보를 분류하기 위한 S3 이벤트 기반 인공 지능/머신 러닝(AI/ML) 파이프라인을 생성합니다.**
  - Amazon Rekognition은 이미지 및 비디오 분석에 적합한 서비스로, 주로 얼굴 인식이나 객체 인식 등에 사용됩니다. 텍스트 또는 개인 정보 검색에는 적합하지 않으므로, S3 파일에서 민감한 개인 정보를 찾는 데 사용할 수 없습니다.

- **C. Amazon GuardDuty를 활성화합니다. Amazon S3 내부의 모든 데이터를 모니터링하도록 S3 보호를 구성합니다.**
  - Amazon GuardDuty는 보안 위협 탐지 서비스로, 계정이나 리소스의 악의적인 활동을 모니터링하고 경고합니다. 하지만 GuardDuty는 데이터 내용 분석보다는 이상 징후를 탐지하는 데 중점을 두므로, S3 파일에서 민감한 정보를 검색하는 데는 적합하지 않습니다.

### 결론
따라서, **D** 선택이 가장 적합한 솔루션으로, Amazon Macie를 사용하여 S3에 저장된 민감한 개인 정보를 효과적으로 찾아내고 분류할 수 있습니다.


## 질문 #49
한 회사가 Amazon EC2 인스턴스에서 웹 포털을 호스팅합니다. 

웹 포털은 퍼블릭 DNS 서비스에 Elastic Load Balancer(ELB)와 Amazon Route 53을 사용합니다.
ELB와 EC2 인스턴스는 us-east-1 리전에서 단일 AWS CloudFormation 스택을 통해 배포됩니다. 웹 포털은 여러 리전에서 고가용성이어야 합니다.
이러한 요구 사항을 충족하는 구성은 무엇입니까?

A. us-west-2 지역에 스택 사본을 배포합니다. Route 53에 각 ELB의 IP 주소를 포함하는 단일 권한 시작(SOA) 레코드를 만듭니다. 상태 검사를 사용하여 SOA 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다.
B. us-west-2 Region에 스택 사본을 배포합니다. Route 53에 별칭 대상으로 us-west-2의 ELB를 포함하는 추가 A 레코드를 만듭니다. 장애 조치 라우팅 정책 및 상태 검사를 사용하여 A 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다. 가장 많이 투표된
C. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 새로운 EC2 인스턴스를 기존 ELB와 연결하고 모든 EC2 인스턴스에서 로드 밸런서 상태 검사를 구성합니다. us-west-2의 EC2 인스턴스가 상태 검사에 실패하면 Route 53을 업데이트하도록 ELB를 구성합니다.
D. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 각 지역의 모든 EC2 인스턴스에 EC2 상태 검사를 구성합니다. VPC 간에 피어링 연결을 구성합니다. us-east-1의 VPC를 기본 레코드로 사용하고 us-west-2의 VPC를 보조 레코드로 사용합니다.



고가용성을 위해 여러 리전에서 웹 포털을 배포하는 데 필요한 요구 사항을 충족하는 구성을 선택해야 합니다. 이와 관련하여 가장 적합한 선택지는 **B. us-west-2 Region에 스택 사본을 배포합니다. Route 53에 별칭 대상으로 us-west-2의 ELB를 포함하는 추가 A 레코드를 만듭니다. 장애 조치 라우팅 정책 및 상태 검사를 사용하여 A 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다.**입니다.

### 선택지 B 설명
- **장애 조치 라우팅**: 이 옵션은 Route 53의 장애 조치 라우팅 정책을 활용하여, 주 리전(us-east-1)에서 ELB가 실패할 경우 보조 리전(us-west-2)으로 트래픽을 자동으로 전환합니다.
- **상태 검사**: Route 53의 상태 검사를 사용하여 주 리전의 ELB가 비정상 상태일 때 보조 리전의 ELB로 트래픽을 전환합니다. 이는 높은 가용성을 보장합니다.
- **별칭 A 레코드**: 별칭을 사용하면 Route 53이 ELB의 DNS 이름을 사용하여 리전 간 트래픽을 유연하게 관리할 수 있습니다.

### 다른 선택지 설명

- **A. us-west-2 지역에 스택 사본을 배포합니다. Route 53에 각 ELB의 IP 주소를 포함하는 단일 권한 시작(SOA) 레코드를 만듭니다. 상태 검사를 사용하여 SOA 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다.**
  - **문제점**: SOA 레코드는 DNS 관리와 관련이 있으며, 장애 조치와 같은 상황을 처리하는 데 적합하지 않습니다. IP 주소 기반으로 트래픽을 라우팅하는 것은 비효율적이며, ELB의 IP 주소는 동적으로 변할 수 있습니다.

- **C. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 새로운 EC2 인스턴스를 기존 ELB와 연결하고 모든 EC2 인스턴스에서 로드 밸런서 상태 검사를 구성합니다. us-west-2의 EC2 인스턴스가 상태 검사에 실패하면 Route 53을 업데이트하도록 ELB를 구성합니다.**
  - **문제점**: ELB가 EC2 인스턴스 상태 검사 실패를 Route 53에 직접 알릴 수는 없습니다. 또한 이 구성은 여러 리전에서 고가용성을 보장하는 방식이 아닙니다.

- **D. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 각 지역의 모든 EC2 인스턴스에 EC2 상태 검사를 구성합니다. VPC 간에 피어링 연결을 구성합니다. us-east-1의 VPC를 기본 레코드로 사용하고 us-west-2의 VPC를 보조 레코드로 사용합니다.**
  - **문제점**: VPC 피어링은 두 VPC 간의 네트워크 연결을 제공하지만, 웹 애플리케이션의 고가용성 요구 사항을 충족하기 위한 DNS 및 트래픽 라우팅 구성에는 적합하지 않습니다. 또한 EC2 상태 검사는 직접적으로 Route 53의 장애 조치 라우팅에 사용할 수 없습니다.

### 결론
따라서, **B** 선택지가 여러 리전에서의 고가용성과 트래픽 라우팅 요구 사항을 가장 잘 충족하는 방법입니다.




## 질문 #50
SysOps 관리자가 사용자가 RDP를 사용하여 홈 컴퓨터에서 Amazon EC2 Windows 인스턴스에서 실행되는 베스천 서버에 인터넷을 통해 연결할 수 없는 이유를 조사하고 있습니다.
다음 중 이 문제의 가능한 원인은 무엇입니까? (두 가지를 선택하세요.)


A. 요새 서브넷과 연결된 네트워크 ACL이 네트워크 트래픽을 차단하고 있습니다. 가장 많이 투표된
B. 인스턴스에 개인 IP 주소가 없습니다.
C. 배스천의 서브넷과 연결된 경로 테이블에 인터넷 게이트웨이로 가는 경로가 없습니다. 가장 많이 투표된
D. 인스턴스의 보안 그룹에 포트 22에 대한 인바운드 규칙이 없습니다.
E. 인스턴스의 보안 그룹에 포트 3389에 대한 아웃바운드 규칙이 없습니다.

사용자가 RDP(원격 데스크톱 프로토콜)를 사용하여 Amazon EC2 Windows 인스턴스에서 실행되는 배스천 서버에 연결할 수 없는 이유를 조사하는 데 있어, 올바른 선택지는 **A**와 **C**입니다.

### 올바른 선택지

- **A. 요새 서브넷과 연결된 네트워크 ACL이 네트워크 트래픽을 차단하고 있습니다.**
  - **설명**: 네트워크 ACL(Network Access Control List)은 서브넷 수준에서 트래픽을 제어합니다. ACL이 RDP(포트 3389) 트래픽을 차단하면 홈 컴퓨터에서 배스천 서버로의 연결이 실패합니다.

- **C. 배스천의 서브넷과 연결된 경로 테이블에 인터넷 게이트웨이로 가는 경로가 없습니다.**
  - **설명**: 배스천 호스트가 있는 서브넷의 경로 테이블에 인터넷 게이트웨이로의 경로가 없으면 외부 인터넷과 연결할 수 없습니다. 이로 인해 RDP 연결이 실패할 수 있습니다.

### 잘못된 선택지

- **B. 인스턴스에 개인 IP 주소가 없습니다.**
  - **설명**: Amazon EC2 인스턴스는 항상 개인 IP 주소를 가집니다. 배스천 서버는 퍼블릭 IP 주소를 가질 수 있으며, 개인 IP 주소가 없이는 정상적인 작동이 불가능합니다. 이 선택지는 문제의 원인이 아닙니다.

- **D. 인스턴스의 보안 그룹에 포트 22에 대한 인바운드 규칙이 없습니다.**
  - **설명**: RDP 연결에는 포트 3389가 필요하므로, 포트 22(SSH)는 이 경우와 관련이 없습니다. 이는 잘못된 선택지입니다.

- **E. 인스턴스의 보안 그룹에 포트 3389에 대한 아웃바운드 규칙이 없습니다.**
  - **설명**: RDP 연결을 설정할 때, 보안 그룹의 아웃바운드 규칙은 일반적으로 필요하지 않습니다. 인바운드 규칙이 없으면 연결이 실패할 수 있으며, 아웃바운드 규칙이 없다고 해서 연결이 안 되는 것은 아닙니다. 따라서 이 선택지는 잘못된 것입니다.

### 결론
따라서, **A**와 **C**가 문제의 원인으로 적절한 선택지입니다.


## 질문 #51
SysOps 관리자가 다음 AWS CloudFormation 템플릿을 검토하고 있습니다.

스택 생성이 실패하는 이유는 무엇일까요?
A. CloudFormation 템플릿의 출력 섹션이 생략되었습니다.
B. CloudFormation 템플릿의 매개변수 섹션이 생략되었습니다.
C. PrivateDnsName은 CloudFormation 템플릿에서 설정할 수 없습니다. 가장 많이 투표된
D. CloudFormation 템플릿에 VPC가 지정되지 않았습니다.


AWS CloudFormation 스택 생성 실패 원인 분석
AWS CloudFormation은 인프라를 코드로 관리할 수 있게 해주는 서비스입니다. 그러나 템플릿 작성 시 여러 가지 오류가 발생할 수 있으며, 이는 스택 생성 실패로 이어질 수 있습니다. 주어진 선택지들을 하나씩 검토하여 어떤 경우에 스택 생성이 실패할 수 있는지 살펴보겠습니다.

A. CloudFormation 템플릿의 출력 섹션이 생략되었습니다.
출력 섹션은 선택 사항입니다. 이 섹션은 스택 생성 후 반환되는 값을 정의합니다. 따라서 이 섹션이 생략되었다고 해서 스택 생성이 반드시 실패하는 것은 아닙니다.
B. CloudFormation 템플릿의 매개변수 섹션이 생략되었습니다.
매개변수 섹션도 선택 사항입니다. 이 섹션은 사용자로부터 입력받을 값을 정의합니다. 매개변수가 필요하지 않은 경우에는 생략해도 됩니다. 따라서 이 섹션이 생략되었다고 해서 스택 생성이 실패하는 것은 아닙니다.
C. PrivateDnsName은 CloudFormation 템플릿에서 설정할 수 없습니다.
PrivateDnsName은 특정 리소스의 속성으로, 일반적으로 EC2 인스턴스와 같은 리소스에 대해 설정됩니다. 그러나 이 속성을 잘못 설정하거나 지원되지 않는 경우 스택 생성이 실패할 수 있습니다. 예를 들어, VPC 내부에서만 유효한 DNS 이름을 외부에서 접근하려는 경우 문제가 될 수 있습니다.
D. CloudFormation 템플릿에 VPC가 지정되지 않았습니다.

**VPC (Virtual Private Cloud)**는 AWS 리소스를 격리된 네트워크 환경에서 실행하기 위한 가상 네트워크입니다. 많은 리소스는 VPC 내에서 동작해야 하며, VPC가 지정되지 않으면 해당 리소스가 올바르게 생성되지 않을 수 있습니다. 특히, 서브넷이나 보안 그룹과 같은 리소스는 반드시 VPC 내에서 정의되어야 합니다.

결론
주어진 선택지 중에서 스택 생성이 실패할 가능성이 높은 이유는 D. CloudFormation 템플릿에 VPC가 지정되지 않았습니다입니다. VPC는 많은 AWS 리소스가 올바르게 동작하기 위해 필수적인 요소이며, 이를 지정하지 않으면 리소스 생성이 실패할 수 있습니다.

따라서, SysOps 관리자는 템플릿에 VPC가 제대로 지정되었는지 확인해야 합니다. VPC가 지정되지 않았다면, 이를 추가하여 스택을 다시 생성해보는 것이 좋습니다.


## 질문 #52
새로운 애플리케이션이 Amazon EC2 인스턴스에서 실행되고 Amazon RDS 데이터베이스 인스턴스의 데이터에 액세스합니다. 


프로덕션에 완전히 배포되면 애플리케이션이 실패합니다. 데이터베이스는 배스천 호스트의 콘솔에서 쿼리할 수 있습니다. 웹 서버 로그를 살펴보면 다음 오류가 여러 번 반복됩니다.
*** 데이터베이스 연결 설정 오류
다음 중 연결 문제의 원인은 무엇일까요? (두 가지를 선택하세요.)


A. 데이터베이스의 보안 그룹에 데이터베이스에서 웹 서버로의 적절한 탈출 규칙이 없습니다.
B. 웹 서버에서 사용하는 인증서를 RDS 인스턴스에서 신뢰하지 않습니다.
C. 데이터베이스의 보안 그룹에 웹 서버에서 데이터베이스로의 적절한 유입 규칙이 없습니다. 가장 많이 투표된
D. 애플리케이션 개발자가 사용하는 포트가 RDS 구성에 지정된 포트와 일치하지 않습니다. 가장 많이 투표된
E. 데이터베이스가 아직 생성 중이므로 연결할 수 없습니다.

Amazon EC2 및 Amazon RDS 연결 문제 해결
Amazon EC2 인스턴스에서 실행되는 애플리케이션이 Amazon RDS 데이터베이스 인스턴스에 접근할 때 발생하는 연결 문제는 다양한 원인으로 인해 발생할 수 있습니다. 주어진 상황에서 두 가지 주요 원인을 식별해 보겠습니다.

C. 데이터베이스의 보안 그룹에 웹 서버에서 데이터베이스로의 적절한 유입 규칙이 없습니다.
보안 그룹은 AWS에서 네트워크 트래픽을 제어하는 방화벽 역할을 합니다. EC2 인스턴스와 RDS 인스턴스는 각각 별도의 보안 그룹에 속하게 되며, 이들 간의 통신을 허용하기 위해서는 적절한 유입 규칙(Inbound Rule)이 필요합니다.
유입 규칙: 웹 서버(EC2 인스턴스)에서 데이터베이스(RDS 인스턴스)로의 트래픽을 허용하는 규칙이 없다면, 데이터베이스에 대한 연결 요청이 차단될 것입니다.
예시: 웹 서버의 IP 주소 또는 보안 그룹 ID를 대상으로 하는 RDS 보안 그룹의 유입 규칙을 설정해야 합니다.
D. 애플리케이션 개발자가 사용하는 포트가 RDS 구성에 지정된 포트와 일치하지 않습니다.
포트 설정: 기본적으로 RDS 인스턴스는 특정 포트(일반적으로 MySQL의 경우 3306, PostgreSQL의 경우 5432 등)를 통해 접속을 허용합니다. 애플리케이션이 다른 포트를 사용하려고 하면 연결이 실패할 수 있습니다.
포트 일치 여부 확인: 애플리케이션 코드나 설정 파일에서 사용하는 포트가 RDS 인스턴스의 포트와 일치하는지 확인해야 합니다.
예시: application.properties 파일에서 jdbc:mysql://<RDS_ENDPOINT>:3306/<DB_NAME> 형식으로 올바른 포트를 지정했는지 확인합니다.
기타 고려 사항
배스천 호스트에서의 접근 가능성: 배스천 호스트에서 데이터베이스에 접근할 수 있다는 점은 네트워크 레벨에서의 큰 문제는 없음을 시사하지만, 이는 배스천 호스트와 RDS 간의 보안 그룹 설정이 올바르다는 것을 의미합니다.
인증서 문제: B 옵션은 SSL/TLS 인증서 관련 문제인데, 이는 주어진 오류 메시지와 직접적인 연관이 없어 보입니다.
데이터베이스 상태: E 옵션은 데이터베이스가 아직 생성 중이라는 문제인데, 이는 배스천 호스트에서 이미 데이터베이스에 접근 가능한 상황에서는 해당되지 않습니다.
따라서, 위의 두 가지(C와 D)를 주요 원인으로 파악하고, 이를 해결하기 위한 조치를 취하는 것이 바람직합니다.


## 질문 #53
규정 준수 팀은 Amazon RDS DB 인스턴스의 모든 관리자 비밀번호를 최소 1년에 한 번 변경하도록 요구합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족합니까?

A. AWS Secrets Manager에 데이터베이스 자격 증명을 저장합니다. 365일마다 비밀에 대한 자동 로테이션을 구성합니다. 가장 많이 투표된
B. 데이터베이스 자격 증명을 RDS 매개변수 그룹의 매개변수로 저장합니다. 365일마다 비밀번호를 회전하는 데이터베이스 트리거를 만듭니다.
C. 데이터베이스 자격 증명을 개인 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 예약하여 365일마다 새로운 자격 증명 세트를 생성합니다.
D. AWS Systems Manager Parameter Store에 데이터베이스 자격 증명을 안전한 문자열 매개변수로 저장합니다. 365일마다 매개변수에 대한 자동 로테이션을 구성합니다.


Amazon RDS DB 인스턴스 비밀번호 관리: 운영적 효율성
규정 준수를 위해 Amazon RDS DB 인스턴스의 관리자 비밀번호를 최소 1년에 한 번 변경하는 것은 중요한 보안 관행입니다. 이를 효율적으로 수행하기 위해 다양한 AWS 서비스와 도구를 활용할 수 있습니다. 각 옵션을 검토하여 가장 운영적으로 효율적인 방법을 찾아보겠습니다.

A. AWS Secrets Manager에 데이터베이스 자격 증명을 저장합니다. 365일마다 비밀에 대한 자동 로테이션을 구성합니다.
AWS Secrets Manager는 민감한 정보를 안전하게 저장하고 관리하는 데 사용됩니다. 이 서비스는 비밀번호와 같은 자격 증명의 자동 로테이션 기능을 제공합니다.
자동 로테이션: Secrets Manager는 일정 기간마다 비밀번호를 자동으로 갱신할 수 있도록 설정할 수 있습니다. 이를 통해 관리 부담을 줄이고 규정 준수를 쉽게 유지할 수 있습니다.
통합성: Secrets Manager는 AWS Lambda, Amazon RDS 등과의 통합이 용이하여, 비밀번호 변경 후에도 시스템이 원활히 작동하도록 할 수 있습니다.

B. 데이터베이스 자격 증명을 RDS 매개변수 그룹의 매개변수로 저장합니다. 365일마다 비밀번호를 회전하는 데이터베이스 트리거를 만듭니다.
RDS 매개변수 그룹: RDS 매개변수 그룹은 데이터베이스 설정을 관리하는 데 사용되지만, 민감한 정보를 저장하는 데 적합하지 않습니다.
보안 문제: 매개변수 그룹은 암호화를 제공하지 않으므로, 민감한 정보를 저장하는 데 부적절합니다.
복잡성 증가: 데이터베이스 트리거를 통해 비밀번호를 회전시키는 것은 복잡성을 증가시키고, 실수로 인한 오류 가능성을 높입니다.
C. 데이터베이스 자격 증명을 개인 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 예약하여 365일마다 새로운 자격 증명 세트를 생성합니다.

Amazon S3: S3는 객체 스토리지 서비스로, 민감한 정보를 저장하는 데 적합하지 않습니다.
보안 문제: S3는 암호화를 지원하지만, 자격 증명을 저장하는 데는 비효율적이며 보안 위험이 존재합니다.
복잡성 증가: Lambda 함수를 통해 비밀번호를 갱신하는 과정은 구현이 복잡하며, 실수로 인한 오류 가능성이 높습니다.

D. AWS Systems Manager Parameter Store에 데이터베이스 자격 증명을 안전한 문자열 매개변수로 저장합니다. 365일마다 매개변수에 대한 자동 로테이션을 구성합니다.
AWS Systems Manager Parameter Store: 이 서비스는 애플리케이션 구성 데이터를 중앙에서 관리할 수 있게 해줍니다.
암호화 지원: Parameter Store는 암호화를 지원하여 민감한 정보를 안전하게 저장할 수 있습니다.
자동 로테이션 미지원: 현재 Parameter Store는 자동 로테이션 기능을 제공하지 않으므로, 비밀번호 갱신을 수동으로 처리해야 합니다.

결론
가장 운영적으로 효율적인 방식은 A. AWS Secrets Manager에 데이터베이스 자격 증명을 저장하고 365일마다 비밀에 대한 자동 로테이션을 구성하는 것입니다. Secrets Manager는 자동 로테이션 기능을 제공하여 관리 부담을 줄이고, 규정 준수를 쉽게 유지할 수 있습니다. 또한, 다른 AWS 서비스와의 통합이 용이하여 전체 시스템의 안정성을 보장할 수 있습니다.


## 질문 #54
SysOps 관리자는 Amazon EC2 인스턴스 플릿을 관리할 책임이 있습니다. 

이러한 EC2 인스턴스는 빌드 아티팩트를 타사 서비스에 업로드합니다. 타사 서비스는 최근 모든 빌드 업로드가 단일 IP 주소에서 이루어져야 하는 엄격한 IP 허용 목록을 구현했습니다.
시스템 관리자는 이 새로운 요구 사항을 준수하기 위해 기존 빌드 플릿에 어떤 변경을 해야 합니까?


A. 모든 EC2 인스턴스를 NAT 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다. 가장 많이 투표된
B. 모든 EC2 인스턴스를 인터넷 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.
C. 모든 EC2 인스턴스를 단일 가용성 영역으로 이동하고 가용성 영역 IP 주소를 서비스에 제공합니다.
D. 모든 EC2 인스턴스를 피어링된 VPC로 이동하고 VPC IP 주소를 서비스에 제공합니다.


Amazon EC2 인스턴스 플릿의 IP 허용 목록 준수
SysOps 관리자가 관리하는 Amazon EC2 인스턴스 플릿은 빌드 아티팩트를 타사 서비스에 업로드합니다. 최근 타사 서비스는 모든 빌드 업로드가 단일 IP 주소에서 이루어져야 한다는 엄격한 IP 허용 목록을 구현했습니다. 이를 준수하기 위해 필요한 변경 사항을 검토해 보겠습니다.

A. 모든 EC2 인스턴스를 NAT 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.
NAT 게이트웨이: NAT(Network Address Translation) 게이트웨이는 프라이빗 서브넷에 있는 인스턴스가 인터넷에 접근할 수 있도록 하지만, 고정된 공용 IP 주소를 제공합니다.
공용 IP 주소: NAT 게이트웨이는 고정된 공용 IP 주소를 가지고 있어, 이를 타사 서비스에 제공하면 모든 EC2 인스턴스가 동일한 출발 지점(IP 주소)을 가지게 됩니다.
설정 용이성: NAT 게이트웨이를 설정하고 모든 EC2 인스턴스를 해당 게이트웨이를 통해 라우팅하는 것은 비교적 간단하며, 기존 인프라 구조를 크게 변경하지 않고도 적용할 수 있습니다.

B. 모든 EC2 인스턴스를 인터넷 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.
인터넷 게이트웨이: 인터넷 게이트웨이는 VPC와 인터넷 간의 트래픽을 라우팅하는 역할을 합니다.
IP 주소 문제: 인터넷 게이트웨이는 고정된 공용 IP 주소를 제공하지 않으며, 각 인스턴스가 개별적으로 인터넷에 접근하게 됩니다. 따라서 단일 IP 주소로 통제할 수 없습니다.
비효율성: 이 방법은 타사 서비스의 요구 사항을 충족하지 못합니다.

C. 모든 EC2 인스턴스를 단일 가용성 영역으로 이동하고 가용성 영역 IP 주소를 서비스에 제공합니다.
가용성 영역(AZ): AZ는 물리적으로 분리된 데이터 센터 집합으로, 고가용성을 위해 설계되었습니다.
AZ IP 주소: AZ 자체는 고정된 공용 IP 주소를 제공하지 않습니다. 대신, 각 인스턴스는 자신의 공용 IP 주소를 가집니다.
불가능성: 이 방법 역시 단일 IP 주소로 통제할 수 없으므로 타사 서비스의 요구 사항을 충족하지 못합니다.

D. 모든 EC2 인스턴스를 피어링된 VPC로 이동하고 VPC IP 주소를 서비스에 제공합니다.
VPC 피어링: 서로 다른 VPC 간의 네트워크 연결을 가능하게 합니다.
IP 주소 문제: VPC 피어링은 네트워크 연결을 제공하지만, 단일 공용 IP 주소를 제공하지 않습니다. 각 인스턴스는 여전히 개별적인 출발 지점을 가집니다.
비효율성: 이 방법도 타사 서비스의 요구 사항을 충족하지 못합니다.

결론
타사 서비스의 요구 사항을 가장 효율적으로 충족하기 위해서는 A. 모든 EC2 인스턴스를 NAT 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공하는 것이 가장 적합합니다. NAT 게이트웨이는 고정된 공용 IP 주소를 제공하여 모든 인스턴스가 동일한 출발 지점을 가지게 함으로써, 타사 서비스의 IP 허용 목록 요구 사항을 쉽게 준수할 수 있습니다.


## 질문 #55
한 회사가 Amazon CloudFront 배포를 사용하여 웹사이트를 제공합니다. 

웹사이트의 트래픽 로그는 중앙에 저장되어야 하며 모든 데이터는 저장 시 암호화되어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?


A. 기본 AWS 관리형 고객 마스터 키(CMK)를 사용하는 인터넷 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용하도록 CloudFront를 구성합니다.
B. AES-256을 사용하는 VPC 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. CloudFront를 구성하여 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용합니다.
C. AES-256을 사용하는 기본 서버 측 암호화로 구성된 Amazon S3 버킷을 만듭니다. S3 버킷을 로그 대상으로 사용하도록 CloudFront를 구성합니다. 가장 많이 투표된
D. 기본 암호화 없이 구성된 Amazon S3 버킷을 만듭니다. CloudFront 배포에서 암호화를 활성화하고 S3 버킷을 로그 대상으로 사용합니다.



Amazon CloudFront 트래픽 로그 저장 및 암호화
Amazon CloudFront는 글로벌 콘텐츠 전송 네트워크(CDN)으로, 웹사이트의 성능과 보안을 향상시키는 데 사용됩니다. 웹사이트의 트래픽 로그를 중앙에 저장하고, 저장 시 모든 데이터를 암호화하는 요구 사항을 충족하기 위해 적절한 솔루션을 찾는 것이 중요합니다.

A. 기본 AWS 관리형 고객 마스터 키(CMK)를 사용하는 인터넷 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용하도록 CloudFront를 구성합니다.
Amazon OpenSearch Service(Amazon Elasticsearch Service): 검색 및 분석 엔진으로, 로그 데이터를 저장하고 검색할 수 있습니다.
서버 측 암호화: 기본 AWS 관리형 CMK를 사용하여 데이터를 암호화할 수 있습니다.
로그 대상 설정: CloudFront의 로그를 Amazon OpenSearch Service 도메인에 직접 보내는 기능은 제공되지 않습니다.
B. AES-256을 사용하는 VPC 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. CloudFront를 구성하여 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용합니다.
AES-256 암호화: 강력한 암호화 알고리즘으로 데이터 보호에 효과적입니다.
VPC 액세스: VPC 내에서만 접근 가능하도록 설정할 수 있습니다.
로그 대상 설정: 마찬가지로, CloudFront의 로그를 Amazon OpenSearch Service 도메인에 직접 보내는 기능은 제공되지 않습니다.
C. AES-256을 사용하는 기본 서버 측 암호화로 구성된 Amazon S3 버킷을 만듭니다. S3 버킷을 로그 대상으로 사용하도록 CloudFront를 구성합니다.
Amazon S3: 객체 스토리지 서비스로, 대량의 데이터를 저장할 수 있습니다.
서버 측 암호화(SSE): AES-256을 사용하여 데이터를 암호화할 수 있습니다.
CloudFront 로그 저장: CloudFront는 로그를 Amazon S3 버킷에 저장할 수 있습니다. 이를 통해 중앙에서 로그를 관리하고, 저장 시 암호화된 상태로 유지할 수 있습니다.
D. 기본 암호화 없이 구성된 Amazon S3 버킷을 만듭니다. CloudFront 배포에서 암호화를 활성화하고 S3 버킷을 로그 대상으로 사용합니다.
기본 암호화 없음: 데이터가 암호화되지 않은 상태로 저장됩니다.
CloudFront 암호화 설정: CloudFront 자체에서 암호화를 활성화하는 기능은 제공되지 않습니다.

#### 결론
위의 옵션 중에서 요구 사항을 가장 잘 충족하는 솔루션은 C. AES-256을 사용하는 기본 서버 측 암호화로 구성된 Amazon S3 버킷을 만들고, S3 버킷을 로그 대상으로 사용하도록 CloudFront를 구성하는 것입니다. 이 방법은 다음과 같은 장점을 제공합니다:

중앙 집중식 로그 관리: 모든 로그가 하나의 S3 버킷에 저장됩니다.
데이터 암호화: AES-256을 사용하여 데이터를 암호화함으로써 보안을 강화합니다.
CloudFront와의 통합: CloudFront는 로그를 Amazon S3 버킷에 직접 저장할 수 있어 설정이 간편합니다.



## 질문 #56
한 조직에서 파일 시스템 ID가 fs-85ba41fc인 Amazon Elastic File System(Amazon EFS) 볼륨을 생성했고, 10개의 Amazon EC2 호스트에서 활발하게 사용되고 있습니다. 

이 조직은 파일 시스템이 암호화되지 않은 것에 대해 우려하고 있습니다.
이를 어떻게 해결할 수 있을까요?


A. Amazon EFS 볼륨에 대한 각 호스트 연결에서 암호화를 활성화합니다. 암호화가 적용되려면 각 연결을 다시 만들어야 합니다.
B. AWS 명령줄 인터페이스를 사용하여 기존 EFS 볼륨에서 암호화를 활성화합니다.
C. 각 호스트의 로컬 드라이브에서 암호화를 활성화합니다. 각 호스트를 다시 시작하여 드라이브를 암호화합니다.
D. 새로 생성된 볼륨에서 암호화를 활성화하고 원래 볼륨에서 모든 데이터를 복사합니다. 각 호스트를 새 볼륨에 다시 연결합니다. 가장 많이 투표된


#### 결론
조직의 요구 사항을 가장 잘 충족하는 솔루션은 D. 새로운 암호화된 EFS 볼륨을 생성하고, 원래 볼륨에서 모든 데이터를 복사한 후, 각 호스트를 새 볼륨에 다시 연결하는 것입니다. 이 방법은 다음과 같은 장점을 제공합니다:

데이터 보안 강화: 새로운 EFS 볼륨에서 암호화를 활성화하여 데이터 보안을 강화할 수 있습니다.
데이터 무손실: 기존 볼륨의 데이터를 새로운 볼륨으로 복사하여 데이터 손실을 방지할 수 있습니다.
운영 중단 최소화: 계획적으로 작업을 수행하면 운영 중단을 최소화할 수 있습니다.




## 질문 #57
한 회사가 AWS Service Catalog 포트폴리오를 사용하여 리소스를 만들고 관리합니다.

SysOps 관리자는 새 AWS 계정에서 회사의 기존 AWS 인프라의 복제본을 만들어야 합니다.
이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. 새로운 AWS 계정에서 AWS Service Catalog 포트폴리오를 사용하려면 AWS CloudFormation 템플릿을 만듭니다.
B. 새로운 AWS 계정에서 원래 포트폴리오를 복제하는 AWS Service Catalog 포트폴리오를 수동으로 생성합니다.
C. AWS Lambda 함수를 실행하여 DescribePortfolio API 작업의 출력을 기반으로 새로운 AWS Service Catalog 포트폴리오를 생성합니다.
D. AWS Service Catalog 포트폴리오를 새 AWS 계정과 공유합니다. 포트폴리오를 새 AWS 계정으로 가져옵니다. 가장 많이 투표된

AWS Service Catalog 포트폴리오 복제
AWS Service Catalog는 IT 서비스 카탈로그를 통해 AWS 리소스를 프로비저닝하고 관리하는 데 사용됩니다. 새로운 AWS 계정에서 기존 AWS 인프라의 복제본을 만드는 것은 여러 가지 방법으로 가능하지만, 가장 운영 효율적인 방법을 찾는 것이 중요합니다.

A. 새로운 AWS 계정에서 AWS Service Catalog 포트폴리오를 사용하려면 AWS CloudFormation 템플릿을 만듭니다.
AWS CloudFormation 템플릿: 인프라를 코드로 정의하여 자동화된 배포를 가능하게 합니다.
템플릿 작성: AWS Service Catalog 포트폴리오를 CloudFormation 템플릿으로 변환해야 합니다. 이는 상당한 시간과 노력이 필요할 수 있습니다.
복잡성: 템플릿 작성 및 테스트 과정이 복잡할 수 있으며, 실수로 인한 오류 가능성이 있습니다.
B. 새로운 AWS 계정에서 원래 포트폴리오를 복제하는 AWS Service Catalog 포트폴리오를 수동으로 생성합니다.
수동 생성: 새로운 AWS 계정에서 기존 포트폴리오를 수동으로 재생성하는 방법입니다.
시간 소모: 모든 항목을 수동으로 설정해야 하므로 매우 시간이 많이 걸리고 오류가 발생할 가능성이 큽니다.
비효율성: 자동화된 방법보다 훨씬 비효율적입니다.
C. AWS Lambda 함수를 실행하여 DescribePortfolio API 작업의 출력을 기반으로 새로운 AWS Service Catalog 포트폴리오를 생성합니다.
AWS Lambda 함수: 이벤트 기반 컴퓨팅 서비스로, 특정 작업을 자동으로 수행할 수 있습니다.
API 호출: DescribePortfolio API를 사용하여 기존 포트폴리오의 정보를 가져온 후, 이를 기반으로 새로운 포트폴리오를 생성하는 스크립트를 작성할 수 있습니다.
자동화: 자동화된 프로세스로 인해 효율성이 높아지지만, 초기 설정과 디버깅에 시간이 걸릴 수 있습니다.
D. AWS Service Catalog 포트폴리오를 새 AWS 계정과 공유합니다. 포트폴리오를 새 AWS 계정으로 가져옵니다.
포트폴리오 공유: AWS Service Catalog 포트폴리오를 다른 AWS 계정과 공유할 수 있습니다.
간편성: 포트폴리오를 공유하고 가져오는 과정이 상대적으로 간단하며, 수동 작업이나 스크립트 작성이 필요 없습니다.
효율성: 빠르고 효율적으로 포트폴리오를 복제할 수 있습니다.

#### 결론
가장 운영 효율적인 방법은 D. AWS Service Catalog 포트폴리오를 새 AWS 계정과 공유하고, 포트폴리오를 새 AWS 계정으로 가져오는 것입니다. 이 방법은 다음과 같은 장점을 제공합니다:

간편성: 복잡한 스크립트나 템플릿 작성이 필요 없습니다.
빠른 배포: 포트폴리오를 빠르게 공유하고 가져올 수 있습니다.
오류 감소: 수동 작업이나 자동화 스크립트 작성으로 인한 오류 가능성이 줄어듭니다.



## 질문 #58
SysOps 관리자는 AWS 계정의 보안을 관리해야 합니다. 

최근에 IAM 사용자의 액세스 키가 실수로 공개 코드 저장소에 업로드되었습니다.
SysOps 관리자는 이 액세스 키를 사용하여 변경된 모든 것을 식별해야 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?


A. 모든 IAM 이벤트를 분석을 위해 AWS Lambda 함수로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
B. Amazon CloudWatch Logs Insights를 사용하여 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 Amazon EC2 로그를 쿼리합니다.
C. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 AWS CloudTrail 이벤트 기록을 검색합니다. 가장 많이 투표된
D. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 VPC 흐름 로그를 검색합니다.


AWS 계정 보안 관리: IAM 사용자 액세스 키 노출 대응
IAM(Identity and Access Management) 사용자의 액세스 키가 실수로 공개 코드 저장소에 업로드된 경우, 해당 키를 사용하여 어떤 변경 사항이 있었는지 식별하는 것은 매우 중요합니다. 이를 통해 잠재적인 보안 위협을 평가하고 대응할 수 있습니다.

A. 모든 IAM 이벤트를 분석을 위해 AWS Lambda 함수로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
Amazon EventBridge: 이벤트 기반 아키텍처를 지원하는 서비스로, 다양한 AWS 서비스 간의 이벤트를 라우팅할 수 있습니다.
Lambda 함수와의 통합: IAM 이벤트를 Amazon EventBridge를 통해 AWS Lambda 함수로 전송하여 분석할 수 있습니다.
실시간 분석: 실시간으로 이벤트를 처리하고 분석할 수 있지만, 과거 이벤트를 조회하는 데는 적합하지 않습니다.

B. Amazon CloudWatch Logs Insights를 사용하여 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 Amazon EC2 로그를 쿼리합니다.
Amazon CloudWatch Logs Insights: 로그 데이터를 분석하고 시각화하는 도구입니다.
EC2 로그 분석: EC2 인스턴스의 로그를 분석하여 특정 액세스 키로 인한 활동을 추적할 수 있습니다.
범위 제한: EC2 로그만 분석하므로, 다른 AWS 서비스에서 발생한 이벤트는 포함되지 않습니다.

C. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 AWS CloudTrail 이벤트 기록을 검색합니다.
AWS CloudTrail: AWS 계정의 API 호출을 기록하고 모니터링하는 서비스입니다.
이벤트 기록 검색: CloudTrail 이벤트 기록을 통해 특정 액세스 키를 사용한 모든 API 호출을 추적할 수 있습니다.
종합적인 분석: AWS 계정 내 모든 서비스에서 발생한 이벤트를 포함하므로, 종합적인 분석이 가능합니다.

D. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 VPC 흐름 로그를 검색합니다.
VPC 흐름 로그: VPC 내에서 발생하는 네트워크 트래픽을 기록하는 기능입니다.
네트워크 트래픽 분석: 네트워크 레벨에서의 트래픽을 분석할 수 있지만, API 호출이나 리소스 변경 사항을 직접적으로 추적하기 어렵습니다.
범위 제한: 네트워크 트래픽에 국한되므로, 전체적인 보안 분석에는 부족함이 있습니다.

#### 결론
가장 적합한 방법은 C. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 AWS CloudTrail 이벤트 기록을 검색하는 것입니다. 이 방법은 다음과 같은 장점을 제공합니다:

종합적인 분석: AWS 계정 내 모든 서비스에서 발생한 이벤트를 포함하여 종합적으로 분석할 수 있습니다.
정확한 추적: 특정 액세스 키를 사용한 모든 API 호출을 정확하게 추적할 수 있습니다.
보안 평가: 잠재적인 보안 위협을 평가하고 대응하는 데 유용합니다.



## 질문 #59
한 회사가 Application Load Balancer(ALB) 뒤의 여러 Amazon EC2 인스턴스에서 리테일 웹사이트를 운영합니다. 

이 회사는 HTTPS 연결을 통해 웹사이트로의 트래픽을 보호해야 합니다.
이러한 요구 사항을 충족하기 위해 SysOps 관리자는 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. 각 EC2 인스턴스에 인증서를 첨부합니다.
B. ALB에 인증서를 첨부합니다. 가장 많이 투표된
C. AWS Certificate Manager(ACM)에서 개인 인증서를 만듭니다.
D. AWS Certificate Manager(ACM)에서 공용 인증서를 만듭니다. 가장 많이 투표된
E. 인증서를 내보내어 웹사이트에 첨부합니다.

HTTPS 연결을 통한 웹사이트 트래픽 보호
HTTPS는 웹사이트와 사용자 간의 통신을 암호화하여 데이터의 기밀성과 무결성을 보장합니다. 이를 위해 SSL/TLS 인증서를 사용해야 합니다. Amazon Web Services(AWS)에서는 Application Load Balancer(ALB)와 AWS Certificate Manager(ACM)를 활용하여 HTTPS 연결을 설정할 수 있습니다.

A. 각 EC2 인스턴스에 인증서를 첨부합니다.
EC2 인스턴스에 인증서 첨부: 각 EC2 인스턴스에 개별적으로 SSL/TLS 인증서를 설치하는 방법입니다.
복잡성 증가: 여러 인스턴스에 대해 인증서를 관리해야 하므로 복잡성이 증가합니다.
비효율성: ALB를 사용하는 경우, ALB 레벨에서 인증서를 관리하는 것이 더 효율적입니다.

B. ALB에 인증서를 첨부합니다.
ALB에 인증서 첨부: ALB는 HTTPS 트래픽을 처리하고, 이를 백엔드 EC2 인스턴스로 전달합니다. ALB에 SSL/TLS 인증서를 첨부하면 모든 트래픽이 암호화됩니다.
중앙 집중식 관리: ALB에서 인증서를 관리하므로, 개별 인스턴스에 인증서를 설치할 필요가 없습니다.
간편성: 설정이 간편하며, ALB가 트래픽을 분산시키면서 암호화를 처리합니다.

C. AWS Certificate Manager(ACM)에서 개인 인증서를 만듭니다.
개인 인증서 생성: ACM을 통해 개인 인증서를 생성할 수 있습니다.
비용 발생: 개인 인증서는 비용이 발생할 수 있습니다.
제한적 사용: 특정 도메인에 대해서만 유효하므로, 범용적으로 사용하기 어렵습니다.

D. AWS Certificate Manager(ACM)에서 공용 인증서를 만듭니다.
공용 인증서 생성: ACM을 통해 무료로 공용 SSL/TLS 인증서를 발급받을 수 있습니다.
무료 제공: AWS에서 무료로 제공하므로 비용 부담이 없습니다.
간편한 발급: 몇 가지 단계만 거쳐 쉽게 인증서를 발급받을 수 있습니다.

E. 인증서를 내보내어 웹사이트에 첨부합니다.
인증서 내보내기: 발급받은 인증서를 다운로드하여 웹사이트에 직접 첨부하는 방법입니다.
추가 작업 필요: 인증서를 내보내고 웹사이트에 수동으로 첨부해야 하므로 추가 작업이 필요합니다.
비효율성: ALB와 ACM을 함께 사용하는 것이 더 효율적입니다.

#### 결론
HTTPS 연결을 통해 웹사이트 트래픽을 보호하기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

B. ALB에 인증서를 첨부합니다.
ALB에서 HTTPS 트래픽을 처리하고 암호화하여 백엔드 EC2 인스턴스로 전달합니다.

D. AWS Certificate Manager(ACM)에서 공용 인증서를 만듭니다.
ACM을 통해 무료로 공용 SSL/TLS 인증서를 발급받아 ALB에 첨부합니다.
이 두 가지 조치를 통해 HTTPS 연결을 설정하고 웹사이트 트래픽을 안전하게 보호할 수 있습니다.


## 질문 #60
시뮬레이션 -

지침 -
환경에서 복사-붙여넣기 기능이 작동하지 않는 경우 VM 데스크톱의 지침 파일을 참조하고 Ctrl+C, Ctrl+V 또는 Command-C,
Command-V를 사용합니다.
다음 요구 사항을 충족하도록 Amazon EventBridge를 구성합니다.

1. 모든 리소스에 us-east-2 리전을 사용합니다.
2. 아래에 지정되지 않은 경우 기본 구성 설정을 사용합니다.
3. 아래에 리소스 이름이 지정되지 않은 경우 고유한 리소스 명명을 사용합니다.
4. 기본 이벤트 버스의 모든 Amazon EC2 이벤트가 지난 45일 동안 재생 가능한지 확인합니다.
5. RunFunction이라는 규칙을 만들어 15분마다 정확한 메시지 {"name":"example")를 LogEventFunction이라는 기존 AWS Lambda 함수로 보냅니다.
6. SpotWarning이라는 규칙을 만들어 Amazon EC2 Spot Instance가 중단될 때마다 TopicEvents라는 새 표준 Amazon SNS 토픽으로 알림을 보냅니다. 토픽 구독을 만들지 마십시오. 알림은 다음 구조와 일치해야 합니다.
7. 
입력 경로:
{`instance`:`detail.instance-id}
입력 템플릿:
`EC2 Spot 인스턴스 <instance>가 중단되었습니다.`
중요: 다음 버튼을 클릭하여 이 랩을 완료하고 다음 랩으로 넘어가세요. 다음 버튼을 클릭하면 이 랩으로 돌아갈 수 없습니다.


## 질문 #61
한 회사가 단일 xlarge 범용 Amazon EC2 온디맨드 인스턴스에서 상태가 유지되는 장기 실행 워크로드를 보유하고 있습니다. 

메트릭은 서비스가 항상 사용 가능한 메모리의 80%와 사용 가능한 CPU의 40%를 사용하고 있음을 보여줍니다. SysOps 관리자는 성능에 부정적인 영향을 미치지 않으면서 서비스 비용을 줄여야 합니다.
이러한 요구 사항을 충족하는 인스턴스 유형의 변경은 무엇입니까?

A. 하나의 대규모 컴퓨팅 최적화 온디맨드 인스턴스로 변경합니다.
B. 대용량 메모리 최적화된 단일 온디맨드 인스턴스로 변경합니다. 가장 많이 투표된
C. 하나의 xlarge 범용 스팟 인스턴스로 변경합니다.
D. 두 개의 대규모 일반 용도 온디맨드 인스턴스로 변경합니다.

#### 결론
가장 적합한 옵션은 B. 대용량 메모리 최적화된 단일 온디맨드 인스턴스로 변경하는 것입니다. 이 옵션은 현재 워크로드의 높은 메모리 사용률을 충족하면서도, CPU 사용률이 낮아지는 것을 감안해도 성능 저하 없이 비용을 절감할 수 있습니다.

참고: 실제로는 워크로드의 특성과 예측되는 변화에 따라 최적의 인스턴스 유형을 선택하는 것이 중요합니다. 필요시 AWS Cost Explorer와 같은 도구를 사용하여 비용 분석을 진행하는 것도 좋은 방법입니다.

## 질문 #62
한 회사에서 SysOps 관리자에게 AWS CloudTrail 파일이 생성된 후 변조되지 않도록 해달라고 요청했습니다. 

현재 이 회사는 AWSIdentity and Access Management(IAM)를 사용하여 특정 트레일에 대한 액세스를 제한합니다. 이 회사의 보안 팀은 각 파일의 무결성을 추적할 수 있어야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 새 파일이 전달될 때 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 파일에서 MD5 해시 검사를 계산하고 결과를 Amazon DynamoDB 테이블에 저장합니다. 보안 팀은 DynamoDB에 저장된 값을 사용하여 전달된 파일의 무결성을 확인할 수 있습니다.
B. CloudTrail 버킷에 새 파일이 전달될 때마다 호출되는 AWS Lambda 함수를 만듭니다. Lambda 함수를 구성하여 파일에 대한 MD5 해시 검사를 계산하고 결과를 Amazon 53 객체의 태그로 저장합니다. 보안 팀은 태그의 정보를 사용하여 전달된 파일의 무결성을 확인할 수 있습니다.
C. Amazon S3 버킷에서 CloudTrail 파일 무결성 기능을 활성화합니다. 보안 팀에 S3 버킷에 저장된 파일 무결성 로그에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다.
D. 트레일에서 CloudTrail 파일 무결성 기능을 활성화합니다. 보안 팀은 CloudTrail에서 생성한 다이제스트 파일을 사용하여 전달된 파일의 무결성을 확인할 수 있습니다. 가장 많이 투표된

AWS CloudTrail 파일 무결성 보장: 운영 효율적인 솔루션
AWS CloudTrail은 AWS 계정의 API 호출을 기록하여 감사 및 모니터링을 돕는 서비스입니다. CloudTrail 파일의 무결성을 보장하는 것은 보안상의 중요한 요구 사항입니다. 이 회사는 AWS Identity and Access Management(IAM)를 사용하여 특정 트레일에 대한 액세스를 제한하고 있으며, 각 파일의 무결성을 추적할 수 있어야 합니다.

요구 사항 분석
파일 무결성 보장: CloudTrail 파일이 생성된 후 변조되지 않도록 해야 합니다.
무결성 추적: 보안 팀이 각 파일의 무결성을 확인할 수 있어야 합니다.
운영 효율성: 솔루션이 운영적으로 효율적이어야 합니다.
옵션 분석
A. Amazon EventBridge(Amazon CloudWatch Events) 규칙과 AWS Lambda 함수 사용
EventBridge 규칙: 새 파일이 전달될 때 AWS Lambda 함수를 호출합니다.
Lambda 함수: 파일에서 MD5 해시 검사를 계산하고 결과를 Amazon DynamoDB 테이블에 저장합니다.
무결성 확인: 보안 팀은 DynamoDB에 저장된 값을 사용하여 파일의 무결성을 확인할 수 있습니다.
장점: 자동화된 프로세스로 무결성 체크를 수행할 수 있습니다.
단점: 추가적인 인프라 설정과 관리가 필요합니다.

B. AWS Lambda 함수와 Amazon Route 53 객체 태그 사용
Lambda 함수: CloudTrail 버킷에 새 파일이 전달될 때마다 호출됩니다.
MD5 해시 검사: 파일에 대한 MD5 해시 검사를 계산하고 결과를 Amazon Route 53 객체의 태그로 저장합니다.
무결성 확인: 보안 팀은 태그의 정보를 사용하여 파일의 무결성을 확인할 수 있습니다.
장점: Route 53을 활용한 간단한 무결성 체크.
단점: Route 53은 주로 DNS 관리에 사용되므로, 이 용도로 사용하는 것은 비효율적일 수 있습니다.

C. Amazon S3 버킷에서 CloudTrail 파일 무결성 기능 활성화
S3 버킷 무결성 기능: Amazon S3 버킷에서 CloudTrail 파일 무결성 기능을 활성화합니다.
IAM 정책: 보안 팀에 S3 버킷에 저장된 파일 무결성 로그에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다.
무결성 확인: 보안 팀은 S3 버킷에 저장된 파일 무결성 로그를 통해 파일의 무결성을 확인할 수 있습니다.
장점: S3의 내장 기능을 활용하여 간편하게 무결성을 관리할 수 있습니다.
단점: S3 버킷의 설정 변경이 필요합니다.

D. CloudTrail 파일 무결성 기능 활성화
CloudTrail 파일 무결성 기능: 트레일에서 CloudTrail 파일 무결성 기능을 활성화합니다.
다이제스트 파일: CloudTrail에서 생성한 다이제스트 파일을 사용하여 파일의 무결성을 확인할 수 있습니다.
무결성 확인: 보안 팀은 다이제스트 파일을 통해 파일의 무결성을 확인할 수 있습니다.
장점: CloudTrail 자체 기능을 사용하여 간편하게 무결성을 관리할 수 있습니다.
단점: 추가적인 설정이 필요하지만, 가장 직관적이고 운영적으로 효율적입니다.

#### 결론
가장 운영 효율적인 솔루션은 D. 트레일에서 CloudTrail 파일 무결성 기능을 활성화하는 것입니다. 이 방법은 CloudTrail 자체 기능을 활용하여 파일의 무결성을 보장하고, 보안 팀이 다이제스트 파일을 통해 쉽게 무결성을 확인할 수 있습니다. 이는 추가적인 인프라 설정 없이도 간편하게 구현할 수 있는 방법입니다.


## 질문 #63
AWS 클라우드 인프라에서 조직에 영향을 미칠 수 있는 이벤트가 발생하는 경우, 어떤 AWS 서비스를 사용하여 조직의 어떤 리소스가 영향을 받는지 확인할 수 있습니까?

A. AWS 서비스 상태 대시보드
B. AWS 신뢰할 수 있는 고문
C. AWS 개인 건강 대시보드 가장 많이 투표된
D. AWS 시스템 관리자


AWS 클라우드 인프라에서 이벤트 영향 확인
AWS 클라우드 인프라에서 조직에 영향을 미칠 수 있는 이벤트가 발생할 때, 이를 모니터링하고 분석하는 것은 매우 중요합니다. AWS는 이러한 요구를 충족시키기 위해 다양한 서비스를 제공합니다. 이 질문에서는 특정 이벤트가 발생했을 때 조직의 어떤 리소스가 영향을 받았는지 확인할 수 있는 서비스를 묻고 있습니다.

옵션 분석

A. AWS 서비스 상태 대시보드
AWS 서비스 상태 대시보드: AWS의 전 세계 서비스 상태를 실시간으로 모니터링할 수 있는 대시보드입니다.
서비스 상태 확인: 각 서비스의 현재 상태와 문제 발생 시 공지사항을 제공합니다.
지역별 정보: 특정 지역에서 발생한 문제를 확인할 수 있습니다.
제한 사항: 개별 리소스에 대한 상세한 영향 분석은 제공하지 않습니다.

B. AWS 신뢰할 수 있는 고문
AWS 신뢰할 수 있는 고문: AWS 환경의 최적화 및 모범 사례 준수를 위한 권장 사항을 제공하는 서비스입니다.
자동화된 모니터링: 리소스의 구성 및 운영 상태를 지속적으로 평가합니다.
권장 사항 제공: 성능, 보안, 비용 최적화 등을 위한 권장 사항을 제공합니다.
제한 사항: 실시간 이벤트 영향 분석보다는 주로 최적화 및 모범 사례 준수에 초점을 맞춥니다.

C. AWS 개인 건강 대시보드
AWS 개인 건강 대시보드: 조직의 AWS 리소스에 영향을 미치는 이벤트를 실시간으로 모니터링하고 분석할 수 있는 대시보드입니다.
맞춤형 알림: 특정 리소스나 서비스에 대한 맞춤형 알림을 설정할 수 있습니다.
상세 분석: 이벤트가 발생했을 때 영향을 받은 리소스를 상세히 분석할 수 있습니다.
강점: 실시간 모니터링과 상세 분석 기능으로 이벤트 영향 확인에 매우 유용합니다.

D. AWS 시스템 관리자
AWS 시스템 관리자: AWS 인프라의 운영 및 관리를 돕기 위한 다양한 도구와 기능을 제공하는 서비스입니다.
자동화된 작업: 패치 관리, 인벤토리 관리, 운영 작업 자동화 등을 지원합니다.
제한 사항: 이벤트 영향 분석보다는 주로 운영 관리에 초점을 맞춥니다.

#### 결론
조직의 AWS 클라우드 인프라에서 발생한 이벤트가 어떤 리소스에 영향을 미쳤는지 확인하기 위해 가장 적합한 서비스는 C. AWS 개인 건강 대시보드입니다. 이 대시보드는 실시간 모니터링과 상세 분석 기능을 제공하여 이벤트 발생 시 영향을 받은 리소스를 정확히 파악할 수 있습니다.


## 질문 #64
한 회사에서 가져온 키 자료가 있는 AWS KMS 고객 마스터 키(CMK)를 사용하고 있습니다. 

이 회사는 Java 애플리케이션에서 별칭으로 CMK를 참조하여 데이터를 암호화합니다. CMK는 6개월마다 순환해야 합니다.
키를 순환하는 프로세스는 무엇입니까?

A. CMK에 대해 자동 키 회전을 활성화하고 6개월 기간을 지정합니다.
B. 새로 가져온 자료로 새 CMK를 만들고 키 별칭을 업데이트하여 새 CMK를 가리키도록 합니다. 가장 많이 투표된
C. 현재 키 자료를 삭제하고 새 자료를 기존 CMK로 가져옵니다.
D. 기존 키 자료의 사본을 백업용으로 새 CMK로 가져오고, 순환 일정을 6개월로 설정합니다.


#### AWS KMS 고객 마스터 키(CMK) 순환 프로세스
AWS Key Management Service(KMS)는 데이터 암호화 및 키 관리를 위한 강력한 도구입니다. 고객 마스터 키(CMK)는 이러한 암호화 작업의 핵심 요소로, 주기적인 키 순환이 보안성을 유지하는 데 중요합니다. 이 회사는 Java 애플리케이션에서 별칭으로 CMK를 참조하여 데이터를 암호화하고 있으며, CMK를 6개월마다 순환해야 합니다.

키 순환 프로세스 분석
A. CMK에 대해 자동 키 회전을 활성화하고 6개월 기간을 지정합니다.
자동 키 회전: AWS KMS는 자동 키 회전 기능을 제공하여 CMK를 주기적으로 갱신할 수 있습니다.
설정 방법: AWS Management Console, AWS CLI, 또는 SDK를 통해 자동 키 회전을 활성화하고 회전 주기를 설정할 수 있습니다.
장점: 자동화된 프로세스로 관리 부담이 줄어듭니다.
단점: 자동 키 회전은 최소 1년 주기로만 설정할 수 있어, 6개월 주기는 지원되지 않습니다.

B. 새로 가져온 자료로 새 CMK를 만들고 키 별칭을 업데이트하여 새 CMK를 가리키도록 합니다.
새 CMK 생성: 새로 가져온 키 자료를 사용하여 새로운 CMK를 생성합니다.
키 별칭 업데이트: 기존 키 별칭을 새 CMK로 가리키도록 업데이트합니다.
장점: 6개월 주기의 키 순환을 정확히 따를 수 있습니다.
단점: 수동으로 키 별칭을 업데이트해야 하므로 관리가 복잡할 수 있습니다.

C. 현재 키 자료를 삭제하고 새 자료를 기존 CMK로 가져옵니다.
키 자료 교체: 기존 CMK에 대해 현재 키 자료를 삭제하고 새 키 자료를 가져옵니다.
제한 사항: AWS KMS는 기존 CMK의 키 자료를 직접 수정할 수 없습니다.
단점: 이 방법은 AWS KMS의 기능으로 지원되지 않습니다.

D. 기존 키 자료의 사본을 백업용으로 새 CMK로 가져오고, 순환 일정을 6개월로 설정합니다.
백업 및 새 CMK 생성: 기존 키 자료의 사본을 백업용으로 새 CMK로 가져옵니다.
순환 일정 설정: 새 CMK에 대해 6개월 순환 일정을 설정합니다.
장점: 백업을 통해 데이터 손실을 방지할 수 있습니다.
단점: AWS KMS는 자동 키 회전을 1년 주기로만 지원하므로, 6개월 주기는 수동으로 관리해야 합니다.

#### 결론
가장 적합한 키 순환 프로세스는 B. 새로 가져온 자료로 새 CMK를 만들고 키 별칭을 업데이트하여 새 CMK를 가리키도록 하는 것입니다. 이 방법은 6개월 주기의 키 순환을 정확히 따를 수 있으며, Java 애플리케이션이 별칭을 통해 CMK를 참조하므로, 별칭만 업데이트하면 애플리케이션 코드 변경 없이 새로운 CMK를 사용할 수 있습니다.

## 질문 #65
보안팀은 환경에서 사용되는 AWS Identity and Access Management(IAM) 정책의 수가 증가하고 있기 때문에 우려하고 있습니다. 

팀은 SysOps 관리자에게 현재 사용 중인 IAM 정책의 수와 사용 가능한 총 IAM 정책에 대해 보고하도록 했습니다.
관리자는 현재 IAM 정책 사용량을 현재 서비스 한도와 비교하기 위해 어떤 AWS 서비스를 사용해야 합니까?

A. AWS 신뢰할 수 있는 고문 가장 많이 투표된
B. 아마존 인스펙터
C. AWS 구성
D. AWS 조직


AWS IAM 정책 사용량 모니터링: 적절한 서비스 선택
AWS Identity and Access Management(IAM)는 AWS 리소스에 대한 액세스를 제어하는 중요한 서비스입니다. 보안팀이 현재 사용 중인 IAM 정책의 수와 사용 가능한 총 IAM 정책에 대해 보고를 요청한 상황에서, SysOps 관리자는 이를 효율적으로 모니터링하고 관리할 수 있는 도구를 선택해야 합니다.

옵션 분석
A. AWS 신뢰할 수 있는 고문
AWS 신뢰할 수 있는 고문: AWS 환경의 최적화 및 모범 사례 준수를 위한 권장 사항을 제공하는 서비스입니다.
IAM 정책 분석: 현재 사용 중인 IAM 정책의 수와 서비스 한도를 비교하여 보고할 수 있습니다.
자동화된 모니터링: IAM 정책 사용량을 지속적으로 평가하고, 필요 시 알림을 제공합니다.
강점: AWS 환경 전반에 걸친 모범 사례 준수와 최적화를 지원합니다.

B. 아마존 인스펙터
아마존 인스펙터: AWS 리소스의 보안 및 규정 준수 상태를 평가하는 서비스입니다.
보안 평가: 주로 보안 취약점과 규정 준수 문제를 식별하는 데 중점을 둡니다.
제한 사항: IAM 정책 사용량 모니터링보다는 보안 평가에 더 적합합니다.

C. AWS 구성
AWS 구성: AWS 리소스의 구성 정보를 기록하고 관리하는 서비스입니다.
구성 기록: 리소스의 구성 변경 사항을 추적하고, 현재 상태를 기록합니다.
제한 사항: IAM 정책 사용량 모니터링보다는 리소스 구성 관리에 더 적합합니다.

D. AWS 조직
AWS 조직: 여러 AWS 계정을 중앙에서 관리할 수 있는 서비스입니다.
계정 관리: 다수의 AWS 계정을 통합하여 관리할 수 있습니다.
제한 사항: IAM 정책 사용량 모니터링보다는 계정 관리에 더 적합합니다.

#### 결론
현재 사용 중인 IAM 정책의 수와 사용 가능한 총 IAM 정책에 대해 보고하기 위해 가장 적합한 서비스는 A. AWS 신뢰할 수 있는 고문입니다. 이 서비스는 AWS 환경의 IAM 정책 사용량을 자동으로 모니터링하고, 현재 서비스 한도와 비교하여 보고할 수 있는 기능을 제공합니다. 이를 통해 SysOps 관리자는 IAM 정책 사용 현황을 효율적으로 파악하고 관리할 수 있습니다.


## 질문 #66
SysOps 관리자가 Amazon S3에 호스팅된 웹사이트로 트래픽을 라우팅하기 위해 Amazon Route 53 도메인 이름을 설정하려고 합니다. 

웹사이트의 도메인 이름은 www.example.com이고 S3 버킷 이름은 DOC-EXAMPLE-BUCKET입니다. Route 53에서 레코드 세트를 설정한 후 도메인 이름 www.anycompany.com이 작동하지 않는 듯하고 정적 웹사이트가 브라우저에 표시되지 않습니다.
다음 중 어떤 것이 원인일까요?

A. S3 버킷은 먼저 Amazon CloudFront로 구성되어야 합니다.
B. Route 53 레코드 세트에는 S3 버킷에 대한 액세스를 허용하는 IAM 역할이 있어야 합니다.
C. Route 53 레코드 세트는 S3 버킷과 동일한 지역에 있어야 합니다.
D. S3 버킷 이름은 Route 53의 레코드 세트 이름과 일치해야 합니다. 가장 많이 투표된


Amazon S3와 Route 53 설정 문제 해결
Amazon S3에 호스팅된 웹사이트로 트래픽을 라우팅하기 위해 Amazon Route 53 도메인 이름을 설정하는 과정에서 발생할 수 있는 문제를 이해하고 해결하는 것이 중요합니다. 주어진 시나리오에서는 도메인 이름 www.example.com이 S3 버킷 DOC-EXAMPLE-BUCKET으로 제대로 라우팅되지 않는 상황입니다.

문제 원인 분석
A. S3 버킷은 먼저 Amazon CloudFront로 구성되어야 합니다.
CloudFront 구성 필요성: Amazon CloudFront는 CDN(Content Delivery Network)으로, 전 세계적으로 콘텐츠를 빠르게 배포하는 데 사용됩니다.
필수 여부: S3 버킷을 CloudFront로 구성하는 것은 선택 사항이며, 필수는 아닙니다. 단순히 S3 버킷을 Route 53과 연결하는 것만으로도 웹사이트를 호스팅할 수 있습니다.
문제 해결 여부: 이 옵션은 현재 문제의 원인이 아닙니다.

B. Route 53 레코드 세트에는 S3 버킷에 대한 액세스를 허용하는 IAM 역할이 있어야 합니다.
IAM 역할 필요성: Route 53은 DNS 서비스로, 도메인 이름을 IP 주소로 변환하는 역할을 합니다. S3 버킷에 대한 액세스는 IAM 정책을 통해 제어됩니다.
필수 여부: Route 53 레코드 세트 자체에는 IAM 역할이 필요하지 않습니다. 대신, S3 버킷에 대한 액세스는 S3 버킷 정책을 통해 제어됩니다.
문제 해결 여부: 이 옵션은 현재 문제의 원인이 아닙니다.

C. Route 53 레코드 세트는 S3 버킷과 동일한 지역에 있어야 합니다.
지역 일치 필요성: Route 53은 글로벌 DNS 서비스로, 특정 지역에 종속되지 않습니다.
필수 여부: Route 53 레코드 세트는 S3 버킷과 동일한 지역에 있을 필요가 없습니다.
문제 해결 여부: 이 옵션은 현재 문제의 원인이 아닙니다.

D. S3 버킷 이름은 Route 53의 레코드 세트 이름과 일치해야 합니다.
버킷 이름과 레코드 세트 이름 일치 필요성: S3 버킷 이름과 Route 53 레코드 세트 이름이 일치해야 하는 것은 아닙니다. 중요한 것은 S3 버킷이 올바르게 설정되어 있고, Route 53에서 해당 버킷을 가리키는 레코드 세트가 올바르게 구성되어 있는 것입니다.
필수 여부: S3 버킷 이름과 Route 53 레코드 세트 이름이 일치할 필요는 없습니다.
문제 해결 여부: 이 옵션은 현재 문제의 원인이 아닙니다.

#### 실제 문제 원인 및 해결책
주어진 상황에서 가장 가능성이 높은 문제는 다음과 같습니다:

Route 53 레코드 세트 설정 오류: Route 53에서 S3 버킷을 가리키는 레코드 세트가 올바르게 설정되지 않았을 가능성이 큽니다. 특히, Alias 레코드를 사용하여 S3 버킷을 가리키도록 설정해야 합니다.
S3 버킷 설정 오류: S3 버킷이 정적 웹사이트 호스팅을 위해 올바르게 설정되지 않았을 수 있습니다. S3 버킷의 퍼블릭 액세스 설정과 정적 웹사이트 호스팅 설정을 확인해야 합니다.


## 질문 #67
SysOps 관리자가 AWS CloudFormation을 사용하여 서버리스 애플리케이션을 프로덕션 VPC에 배포했습니다. 

이 애플리케이션은 AWS Lambda 함수, Amazon DynamoDB 테이블, Amazon API Gateway API로 구성되어 있습니다. SysOps 관리자는 DynamoDB 테이블을 삭제하지 않고 AWS CloudFormation 스택을 삭제해야 합니다.
SysOps 관리자는 AWS CloudFormation 스택을 삭제하기 전에 어떤 조치를 취해야 합니까?

A. AWS CloudFormation 스택의 DynamoDB 리소스에 보존 삭제 정책을 추가합니다. 가장 많이 투표된
B. AWS CloudFormation 스택의 DynamoDB 리소스에 스냅샷 삭제 정책을 추가합니다.
C. AWS CloudFormation 스택에서 종료 보호를 활성화합니다.
D. dynamodb:DeleteTable 작업에 대한 Deny 문으로 애플리케이션의 IAM 정책을 업데이트합니다.

#### 결론
가장 적합한 방법은 A. AWS CloudFormation 스택의 DynamoDB 리소스에 보존 삭제 정책을 추가하는 것입니다. 이를 통해 DynamoDB 테이블을 삭제하지 않고 AWS CloudFormation 스택을 삭제할 수 있습니다. CloudFormation 템플릿에서 DeletionPolicy 속성을 Retain으로 설정하여 이 작업을 수행할 수 있습니다.

## 질문 #68
SysOps 관리자는 Amazon EC2 인스턴스가 응답을 멈췄다는 알림을 받습니다. 

AWS Management Console은 시스템 검사가 실패하고 있다고 표시합니다.
이 문제를 해결하기 위해 관리자는 먼저 무엇을 해야 합니까?

A. EC2 인스턴스를 재부팅하여 새 호스트에서 시작할 수 있도록 합니다.
B. EC2 인스턴스를 중지한 다음 다시 시작하여 새 호스트에서 시작할 수 있도록 합니다. 가장 많이 투표된
C. EC2 인스턴스를 종료하고 다시 시작합니다.
D. AWS CloudTrail 로그를 보고 EC2 인스턴스에서 어떤 변경 사항이 발생했는지 조사합니다.

####  결론
가장 적합한 첫 번째 조치는 B. EC2 인스턴스를 중지한 다음 다시 시작하여 새 호스트에서 시작할 수 있도록 하는 것입니다. 이를 통해 하드웨어 문제나 호스트 관련 문제를 해결할 수 있으며, 인스턴스가 다른 호스트에서 시작될 가능성이 높아집니다. 이후 문제가 지속되면 CloudTrail 로그를 분석하여 근본 원인을 파악할 수 있습니다.

## 질문 #69
소프트웨어 개발 회사에는 동일한 제품을 작업하는 여러 개발자가 있습니다. 

각 개발자는 자체 개발 환경을 가져야 하며 이러한 개발 환경은 동일해야 합니다. 각 개발 환경은 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스로 구성됩니다. 개발 환경은 필요할 때만 만들어야 하며 비용을 최소화하기 위해 매일 밤 종료해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 각 개발 인스턴스에서 매일 밤 cron 작업을 예약하여 실행 중인 모든 프로세스를 중지하고 CPU 사용률을 거의 0으로 줄입니다.

B. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 AWS CloudFormation 스택을 삭제합니다. 가장 많이 투표된

C. 개발자에게 CLI 명령을 제공하여 필요할 때 자체 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 모든 EC2 인스턴스와 DB 인스턴스를 종료합니다.

D. 개발자에게 CLI 명령을 제공하여 필요할 때 자체 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS CloudFormation이 모든 개발 환경 리소스를 삭제하도록 합니다.

#### 결론
가장 운영 효율적인 솔루션은 B. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 AWS CloudFormation 스택을 삭제하는 것입니다. 이 방법은 다음과 같은 장점을 제공합니다:

자동화된 프로세스: EventBridge와 Lambda를 사용하여 매일 밤 자동으로 스택을 삭제함으로써 비용을 절감할 수 있습니다.
일관된 환경: CloudFormation 템플릿을 사용하여 모든 개발자가 동일한 환경을 프로비저닝할 수 있습니다.
관리 용이성: 중앙에서 관리할 수 있어 복잡성이 줄어듭니다.

## 질문 #70
회사가 외부 공급업체와 협력하여 데이터 처리 서비스를 제공하고 있습니다. 

이 통합을 위해 공급업체는 공급업체의 AWS 계정에서 Amazon S3 버킷에 회사 데이터를 호스팅해야 합니다. 공급업체는 회사가 AWS Key Management Service(AWS KMS) 키를 제공하여 회사 데이터를 암호화하도록 허용합니다. 공급업체는 이 통합을 위해 회사에 IAM 역할 Amazon Resources Name(ARN)을 제공했습니다.
SysOps 관리자는 이 통합을 구성하기 위해 무엇을 해야 합니까?

A. 새 KMS 키를 만듭니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 새 KMS 키 ARN을 제공합니다. 가장 많이 투표된

B. 새 KMS 키를 만듭니다. 새 IAM 키를 만듭니다. 공급업체의 IAM 역할 ARN을 IAM 사용자에게 연결된 인라인 정책에 추가합니다. 공급업체에 새 IAM 사용자 ARN을 제공합니다.

C. KMS 관리형 S3 키를 사용하여 암호화를 구성합니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 KMS 관리형 S3 키 ARN을 제공합니다.

D. KMS 관리 S3 키를 사용하여 암호화를 구성합니다. S3 버킷을 만듭니다. 공급업체의 IAM 역할 ARN을 S3 버킷 정책에 추가합니다. 공급업체에 S3 버킷 ARN을 제공합니다.

#### AWS KMS를 이용한 데이터 암호화 통합 구성
회사가 외부 공급업체와 협력하여 데이터 처리 서비스를 제공하는 과정에서, 데이터의 보안을 위해 AWS Key Management Service(AWS KMS)를 사용하여 데이터를 암호화하는 것이 중요합니다. 이 통합을 위해 공급업체는 회사 데이터를 Amazon S3 버킷에 호스팅하고, 회사는 AWS KMS 키를 제공하여 데이터를 암호화하도록 허용해야 합니다. 공급업체는 이 통합을 위해 회사에 IAM 역할 Amazon Resources Name(ARN)을 제공했습니다.

요구 사항 분석
데이터 암호화: 회사 데이터를 AWS KMS 키를 사용하여 암호화
IAM 역할 ARN: 공급업체가 제공한 IAM 역할 ARN을 사용하여 KMS 키 정책에 추가
KMS 키 제공: 공급업체에 새 KMS 키 ARN을 제공
옵션 분석

A. 새 KMS 키를 만듭니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 새 KMS 키 ARN을 제공합니다.
새 KMS 키 생성: AWS KMS 콘솔 또는 CLI를 통해 새 KMS 키를 생성합니다.
KMS 키 정책 업데이트: 생성된 KMS 키의 정책에 공급업체의 IAM 역할 ARN을 추가하여 해당 역할이 KMS 키를 사용할 수 있도록 합니다.
KMS 키 ARN 제공: 새로 생성된 KMS 키의 ARN을 공급업체에 제공합니다.
장점: 이 방법은 명확하고, KMS 키를 직접 관리할 수 있습니다.
문제 해결 여부: 이 옵션은 현재 문제를 해결하는 데 가장 적합합니다.

B. 새 KMS 키를 만듭니다. 새 IAM 키를 만듭니다. 공급업체의 IAM 역할 ARN을 IAM 사용자에게 연결된 인라인 정책에 추가합니다. 공급업체에 새 IAM 사용자 ARN을 제공합니다.
새 KMS 키 생성: AWS KMS 콘솔 또는 CLI를 통해 새 KMS 키를 생성합니다.
IAM 사용자 생성 및 정책 추가: 새 IAM 사용자를 생성하고, 공급업체의 IAM 역할 ARN을 해당 사용자에게 연결된 인라인 정책에 추가합니다.
IAM 사용자 ARN 제공: 새로 생성된 IAM 사용자의 ARN을 공급업체에 제공합니다.
제한 사항: 이 방법은 불필요하게 복잡하며, KMS 키를 직접 제공하는 것보다 덜 직관적입니다.

C. KMS 관리형 S3 키를 사용하여 암호화를 구성합니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 KMS 관리형 S3 키 ARN을 제공합니다.
KMS 관리형 S3 키 사용: S3 버킷의 기본 암호화 옵션으로 KMS 관리형 S3 키를 사용합니다.
KMS 키 정책 업데이트: KMS 관리형 S3 키의 정책에 공급업체의 IAM 역할 ARN을 추가합니다.
KMS 관리형 S3 키 ARN 제공: KMS 관리형 S3 키의 ARN을 공급업체에 제공합니다.
제한 사항: KMS 관리형 S3 키는 AWS에서 관리하므로, 직접 관리할 수 없는 부분이 있습니다.

D. KMS 관리 S3 키를 사용하여 암호화를 구성합니다. S3 버킷을 만듭니다. 공급업체의 IAM 역할 ARN을 S3 버킷 정책에 추가합니다. 공급업체에 S3 버킷 ARN을 제공합니다.
KMS 관리 S3 키 사용: S3 버킷의 기본 암호화 옵션으로 KMS 관리 S3 키를 사용합니다.
S3 버킷 생성: 새로운 S3 버킷을 생성합니다.
S3 버킷 정책 업데이트: S3 버킷 정책에 공급업체의 IAM 역할 ARN을 추가합니다.
S3 버킷 ARN 제공: 생성된 S3 버킷의 ARN을 공급업체에 제공합니다.
제한 사항: 이 방법은 S3 버킷 정책을 통해 접근을 제어하지만, KMS 키를 직접 관리하지 않습니다.

#### 결론
가장 적합한 방법은 A. 새 KMS 키를 만듭니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 새 KMS 키 ARN을 제공합니다입니다. 이 방법은 명확하고, KMS 키를 직접 관리할 수 있으며, 공급업체가 회사 데이터를 안전하게 암호화할 수 있도록 합니다.

## 질문 #71
SysOps 관리자가 AWS Systems Manager Patch Manager를 사용하여 Amazon EC2 인스턴스 플릿에 패치를 적용하고 있습니다. 

SysOps 관리자는 패치 기준선과 유지 관리 기간을 구성했습니다. SysOps 관리자는 또한 인스턴스 태그를 사용하여 패치할 인스턴스를 식별했습니다. SysOps 관리자는
Systems Manager에 EC2 인스턴스에 액세스할 수 있는 권한을 부여해야 합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자가 수행해야 하는 추가 작업은 무엇입니까?

A. 인스턴스 보안 그룹에 인바운드 규칙을 추가합니다.
B. Systems Manager에 대한 액세스 권한이 있는 IAM 인스턴스 프로필을 인스턴스에 연결합니다. 가장 많이 투표된
C. Systems Manager 활성화를 만듭니다. 그런 다음 인스턴스 플릿을 활성화합니다.
D. 태그 기반 선택을 사용하는 대신 패치할 인스턴스를 수동으로 지정합니다.


#### 결론
가장 적합한 방법은 B. Systems Manager에 대한 액세스 권한이 있는 IAM 인스턴스 프로필을 인스턴스에 연결하는 것입니다. 이를 통해 Systems Manager가 EC2 인스턴스에 필요한 권한을 갖추고, 패치 작업을 수행할 수 있습니다. IAM 역할을 생성하고 이를 인스턴스 프로필로 인스턴스에 연결하는 과정이 필요합니다.


## 질문 #72
한 회사가 us-east-1 지역의 Amazon EC2 인스턴스에 웹사이트를 호스팅합니다. 

이 회사는 웹사이트를 eu-central-1 지역으로 확장할 준비를 하고 있지만, 데이터베이스는 us-east-1에만 있어야 합니다. 배포 후 eu-central-1의 EC2 인스턴스는 us-east-1의 데이터베이스에 연결할 수 없습니다.
이 연결 문제를 해결할 가장 운영 효율적인 솔루션은 무엇입니까?

A. 두 지역 간에 VPC 피어링 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다. 가장 많이 투표된
B. 두 지역 간에 VPC 피어링 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
C. 두 지역 간에 VPN 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
D. 두 지역 간에 VPN 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.

Amazon EC2 인스턴스 간의 지역 간 연결 문제 해결
한 회사가 us-east-1 지역의 Amazon EC2 인스턴스에 웹사이트를 호스팅하고 있으며, 이를 eu-central-1 지역으로 확장하려고 합니다. 그러나 데이터베이스는 us-east-1에만 위치해야 합니다. 배포 후 eu-central-1의 EC2 인스턴스가 us-east-1의 데이터베이스에 연결할 수 없는 문제가 발생했습니다. 이 연결 문제를 해결하기 위한 가장 운영 효율적인 솔루션을 찾는 것이 중요합니다.

문제 분석
웹사이트 호스팅 지역: us-east-1
확장 지역: eu-central-1
데이터베이스 위치: us-east-1
연결 문제: eu-central-1의 EC2 인스턴스가 us-east-1의 데이터베이스에 연결할 수 없음
옵션 분석
A. 두 지역 간에 VPC 피어링 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.
VPC 피어링: 두 VPC 간의 네트워크 트래픽을 허용하는 연결을 설정합니다.
장점: VPC 피어링은 두 VPC 간의 네트워크 연결을 설정하여 인스턴스가 서로 통신할 수 있게 합니다.
보안 그룹 설정: 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가하여 접근을 허용합니다.
문제 해결 여부: 이 방법은 두 지역 간의 네트워크 연결을 설정하고, 보안 그룹 규칙을 통해 접근을 허용하므로 연결 문제를 해결할 수 있습니다.

B. 두 지역 간에 VPC 피어링 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
VPC 피어링: 두 VPC 간의 네트워크 트래픽을 허용하는 연결을 설정합니다.
보안 그룹 설정: eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
제한 사항: 보안 그룹의 아웃바운드 규칙은 일반적으로 설정되지 않으며, 인바운드 규칙을 통해 접근을 제어하는 것이 일반적입니다.

C. 두 지역 간에 VPN 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
VPN 연결: 두 지역 간의 네트워크 트래픽을 허용하는 연결을 설정합니다.
보안 그룹 설정: 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
제한 사항: 보안 그룹의 아웃바운드 규칙은 일반적으로 설정되지 않으며, 인바운드 규칙을 통해 접근을 제어하는 것이 일반적입니다.

D. 두 지역 간에 VPN 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.
VPN 연결: 두 지역 간의 네트워크 트래픽을 허용하는 연결을 설정합니다.
보안 그룹 설정: eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.
제한 사항: 보안 그룹 간의 직접적인 규칙 추가는 불가능하며, IP 주소 또는 CIDR 블록을 사용해야 합니다.

#### 결론
가장 운영 효율적인 솔루션은 A. 두 지역 간에 VPC 피어링 연결을 만들고, 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가하는 것입니다. 이 방법은 두 지역 간의 네트워크 연결을 설정하고, 보안 그룹 규칙을 통해 접근을 허용하므로 연결 문제를 효과적으로 해결할 수 있습니다.

## 질문 #73
한 회사에서는 AWS Organizations에서 관리하는 모든 계정에 대해 자동화된 솔루션을 만들어 인바운드 트래픽의 소스 주소로 0.0.0.0/0을 사용하는 모든 보안 그룹을 감지하려고 합니다. 

또한 회사는 회사 인트라넷과 일치하는 특정 CIDR 블록에 대한 액세스를 제한하여 모든 비준수 보안 그룹을 자동으로 수정하려고 합니다.
SysOps 관리자는 솔루션을 만들기 위해 어떤 작업을 수행해야 합니까?

A. 규정을 준수하지 않는 보안 그룹을 감지하기 위한 AWS Config 규칙을 만듭니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다. 가장 많이 투표된
B. 소스 주소가 0.0.0.0/0인 보안 그룹 생성을 거부하는 IAM 정책을 만듭니다. 이 IAM 정책을 회사의 모든 사용자에게 첨부합니다.
C. 새 보안 그룹과 기존 보안 그룹을 검사하기 위한 AWS Lambda 함수를 만듭니다. 비준수 0.0.0.0/0 소스 주소를 확인하고 소스 주소를 승인된 CIDR 블록으로 변경합니다.
D. 조직 단위(OU)에 대한 서비스 제어 정책(SCP)을 만들어 0.0.0.0/0 소스 주소가 있는 보안 그룹 생성을 거부합니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다.

#### 결론
가장 적합한 솔루션은 A. 규정을 준수하지 않는 보안 그룹을 감지하기 위한 AWS Config 규칙을 만들고, 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정하는 것입니다. 이 방법은 AWS Config와 AWS Systems Manager를 통합하여 비준수 보안 그룹을 감지하고 자동으로 수정할 수 있는 강력한 자동화 솔루션을 제공합니다.

## 질문 #74
회사에서는 AWS 계정의 모든 활동을 AWS CloudTrail을 사용하여 기록해야 합니다. 

또한 SysOps 관리자는 CloudTrail 로그 파일이 수정되거나 삭제되는 시점을 알아야 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?


A. 로그 파일 무결성 검증을 활성화합니다. AWS CLI를 사용하여 로그 파일을 검증합니다. 가장 많이 투표된
B. 로그 파일 무결성 검증을 활성화합니다. AWS CloudTrail Processing Library를 사용하여 로그 파일을 검증합니다.
C. CloudTrail Insights를 사용하여 로그 파일의 수정 사항을 모니터링합니다.
D. Amazon CloudWatch Logs를 사용하여 로그 파일의 수정 사항을 모니터링합니다.

로그 파일 무결성 검증
로그 파일 무결성 검증은 CloudTrail에서 제공하는 기능으로, 로그 파일이 수정되지 않았음을 확인할 수 있습니다. 이를 통해 로그 파일의 신뢰성을 보장할 수 있습니다.

로그 파일 무결성 검증 활성화
CloudTrail 콘솔 또는 AWS CLI를 사용하여 로그 파일 무결성 검증을 활성화할 수 있습니다.
이 기능을 활성화하면 CloudTrail은 각 로그 파일에 대해 해시 값을 생성하고, 이를 통해 파일의 무결성을 확인할 수 있습니다.

#### 결론
SysOps 관리자가 AWS CloudTrail 로그 파일의 무결성을 검증하고 변경 사항을 모니터링하기 위해서는 다음 단계를 따르는 것이 좋습니다:

로그 파일 무결성 검증 활성화: CloudTrail 콘솔이나 AWS CLI를 통해 로그 파일 무결성 검증을 활성화합니다.
자동화된 검증: AWS CloudTrail Processing Library를 사용하여 프로그래밍 방식으로 로그 파일의 무결성을 검증합니다.
실시간 모니터링: Amazon CloudWatch Logs를 사용하여 로그 파일의 변경 사항을 실시간으로 모니터링합니다.
이러한 접근 방식을 통해 AWS 환경에서의 보안과 규정 준수를 효과적으로 관리할 수 있습니다.

## 질문 #75
한 회사가 AWS에서 상태 저장 웹 기반 애플리케이션을 호스팅할 계획입니다. 

SysOps 관리자가 Amazon EC2 인스턴스의 자동 확장 그룹을 사용하고 있습니다. 웹 애플리케이션은 연중무휴 24시간 실행됩니다. 회사는 트래픽 및 사용 패턴에 따라 올해 말에 동일한 인스턴스 패밀리 내에서 인스턴스 유형을 변경할 수 있어야 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족할 EC2 인스턴스 구매 옵션은 무엇입니까?

A. 변환 가능한 예약 인스턴스 가장 많이 투표된
B. 주문형 인스턴스
C. 스팟 인스턴스
D. 표준 예약 인스턴스

AWS EC2 인스턴스 구매 옵션: 비용 효율적인 선택
회사가 AWS에서 상태 저장 웹 기반 애플리케이션을 호스팅하고 있으며, 연중무휴 24시간 운영되고 트래픽 및 사용 패턴에 따라 인스턴스 유형을 변경할 필요가 있습니다. 이러한 요구 사항을 가장 비용 효율적으로 충족할 수 있는 EC2 인스턴스 구매 옵션을 살펴보겠습니다.

주요 고려 사항
연중무휴 24시간 운영: 이는 고정된 용량이 필요함을 의미합니다.
인스턴스 유형 변경 가능성: 동일한 인스턴스 패밀리 내에서 인스턴스 유형을 변경할 수 있어야 합니다.
비용 효율성: 최대한 저렴하게 운영 비용을 절감해야 합니다.
EC2 인스턴스 구매 옵션
각 옵션의 특징과 장단점을 비교해 보겠습니다:

변환 가능한 예약 인스턴스 (Convertible Reserved Instances)

특징: 일정 기간 동안 할인된 가격으로 인스턴스를 예약하며, 필요에 따라 다른 인스턴스 유형으로 변환할 수 있습니다.
장점: 유연성이 높아 인스턴스 유형을 변경할 수 있으며, 예약 인스턴스의 혜택을 누릴 수 있습니다.
단점: 초기 비용이 발생할 수 있지만, 장기적으로 비용 절감 효과가 큽니다.

주문형 인스턴스 (On-Demand Instances)

특징: 필요할 때마다 인스턴스를 시작하고 종료할 수 있으며, 사용한 만큼만 비용을 지불합니다.
장점: 매우 유연하며, 짧은 시간 동안 필요한 경우 적합합니다.
단점: 장기적으로 사용할 경우 비용이 높아질 수 있습니다.

스팟 인스턴스 (Spot Instances)

특징: 미사용 컴퓨팅 용량을 저렴한 가격에 제공받을 수 있습니다.
장점: 매우 저렴한 비용으로 인스턴스를 사용할 수 있습니다.
단점: 언제든지 중단될 수 있어 안정적인 운영에 부적합합니다.


표준 예약 인스턴스 (Standard Reserved Instances)

특징: 일정 기간 동안 특정 인스턴스 유형을 할인된 가격으로 예약합니다.
장점: 장기적으로 비용을 절감할 수 있습니다.
단점: 인스턴스 유형을 변경할 수 없으므로 유연성이 떨어집니다.



#### 결론
위의 요구 사항을 고려할 때, **변환 가능한 예약 인스턴스 (Convertible Reserved Instances)**가 가장 적합한 선택입니다. 이 옵션은 다음과 같은 이유로 비용 효율적이며 요구 사항을 충족합니다:

유연성: 동일한 인스턴스 패밀리 내에서 인스턴스 유형을 자유롭게 변경할 수 있습니다.
비용 절감: 예약 인스턴스의 혜택을 누리면서도 필요에 따라 인스턴스 유형을 조정할 수 있어 장기적으로 비용을 절감할 수 있습니다.
안정성: 연중무휴 24시간 운영에도 안정적으로 사용할 수 있습니다.
따라서, 변환 가능한 예약 인스턴스가 가장 비용 효율적이고 요구 사항을 충족하는 선택입니다.

## 질문 #76
애플리케이션은 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 

EC2 인스턴스에 새 기능을 배포한 후 일부 인스턴스가 비정상으로 표시되고 Auto Scaling 그룹으로 대체되었습니다. SysOps 관리자가 상태 변경의 원인을 파악하기 전에 EC2 인스턴스가 종료되었습니다. 이 문제를 해결하기 위해 SysOps 관리자는 이 상황에서 AWS Lambda 함수가 호출되도록 하려고 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?

A. Auto Scaling 그룹에 대한 인스턴스 축소 보호 설정을 활성화합니다. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출합니다.
B. Auto Scaling 그룹에 대한 인스턴스 축소 보호 설정을 활성화합니다. Amazon Route 53을 통해 Lambda 함수를 호출합니다.
C. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 라이프사이클 후크를 추가합니다. 가장 많이 투표된
D. Amazon Route 53을 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 수명 주기 후크를 추가합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 C입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

라이프사이클 후크: Auto Scaling 그룹에 라이프사이클 후크를 추가하여 인스턴스 상태 변경 시 Lambda 함수를 호출할 수 있습니다.
Amazon EventBridge: Amazon EventBridge를 통해 Lambda 함수를 호출하여 인스턴스 상태 변경 시 자동으로 조치를 취할 수 있습니다.
따라서, SysOps 관리자는 Auto Scaling 그룹에 라이프사이클 후크를 추가하고, Amazon EventBridge를 통해 Lambda 함수를 호출하도록 설정해야 합니다. 이를 통해 인스턴스 상태 변경 시 문제를 신속히 파악하고 대응할 수 있습니다.


## 질문 #77
한 회사가 여러 클라이언트의 중요 데이터를 호스팅하는 애플리케이션을 실행합니다. 

이 회사는 AWS CloudTrail을 사용하여 다양한 AWS 리소스에서 사용자 활동을 추적합니다. 새로운 보안 요구 사항을 충족하기 위해 이 회사는 CloudTrail 로그 파일이 수정, 삭제 또는 위조되지 않도록 보호해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. CloudTrail 로그 파일 무결성 검증을 활성화합니다. 가장 많이 투표된
B. CloudTrail 로그 파일이 저장된 S3 버킷에서 Amazon S3 MFA Delete를 사용합니다.
C. Amazon S3 버전 관리를 사용하여 CloudTrail 로그 파일의 모든 버전을 보관합니다.
D. AWS Key Management Service(AWS KMS) 보안 키를 사용하여 CloudTrail 로그 파일을 보호합니다.


#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

로그 파일 무결성 검증: CloudTrail 로그 파일 무결성 검증을 활성화하면 로그 파일이 수정되었는지 여부를 쉽게 확인할 수 있습니다.
무결성 보장: 로그 파일의 무결성을 보장하여 수정이나 위조를 방지할 수 있습니다.
따라서, 회사는 CloudTrail 로그 파일 무결성 검증을 활성화하여 로그 파일이 수정, 삭제 또는 위조되지 않도록 보호해야 합니다. 이를 통해 보안 요구 사항을 충족할 수 있습니다.


## 질문 #78
글로벌 기업이 5개의 AWS 지역에서 운영됩니다. 

SysOps 관리자가 회사의 모든 태그가 지정되고 지정되지 않은 Amazon EC2 인스턴스를 식별하려고 합니다.
이 회사는 인스턴스 ID와 태그를 표시하는 출력이 필요합니다.

SysOps 관리자가 이러한 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. AWS 리소스 그룹에서 태그 기반 리소스 그룹을 만듭니다.
B. AWS Trusted Advisor를 사용합니다. Trusted Advisor에서 EC2 On-Demand Instances 확인 결과를 내보냅니다.
C. Cost Explorer를 사용합니다. EC2-Instances의 서비스 유형을 선택하고 리소스별로 그룹화합니다.
D. AWS 리소스 그룹에서 태그 편집기를 사용합니다. 모든 리전을 선택하고 AWS::EC2::Instance의 리소스 유형을 선택합니다. 가장 많이 투표된

#### 결론
위의 요구 사항을 충족하기 위해 가장 운영 효율적인 방법은 옵션 D입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

태그 편집기 사용: 태그 편집기를 통해 모든 리전에서 EC2 인스턴스를 검색하고 태그가 지정된/지정되지 않은 인스턴스를 쉽게 식별할 수 있습니다.
출력 형식: 인스턴스 ID와 태그 정보를 함께 출력할 수 있습니다.
운영 효율성: AWS 콘솔에서 간편하게 접근할 수 있으며, 필요한 정보를 빠르게 얻을 수 있습니다.
따라서, SysOps 관리자는 AWS 리소스 그룹에서 태그 편집기를 사용하여 모든 리전을 선택하고 AWS::EC2::Instance의 리소스 유형을 선택함으로써 요구 사항을 충족할 수 있습니다.

## 질문 #79
회사는 매일 기가바이트의 파일을 업로드해야 합니다. 

회사는 Amazon S3에 더 높은 처리량과 업로드 속도를 달성해야 합니다.
이 요구 사항을 충족하기 위해 SysOps 관리자는 어떤 조치를 취해야 합니까?


A. GET HTTP 메서드를 허용하고 S3 버킷을 원본으로 하여 Amazon CloudFront 배포를 생성합니다.
B. Amazon ElastiCache 클러스터를 생성하고 S3 버킷에 대한 캐싱을 활성화합니다.
C. AWS Global Accelerator를 설정하고 S3 버킷으로 구성합니다.
D. S3 전송 가속을 활성화하고 파일을 업로드할 때 가속 엔드포인트를 사용합니다. 가장 많이 투표된



## 질문 #80
SysOps 관리자는 회사의 AWS 계정의 보안 및 규정 준수를 유지합니다. 

회사의 Amazon EC2 인스턴스가 회사 정책을 따르도록 하기 위해 SysOps 관리자는 부서 태그가 없는 모든 EC2 인스턴스를 종료하려고 합니다. 규정을 준수하지 않는 리소스는 거의 실시간으로 종료해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 필수 태그 관리 규칙으로 AWS Config 규칙을 만들어 비준수 리소스를 식별합니다. AWS-TerminateEC2Instance 자동화 문서를 실행하여 비준수 리소스를 종료하도록 자동 수정을 구성합니다. 가장 많이 투표된
B. 새로운 EC2 인스턴스가 생성될 때 모니터링하기 위한 새로운 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 자동 수정을 위해 이벤트를 Simple Notification Service(Amazon SNS) 토픽으로 보냅니다.
C. EC2 인스턴스를 생성할 수 있는 모든 사용자에게 ec2:CreateTags 및 ec2:DescribeTags 작업을 사용할 수 있는 권한도 있는지 확인합니다. 인스턴스의 종료 동작을 종료로 변경합니다.
D. AWS Systems Manager Compliance가 EC2 인스턴스를 관리하도록 구성되어 있는지 확인합니다. AWS-StopEC2Instances 자동화 문서를 호출하여 비준수 리소스를 중지합니다.


결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 D입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

S3 전송 가속: S3 전송 가속은 대용량 파일 업로드 속도를 크게 향상시킬 수 있습니다.
전세계 지원: 전 세계 어디서나 빠른 업로드를 지원하여 네트워크 지연을 최소화합니다.
직접적인 해결책: 업로드 속도 향상을 위해 특별히 설계된 기능입니다.
따라서, SysOps 관리자는 S3 전송 가속을 활성화하고 파일을 업로드할 때 가속 엔드포인트를 사용함으로써 높은 처리량과 업로드 속도를 달성할 수 있습니다.


## 질문 #81
한 회사가 S3 버전 관리가 활성화된 Amazon S3 버킷에 웹사이트 파일을 업로드했습니다. 

이 회사는 S3 버킷을 원본으로 하는 Amazon CloudFront 배포판을 사용합니다. 이 회사는 최근에 파일을 수정했지만 객체 이름은 동일하게 유지되었습니다. 사용자들은 오래된 콘텐츠가 여전히 웹사이트에 표시된다고 보고합니다.
SysOps 관리자는 이 문제를 어떻게 해결해야 합니까?

A. CloudFront 무효화를 생성하고 업데이트된 파일의 경로를 추가합니다. 가장 많이 투표된
B. CloudFront 서명 URL을 생성하여 각 객체를 즉시 업데이트합니다.
C. S3 원본 액세스 ID(OAI)를 구성하여 사용자에게 업데이트된 파일만 표시합니다.
D. S3 버킷에서 S3 버전 관리를 비활성화하여 업데이트된 파일이 이전 파일을 대체할 수 있도록 합니다.


결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

캐시 무효화: CloudFront 배포판에서 특정 파일 경로를 무효화하여 최신 콘텐츠가 반영되도록 할 수 있습니다.
최신 콘텐츠 제공: 사용자가 항상 최신 콘텐츠를 볼 수 있도록 보장합니다.
유연성: 필요한 파일 경로만 선택적으로 무효화할 수 있어 효율적입니다.
따라서, SysOps 관리자는 CloudFront 무효화를 생성하고 업데이트된 파일의 경로를 추가함으로써 최신 콘텐츠가 사용자에게 제대로 제공되도록 할 수 있습니다.




## 질문 #82
한 회사에 VPC A와 VPC B라는 두 개의 VPC 네트워크가 있습니다. 

VPC A CIDR 블록은 10.0.0.0/16이고 VPC B CIDR 블록은 172.31.0.0/16입니다. 이 회사는 두 VPC 사이에 pcx-12345라는 VPC 피어링 연결을 설정하려고 합니다.
구성 후 VPC A의 경로 테이블에 어떤 규칙이 나타나야 합니까? (두 가지를 선택하세요.)

A. 목적지: 10.0.0.0/16, 타겟: 로컬 가장 많이 투표된
B. 목적지: 172.31.0.0/16, 타겟: 로컬
C. 대상: 10.0.0.0/16, 대상: pcx-12345
D. 목적지: 172.31.0.0/16, 타겟: pcx-12345 가장 많이 투표된
E. 대상: 10.0.0.0/16, 대상: 172.31.0.0/16

VPC A의 경로 테이블에 나타나야 하는 올바른 규칙은 다음과 같습니다:

목적지: 172.31.0.0/16, 타겟: pcx-12345
목적지: 10.0.0.0/16, 타겟: 로컬
이 두 가지 규칙이 VPC A의 경로 테이블에 포함되어야 합니다.


## 질문 #83
한 회사가 고객의 판매 데이터를 분석합니다. 

고객이 회사의 Amazon S3 버킷 중 하나에 파일을 업로드하면 Amazon Simple Queue Service(Amazon SQS) 대기열에 Amazon Resource Name(ARN) 개체가 게시됩니다. Amazon EC2 인스턴스에서 실행되는 애플리케이션이 대기열을 폴링하고 메시지를 처리합니다. 처리 시간은 파일 크기에 따라 다릅니다.
고객이 파일 처리가 지연된다고 보고합니다. SysOps 관리자가 첫 번째 단계로 Amazon EC2 Auto Scaling을 구성하기로 결정했습니다. SysOps
관리자가 기존 EC2 인스턴스를 기반으로 하는 Amazon Machine Image(AMI)를 만듭니다. SysOps 관리자는 또한 AMI를 참조하는 시작 템플릿을 만듭니다. SysOps
관리자는 응답 시간을 개선하기 위해 Auto Scaling 정책을 어떻게 구성해야 합니까?

A. 시작 템플릿에 여러 다른 인스턴스 크기를 추가합니다. ApproximateNumberOfMessagesVisible 메트릭을 기반으로 자동 크기 조정 정책을 만들어 큐의 메시지 수에 따라 인스턴스 크기를 선택합니다.
B. 대기열에 있는 지연된 메시지 수에 따라 인스턴스 수를 조정하기 위해 ApproximateNumberOfMessagesDelayed 메트릭을 기반으로 자동 크기 조정 정책을 만듭니다.
C. ASGAverageCPUUtilization 메트릭과 Auto Scaling 그룹의 GroupPendingInstances 메트릭을 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다.
D. ApproximateNumberOfMessagesVisible 메트릭과 Auto Scaling 그룹의 InService 상태 인스턴스 수를 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다. 가장 많이 투표된


##### 결론
위의 옵션 중에서 옵션 D가 가장 적합합니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

큐의 메시지 수와 서비스 중인 인스턴스 수를 고려: 큐의 메시지 수가 많을 때 더 많은 인스턴스를 확장하여 처리 능력을 높일 수 있습니다.
균형 잡힌 접근: 큐의 메시지 수와 서비스 중인 인스턴스 수를 모두 고려하여 Auto Scaling 정책을 세울 수 있습니다.
응답 시간 개선: 메시지 처리 지연을 최소화하고 응답 시간을 개선할 수 있습니다.
따라서, SysOps 관리자는 ApproximateNumberOfMessagesVisible 메트릭과 Auto Scaling 그룹의 InService 상태 인스턴스 수를 기반으로 사용자 지정 메트릭을 만들고, 이를 기반으로 Auto Scaling 정책을 구성하여 인스턴스 수를 확장해야 합니다.



## 질문 #84
한 회사가 us-east-1 지역의 한 가용성 영역에 두 개의 Amazon EC2 인스턴스가 있는 다중 계층 웹 애플리케이션을 실행합니다. 

SysOps 관리자는 EC2 인스턴스 중 하나를 새 가용성 영역으로 마이그레이션해야 합니다.
어떤 솔루션이 이를 달성할까요?


A. EC2 인스턴스를 다른 가용성 영역으로 복사합니다. 원래 인스턴스를 종료합니다.
B. EC2 인스턴스에서 Amazon Machine Image(AMI)를 생성하고 다른 가용성 영역에서 시작합니다. 원래 인스턴스를 종료합니다. 가장 많이 투표된
C. AWS CLI를 사용하여 EC2 인스턴스를 다른 가용성 영역으로 이동합니다.
D. EC2 인스턴스를 중지하고 가용성 영역을 수정한 다음 인스턴스를 시작합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 B입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 데이터 일관성 유지: AMI를 사용하여 인스턴스의 상태와 데이터를 완벽히 복제할 수 있습니다.
* 신뢰성: AMI를 통해 새로운 인스턴스를 시작하면 기존 인스턴스와 동일한 환경을 보장할 수 있습니다.
* 유연성: 다른 가용성 영역에서 새로운 인스턴스를 시작할 수 있어 유연성이 높습니다.
* 따라서, SysOps 관리자는 EC2 인스턴스에서 Amazon Machine Image(AMI)를 생성하고 다른 가용성 영역에서 시작한 후 원래 인스턴스를 종료하는 방법을 사용하여 인스턴스를 새 가용성 영역으로 마이그레이션해야 합니다.

## 질문 #85
한 회사가 트래픽 증가가 예상되기 전에 Amazon EC2 인스턴스의 플릿을 확장하고 있습니다. 

SysOps 관리자가 인스턴스를 더 추가하려고 하면 InstanceLimitExceeded 오류가 반환됩니다.
SysOps 관리자는 이 오류를 해결하기 위해 무엇을 해야 합니까?

A. VPC에 추가 CIDR 블록을 추가합니다.
B. 다른 가용성 영역에서 EC2 인스턴스를 시작합니다.
C. 다른 VPC에서 새로운 EC2 인스턴스를 시작합니다.
D. 서비스 할당량을 사용하여 EC2 할당량 증가를 요청합니다. 가장 많이 투표된

##### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 D입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

근본적인 해결책: EC2 인스턴스 할당량을 늘림으로써 문제를 근본적으로 해결할 수 있습니다.
공식적인 절차: AWS Support를 통해 할당량 증가를 요청하는 공식적인 절차를 따릅니다.
확장성: 향후 트래픽 증가에 대비하여 더 많은 인스턴스를 확보할 수 있습니다.
따라서, SysOps 관리자는 서비스 할당량을 사용하여 EC2 할당량 증가를 요청함으로써 InstanceLimitExceeded 오류를 해결하고 인스턴스 플릿을 성공적으로 확장할 수 있습니다.

## 질문 #86
한 회사가 개발자가 특정 Amazon EC2 인스턴스 패밀리를 사용하는 것을 금지하려고 합니다. 

이 회사는 AWS Organizations를 사용하고 여러 계정에 제한을 적용하려고 합니다.
이 회사가 이러한 요구 사항을 충족하기 위해 서비스 제어 정책(SCP)을 적용하는 가장 운영 효율적인 방법은 무엇입니까?


A. 조직 단위(OU)에 계정을 추가합니다. OU에 SCP를 적용합니다. 가장 많이 투표된
B. AWS Resource Groups의 리소스 그룹에 계정을 추가합니다. SCP를 리소스 그룹에 적용합니다.
C. 각 개발자 계정에 SCP 적용
D. AWS Control Tower에 계정을 등록합니다. AWS Control Tower 관리 계정에 SCP를 적용합니다.


#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 조직 단위 활용: AWS Organizations의 조직 단위를 활용하여 여러 계정에 일괄적으로 정책을 적용할 수 있습니다.
* 관리 효율성: 조직 구조를 활용하여 정책 관리가 용이하며, 일관된 정책 적용이 가능합니다.
* 확장성: 조직 단위 내에 더 많은 계정을 추가할 수 있어 확장성이 뛰어납니다.
따라서, 회사는 조직 단위(OU)에 계정을 추가하고 OU에 SCP를 적용함으로써 특정 Amazon EC2 인스턴스 패밀리의 사용을 금지하는 정책을 효율적으로 관리할 수 있습니다.


## 질문 #87

애플리케이션은 기본 DHCP 옵션이 설정된 VPC의 Amazon EC2 인스턴스에서 실행 중입니다. 

애플리케이션은 DNS 이름 mssql.example.com을 사용하여 온프레미스 Microsoft SQL Server 데이터베이스에 연결합니다 . 애플리케이션은 데이터베이스 DNS 이름을 확인할 수 없습니다.
어떤 솔루션이 이 문제를 해결할까요?


A. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 전달 규칙을 추가합니다. 전달 규칙을 VPC와 연결합니다.
B. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 시스템 규칙을 추가합니다. 시스템 규칙을 VPC와 연결합니다.
C. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 전달 규칙을 추가합니다. 전달 규칙을 VPC와 연결합니다. 가장 많이 투표된
D. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 시스템 규칙을 추가합니다. 시스템 규칙을 VPC와 연결합니다.

Amazon Route 53 Resolver: DNS 문제 해결
애플리케이션이 기본 DHCP 옵션이 설정된 VPC의 Amazon EC2 인스턴스에서 실행 중이며, DNS 이름 mssql.example.com을 사용하여 온프레미스 Microsoft SQL Server 데이터베이스에 연결하려고 합니다. 그러나 애플리케이션은 데이터베이스 DNS 이름을 확인할 수 없는 문제가 발생했습니다. 이 문제를 해결하기 위한 방법을 살펴보겠습니다.

주요 고려 사항
DNS 조회 문제: 애플리케이션이 외부 DNS 이름을 확인할 수 없습니다.
온프레미스와의 통합: 온프레미스 DNS 서버와 VPC 간의 DNS 조회가 원활하게 이루어져야 합니다.
Route 53 Resolver 사용: AWS Route 53 Resolver를 사용하여 DNS 조회 문제를 해결할 수 있습니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 C입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

아웃바운드 엔드포인트 사용: VPC 내부에서 외부 DNS 서버로의 쿼리를 처리할 수 있습니다.
전달 규칙 설정: 도메인 example.com에 대한 전달 규칙을 추가하여 온프레미스 DNS 서버로 쿼리를 전달할 수 있습니다.
VPC와의 연결: 전달 규칙을 VPC와 연결하여 애플리케이션이 외부 DNS 이름을 확인할 수 있도록 합니다.
따라서, 회사는 Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만들고, 도메인 example.com에 대한 전달 규칙을 추가하여 VPC와 연결함으로써 DNS 조회 문제를 해결할 수 있습니다.


## 질문 #88
회사의 애플리케이션은 app.example.com에서 인터넷 제공자에 의해 호스팅됩니다. 

회사는 Amazon Route 53으로 소유하고 관리하는 www.company.com을 사용하여 애플리케이션에 액세스하려고 합니다.
이를 해결하기 위해 어떤 Route 53 레코드를 만들어야 합니까?


A. 기록
B. 별칭 기록
C. CNAME 레코드 가장 많이 투표된
D. 포인터(PTR) 레코드


Amazon Route 53: 도메인 재지정
회사의 애플리케이션은 app.example.com에서 인터넷 제공자에 의해 호스팅되고 있습니다. 회사는 Amazon Route 53으로 소유하고 관리하는 www.company.com을 사용하여 애플리케이션에 액세스하려고 합니다. 이를 해결하기 위해 적절한 Route 53 레코드를 설정해야 합니다.

주요 고려 사항
도메인 재지정: www.company.com을 app.example.com으로 재지정해야 합니다.
DNS 레코드 유형: 올바른 DNS 레코드 유형을 선택하여 도메인 재지정을 구현해야 합니다.
옵션 분석
각 옵션의 특징과 장단점을 비교해 보겠습니다:

* 옵션 A: 기록

설명: 일반적인 A 레코드는 특정 도메인 이름을 IPv4 주소로 매핑합니다.
장점: IP 주소를 직접 지정할 수 있습니다.
단점: 도메인 이름 간의 재지정에는 적합하지 않습니다.

* 옵션 B: 별칭 기록

설명: AWS에서 제공하는 별칭 레코드는 한 AWS 리소스를 다른 AWS 리소스로 매핑할 수 있습니다.
장점: AWS 리소스 간의 매핑에 유용합니다.
단점: 외부 도메인과의 재지정에는 적합하지 않습니다.

* 옵션 C: CNAME 레코드

설명: CNAME 레코드는 하나의 도메인 이름을 다른 도메인 이름으로 매핑합니다.
장점: 도메인 이름 간의 재지정에 적합합니다.
단점: 루트 도메인(company.com)에는 사용할 수 없습니다.

* 옵션 D: 포인터(PTR) 레코드

설명: PTR 레코드는 IP 주소를 도메인 이름으로 매핑하는 역방향 DNS 조회를 지원합니다.
장점: 역방향 DNS 조회에 유용합니다.
단점: 도메인 이름 간의 재지정에는 적합하지 않습니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 C입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

도메인 이름 재지정: CNAME 레코드는 www.company.com을 app.example.com으로 재지정하는 데 적합합니다.
간편한 설정: CNAME 레코드를 사용하면 도메인 이름 간의 매핑이 간편합니다.
따라서, 회사는 CNAME 레코드를 만들어 www.company.com을 app.example.com으로 재지정함으로써 애플리케이션에 액세스할 수 있습니다.


## 질문 #89
한 회사가 전 세계 청중에게 서비스를 제공하기 위해 웹 애플리케이션을 확장했습니다. 

SysOps 관리자가 모든 프로덕션 인프라에 대해 다중 지역 AWS 배포를 구현했습니다. SysOps 관리자는 리소스의 위치를 ​​기반으로 트래픽을 라우팅해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 Amazon Route 53 라우팅 정책을 사용해야 합니까?


A. 지리적 위치 라우팅 정책
B. 지근거리 라우팅 정책 가장 많이 투표된
C. 지연 기반 라우팅 정책
D. 다중값 답변 라우팅 정책


Amazon Route 53: 다중 지역 AWS 배포를 위한 라우팅 정책
한 회사가 전 세계 청중에게 서비스를 제공하기 위해 웹 애플리케이션을 확장했습니다. SysOps 관리자는 모든 프로덕션 인프라에 대해 다중 지역 AWS 배포를 구현했습니다. 이제 리소스의 위치를 기반으로 트래픽을 라우팅해야 합니다. 이를 위해 적절한 Amazon Route 53 라우팅 정책을 선택해야 합니다.

주요 고려 사항
리소스 위치 기반 라우팅: 사용자의 지리적 위치에 따라 가까운 리소스로 트래픽을 라우팅해야 합니다.
글로벌 서비스 제공: 전 세계 사용자에게 최적의 성능을 제공해야 합니다.
라우팅 정책 선택: Route 53에서 제공하는 다양한 라우팅 정책 중 적절한 것을 선택해야 합니다.
옵션 분석
각 옵션의 특징과 장단점을 비교해 보겠습니다:

* 옵션 A: 지리적 위치 라우팅 정책

설명: 지리적 위치 라우팅 정책은 사용자의 지리적 위치(국가 또는 대륙)에 따라 트래픽을 라우팅합니다.
장점: 특정 국가나 대륙의 사용자를 특정 리소스로 라우팅할 수 있습니다.
단점: 더 세밀한 위치 기반 라우팅이 필요할 경우 한계가 있을 수 있습니다.

* 옵션 B: 지근거리 라우팅 정책

설명: 지근거리 라우팅 정책은 사용자의 위치와 가장 가까운 AWS 리전으로 트래픽을 라우팅합니다.
장점: 사용자의 물리적 위치와 가장 가까운 리전으로 트래픽을 라우팅하여 지연 시간을 최소화할 수 있습니다.
단점: 특정 국가나 대륙 단위의 라우팅보다 더 세밀한 제어가 가능하지만, 설정이 복잡할 수 있습니다.

* 옵션 C: 지연 기반 라우팅 정책

설명: 지연 기반 라우팅 정책은 사용자가 가장 낮은 지연 시간을 경험할 수 있는 리소스로 트래픽을 라우팅합니다.
장점: 지연 시간을 최소화하여 사용자 경험을 최적화할 수 있습니다.
단점: 지리적 위치보다는 네트워크 지연 시간에 초점을 맞추므로, 위치 기반 라우팅이 필요할 경우 적합하지 않을 수 있습니다.

* 옵션 D: 다중값 답변 라우팅 정책

설명: 다중값 답변 라우팅 정책은 여러 리소스의 IP 주소를 반환하여 클라이언트가 가장 가까운 리소스로 연결할 수 있도록 합니다.
장점: 여러 리소스를 동시에 제공하여 가용성을 높일 수 있습니다.
단점: 위치 기반 라우팅보다는 가용성에 중점을 둡니다.

##### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 B입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

리소스 위치 기반 라우팅: 사용자의 물리적 위치와 가장 가까운 AWS 리전으로 트래픽을 라우팅하여 지연 시간을 최소화할 수 있습니다.
글로벌 서비스 최적화: 전 세계 사용자에게 최적의 성능을 제공할 수 있습니다.
세밀한 제어: 특정 국가나 대륙 단위의 라우팅보다 더 세밀한 제어가 가능합니다.
따라서, SysOps 관리자는 지근거리 라우팅 정책을 사용하여 리소스의 위치를 기반으로 트래픽을 라우팅함으로써 전 세계 사용자에게 최적의 성능을 제공할 수 있습니다.


## 질문 #90
SysOps 관리자가 온프레미스에서 Amazon S3 버킷으로 멀티파트 업로드를 사용하여 1TB 크기의 파일을 업로드하려고 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?


A. S3 콘솔을 사용하여 파일을 업로드합니다.
B. s3api copy-object 명령을 사용합니다.
C. s3api put-object 명령을 사용합니다.
D. s3 cp 명령을 사용합니다. 가장 많이 투표된

Amazon S3: 멀티파트 업로드를 통한 대용량 파일 전송
SysOps 관리자가 온프레미스에서 Amazon S3 버킷으로 1TB 크기의 파일을 업로드하려고 합니다. 이 작업을 효율적으로 수행하기 위해 멀티파트 업로드를 사용해야 합니다. 멀티파트 업로드는 대용량 파일을 작은 부분으로 나누어 병렬로 업로드함으로써 전송 속도를 높이고 중단된 업로드를 쉽게 재개할 수 있게 합니다.

주요 고려 사항
* 멀티파트 업로드 사용: 대용량 파일을 업로드할 때는 멀티파트 업로드가 필수적입니다.
* CLI 도구 사용: AWS CLI(Command Line Interface)를 사용하여 멀티파트 업로드를 수행할 수 있습니다.
* 자동화 및 편의성: AWS CLI 명령어를 통해 업로드 과정을 자동화하고 관리할 수 있습니다.
옵션 분석
각 옵션의 특징과 장단점을 비교해 보겠습니다:

* 옵션 A: S3 콘솔을 사용하여 파일을 업로드합니다.

설명: AWS Management Console을 통해 파일을 업로드합니다.
장점: GUI 환경에서 쉽게 파일을 업로드할 수 있습니다.
단점: 대용량 파일 업로드에는 비효율적이며, 멀티파트 업로드를 지원하지 않습니다.

* 옵션 B: s3api copy-object 명령을 사용합니다.

설명: AWS CLI의 copy-object 명령을 사용하여 객체를 복사합니다.
장점: S3 객체 간의 복사를 지원합니다.
단점: 온프레미스에서 S3로의 업로드에는 적합하지 않습니다.

* 옵션 C: s3api put-object 명령을 사용합니다.

설명: AWS CLI의 put-object 명령을 사용하여 객체를 업로드합니다.
장점: S3에 객체를 업로드할 수 있습니다.
단점: 멀티파트 업로드를 직접 지원하지 않으며, 대용량 파일 업로드에는 비효율적입니다.

* 옵션 D: s3 cp 명령을 사용합니다.

설명: AWS CLI의 cp 명령을 사용하여 파일을 업로드합니다.
장점: aws s3 cp 명령은 멀티파트 업로드를 자동으로 처리하여 대용량 파일 업로드에 적합합니다.
단점: 특별한 단점이 없으며, 대용량 파일 업로드에 가장 적합한 방법입니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 D입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

멀티파트 업로드 지원: aws s3 cp 명령은 멀티파트 업로드를 자동으로 처리하여 대용량 파일 업로드에 적합합니다.
편리성: CLI 명령어를 통해 업로드 과정을 쉽게 관리하고 자동화할 수 있습니다.
효율성: 대용량 파일 업로드 시 병렬 처리를 통해 전송 속도를 높일 수 있습니다.
따라서, SysOps 관리자는 s3 cp 명령을 사용하여 1TB 크기의 파일을 Amazon S3 버킷으로 업로드하는 것이 가장 효율적입니다.

## 질문 #91
애플리케이션 팀은 SysOps 관리자와 협력하여 애플리케이션에 대한 Amazon CloudWatch 알람을 정의하고 있습니다. 

애플리케이션 팀은 애플리케이션의 예상 사용량이나 예상 성장을 알지 못합니다.
SysOps 관리자는 어떤 솔루션을 추천해야 합니까?

A. 이상 감지를 기반으로 CloudWatch 알람을 생성합니다. 가장 많이 투표된
B. 복합 알람 세트를 사용하여 CloudWatch 알람을 만듭니다.
C. 정적 임계값을 사용하여 CloudWatch 경보를 만듭니다.
D. 누락된 데이터를 침해로 처리하는 CloudWatch 알람을 생성합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 이상 감지 기능: CloudWatch Anomaly Detection 기능을 사용하여 정상적인 메트릭 패턴에서 벗어난 이상을 자동으로 감지하고 알람을 생성할 수 있습니다.
* 유연성: 예측 불가능한 사용량에도 유연하게 대응할 수 있습니다.
* 자동화: 자동으로 이상을 감지하여 알람을 생성하므로, 수동 설정의 부담이 줄어듭니다.

따라서, SysOps 관리자는 이상 감지를 기반으로 CloudWatch 알람을 생성하는 것을 추천해야 합니다. 이를 통해 애플리케이션의 예측 불가능한 사용량에도 효과적으로 대응할 수 있습니다.

## 질문 #92
한 회사가 Amazon EC2 인스턴스에 호스팅된 상태 없는 애플리케이션을 실행합니다. 

사용자들이 성능 문제를 보고하고 있습니다. SysOps 관리자가
애플리케이션에 대한 Amazon CloudWatch 메트릭을 검토하고 인스턴스의 CPU 사용률이 업무 시간 동안 자주 90%에 도달한다는 것을 알아챘습니다.
애플리케이션의 응답성을 개선할 가장 운영 효율적인 솔루션은 무엇입니까?


A. EC2 인스턴스에서 CloudWatch 로깅을 구성합니다. CPU 사용률이 90%를 넘을 때 SysOps 관리자에게 경고하도록 CPU 사용률에 대한 CloudWatch 알람을 구성합니다.
B. 애플리케이션 사용자가 EC2 인스턴스 개인 IP 주소에 직접 연결하여 지연 시간을 줄일 수 있도록 AWS 클라이언트 VPN 연결을 구성합니다.
C. 자동 스케일링 그룹을 만들고 이를 애플리케이션 로드 밸런서에 할당합니다. 자동 스케일링 그룹의 평균 CPU 사용률을 기반으로 하는 대상 추적 스케일링 정책을 구성합니다. 가장 많이 투표된
D. EC2 인스턴스의 CPU 사용률이 80%를 넘을 때 활성화되는 CloudWatch 알람을 만듭니다. 인스턴스를 수직으로 확장하는 AWS Lambda 함수를 호출하도록 알람을 구성합니다.

##### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 C입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 자동 스케일링 그룹: 필요에 따라 인스턴스를 자동으로 추가하거나 제거할 수 있습니다.
* 대상 추적 스케일링 정책: 평균 CPU 사용률을 기준으로 인스턴스 수를 조정하여 성능을 유지할 수 있습니다.
* 로드 밸런서와의 통합: 애플리케이션 로드 밸런서(ALB)와 통합하여 트래픽을 효율적으로 분산할 수 있습니다.

따라서, SysOps 관리자는 자동 스케일링 그룹을 만들고 이를 애플리케이션 로드 밸런서에 할당한 후, 평균 CPU 사용률을 기반으로 하는 대상 추적 스케일링 정책을 구성하는 것이 가장 운영 효율적인 솔루션입니다.

## 질문 #93
전자상거래 회사는 쇼핑 사이트에서 인기 있는 제품 쿼리의 메모리 내 캐싱을 위해 Amazon ElastiCache for Memcached 클러스터를 사용합니다. 

ElastiCache 클러스터에 대한 최근 Amazon CloudWatch 메트릭 데이터를 볼 때 SysOps 관리자는 많은 수의 퇴거를 알아차립니다.
다음 중 어떤 조치가 이러한 퇴거를 줄일 수 있을까요? (두 가지를 선택하세요.)


A. ElastiCache 클러스터에 추가 노드를 추가합니다. 가장 많이 투표된
B. ElastiCache의 TTL(수명)을 늘립니다.
C. ElastiCache 클러스터 내의 개별 노드 크기를 늘립니다. 가장 많이 투표된
D. ElastiCache 클러스터 앞에 Elastic Load Balancer를 배치합니다.
E. Amazon Simple Queue Service(Amazon SQS)를 사용하여 ElastiCache 클러스터를 분리합니다.

Amazon ElastiCache for Memcached: 퇴거(Evictions) 문제 해결
전자상거래 회사는 쇼핑 사이트에서 인기 있는 제품 쿼리의 메모리 내 캐싱을 위해 Amazon ElastiCache for Memcached 클러스터를 사용하고 있습니다. 최근 Amazon CloudWatch 메트릭 데이터를 검토한 결과, 많은 수의 퇴거(eviction)가 발생하고 있음을 SysOps 관리자가 발견했습니다. 퇴거란 캐시 메모리가 가득 찼을 때 오래된 항목을 제거하고 새로운 항목을 추가하는 과정을 의미합니다. 이를 줄이기 위한 조치를 살펴보겠습니다.

주요 고려 사항
* 퇴거 감소: 캐시 메모리에서 항목이 너무 자주 제거되는 것을 방지해야 합니다.
* 캐시 용량 확장: 캐시 메모리의 용량을 늘려 더 많은 데이터를 저장할 수 있도록 해야 합니다.
* 노드 구성 최적화: 클러스터 내의 노드 크기와 수를 조정하여 성능을 최적화해야 합니다.


##### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A와 옵션 C입니다. 이 두 가지 옵션은 다음과 같은 이유로 가장 적절합니다:

* 옵션 A: ElastiCache 클러스터에 추가 노드를 추가합니다.

캐시 용량 확장: 더 많은 노드를 추가하여 캐시 용량을 확장함으로써 퇴거를 줄일 수 있습니다.
부하 분산: 여러 노드로 트래픽을 분산시켜 클러스터의 부하를 줄일 수 있습니다.
옵션 C: ElastiCache 클러스터 내의 개별 노드 크기를 늘립니다.

* 노드 용량 증가: 각 노드의 메모리 크기를 늘려 더 많은 데이터를 저장할 수 있도록 함으로써 퇴거를 줄일 수 있습니다.
성능 최적화: 노드 크기를 늘림으로써 클러스터의 전체 성능을 향상시킬 수 있습니다.
따라서, SysOps 관리자는 ElastiCache 클러스터에 추가 노드를 추가하고, 클러스터 내의 개별 노드 크기를 늘리는 조치를 통해 퇴거를 줄일 수 있습니다.

## 질문 #94
SysOps 관리자가 여러 IAM 사용자에게 IAM 정책을 연결하여 AWS 서비스에 대한 액세스를 제공하려고 합니다. 

SysOps 관리자는 또한 정책을 변경하고 새 버전을 만들 수 있기를 원합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하십시오.)

A. 사용자를 IAM 서비스 연결 역할에 추가합니다. 정책을 역할에 연결합니다.
B. 사용자를 IAM 사용자 그룹에 추가합니다. 정책을 그룹에 연결합니다. 가장 많이 투표된
C. AWS 관리 정책을 생성합니다.
D. 고객 관리 정책을 만듭니다. 가장 많이 투표된
마. 인라인 정책을 만듭니다.

AWS IAM: 사용자 그룹 및 정책 관리
SysOps 관리자가 여러 IAM 사용자에게 AWS 서비스에 대한 액세스를 제공하고, 정책을 변경하고 새 버전을 만들 수 있도록 하기 위해 적절한 작업의 조합을 선택해야 합니다. 이를 위해 IAM 사용자 그룹과 정책을 활용하는 방법을 살펴보겠습니다.

주요 고려 사항
IAM 사용자 그룹: 여러 사용자에게 공통된 권한을 부여하기 위해 사용자 그룹을 사용합니다.
정책 연결: 사용자 그룹에 정책을 연결하여 권한을 부여합니다.
정책 관리: 정책을 변경하고 새 버전을 만들 수 있어야 합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 B와 옵션 D입니다. 이 두 가지 옵션은 다음과 같은 이유로 가장 적절합니다:

* 옵션 B: 사용자를 IAM 사용자 그룹에 추가합니다. 정책을 그룹에 연결합니다.

사용자 그룹 관리: 여러 사용자에게 공통된 권한을 쉽게 부여할 수 있습니다.
정책 적용: 그룹에 정책을 연결하여 사용자 그룹 전체에 적용할 수 있습니다.

* 옵션 D: 고객 관리 정책을 만듭니다.

정책 커스터마이즈: 필요에 따라 정책 내용을 자유롭게 정의할 수 있습니다.
정책 변경 및 버전 관리: 정책을 변경하고 새 버전을 만들 수 있습니다.
따라서, SysOps 관리자는 사용자를 IAM 사용자 그룹에 추가하고 정책을 그룹에 연결하며, 고객 관리 정책을 생성함으로써 여러 사용자에게 AWS 서비스에 대한 액세스를 제공하고 정책을 효율적으로 관리할 수 있습니다.

## 질문 #95
한 회사가 Amazon S3 버킷에 중요한 데이터를 저장합니다. 

SysOps 관리자는 모든 S3 API 활동을 기록하는 솔루션을 구축해야 합니다.
어떤 작업이 이 요구 사항을 충족할까요?

A. S3 버킷 메트릭을 구성하여 객체 액세스 로그를 기록합니다.
B. 모든 S3 객체에 대한 데이터 이벤트를 기록하기 위한 AWS CloudTrail 트레일을 생성합니다. 가장 많이 투표된
C. 각 S3 버킷에 대해 S3 서버 액세스 로깅을 활성화합니다.
D. Amazon S3용 AWS IAM Access Analyzer를 사용하여 객체 액세스 로그를 저장합니다.


Amazon S3: 모든 S3 API 활동 기록
한 회사가 Amazon S3 버킷에 중요한 데이터를 저장하고 있으며, SysOps 관리자는 모든 S3 API 활동을 기록하는 솔루션을 구축해야 합니다. 이를 위해 적절한 작업을 선택해야 합니다.

주요 고려 사항
API 활동 기록: 모든 S3 API 호출을 기록해야 합니다.
보안 및 감사: 보안 및 감사 목적으로 API 활동을 추적할 수 있어야 합니다.
중앙 집중식 관리: 중앙에서 모든 활동을 관리하고 모니터링할 수 있어야 합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 B입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 포괄적인 기록: 모든 S3 API 호출을 상세히 기록할 수 있습니다.
* 보안 및 감사: 보안 및 감사 목적으로 유용하며, 중앙에서 모든 활동을 관리하고 모니터링할 수 있습니다.
* AWS CloudTrail 사용: AWS CloudTrail을 사용하여 데이터 이벤트를 기록함으로써, S3 API 활동을 체계적으로 추적할 수 있습니다.
따라서, SysOps 관리자는 모든 S3 객체에 대한 데이터 이벤트를 기록하기 위한 AWS CloudTrail 트레일을 생성함으로써 모든 S3 API 활동을 기록하는 솔루션을 구축할 수 있습니다.


## 질문 #96
한 회사가 Amazon EC2 인스턴스에서 MySQL 데이터베이스를 사용하는 애플리케이션을 실행합니다. 

EC2 인스턴스에는 General Purpose SSD Amazon Elastic Block
Store(Amazon EBS) 볼륨이 있습니다. 이 회사는 애플리케이션 코드를 변경했고 이제 코드 변경의 영향을 평가하기 위해 부하 테스트를 수행하려고 합니다.
SysOps 관리자는 기존 프로덕션 인스턴스의 스냅샷에서 새 MySQL 인스턴스를 만들어야 합니다. 이 새 인스턴스는 프로덕션 인스턴스와 가능한 한 비슷하게 수행되어야 합니다.
이러한 요구 사항을 충족하는 복원 옵션은 무엇입니까?

A. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성합니다. 가장 많이 투표된
B. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 프로비저닝된 IOPS SSD EBS 볼륨을 생성합니다.
C. EBS 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성합니다.
D. EBS 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 Provisioned IOPS SSD EBS 볼륨을 생성합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

빠른 스냅샷 복원: EBS 빠른 스냅샷 복원을 사용하여 빠르게 볼륨을 생성할 수 있습니다.
범용 SSD: 범용 SSD는 비용 효율적이며, 대부분의 일반적인 워크로드에 적합합니다.
프로덕션 인스턴스와 유사한 성능: 범용 SSD는 프로덕션 인스턴스와 유사한 성능을 제공할 수 있습니다.
따라서, SysOps 관리자는 EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성함으로써 부하 테스트를 위한 새 MySQL 인스턴스를 준비할 수 있습니다.

## 질문 #97
대기 엔지니어 팀은 문제를 해결하고 명령을 실행하기 위해 프라이빗 서브넷의 Amazon EC2 인스턴스에 자주 연결해야 합니다. 

인스턴스는 최신 AWS 제공 Windows Amazon Machine Images(AMI) 또는 Amazon Linux AMI를 사용합니다.
팀에는 권한 부여를 위한 기존 1AM 역할이 있습니다. SysOps 관리자는 이 역할에 IAM 권한을 부여하여 팀에 인스턴스에 대한 액세스 권한을 제공해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. 인스턴스에서 ssm:StartSession 작업을 허용하기 위해 1AM 역할 정책에 명령문을 추가합니다. 팀에 AWS Systems Manager Session Manager를 사용하여 가정된 IAM 역할을 사용하여 인스턴스에 연결하도록 지시합니다. 가장 많이 투표된
B. 각 인스턴스에 Elastic IP 주소와 보안 그룹을 연결합니다. 엔지니어의 IP 주소를 보안 그룹 인바운드 규칙에 추가합니다. 팀이 인스턴스에 연결할 수 있도록 ec2:AuthorizeSecurityGrouplngress 작업을 허용하는 IAM 역할 정책에 명령문을 추가합니다.
C. EC2 인스턴스로 배스천 호스트를 만들고 배스천 호스트를 VPC와 연결합니다. 배스천 호스트에서 ec2:CreateVpnConnection 작업을 허용하도록 1AM 역할 정책에 명령문을 추가합니다. 팀에 배스천 호스트 엔드포인트를 사용하여 인스턴스에 연결하도록 지시합니다.
D. 인터넷 연결 네트워크 로드 밸런서를 만듭니다. 두 개의 리스너를 사용합니다. 포트 22를 Linux 인스턴스의 대상 그룹으로 전달합니다. 포트 3389를 Windows 인스턴스의 대상 그룹으로 전달합니다. 팀이 인스턴스에 연결할 수 있도록 ec2:CreateRoute 작업을 허용하는 IAM 역할 정책에 명령문을 추가합니다.

Amazon EC2: 프라이빗 서브넷 인스턴스에 대한 접근
대기 엔지니어 팀이 프라이빗 서브넷의 Amazon EC2 인스턴스에 자주 연결해야 하는 상황입니다. 인스턴스는 최신 AWS 제공 Windows Amazon Machine Images(AMI) 또는 Amazon Linux AMI를 사용합니다. 팀에는 권한 부여를 위한 기존 IAM 역할이 있으며, SysOps 관리자는 이 역할에 IAM 권한을 부여하여 팀에 인스턴스에 대한 액세스 권한을 제공해야 합니다. 이를 위해 적절한 솔루션을 선택해야 합니다.

주요 고려 사항
프라이빗 서브넷 접근: 프라이빗 서브넷에 있는 인스턴스에 안전하게 접근할 수 있어야 합니다.
IAM 역할 및 정책: 기존 IAM 역할에 적절한 권한을 부여하여 팀이 인스턴스에 접근할 수 있도록 해야 합니다.
보안 및 편의성: 보안성을 유지하면서도 팀이 쉽게 접근할 수 있는 방법이어야 합니다.


#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

프라이빗 서브넷 접근: AWS Systems Manager Session Manager를 사용하여 프라이빗 서브넷의 인스턴스에 안전하게 접근할 수 있습니다.
IAM 역할 및 정책: 기존 IAM 역할에 ssm:StartSession 작업을 허용하는 정책을 추가하여 팀이 인스턴스에 접근할 수 있도록 합니다.
보안 및 편의성: 추가적인 네트워크 설정 없이도 안전하게 접근할 수 있으며, AWS 관리형 서비스를 활용하여 편리하게 관리할 수 있습니다.
따라서, SysOps 관리자는 AWS Systems Manager Session Manager를 사용하여 인스턴스에 연결하도록 지시하고, IAM 역할에 ssm:StartSession 작업을 허용하는 정책을 추가하는 것이 가장 적합한 솔루션입니다.





## 질문 #98
한 회사는 AWS에 배포된 25개 애플리케이션에 대한 예산을 엄격히 준수해야 합니다. 

별도의 팀이 스토리지, 컴퓨팅 및 데이터베이스 비용을 담당합니다. SysOps 관리자는 재무 부서에서 설정한 분기별 금액을 예상 지출이 초과할 경우 각 팀에 경고하는 자동화된 솔루션을 구현해야 합니다. 이 솔루션은 추가 컴퓨팅, 스토리지 또는 데이터베이스 비용을 발생시킬 수 없습니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. AWS 비용 및 사용 보고서를 구성하여 Amazon S3 버킷에 일일 보고서를 보냅니다. 서비스별 지출을 평가하고 Amazon Simple Notification Service(Amazon SNS) 알림을 사용하여 각 팀에 알리는 AWS Lambda 함수를 만듭니다. 보고서가 S3 버킷에 배치되면 Lambda 함수를 호출합니다.
B. AWS 비용 및 사용 보고서를 구성하여 Amazon S3 버킷에 일일 보고서를 보냅니다. Amazon EventBridge(Amazon CloudWatch Events)에서 서비스별 지출을 평가하고 비용 임계값을 초과하면 Amazon Simple Queue Service(Amazon SQS)를 사용하여 각 팀에 알리는 규칙을 만듭니다.
C. AWS Budgets를 사용하여 하나의 비용 예산을 만들고 사용 중인 각 서비스를 선택합니다. 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다. 예산에 대한 적절한 이메일 수신자를 입력합니다.
D. AWS Budgets를 사용하여 각 팀에 대한 비용 예산을 만들고, 팀이 소유한 서비스로 필터링합니다. 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다. 각 예산에 대한 적절한 이메일 수신자를 입력합니다. 가장 많이 투표된


AWS 비용 관리: 예산 준수를 위한 자동화된 솔루션
AWS 환경에서 여러 애플리케이션의 비용을 관리하고 예산을 준수하는 것은 매우 중요합니다. 특히, 스토리지, 컴퓨팅, 데이터베이스 비용을 별도로 관리하는 팀이 있는 경우, 각 팀에 대한 비용 경고 시스템을 구축하는 것이 필요합니다. 아래에서는 주어진 요구 사항을 충족하는 최적의 솔루션을 분석해 보겠습니다.

요구 사항 분석
예산 준수: 재무 부서에서 설정한 분기별 금액을 초과하지 않도록 해야 합니다.
자동화된 경고 시스템: 예상 지출이 예산을 초과할 경우 각 팀에 자동으로 경고를 보내야 합니다.
추가 비용 없음: 추가적인 컴퓨팅, 스토리지 또는 데이터베이스 비용을 발생시키지 않아야 합니다.
솔루션 옵션 분석

#### 결론
주어진 요구 사항을 가장 잘 충족하는 솔루션은 옵션 D입니다. AWS Budgets를 사용하여 각 팀에 대한 비용 예산을 생성하고, 팀별로 세분화된 경고를 설정할 수 있습니다. 또한, 추가적인 컴퓨팅, 스토리지 또는 데이터베이스 비용 없이 예산을 모니터링하고 경고를 받을 수 있습니다.

추천 솔루션:

AWS Budgets를 사용하여 각 팀에 대한 비용 예산을 생성합니다.
팀별로 소유한 서비스로 필터링하고, 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다.
각 예산에 대한 이메일 수신자를 입력하여 경고를 받습니다.
이 솔루션은 간단하면서도 효과적으로 예산을 관리하고, 각 팀에 필요한 경고를 제공할 수 있습니다.


## 질문 #99
한 회사가 Amazon S3에 정적 웹사이트를 호스팅합니다. 

Amazon CloudFront 배포판은 이 사이트를 글로벌 사용자에게 제공합니다. 이 회사는 Managed-CachingDisabled CloudFront 캐시 정책을 사용합니다. 이 회사의 개발자는 Amazon S3의 파일을 새 정보로 자주 업데이트한다고 확인합니다.
사용자는 웹사이트가 처음 파일을 로드할 때 올바른 정보를 제공한다고 보고합니다. 그러나 사용자의 브라우저는 새로 고침 후 업데이트된 파일을 검색하지 않습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 권장해야 합니까?

A. S3 객체에 max-age=0인 Cache-Control 헤더 필드를 추가합니다. 가장 많이 투표된
B. CloudFront 캐시 정책을 Managed-CachingOptimized로 변경합니다.
C. S3 버킷 구성에서 버킷 버전 관리를 비활성화합니다.
D. CloudFront 구성에서 콘텐츠 압축을 활성화합니다.

#### 추천 솔루션
위의 옵션들을 종합적으로 고려했을 때, 가장 적절한 해결책은 옵션 A입니다. S3 객체에 Cache-Control: max-age=0 헤더를 추가함으로써, 브라우저가 항상 최신 파일을 가져오도록 강제할 수 있습니다. 이는 사용자가 새로 고침 후에도 업데이트된 파일을 제대로 볼 수 있게 해줍니다.

권장 조치:

S3 객체에 Cache-Control: max-age=0 헤더를 추가하여 브라우저가 항상 최신 파일을 요청하도록 설정합니다.
이렇게 하면 사용자가 웹사이트를 새로 고침할 때마다 최신 정보를 제공받을 수 있습니다.

## 질문 #100
어떤 회사에서는 모든 Amazon EC2 인스턴스에 특정 태그 집합이 있어야 한다는 정책을 가지고 있습니다. 

EC2 인스턴스에 필수 태그가 없으면, 규정을 준수하지 않는 인스턴스를 종료해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?


A. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 모든 EC2 인스턴스 상태 변경 사항을 AWS Lambda 함수로 전송하여 각 인스턴스가 규정을 준수하는지 확인합니다. 규정을 준수하지 않는 인스턴스는 모두 종료합니다.
B. 모든 EC2 인스턴스 태그 요구 사항을 적용하는 IAM 정책을 만듭니다. 인스턴스에 필요한 태그가 없으면 정책은 비준수 인스턴스를 종료합니다.
C. 각 EC2 인스턴스가 규정을 준수하는지 확인하고 규정을 준수하지 않는 경우 인스턴스를 종료하는 AWS Lambda 함수를 만듭니다. Lambda 함수가 5분마다 호출되도록 예약합니다.
D. 필수 태그가 있는지 확인하기 위해 AWS Config 규칙을 만듭니다. EC2 인스턴스가 비준수인 경우 AWS Systems Manager Automation 문서를 호출하여 인스턴스를 종료합니다. 가장 많이 투표된


#### 추천 솔루션
위의 옵션들을 종합적으로 고려했을 때, 가장 운영 효율적인 솔루션은 옵션 D입니다. AWS Config 규칙과 AWS Systems Manager Automation을 활용하면 지속적인 모니터링과 자동화된 대응이 가능하며, 실시간성을 어느 정도 확보할 수 있습니다.

권장 조치:

AWS Config 규칙을 만들어 필수 태그가 있는지 확인합니다.
비준수 인스턴스가 발견되면 AWS Systems Manager Automation 문서를 호출하여 해당 인스턴스를 종료합니다.
이렇게 하면 모든 EC2 인스턴스가 필수 태그를 갖추도록 지속적으로 모니터링하고, 비준수 인스턴스를 자동으로 종료할 수 있습니다.


## 질문 #101
SysOps 관리자가 AWS Elastic Beanstalk로 웹 서버 애플리케이션을 관리하려고 합니다. 

Elastic Beanstalk 서비스는 항상 새로운 배포에 대한 전체 용량을 유지해야 합니다.
어떤 배포 정책이 이 요구 사항을 충족합니까? (두 가지를 선택하세요.)

A. 한꺼번에
B. 불변 가장 많이 투표된
C. 재건
D. 롤링
E. 추가 배치로 롤링 가장 많이 투표된



## 질문 #102
한 회사에는 평균 CPU 사용률에 따라 확장되는 Amazon EC2 인스턴스의 Auto Scaling 그룹이 있습니다. 

Auto Scaling 그룹 이벤트 로그는 InsufficientInstanceCapacity 오류를 나타냅니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. 회사에서 사용 중인 인스턴스 유형을 변경합니다. 가장 많이 투표된
B. 다양한 가용성 영역에서 자동 크기 조정 그룹을 구성합니다. 가장 많이 투표된
C. 다양한 Amazon Elastic Block Store(Amazon EBS) 볼륨 크기를 사용하도록 자동 크기 조정 그룹을 구성합니다.
D. 자동 크기 조정 그룹의 최대 크기를 늘립니다.
E. 인스턴스 서비스 할당량 증가를 요청합니다.



## 질문 #103
SysOps 관리자는 AWS Systems Manager Session Manager를 사용하여 Amazon EC2 인스턴스 그룹에 대한 액세스를 제어해야 합니다. 

EC2 인스턴스의 특정 태그는 이미 추가되었습니다.
관리자는 액세스를 제어하기 위해 어떤 추가 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. EC2 인스턴스에 액세스해야 하는 사용자 또는 그룹에 IAM 정책을 연결합니다. 가장 많이 투표된
B. EC2 인스턴스에 대한 액세스를 제어하기 위해 IAM 역할을 연결합니다.
C. EC2 인스턴스에 대한 배치 그룹을 만들고 특정 태그를 추가합니다.
D. 서비스 계정을 생성하여 제어해야 하는 EC2 인스턴스에 연결합니다.
E. Condition 요소에 지정된 태그가 있는 모든 EC2 인스턴스에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다. 가장 많이 투표된



## 질문 #104
한 회사가 계정 A에 AWS Lambda 함수를 가지고 있습니다. 

Lambda 함수는 계정 B의 Amazon S3 버킷에 있는 객체를 읽어야 합니다. SysOps 관리자는 두 계정 모두에 해당 IAM 역할을 만들어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 계정 A에서 계정 B의 역할을 맡을 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다. 가장 많이 투표된
B. 계정 A에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 맡을 수 있는 역할을 만듭니다.
C. 계정 A에서 함수가 맡을 수 있는 역할을 만듭니다. 계정 B에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다.
D. 계정 A에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다. 계정 B에서 계정 A의 역할을 맡을 Lambda 실행 역할을 만듭니다.



## 질문 #105
AWS Lambda 함수가 하루에 여러 번 간헐적으로 실패합니다. 

SysOps 관리자는 지난 7일 동안 이 오류가 얼마나 자주 발생했는지 알아내야 합니다.
어떤 조치가 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족할까요?

A. Amazon Athena를 사용하여 Lambda 함수와 관련된 Amazon CloudWatch 로그를 쿼리합니다.
B. Amazon Athena를 사용하여 Lambda 함수와 연결된 AWS CloudTrail 로그를 쿼리합니다.
C. Amazon CloudWatch Logs Insights를 사용하여 연관된 Lambda 함수 로그를 쿼리합니다. 가장 많이 투표된
D. Amazon OpenSearch Service(Amazon Elasticsearch Service)를 사용하여 Lambda 함수에 대한 Amazon CloudWatch 로그를 스트리밍합니다.



## 질문 #106
한 회사가 Amazon CloudFront를 사용하여 웹 애플리케이션의 정적 콘텐츠를 사용자에게 제공하고 있습니다. 

CloudFront 배포는 기존 온프레미스 웹사이트를 사용자 지정 오리진으로 사용합니다.
이 회사는 CloudFront와 오리진 서버 간에 TLS를 사용해야 합니다. 이 구성은 몇 달 동안 예상대로 작동했습니다. 그러나 이제 사용자는 CloudFront 배포의 콘텐츠가 포함된 웹 페이지를 볼 때 HTTP 502(잘못된 게이트웨이) 오류를 경험하고 있습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 원본 사이트의 인증서 만료일을 검사합니다. 인증서가 만료되지 않았는지 확인합니다. 필요한 경우 인증서를 교체합니다. 가장 많이 투표된
B. 원본 사이트의 인증서에서 호스트 이름을 검사합니다. 호스트 이름이 CloudFront 배포의 호스트 이름 중 하나와 일치하는지 확인합니다. 필요한 경우 인증서를 교체합니다.
C. 원본 서버와 연관된 방화벽 규칙을 검사합니다. 인터넷에서 들어오는 트래픽에 대해 포트 443이 열려 있는지 확인합니다. 필요한 경우 인바운드 규칙을 만듭니다.
D. CloudFront 배포와 연관된 네트워크 ACL 규칙을 검토합니다. 포트 443이 오리진 서버로의 아웃바운드 트래픽에 열려 있는지 확인합니다. 필요한 경우 아웃바운드 규칙을 만듭니다.



## 질문 #107
Amazon CloudFront 배포판에는 단일 Amazon S3 버킷이 원본으로 있습니다. 

SysOps 관리자는 사용자가 CloudFront 엔드포인트의 요청을 통해서만 S3 버킷에 액세스할 수 있도록 해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. S3 버킷에서 S3 Block Public Access를 구성합니다. CloudFront 배포에서만 GetObject 작업을 허용하도록 S3 버킷 정책을 업데이트합니다.
B. CloudFront 배포에서 Origin Shield를 구성합니다. CloudFront 오리진을 업데이트하여 사용자 지정 Origin_Shield 헤더를 포함합니다.
C. 원본 액세스 ID(OAI)를 만듭니다. OAI를 CloudFront 배포에 할당합니다. S3 버킷 정책을 업데이트하여 OAI에 대한 액세스를 제한합니다. 가장 많이 투표된
D. 원본 액세스 ID(OAI)를 만듭니다. S3 버킷에 OAI를 할당합니다. CloudFront 원본을 업데이트하여 OAI 값이 있는 사용자 지정 원본 헤더를 포함합니다.



## 질문 #108
SysOps 관리자가 Amazon RDS for PostgreSQL DB 인스턴스에 대한 솔루션을 설계하고 있습니다. 

데이터베이스 자격 증명은 매월 저장하고 순환해야 합니다. DB 인스턴스에 연결하는 애플리케이션은 가변적인 클라이언트 연결로 쓰기 집약적 트래픽을 전송하며, 이는 때때로 단시간에 크게 증가합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 선택해야 합니까?

A. AWS Key Management Service(AWS KMS)를 구성하여 DB 인스턴스의 키를 자동으로 순환합니다. RDS Proxy를 사용하여 데이터베이스 연결 증가를 처리합니다.
B. AWS Key Management Service(AWS KMS)를 구성하여 DB 인스턴스의 키를 자동으로 순환합니다. RDS 읽기 복제본을 사용하여 데이터베이스 연결 증가를 처리합니다.
C. AWS Secrets Manager를 구성하여 DB 인스턴스의 자격 증명을 자동으로 회전합니다. RDS Proxy를 사용하여 데이터베이스 연결 증가를 처리합니다. 가장 많이 투표된
D. AWS Secrets Manager를 구성하여 DB 인스턴스의 자격 증명을 자동으로 순환합니다. RDS 읽기 복제본을 사용하여 데이터베이스 연결 증가를 처리합니다.



## 질문 #109
회사는 언제든지 완료할 수 있는 작업의 비용을 줄이고자 합니다. 

현재 작업은 여러 Amazon EC2 On-Demand 인스턴스를 사용하여 실행되고 있으며 작업을 완료하는 데 약 2시간도 걸리지 않습니다. 어떤 이유로든 작업이 중단되면 처음부터 다시 시작해야 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. 작업에 대한 예약 인스턴스를 구매합니다.
B. 해당 작업에 대한 일회성 스팟 인스턴스에 대한 요청을 제출합니다.
C. 작업에 대해 정의된 기간으로 스팟 인스턴스에 대한 요청을 제출합니다. 가장 많이 투표된
D. 작업에 대해 온디맨드 인스턴스와 스팟 인스턴스를 혼합하여 사용합니다.



## 질문 #110
환경은 100개의 Amazon EC2 Windows 인스턴스로 구성되어 있습니다. 

Amazon CloudWatch 에이전트는 모든 EC2 인스턴스에 배포되어 실행 중이며, 로그 파일을 캡처하기 위한 기준 구성 파일이 있습니다. 인스턴스 50개에 있는 DHCP 로그 파일을 캡처해야 하는 새로운 요구 사항이 있습니다.
이 새로운 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. DHCP 로그를 캡처하기 위해 추가 CloudWatch 에이전트 구성 파일을 만듭니다. AWS Systems Manager Run Command를 사용하여 각 EC2 인스턴스에서 CloudWatch 에이전트를 다시 시작하고 append-config 옵션을 사용하여 추가 구성 파일을 적용합니다. 가장 많이 투표된
B. 관리자 권한으로 각 EC2 인스턴스에 로그인합니다. 필요한 기준 로그 파일과 DHCP 로그 파일을 CloudWatch에 푸시하는 PowerShell 스크립트를 만듭니다.
C. 각 EC2 인스턴스에서 CloudWatch 에이전트 구성 파일 마법사를 실행합니다. 기준 로그 파일이 포함되어 있는지 확인하고 마법사 생성 프로세스 중에 DHCP 로그 파일을 추가합니다.
D. 각 EC2 인스턴스에서 CloudWatch 에이전트 구성 파일 마법사를 실행하고 고급 세부 정보 수준을 선택합니다. 이렇게 하면 운영 체제 로그 파일이 캡처됩니다.



## 질문: 111
한 회사가 프로덕션 계정에 Amazon EC2 인스턴스 10개를 보유하고 있습니다. 
SysOps 관리자는 EC2 인스턴스 상태가 변경될 때마다 이메일 알림이 관리자에게 전송되도록 해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. EC2 인스턴스 상태가 변경될 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon Route 53 단순 라우팅 정책을 구성합니다. 그러면 이 SNS 토픽이 이메일 구독자에게 알림을 보냅니다.
B. EC2 인스턴스 상태가 변경될 때 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Amazon Route 53 단순 라우팅 정책을 구성합니다. 그런 다음 이 SQS 대기열은 이메일 구독자에게 알림을 보냅니다.
C. EC2 인스턴스 상태가 변경될 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 그러면 이 SNS 토픽이 이메일 구독자에게 알림을 보냅니다.
D. EC2 인스턴스 상태가 변경될 때 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 그런 다음 이 SQS 대기열은 이메일 구독자에게 알림을 보냅니다.



## 질문: 112
한 회사에는 Elastic Load Balancer 뒤에 있는 Amazon EC2 인스턴스 플릿에서 실행되는 애플리케이션이 있습니다. 

인스턴스는 Auto Scaling 그룹에서 실행됩니다. 애플리케이션의 성능은 매일 대부분 일관되게 유지됩니다. 그러나 사용자 트래픽이 증가하면 매일 같은 4시간 동안 성능이 느려집니다.
이 문제를 해결할 가장 운영 효율적인 솔루션은 무엇입니까?

1. 가중치 라우팅 정책을 사용하여 Auto Scaling 그룹 앞에 두 번째 Elastic Load Balancer를 구성합니다.
2. 사용자 트래픽 증가를 지원하기 위해 더 큰 인스턴스 유형에서 실행되도록 EC2 인스턴스 플릿을 구성합니다.
3. 사용자 트래픽이 증가하기 직전에 EC2 인스턴스 수를 확장하기 위해 예약된 확장 작업을 만듭니다.
4. 사용자 트래픽 증가에 대응하기 위해 Auto Scaling 그룹에 몇 개의 EC2 인스턴스를 수동으로 추가합니다.



## 질문: 113
한 회사가 단일 AWS 리전의 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 

이 애플리케이션은 비 HTTP TCP 트래픽과 HTTP 트래픽에 대한 지원이 필요합니다.
이 회사는 AWS 네트워크를 활용하여 낮은 지연 시간으로 콘텐츠를 제공하려고 합니다. 또한 이 회사는 Elastic Load Balancer가 있는 Auto Scaling 그룹을 구현하려고 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?

1. Application Load Balancer(ALB)로 자동 확장 그룹을 만듭니다. ALB를 원본으로 하는 Amazon CloudFront 배포를 추가합니다.
2. Application Load Balancer(ALB)로 자동 스케일링 그룹을 만듭니다. ALB를 엔드포인트로 사용하여 AWS Global Accelerator로 가속기를 추가합니다.
3. 네트워크 로드 밸런서(NLB)로 자동 확장 그룹을 만듭니다. NLB를 원본으로 하는 Amazon CloudFront 배포를 추가합니다.
4. 네트워크 로드 밸런서(NLB)로 자동 스케일링 그룹을 만듭니다. NLB를 엔드포인트로 사용하여 AWS Global Accelerator로 가속기를 추가합니다.




## 질문: 114
SysOps 관리자는 암호화된 Amazon Machine Image(AMI)를 배포하는 데 사용되는 AWS CloudFormation 템플릿을 가지고 있습니다. 

CloudFormation 템플릿은 두 번째 계정에서 사용되므로 SysOps 관리자는 암호화된 AMI를 두 번째 계정에 복사합니다. 두 번째 계정에서 새 CloudFormation 스택을 시작하면 실패합니다.
SysOps 관리자는 문제를 해결하기 위해 어떤 조치를 취해야 합니까?

1. AMI 권한을 변경하여 AMI를 공개로 표시합니다.
2. 소스 계정에서 AMI 등록을 해제합니다.
3. 대상 계정의 AWS Key Management Service(AWS KMS) 키로 대상 AMI를 다시 암호화합니다.
4. 대상 계정의 AMI ID로 CloudFormation 템플릿을 업데이트합니다.



## 질문: 115
회사의 SysOps 관리자가 표준 Amazon Linux 2 Amazon Machine Image(AMI)를 사용하여 4개의 새로운 Amazon EC2 인스턴스를 배포합니다. 

회사는 AWS Systems Manager를 사용하여 인스턴스를 관리할 수 있어야 합니다. SysOps 관리자는 인스턴스가 Systems Manager 콘솔에 나타나지 않는다는 것을 알아챘습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1. SSH를 사용하여 각 인스턴스에 연결합니다. 각 인스턴스에 Systems Manager Agent를 설치합니다. 인스턴스가 시작될 때 Systems Manager Agent가 자동으로 시작되도록 구성합니다.
2. AWS Certificate Manager(ACM)를 사용하여 TLS 인증서를 만듭니다. 인증서를 각 인스턴스로 가져옵니다. Systems Manager Agent를 구성하여 보안 통신에 TLS 인증서를 사용합니다.
3. SSH를 사용하여 각 인스턴스에 연결합니다. ssm-user 계정을 만듭니다. ssm-user 계정을 /etc/sudoers.d 디렉토리에 추가합니다.
4. 인스턴스에 IAM 인스턴스 프로필을 연결합니다. 인스턴스 프로필에 AmazonSSMManagedInstanceCore 정책이 포함되어 있는지 확인합니다.




## 질문: 116
SysOps 관리자가 Amazon CloudFront 웹 배포, Application Load Balancer(ALB), Amazon RDS, Amazon EC2를 VPC에 사용하여 웹 애플리케이션을 유지 관리하고 있습니다. 

모든 서비스에서 로깅이 활성화되어 있습니다. 관리자는 웹 애플리케이션의 HTTP Layer 7 상태 코드를 조사해야 합니다.

어떤 로그 소스에 상태 코드가 포함되어 있습니까? (두 가지를 선택하세요.)

1. VPC 흐름 로그
2. AWS CloudTrail 로그
3. ALB 액세스 로그
4. CloudFront 액세스 권한
5. RDS 로그

정답은 **3. ALB 액세스 로그**와 **4. CloudFront 액세스 로그**입니다.

선택 이유:
- **3. ALB 액세스 로그**: Application Load Balancer(ALB) 액세스 로그에는 요청의 HTTP 상태 코드가 포함됩니다. ALB는 HTTP/HTTPS 요청을 처리하는 Layer 7 로드 밸런서이므로, 이를 통해 웹 애플리케이션의 HTTP 상태 코드를 조사할 수 있습니다.
  
- **4. CloudFront 액세스 로그**: CloudFront는 콘텐츠를 캐싱하고 배포하는 데 사용되며, 액세스 로그에는 캐시 상태와 함께 HTTP 상태 코드가 기록됩니다. 이를 통해 웹 애플리케이션에 대한 요청의 HTTP 상태 코드를 확인할 수 있습니다.

다른 선택지:
- **1. VPC 흐름 로그**: VPC 흐름 로그는 네트워크 계층의 트래픽 정보를 기록하며, 상태 코드와 같은 HTTP Layer 7 정보를 포함하지 않습니다.
  
- **2. AWS CloudTrail 로그**: CloudTrail은 AWS 서비스 API 호출을 기록하며, HTTP 상태 코드에 대한 세부 정보를 제공하지 않습니다.
  
- **5. RDS 로그**: RDS 로그는 데이터베이스와 관련된 로그로, HTTP 상태 코드와는 관련이 없습니다.

따라서 HTTP Layer 7 상태 코드를 확인하려면 **ALB 액세스 로그**와 **CloudFront 액세스 로그**를 사용해야 합니다.

## 질문: 117
한 회사가 AWS 계정 내에서 IAM CreateUser API 호출이 이루어질 때 이메일로 알림을 받고 싶어합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. 이벤트 소스로 AWS CloudTrail을, 이벤트 패턴에 대한 특정 API 호출로 IAM CreateUser를 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
2. 이벤트 소스로 Amazon CloudSearch를 지정하고 이벤트 패턴에 대한 특정 API 호출로 IAM CreateUser를 지정하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
3. AWS IAM Access Analyzer를 이벤트 소스로, IAM CreateUser를 이벤트 패턴에 대한 특정 API 호출로 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
4. 이메일 구독을 통해 Amazon Simple Notification Service(Amazon SNS) 주제를 이벤트 대상으로 사용합니다.
5. 이메일 구독을 통해 Amazon Simple Email Service(Amazon SES) 알림을 이벤트 대상으로 사용합니다.



## 질문: 118
데이터베이스가 Amazon RDS Multi-AZ DB 인스턴스에서 실행 중입니다. 

최근 보안 감사에서 데이터베이스가 암호화되지 않았기 때문에 규정을 준수하지 않는 것으로 나타났습니다.

어떤 접근 방식으로 암호화 요구 사항을 해결할 수 있을까요?

1. RDS 콘솔에 로그인하고 암호화 상자를 선택하여 데이터베이스를 암호화합니다.
2. 새로운 암호화된 Amazon EBS 볼륨을 생성하여 인스턴스에 연결합니다.
3. 보조 가용성 영역의 대기 복제본을 암호화하고 기본 인스턴스로 승격시킵니다.
4. RDS 인스턴스의 스냅샷을 찍고, 스냅샷을 복사하고 암호화한 다음, 새 RDS 인스턴스로 복원합니다.



## 질문: 119
AWS Organizations를 사용하는 회사에서는 프로덕션 계정의 Amazon S3 버킷을 절대 삭제해서는 안 됩니다.

SysOps 관리자가 해당 계정의 S3 버킷을 절대 삭제하지 않도록 하기 위해 취할 수 있는 가장 간단한 방법은 무엇입니까?

1. 버킷이 삭제되는 것을 방지하려면 모든 S3 버킷에 MFA 삭제를 설정합니다.
2. 서비스 제어 정책을 사용하여 프로덕션 계정의 모든 버킷에서 s3:DeleteBucket 작업을 거부합니다.
3. 프로덕션 계정의 모든 버킷에 대해 s3:DeleteBucket 작업을 거부하는 IAM 정책이 있는 IAM 그룹을 생성합니다.
4. AWS Shield를 사용하여 모든 S3 버킷이 아닌 AWS 계정에서만 s3:DeleteBucket 작업을 거부합니다.



## 질문: 120
한 회사에 VPC의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 

이 애플리케이션은 인터넷에서 소프트웨어 업데이트를 다운로드할 수 있는 액세스 권한이 필요합니다. VPC에는 퍼블릭 서브넷과 프라이빗 서브넷이 있습니다. 이 회사의 보안 정책에 따라 모든 EC2 인스턴스는 프라이빗 서브넷에 배포해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. VPC에 인터넷 게이트웨이를 추가합니다. 프라이빗 서브넷의 경로 테이블에서 인터넷 게이트웨이로의 경로를 추가합니다.
2. 개인 서브넷에 NAT 게이트웨이를 추가합니다. 개인 서브넷의 경로 테이블에서 NAT 게이트웨이로의 경로를 추가합니다.
3. 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. 프라이빗 서브넷의 경로 테이블에서 NAT 게이트웨이로의 경로를 추가합니다.
4. VPC에 두 개의 인터넷 게이트웨이를 추가합니다. 프라이빗 서브넷과 퍼블릭 서브넷의 경로 테이블에서 각 인터넷 게이트웨이에 대한 경로를 추가합니다.



## 질문: 121
개발팀은 최근 웹 애플리케이션의 새 버전을 프로덕션에 배포했습니다. 

출시 후 침투 테스트에서 사용자 데이터를 노출할 수 있는 크로스 사이트 스크립팅 취약성이 드러났습니다.

어떤 AWS 서비스가 이 문제를 완화할까요?

1. AWS Shield 표준
2. AWS 웹 애플리케이션 방화벽
3. 탄력적 부하 분산
4. 아마존 코그니토

정답은 **2. AWS 웹 애플리케이션 방화벽(AWS WAF)**입니다.

## 선택 이유:
- **AWS WAF**: AWS WAF는 웹 애플리케이션에 대한 HTTP(S) 요청을 필터링하고 모니터링하는 서비스로, 크로스 사이트 스크립팅(XSS) 같은 일반적인 웹 공격으로부터 애플리케이션을 보호할 수 있습니다. 개발팀이 배포한 웹 애플리케이션에서 XSS 취약성이 발견되었으므로, WAF를 사용하여 해당 공격 패턴을 탐지하고 차단할 수 있습니다.

## 다른 선택지:
- **1. AWS Shield 표준**: AWS Shield는 주로 DDoS(Distributed Denial of Service) 공격을 방어하는 데 사용되며, 크로스 사이트 스크립팅 같은 애플리케이션 레벨의 취약성을 완화하지는 않습니다.
  
- **3. 탄력적 부하 분산(ELB)**: ELB는 트래픽 분산과 확장성에 중점을 두며, 보안 기능이 있지만 XSS와 같은 웹 애플리케이션의 취약성을 직접적으로 보호하지는 않습니다.
  
- **4. 아마존 코그니토**: Amazon Cognito는 인증 및 사용자 관리에 사용되며, XSS 공격 방어와는 관련이 없습니다.

따라서, 크로스 사이트 스크립팅 취약성을 완화하려면 **AWS WAF**를 사용하는 것이 적절한 해결책입니다.

## 질문: 122
SysOps 관리자는 고성능 컴퓨팅(HPC) 애플리케이션을 위해 Amazon EC2 인스턴스의 복원성 계층을 구성해야 합니다. 

HPC 애플리케이션은 노드 간에 최소 지연 시간이 필요합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

1. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만듭니다. 사용자 데이터를 사용하여 파일 시스템을 EC2 인스턴스에 마운트합니다.
2. EC2 인스턴스 앞에 다중 AZ 네트워크 로드 밸런서를 생성합니다.
3. EC2 인스턴스를 단일 서브넷 내의 자동 확장 그룹에 배치합니다.
4. EC2 인스턴스를 클러스터 배치 그룹으로 시작합니다.
5. EC2 인스턴스를 파티션 배치 그룹으로 시작합니다.



## 질문: 123
한 회사의 고객이 Amazon S3에서 정적 웹 콘텐츠에 액세스하는 동안 지연 시간이 증가했다고 보고하고 있습니다. SysOps 관리자가 특정 S3 버킷에서 매우 높은 읽기 작업률을 관찰했습니다.

S3 버킷의 부하를 줄여서 지연 시간을 최소화하려면 어떻게 해야 할까요?

1. S3 버킷을 최종 사용자의 지리적 위치에 더 가까운 지역으로 마이그레이션합니다.
2. 교차 지역 복제를 사용하여 모든 데이터를 다른 지역으로 복제합니다.
3. S3 버킷을 원본으로 하는 Amazon CloudFront 배포를 생성합니다.
4. Amazon S3에서 제공되는 데이터를 캐시하려면 Amazon ElastiCache를 사용하세요.




## 질문: 124
SysOps 관리자는 이메일 알림을 제공하고 Amazon S3 버킷에 파일이 들어갈 때마다 데이터베이스에 레코드를 삽입하는 솔루션을 개발해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 하는 S3 이벤트 알림을 설정합니다. SNS 주제에 대한 두 개의 구독을 만듭니다. 한 구독을 사용하여 이메일 알림을 보냅니다. 다른 구독을 사용하여 레코드를 데이터베이스에 삽입하는 AWS Lambda 함수를 호출합니다.
2. S3 버킷에 객체가 생성될 때마다 ALARM 상태로 전환되는 Amazon CloudWatch 알람을 설정합니다. 이메일 알림을 보내고 레코드를 데이터베이스에 삽입하는 AWS Lambda 함수를 호출하도록 알람을 구성합니다.
3. S3 버킷에서 새 객체가 감지될 때마다 이메일 알림을 보내고 데이터베이스에 레코드를 삽입하는 AWS Lambda 함수를 만듭니다. Amazon EventBridge(Amazon CloudWatch Events) 예약된 규칙으로 1분마다 함수를 호출합니다.
4. 두 개의 S3 이벤트 알림을 설정합니다. 각 알림에 별도의 AWS Lambda 함수를 타겟팅합니다. 한 함수는 이메일 알림을 보내도록 구성합니다. 다른 함수는 레코드를 데이터베이스에 삽입하도록 구성합니다.



## 질문: 125
한 회사가 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 인스턴스는 Amazon EC2 Auto Scaling 그룹에 있습니다. 애플리케이션은 공개 URL로 액세스합니다.

SysOps 관리자는 애플리케이션의 가용성을 확인하고 고객과 동일한 경로와 작업을 따르는 모니터링 솔루션을 구현해야 합니다. 모니터링 실행의 95% 미만에서 오류가 발견되지 않으면 SysOps 관리자는 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 고객 경로를 따르는 스크립트로 Amazon CloudWatch Synthetics 카나리아를 만듭니다. 카나리아가 반복 일정에 따라 실행되도록 예약합니다. SuccessPercent 메트릭이 95% 미만일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 CloudWatch 알람을 만듭니다.
2. 엔드포인트의 가용성을 모니터링하는 Amazon Route 53 상태 확인을 만듭니다. HealthCheckPercentageHealthy 지표가 95% 미만일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다.
3. 각 고객 경로에 대해 엔드포인트를 사용할 수 있는지 확인하기 위해 단일 AWS Lambda 함수를 만듭니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 Lambda 함수를 예약합니다. 엔드포인트가 오류를 반환하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 Lambda 함수를 구성합니다.
4. 각 고객 경로에 대해 AWS Lambda 함수를 만들어 해당 엔드포인트를 사용할 수 있는지 확인합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 Lambda 함수를 예약합니다. 각 Lambda 함수를 구성하여 엔드포인트 상태에 대한 사용자 지정 메트릭을 Amazon CloudWatch에 게시합니다. 각 사용자 지정 메트릭을 기반으로 CloudWatch 알람을 만들어 알람이 ALARM 상태일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시합니다.
 




## 질문: 126
SysOps 관리자는 AWS Systems Manager Session Manager를 사용하여 인스턴스에 연결합니다. SysOps 관리자가 새 Amazon EC2 인스턴스를 시작한 후 EC2 인스턴스는 연결 가능한 시스템의 Session Manager 목록에 나타나지 않습니다. SysOps 관리자는 Systems Manager Agent가 EC2 인스턴스에 설치, 업데이트 및 실행 중인지 확인합니다.

이 문제의 이유는 무엇입니까?

1. SysOps 관리자는 연결에 필요한 키 쌍에 액세스할 수 없습니다.
2. SysOps 관리자가 포트 22에서 SSH를 허용하기 위해 EC2 인스턴스에 보안 그룹을 연결하지 않았습니다.
3. EC2 인스턴스에는 Session Manager가 EC2 인스턴스에 연결할 수 있도록 허용하는 연결된 IAM 역할이 없습니다.
4. EC2 인스턴스 ID가 세션 관리자 구성에 입력되지 않았습니다.

이 문제의 이유는 **3. EC2 인스턴스에는 Session Manager가 EC2 인스턴스에 연결할 수 있도록 허용하는 연결된 IAM 역할이 없습니다.**입니다.

선택 이유:
- **AWS Systems Manager Session Manager**는 EC2 인스턴스에 연결하기 위해 인스턴스에 연결된 IAM 역할이 필요합니다. 이 IAM 역할에는 `AmazonSSMManagedInstanceCore`와 같은 정책이 포함되어 있어야 하며, 이를 통해 Systems Manager가 인스턴스에 연결할 수 있습니다. 인스턴스에 올바른 권한이 없는 경우 Session Manager에서 인스턴스를 볼 수 없습니다.

다른 선택지:
- **1. SysOps 관리자는 연결에 필요한 키 쌍에 액세스할 수 없습니다**: Session Manager는 키 쌍을 사용하지 않으며, SSH 연결 대신 AWS Systems Manager의 세션 관리 기능을 사용합니다.
  
- **2. SysOps 관리자가 포트 22에서 SSH를 허용하기 위해 EC2 인스턴스에 보안 그룹을 연결하지 않았습니다**: Session Manager는 SSH 포트(22)를 사용하지 않고, AWS API를 통해 연결을 설정합니다. 보안 그룹에서 포트 22를 열지 않아도 됩니다.
  
- **4. EC2 인스턴스 ID가 세션 관리자 구성에 입력되지 않았습니다**: Session Manager는 별도의 인스턴스 ID를 입력할 필요가 없습니다. 올바르게 구성된 IAM 역할과 Systems Manager Agent가 실행 중이면 EC2 인스턴스는 자동으로 Session Manager에 나타납니다.

따라서 이 문제는 **EC2 인스턴스에 연결된 IAM 역할이 없어서 발생**합니다.

## 질문: 127
SysOps 관리자가 VPC에 사용 가능한 프라이빗 IPv4 주소가 없기 때문에 Amazon EC2 인스턴스를 VPC로 시작할 수 없습니다.

SysOps 관리자가 인스턴스를 시작하기 위해 취해야 하는 작업 조합은 무엇입니까? (두 가지를 선택하세요.)

1. VPC에 보조 IPv4 CIDR 블록을 연결합니다.
2. 기본 IPv6 CIDR 블록을 VPC에 연결합니다.
3. VP에 대한 새 서브넷을 만듭니다.
4. VPC의 CIDR 블록을 수정합니다.
5. 인스턴스와 연관된 서브넷의 CIDR 블록을 수정합니다.


SysOps 관리자가 VPC에 사용 가능한 프라이빗 IPv4 주소가 없을 때 인스턴스를 시작하기 위한 적절한 작업 조합은 다음과 같습니다:

**1. VPC에 보조 IPv4 CIDR 블록을 연결합니다.**  
- 기존 VPC에 사용할 수 있는 IP 주소가 부족할 때, 추가적인 프라이빗 IPv4 주소 공간을 제공하기 위해 **보조 CIDR 블록**을 연결할 수 있습니다.

**3. VPC에 대한 새 서브넷을 만듭니다.**  
- 새로운 서브넷을 만들면 해당 서브넷에 새로운 IP 주소 풀을 할당하여 인스턴스를 시작할 수 있게 됩니다. 단, 서브넷은 연결된 CIDR 블록의 주소 범위 내에 있어야 합니다.

다른 선택지에 대한 설명:
- **2. 기본 IPv6 CIDR 블록을 VPC에 연결합니다.**: IPv6는 IPv4와 다른 주소 체계이기 때문에, IPv4 주소 부족 문제를 해결하지 않습니다.
  
- **4. VPC의 CIDR 블록을 수정합니다.**: VPC의 기본 CIDR 블록은 생성 후 수정할 수 없습니다. 대신 **보조 CIDR 블록**을 추가하는 방법이 필요합니다.

- **5. 인스턴스와 연관된 서브넷의 CIDR 블록을 수정합니다.**: 서브넷의 CIDR 블록은 생성 후 수정할 수 없으므로, 새로운 서브넷을 만들어야 합니다.

따라서 **1번과 3번**이 올바른 조합입니다.

## 질문: 128
SysOps 관리자가 새 AWS 계정에서 Amazon EC2 Auto Scaling 그룹을 만들고 있습니다. 인스턴스를 추가한 후 SysOps 관리자는 그룹이 최소 인스턴스 수에 도달하지 못했다는 것을 알게 됩니다. SysOps 관리자는 다음과 같은 오류 메시지를 받습니다.

새 EC2 인스턴스를 시작합니다. 상태 이유: 할당량에 따라 실행 중인 인스턴스가 0개 더 허용됩니다.
최소 1개를 요청했습니다. EC2 인스턴스 시작이 실패했습니다.

어떤 조치로 이 문제를 해결할 수 있습니까?

1. AWS Billing and Cost Management 콘솔에서 Amazon EC2에 대한 계정 지출 한도를 조정합니다.
2. EC2 콘솔의 EC2 설정 섹션에서 해당 AWS 지역의 EC2 할당량을 수정합니다.
3. AWS Management Console에서 Service Quotas를 사용하여 인스턴스 유형 패밀리에 대한 할당량 증가를 요청합니다.
4. AWS Management Console의 자동 크기 조정 그룹에서 재균형 조정 작업을 사용합니다.



## 질문: 129
SysOps 관리자가 두 개의 AWS CloudFormation 템플릿을 만들고 있습니다. 첫 번째 템플릿은 서브넷, 경로 테이블, 인터넷 게이트웨이와 같은 연관된 리소스가 있는 VPC를 만듭니다. 두 번째 템플릿은 첫 번째 템플릿에서 만든 VPC 내에 애플리케이션 리소스를 배포합니다. 두 번째 템플릿은 첫 번째 템플릿에서 만든 리소스를 참조해야 합니다.

이를 최소한의 관리 노력으로 어떻게 달성할 수 있을까요?

1. 첫 번째 템플릿의 출력에 내보내기 필드를 추가하고 두 번째 템플릿에 있는 값을 가져옵니다.
2. 첫 번째 템플릿에서 생성된 스택을 쿼리하고 필요한 값을 검색하는 사용자 지정 리소스를 만듭니다.
3. 두 번째 템플릿에서 참조되는 첫 번째 템플릿에서 매핑을 만듭니다.
4. 첫 번째 템플릿에 리소스 이름을 입력하고 두 번째 템플릿에서 해당 이름을 매개변수로 참조합니다



## 질문: 130
한 회사가 Application Load Balancer(ALB) 뒤의 세 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 이 회사는 트래픽이 무작위로 증가하면 애플리케이션 성능이 저하된다는 것을 알게 됩니다. SysOps 관리자는 증가한 트래픽에 맞춰 애플리케이션을 확장해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

1. 원하는 임계값에 도달하면 각 EC2 인스턴스의 크기를 늘리고 애플리케이션 지연 시간을 모니터링하기 위해 Amazon CloudWatch 알람을 생성합니다.
2. 애플리케이션 지연 시간을 모니터링하고 원하는 임계값에 도달하면 ALB에 EC2 인스턴스를 추가하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.
3. 대상 추적 스케일링 정책이 있는 EC2 인스턴스의 자동 스케일링 그룹에 애플리케이션을 배포합니다. ALB를 자동 스케일링 그룹에 연결합니다.
4. 예약된 스케일링 정책이 있는 EC2 인스턴스의 자동 스케일링 그룹에 애플리케이션을 배포합니다. ALB를 자동 스케일링 그룹에 연결합니다.



## 질문: 131
어떤 회사에 고성능 Windows 워크로드가 있습니다. 이 워크로드에는 10,000 IOPS의 일관된 성능을 제공하는 스토리지 볼륨이 필요합니다. 이 회사는 이 성능을 달성하기 위해 불필요한 추가 용량에 비용을 지불하고 싶어하지 않습니다.

어떤 솔루션이 가장 적은 비용으로 이러한 요구 사항을 충족할까요?

1. 10,000개의 프로비저닝 IOPS로 구성된 프로비저닝된 IOPS SSD(io1) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.
2. 10,000개의 프로비저닝 IOPS로 구성된 범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.
3. 최대 I/O 모드에서 Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용합니다.
4. 10,000 IOPS로 구성된 Amazon FSx for Windows File Server 파일 시스템을 사용합니다.




## 질문: 132
SysOps 관리자는 60분 이상 평균 CPU 사용률이 10% 미만인 모든 Amazon EC2 인스턴스를 자동으로 종료하는 솔루션을 만들어야 합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족할까요?

1. 각 EC2 인스턴스에 60분마다 한 번씩 실행되도록 cron 작업을 구현하고 현재 CPU 사용률을 계산합니다. CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
2. 각 EC2 인스턴스에 대해 Amazon CloudWatch 알람을 구현하여 평균 CPU 사용률을 모니터링합니다. 기간을 1시간으로 설정하고 임계값을 10%로 설정합니다. 알람에서 인스턴스를 중지하기 위한 EC2 작업을 구성합니다.
3. 각 EC2 인스턴스에 통합 Amazon CloudWatch 에이전트를 설치하고 기본 수준 사전 정의된 메트릭 세트를 활성화합니다. 60분마다 CPU 사용률을 기록하고 CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
4. AWS Systems Manager Run Command를 사용하여 60분마다 각 EC2 인스턴스의 CPU 사용률을 가져옵니다. CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
 




## 질문: 133
SysOps 관리자가 AWS 서비스에 대한 AWS CLI 호출을 인증할 수 없습니다.
다음 중 이 문제의 원인은 무엇입니까?

1. IAM 비밀번호가 올바르지 않습니다.
2. 서버 인증서가 없습니다.
3. SSH 키 쌍이 올바르지 않습니다.
4. 접근 키가 없습니다.



## 질문: 134
회사에서는 90일 이상 사용되지 않은 모든 IAM 사용자 계정의 액세스 키와 비밀번호를 즉시 비활성화해야 합니다. SysOps 관리자는 가장 운영 효율적인 방법을 사용하여 사용되지 않는 키를 비활성화하는 프로세스를 자동화해야 합니다.

SysOps 관리자는 이 솔루션을 어떻게 구현해야 합니까?

1. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Step Functions 워크플로를 만듭니다. 예약된 Amazon EventBridge(Amazon CloudWatch Events) 규칙이 호출되면 AWS Lambda 함수를 실행하여 이러한 IAM 사용자의 AWS 액세스 키와 비밀번호를 자동으로 제거합니다.
2. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Config 규칙을 구성합니다. Amazon EC2 인스턴스에서 자동 주간 일괄 처리 프로세스를 설정하여 이러한 IAM 사용자의 AWS 액세스 키와 비밀번호를 비활성화합니다.
3. Amazon EC2 인스턴스에서 Python 스크립트를 개발하고 실행하여 90일 동안 활성화되지 않은 IAM 사용자를 프로그래밍 방식으로 식별합니다. 이러한 IAM 사용자를 자동으로 삭제합니다.
4. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Config 관리 규칙을 설정합니다. 이러한 IAM 사용자에 대한 AWS 액세스 키를 비활성화하기 위해 AWS Systems Manager 자동화 런북을 설정합니다.




## 질문: 135
한 회사가 AWS CloudFormation 템플릿에서 새로운 Amazon EC2 인스턴스를 시작하여 사용자 지정 AMI 이미지를 만듭니다. 

AWS OpsWorks를 통해 필요한 소프트웨어를 설치하고 구성하고 각 EC2 인스턴스의 이미지를 가져옵니다. 소프트웨어를 설치하고 구성하는 프로세스는 2~3시간이 걸릴 수 있지만, 때때로 설치 오류로 인해 프로세스가 중단됩니다.

SysOps 관리자는 CloudFormation 템플릿을 수정해야 하므로 프로세스가 중단되면 전체 스택이 실패하고 롤백됩니다.

이러한 요구 사항에 따라 템플릿에 무엇을 추가해야 합니까?

1. 시간 초과가 4시간으로 설정된 조건.
2. CreationPolicy의 시간 제한이 4시간으로 설정되었습니다.
3. DependsOn의 시간제한은 4시간으로 설정되어 있습니다.
4. 시간 제한이 4시간으로 설정된 메타데이터입니다.




## 질문: 136
한 회사가 AWS 계정에서 eu-west-1 지역의 90개 Amazon EC2 인스턴스에서 워크로드를 실행합니다. 2개월 후에 회사는 eu-west-1에서 eu-west-3 지역으로 워크로드를 마이그레이션합니다.

회사는 EC2 인스턴스 비용을 줄여야 합니다. 회사는 다음 주에 시작되는 1년 약정을 할 의향이 있습니다. 회사는 1년 기간 동안 지역에 관계없이 90개 EC2 인스턴스에 대한 할인을 제공하는 EC2 인스턴스 구매 옵션을 선택해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. EC2 Standard 예약 인스턴스를 구매하세요.
2. EC2 인스턴스 할인 플랜을 구매하세요.
3. EC2 변환 가능 예약 인스턴스를 구매하세요.
4. 컴퓨팅 절감 플랜을 구매하세요.



## 질문: 137
SysOps 관리자가 퍼블릭 서브넷과 프라이빗 서브넷을 포함하는 VPC를 생성했습니다. 프라이빗 서브넷에서 시작된 Amazon EC2 인스턴스는 인터넷에 액세스할 수 없습니다. 기본 네트워크 ACL은 VPC의 모든 서브넷에서 활성화되어 있으며 모든 보안 그룹은 모든 아웃바운드 트래픽을 허용합니다.

어떤 솔루션이 프라이빗 서브넷의 EC2 인스턴스에 인터넷에 액세스할 수 있게 할까요?

퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. 퍼블릭 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
프라이빗 서브넷에 NAT 게이트웨이를 만듭니다. 퍼블릭 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
프라이빗 서브넷에 NAT 게이트웨이를 만듭니다. 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.



## 질문: 138
한 회사가 Elastic Load Balancer(ELB) 뒤의 Amazon EC2 인스턴스에서 퍼블릭 웹 애플리케이션을 실행하려고 합니다. 회사의 보안 팀은 AWS Certificate Manager(ACM) 인증서를 사용하여 웹사이트를 보호하려고 합니다. ELB는 모든 HTTP 요청을 HTTPS로 자동으로 리디렉션해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

포트 80에 HTTPS 리스너가 하나인 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 80에 SSL/TLS 인증서를 연결합니다. HTTP에서 HTTPS로 요청을 리디렉션하는 규칙을 만듭니다.
포트 80에 HTTP 리스너 하나, 포트 443에 HTTPS 프로토콜 리스너 하나가 있는 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.
포트 80과 포트 443에 두 개의 TCP 리스너가 있는 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.
포트 80과 포트 443에 두 개의 TCP 리스너가 있는 네트워크 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.



## 질문: 139
한 회사가 AWS Organizations의 조직에 속한 모든 멤버 계정에서 AWS 비용을 추적하려고 합니다. 멤버 계정 관리자는 매월 예상 비용이 미리 정해진 금액을 초과할 때 알림을 받고 싶어합니다. 관리자는 청구 알람을 구성할 수 없습니다. 모든 사용자의 IAM 권한이 올바릅니다.

이 문제의 원인은 무엇일까요?

관리/지불자 계정에는 청구 알림이 켜져 있지 않습니다.
회사에서는 회원 계정과 관리/지불자 계정 간에 결제 정보를 공유하도록 AWS Resource Access Manager(AWS RAM)를 구성하지 않았습니다.
모든 계정에 대해 Amazon GuardDuty가 켜져 있습니다.
회사에서는 청구를 모니터링하기 위한 AWS Config 규칙을 구성하지 않았습니다.



## 질문: 140
한 회사가 Amazon EC2 인스턴스에서 컨테이너화된 애플리케이션을 실행하기 위해 Amazon Elastic Container Service(Amazon ECS)를 사용하고 있습니다. SysOps 관리자는 ECS 작업 간의 트래픽 흐름만 모니터링하면 됩니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

각 작업의 탄력적 네트워크 인터페이스에 Amazon CloudWatch Logs를 구성합니다.
각 작업의 탄력적 네트워크 인터페이스에서 VPC 흐름 로그를 구성합니다.
작업 정의에서 awsvpc 네트워크 모드를 지정하세요.
작업 정의에서 브리지 네트워크 모드를 지정하세요.
작업 정의에서 호스트 네트워크 모드를 지정하세요.



## 질문: 141
한 회사가 AWS Organizations를 사용하여 여러 AWS 계정을 관리합니다. 회사의 SysOps 팀은 수동 프로세스를 사용하여 IAM 역할을 만들고 관리해 왔습니다. 이 팀은 여러 AWS 계정에 필요한 IAM 역할을 만들고 관리하기 위한 자동화된 솔루션이 필요합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

AWS CloudFormation 템플릿을 만듭니다. 템플릿을 재사용하여 각 AWS 계정에서 필요한 IAM 역할을 만듭니다.
AWS Directory Service를 AWS Organizations와 함께 사용하면 필요한 IAM 역할을 Microsoft Active Directory 사용자와 자동으로 연결할 수 있습니다.
AWS Organizations와 함께 AWS Resource Access Manager를 사용하면 AWS 계정 간에 공유 리소스를 배포하고 관리할 수 있습니다.
AWS CloudFormation StackSets를 AWS Organizations와 함께 사용하여 AWS 계정에 대한 IAM 역할을 배포하고 관리합니다.




## 질문: 142
SysOps 관리자는 Amazon RDS 데이터베이스 자격 증명에 대한 자동 로테이션을 구성해야 합니다. 자격 증명은 30일마다 로테이션해야 합니다. 솔루션은 Amazon RDS와 통합되어야 합니다.

어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할까요?

자격 증명을 AWS Systems Manager Parameter Store에 보안 문자열로 저장합니다. 30일의 로테이션 간격으로 자동 로테이션을 구성합니다.
AWS Secrets Manager에 자격 증명을 저장합니다. 30일의 로테이션 간격으로 자동 로테이션을 구성합니다.
자격 증명을 Amazon S3 버킷의 파일에 저장합니다. AWS Lambda 함수를 배포하여 30일마다 자격 증명을 자동으로 회전합니다.
AWS Secrets Manager에 자격 증명을 저장합니다. AWS Lambda 함수를 배포하여 30일마다 자격 증명을 자동으로 회전합니다.



## 질문: 143
회사의 SysOps 관리자가 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 복원하려고 시도합니다. 그러나 다른 시스템 관리자가 실수로 스냅샷을 삭제했기 때문에 스냅샷이 없습니다. 회사는 스냅샷이 삭제된 후 지정된 기간 동안 스냅샷을 복구할 수 있는 기능이 필요합니다.

어떤 솔루션이 이 기능을 제공할까요?

보관해야 하는 개별 EBS 스냅샷에 대해 삭제 보호를 켜세요.
스냅샷 연령에 대한 조건문을 사용하여 EBS 스냅샷 삭제를 거부하는 IAM 정책을 만듭니다. 모든 사용자에게 정책을 적용합니다.
원하는 보관 기간 동안 EBS 스냅샷에 대한 휴지통 보관 규칙을 만듭니다.
Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 예약하여 EBS 스냅샷을 Amazon S3 Glacier로 복사합니다.
 




## 질문: 144
SysOps 관리자가 최근 S3 버킷에서 Amazon S3 Cross-Region Replication을 구성했습니다.

이 기능은 기본적으로 대상 S3 버킷에 다음 중 어느 것을 복제합니까?

버킷 소유자에게 권한이 없는 소스 S3 버킷의 개체
S3 Glacier에 저장된 객체
복제가 구성되기 전에 존재했던 개체
객체 메타데이터



## 질문: 145
회사에 Amazon CloudWatch Logs로 로그 데이터를 보내는 작업 부하가 있습니다. 필드 중 하나에 애플리케이션 지연 시간 측정이 포함됩니다. SysOps 관리자는 시간 경과에 따라 이 필드의 p90 통계를 모니터링해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

로그 데이터에 대한 Amazon CloudWatch Contributor Insights 규칙을 만듭니다.
로그 데이터에 대한 메트릭 필터를 만듭니다.
로그 데이터에 대한 구독 필터를 만듭니다.
워크로드에 대한 Amazon CloudWatch Application Insights 규칙을 만듭니다.



## 질문: 146
어떤 회사가 Amazon S3 Glacier에 민감한 데이터를 보관하려고 합니다. 회사의 규제 및 규정 준수 요구 사항은 어떤 계정에서도 데이터를 수정하는 것을 허용하지 않습니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 후에 볼트 잠금 정책을 검증합니다.
보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 이내에 볼트 잠금 정책을 검증합니다.
거버넌스 모드에서 S3 객체 잠금을 구성합니다. 24시간 후에 모든 파일을 업로드합니다.
거버넌스 모드에서 S3 객체 잠금을 구성합니다. 모든 파일을 24시간 이내에 업로드합니다.




## 질문: 147
한 회사가 두 개의 다른 가용성 영역에 걸쳐 분산된 두 개의 초대형 노드가 있는 Amazon ElastiCache for Redis를 사용하는 애플리케이션을 관리합니다. 회사의 IT 팀은 ElastiCache for Redis 클러스터에 75%의 사용 가능한 메모리가 있다는 것을 발견했습니다. 애플리케이션은 높은 가용성을 유지해야 합니다.

클러스터 크기를 조정하는 가장 비용 효율적인 방법은 무엇입니까?

Redis 클러스터용 ElastiCache의 노드 수를 2개에서 1개로 줄입니다.
대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 새 클러스터로 데이터를 마이그레이션합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.
대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 백업을 가져오고 새 클러스터에서 백업을 복원합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.
ElastiCache for Redis 클러스터에 대한 온라인 크기 조정을 수행합니다. 노드 유형을 초대형 노드에서 대형 노드로 변경합니다.




## 질문: 148
회사는 애플리케이션을 AWS로 마이그레이션해야 합니다. 이 회사는 구성 관리를 위해 Chef 레시피를 사용하고 있습니다. 이 회사는 애플리케이션을 AWS로 마이그레이션한 후에도 기존 Chef 레시피를 계속 사용하고 싶어합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

AWS CloudFormation을 사용하여 Amazon EC2 인스턴스를 생성하고, Chef 서버를 설치하고, Chef 레시피를 추가합니다.
AWS CloudFormation을 사용하여 스택을 만들고 Chef 레시피에 대한 계층을 추가합니다.
Docker 플랫폼과 함께 AWS Elastic Beanstalk를 사용하여 Chef 레시피를 업로드합니다.
AWS OpsWorks를 사용하여 스택을 만들고 Chef 레시피로 레이어를 추가합니다.



## 질문: 149
한 회사가 AWS Organizations를 사용하여 AWS 계정을 관리합니다. SysOps 관리자는 회사의 모든 AWS 계정에서 모든 Amazon EC2 인스턴스에 대한 백업 전략을 만들어야 합니다.

어떤 솔루션이 가장 운영 효율적인 방식으로 이러한 요구 사항을 충족할까요?

각 계정에 AWS Lambda 함수를 배포하여 예약된 기준으로 EC2 인스턴스 스냅샷을 실행합니다.
관리 계정에 AWS CloudFormation 스택 세트를 생성하여 모든 EC2 인스턴스에 AutoBackup=True 태그를 추가합니다.
관리 계정에서 AWS Backup을 사용하여 모든 계정과 리소스에 대한 정책을 배포합니다.
SCP(서비스 제어 정책)를 사용하여 각 계정에서 예약된 기준으로 EC2 인스턴스 스냅샷을 실행합니다.




## 질문: 150
SysOps 관리자가 VPC의 연결 문제를 해결하기 위해 VPC Flow Logs를 검토하고 있습니다. SysOps 관리자는 로그를 검토하는 동안 거부된 트래픽이 나열되지 않은 것을 알아차렸습니다.

SysOps 관리자는 모든 트래픽이 기록되도록 하기 위해 무엇을 해야 합니까?

모든 트래픽을 캡처하기 위한 필터 설정이 있는 새로운 흐름 로그를 만듭니다.
새 흐름 로그를 만듭니다. 로그 레코드 형식을 사용자 지정 형식으로 설정합니다. 로그에 포함할 적절한 필드를 선택합니다.
기존 흐름 로그를 편집합니다. 모든 트래픽을 캡처하도록 필터 설정을 변경합니다.
기존 흐름 로그를 편집합니다. 로그 레코드 형식을 사용자 지정 형식으로 설정합니다. 로그에 포함할 적절한 필드를 선택합니다.




## 질문: 151
한 회사가 포트폴리오 전반에 걸쳐 AWS 서비스 사용을 확대하고 있습니다. 이 회사는 보안, 규정 준수 및 청구를 위한 비즈니스 프로세스의 분리를 보장하기 위해 각 팀에 AWS 계정을 프로비저닝하려고 합니다. 계정 생성 및 부트스트래핑은 확장 가능하고 효율적인 방식으로 완료되어야 하며, 정의된 기준선과 거버넌스 가드레일이 있는 새 계정이 생성되어야 합니다. SysOps 관리자는 시간과 리소스를 절약하는 프로비저닝 프로세스를 설계해야 합니다.

이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

AWS Elastic Beanstalk를 사용하여 AWS 계정을 프로비저닝하고, 인프라를 설정하고, AWS Organizations와 통합하는 작업을 자동화합니다.
AWS OpsWorks에서 부트스트래핑 스크립트를 만들고 이를 AWS CloudFormation 템플릿과 결합하여 계정과 인프라를 프로비저닝합니다.
AWS Config를 사용하면 AWS Service Catalog를 통해 계정을 프로비저닝하고 인스턴스를 배포할 수 있습니다.
AWS Control Tower를 사용하여 Account Factory에서 템플릿을 만들고 해당 템플릿을 사용하여 새로운 계정을 프로비저닝합니다.
 




## 질문: 152
SysOps 관리자가 Amazon CloudFront 배포판의 캐시 적중률이 10% 미만임을 알아챘습니다.

어떤 구성 변경 모음이 배포판의 캐시 적중률을 증가시킬까요? (두 가지를 선택하세요.)

캐시 동작 설정에서 필요한 쿠키, 쿼리 문자열, 헤더만 전달되는지 확인하세요.
HTTPS만 사용하도록 뷰어 프로토콜 정책을 변경합니다.
사전 서명된 쿠키와 URL을 사용하여 배포판에 대한 액세스를 제한하도록 배포판을 구성합니다.
캐시 동작 설정에서 객체의 자동 압축을 활성화합니다.
캐시 동작 설정에서 CloudFront TTL(수명) 설정을 늘립니다.



## 질문: 153
SysOps 관리자가 인터넷에서 개인 서브넷의 인스턴스로 패치를 다운로드하려고 합니다.VPC에 대한 인터넷 게이트웨이가 있고 NAT 게이트웨이가 공개 서브넷에 배포되었지만 인스턴스에 인터넷 연결이 없습니다.개인 서브넷에 배포된 리소스는 공개 인터넷에서 직접 액세스할 수 없어야 합니다.

공개 서브넷(10.0.1.0/24) 경로 테이블
대상
10.0.0.0/16 로컬
0.0.0.0/0 IGW

개인 서브넷(10.0.2.0/24) 경로 테이블
대상
10.0.0.0/16 로컬

제공된 정보를 고려할 때, 이 문제를 해결하기 위해 개인 서브넷의 경로 테이블에 무엇을 추가해야 합니까?

0.0.0.0/0 IGW
0.0.0.0/0 NAT
10.0.1.0/24 IGW
10.0.1.0/24 NAT



## 질문: 154
한 회사가 AWS에서 전적으로 실행되는 시스템에 대한 외부 감사를 받고 있습니다. SysOps 관리자는 AWS에서 관리하는 인프라에 대한 PCI DSS(Payment Card Industry Data Security Standard) 준수에 대한 문서를 제공해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

AWS Artifact 포털에서 해당 보고서를 다운로드하여 감사자에게 제공합니다.
AWS CloudTrail 로그 파일의 전체 사본을 다운로드하여 감사자에게 제공합니다.
AWS CloudWatch 로그의 전체 사본을 다운로드하여 감사자에게 제공합니다.
감사자에게 프로덕션 AWS 계정에 대한 관리 액세스 권한을 제공하여 감사자가 규정 준수 여부를 확인할 수 있도록 합니다.




## 질문: 155
한 회사가 Amazon EC2 및 AWS Lambda와 관련된 비용을 줄이기 위한 이니셔티브를 가지고 있습니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

Amazon Athena를 사용하여 AWS 비용 및 사용 보고서를 분석하여 비용 절감 방안을 파악합니다.
계정 지출이 예산의 80%에 도달하면 알림을 보내는 AWS Budgets 알림을 만듭니다.
Amazon EC2 콘솔을 통해 예약 인스턴스를 구매하세요.
AWS Compute Optimizer를 사용하여 제공된 권장 사항에 따라 조치를 취하세요.



## 질문: 156
어떤 회사는 모든 Amazon EC2 인스턴스에 IPv6만 사용하고 싶어합니다. EC2 인스턴스는 인터넷에서 액세스할 수 없어야 하지만, EC2 인스턴스는 인터넷에 액세스할 수 있어야 합니다. 이 회사는 듀얼 스택 VPC와 IPv6 전용 서브넷을 만듭니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 VPC를 어떻게 구성해야 합니까?

NAT 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 NAT 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
인터넷 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 인터넷 게이트웨이로 가리키는 엔트리를 포함하는 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
이탈 전용 인터넷 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 이탈 전용 인터넷 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
인터넷 게이트웨이와 NAT 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 인터넷 게이트웨이로, 모든 IPv4 트래픽을 NAT 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
 




## 질문: 157
한 회사에는 두 개의 가용성 영역에 걸쳐 애플리케이션 로드 밸런서(ALB) 뒤에 있는 두 개의 Amazon EC2 인스턴스에서 실행되는 기존 웹 애플리케이션이 있습니다. 이 애플리케이션은 Amazon RDS Multi-AZ DB 인스턴스를 사용합니다. Amazon Route 53 레코드 세트는 동적 콘텐츠에 대한 요청을 로드 밸런서로 라우팅하고 정적 콘텐츠에 대한 요청을 Amazon S3 버킷으로 라우팅합니다. 사이트 방문자는 로딩 시간이 매우 길다고 보고합니다.

웹사이트 성능을 개선하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

정적 콘텐츠에 대한 Amazon CloudFront 캐싱을 추가합니다.
로드 밸런서 리스너를 HTTPS에서 TCP로 변경합니다.
Amazon Route 53 지연 기반 라우팅을 활성화합니다.
웹 서버에 Amazon EC2 자동 확장을 구현합니다.
정적 콘텐츠를 Amazon S3에서 웹 서버로 옮깁니다.



## 질문: 158
한 회사가 온프레미스에서 애플리케이션을 실행하고 있으며 데이터 백업에 AWS를 사용하려고 합니다. 모든 데이터는 로컬에서 사용할 수 있어야 합니다. 백업 애플리케이션은 POSIX(Portable Operating System Interface)와 호환되는 블록 기반 스토리지에만 쓸 수 있습니다.

어떤 백업 솔루션이 이러한 요구 사항을 충족할까요?

데이터 백업의 대상으로 Amazon S3를 사용하도록 백업 소프트웨어를 구성합니다.
데이터 백업의 대상으로 Amazon S3 Glacier를 사용하도록 백업 소프트웨어를 구성합니다.
AWS Storage Gateway를 사용하고 게이트웨이 캐시 볼륨을 사용하도록 구성합니다.
AWS Storage Gateway를 사용하고 게이트웨이에 저장된 볼륨을 사용하도록 구성합니다.



## 질문: 159
글로벌 기업이 내부 웹 포털을 통해 대량의 개인 식별 정보(PII)를 처리합니다. 이 회사의 애플리케이션은 AWS Direct Connect 연결을 통해 AWS에 연결된 기업 데이터 센터에서 실행됩니다. 이 애플리케이션은 PII를 Amazon S3에 저장합니다. 규정 준수 요구 사항에 따라 웹 포털에서 Amazon S3로의 트래픽은 인터넷을 통과해서는 안 됩니다.

SysOps 관리자는 규정 준수 요구 사항을 충족하기 위해 무엇을 해야 합니까?

Amazon S3에 대한 인터페이스 VPC 엔드포인트를 프로비저닝합니다. 인터페이스 엔드포인트를 사용하도록 애플리케이션을 수정합니다.
AWS 네트워크 방화벽을 구성하여 트래픽을 내부 S3 주소로 리디렉션합니다.
S3 경로 스타일 엔드포인트를 사용하도록 애플리케이션을 수정합니다.
트래픽을 내부 S3 주소로 리디렉션하기 위해 다양한 VPC 네트워크 ACL을 설정합니다.



## 질문: 160
SysOps 관리자가 Amazon EC2 Auto Scaling 그룹의 확장 이벤트를 알아차렸습니다. Amazon CloudWatch는 연관된 Application Load Balancer의 RequestCount 메트릭에서 급증을 보여줍니다. 관리자는 요청 소스의 IP 주소를 알고 싶어합니다.

관리자는 이 정보를 어디에서 찾을 수 있습니까?

자동 크기 조정 로그
AWS CloudTrail 로그
EC2 인스턴스 로그
Elastic Load Balancer 액세스 로그



## 질문: 161
회사의 SysOps 관리자가 회사 웹 애플리케이션 앞에 퍼블릭 네트워크 로드 밸런서(NLB)를 배포합니다. 웹 애플리케이션은 어떠한 Elastic IP 주소도 사용하지 않습니다. 사용자는 회사의 도메인 이름을 사용하여 웹 애플리케이션에 액세스해야 합니다. SysOps 관리자는 트래픽을 NLB로 라우팅하도록 Amazon Route 53을 구성해야 합니다.

어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요?

NLB에 대한 Route 53 AAAA 레코드를 생성합니다.
NL에 대한 Route 53 별칭 레코드를 만듭니다.
NLB에 대한 Route 53 CAA 레코드를 생성합니다.
NLB에 대한 Route 53 CNAME 레코드를 만듭니다.



## 질문: 162
한 회사가 암호화된 Amazon RDS for Oracle DB 인스턴스를 실행합니다. 이 회사는 다른 AWS 지역에서 정기 백업을 제공하고자 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

DB 인스턴스를 수정합니다. 지역 간 자동 백업을 활성화합니다.
다른 지역에서 RDS 읽기 복제본을 만듭니다. 읽기 복제본의 스냅샷을 만듭니다.
AWS Database Migration Service(AWS DMS)를 사용하여 다른 지역의 DB 인스턴스로 데이터를 복사합니다.
DB 인스턴스에서 암호화를 일시적으로 해제합니다. 스냅샷을 찍습니다. 스냅샷을 다른 Region에 복사합니다.



## 질문: 163
한 회사가 웹사이트의 새 버전을 출시하고 있습니다. 경영진은 회사 고객의 20%에 한정된 출시로 새 웹사이트를 배포하려고 합니다. 이 회사는 웹사이트의 DNS 솔루션에 Amazon Route 53을 사용합니다.

어떤 구성이 이러한 요구 사항을 충족할까요?

장애 조치 라우팅 정책을 만듭니다. 정책 내에서 웹사이트 트래픽의 80%를 원래 리소스로 보내도록 구성합니다. 나머지 20%의 트래픽을 새 리소스를 가리키는 장애 조치 레코드로 구성합니다.
다중값 답변 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스의 이름과 IP 주소로 4개의 레코드를 만듭니다. 새 리소스의 이름과 IP 주소로 1개의 레코드를 구성합니다.
지연 기반 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스를 가리키는 레코드를 80의 가중치로 구성합니다. 새 리소스를 가리키는 레코드를 20의 가중치로 구성합니다.
가중치가 적용된 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스를 가리키는 레코드에 대해 가중치 80을 구성합니다. 새 리소스를 가리키는 레코드에 대해 가중치 20을 구성합니다.



## 질문: 164
SysOps 관리자가 Amazon EC2 인스턴스, Elastic Load Balancer(ELB) 및 Amazon RDS DB 인스턴스를 프로비저닝하는 AWS CloudFormation 템플릿을 만들었습니다. 스택 생성 중에 EC2 인스턴스 생성과 ELB 생성이 성공했습니다. 그러나 DB 인스턴스 생성은 실패했습니다.

이 시나리오에서 CloudFormation의 기본 동작은 무엇입니까?

CloudFormation은 스택을 롤백하고 삭제합니다.
CloudFormation은 스택을 롤백하지만 스택을 삭제하지는 않습니다.
CloudFormation은 사용자에게 스택을 롤백할지 아니면 계속할지 묻습니다.
CloudFormation은 스택을 성공적으로 완료하지만 DB 인스턴스에 대해 실패 상태를 보고합니다.



## 질문: 165
SysOps 관리자는 AWS Lambda 함수의 호출을 자동화해야 합니다. Lambda 함수는 Amazon S3 버킷에 저장된 데이터에 대한 보고서를 생성하기 위해 매일 마지막에 실행되어야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

Amazon S3와 Lambda 함수를 대상으로 하는 이벤트 패턴이 있는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
일정과 Lambda 함수를 대상으로 하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
S3 버킷에서 객체가 변경될 때마다 Lambda 함수를 호출하는 S3 이벤트 알림을 만듭니다.
Cron 작업으로 Amazon EC2 인스턴스를 배포하여 Lambda 함수를 호출합니다.



## 질문: 166
한 회사가 Amazon S3에 호스팅된 새로운 정적 웹사이트를 출시합니다. 정적 웹사이트 호스팅 기능이 버킷에서 활성화되었고 콘텐츠가 업로드되었습니다. 하지만 사이트로 이동하면 다음과 같은 오류 메시지가 표시됩니다.

403 Forbidden - Access Denied

이 오류를 해결하려면 어떤 변경을 해야 합니까?

모든 사용자에게 버킷에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가합니다.
모든 사용자에게 버킷 객체에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가합니다.
버킷에 대한 읽기 액세스를 거부하는 기본 버킷 정책을 제거합니다.
버킷에서 CORS(교차 출처 리소스 공유)를 구성합니다.



## 질문: 167
한 회사가 AWS Organizations를 사용합니다. SysOps 관리자가 관리 계정에서 AWS Compute Optimizer와 AWS 태그 정책을 사용하여 청구 패밀리의 모든 멤버 계정을 관리하려고 합니다. SysOps 관리자가 AWS Organizations 콘솔로 이동하지만 관리 계정을 통해 태그 정책을 활성화할 수 없습니다.

이 문제의 원인은 무엇일까요?

조직에서 모든 기능이 활성화되지 않았습니다.
통합 결제가 활성화되지 않았습니다.
회원 계정에는 비용 할당을 위한 태그가 활성화되어 있지 않습니다.
멤버 계정에서 Compute Optimizer에 대한 신뢰할 수 있는 액세스를 수동으로 활성화하지 않았습니다.
 




## 질문: 168
한 회사가 Amazon S3 버킷에 미디어 콘텐츠를 저장하고 Amazon CloudFront를 사용하여 사용자에게 콘텐츠를 배포합니다. 라이선스 조건으로 인해 회사는 일부 국가에서 콘텐츠를 배포할 권한이 없습니다. SysOps 관리자는 특정 국가에 대한 액세스를 제한해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

S3:LocationConstraint 조건에 따라 GetObject 작업을 거부하도록 S3 버킷 정책을 구성합니다.
2차 오리진 액세스 ID(OAI)를 만듭니다. S3 버킷 정책을 구성하여 허가되지 않은 국가의 액세스를 방지합니다.
CloudFront 배포에서 지역 제한 기능을 활성화하여 허가되지 않은 국가의 액세스를 차단합니다.
승인된 국가의 IP 주소에 대해서만 서명된 CloudFront URL을 생성하도록 애플리케이션을 업데이트합니다.



## 질문: 169
SysOps 관리자가 인터넷에 액세스해야 하는 IPv6 CIDR 블록이 있는 Amazon VPC를 만들었습니다. 그러나 인터넷에서 VPC로의 액세스는 금지되어 있습니다. VPC에 필요한 구성 요소를 추가하고 구성한 후 관리자는 인터넷에 있는 도메인에 연결할 수 없습니다.

관리자는 경로 테이블에 어떤 추가 경로 대상 규칙을 추가해야 합니까?

Route ::/0 트래픽을 NAT 게이트웨이로
Route ::/0 인터넷 게이트웨이로의 트래픽
0.0.0.0/0 트래픽을 출구 전용 인터넷 게이트웨이로 경로 지정
Route ::/0 트래픽을 이탈 전용 인터넷 게이트웨이로 전송



## 질문: 170
한 회사가 여러 쓰기 집약적 애플리케이션을 호스팅합니다. 이러한 애플리케이션은 단일 Amazon EC2 인스턴스에서 실행되는 MySQL 데이터베이스를 사용합니다. 이 회사는 SysOps 관리자에게 멀티 테넌트 워크로드에 이상적인 고가용성 데이터베이스 솔루션을 구현해 달라고 요청합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 구현해야 합니까?

MySQL에 대한 두 번째 EC2 인스턴스를 만듭니다. 두 번째 인스턴스를 읽기 복제본으로 구성합니다.
데이터베이스를 Amazon Aurora DB 클러스터로 마이그레이션합니다. Aurora Replica를 추가합니다.
데이터베이스를 Amazon Aurora 다중 마스터 DB 클러스터로 마이그레이션합니다.
데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다



## 질문: 171
한 회사에는 Elastic Load Balancer(ELB) 뒤의 Amazon EC2 인스턴스 플릿에서 실행되는 메모리 집약적 애플리케이션이 있습니다. 인스턴스는 Auto Scaling 그룹에서 실행됩니다. SysOps 관리자는 애플리케이션에 연결하는 사용자 수에 따라 애플리케이션이 확장될 수 있도록 해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

ELB에서 생성된 ActiveConnectionCount Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.
EL에서 생성된 mem_used Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.
추가 연결을 지원하기 위해 자동 크기 조정 그룹의 EC2 인스턴스 수를 늘리려면 예약된 크기 조정 정책을 만듭니다.
ELB에 스크립트를 생성하고 배포하여 연결된 사용자 수를 사용자 정의 Amazon CloudWatch 메트릭으로 노출합니다. 메트릭을 사용하는 스케일링 정책을 만듭니다.
 




## 질문: 172
SysOps 관리자가 퍼블릭 서브넷과 프라이빗 서브넷을 포함하는 새 VPC를 만듭니다. SysOps 관리자가 프라이빗 서브넷에서 11개의 Amazon EC2 인스턴스를 성공적으로 시작합니다. SysOps 관리자가 동일한 서브넷에서 EC2 인스턴스를 하나 더 시작하려고 시도합니다. 그러나 SysOps 관리자는 사용 가능한 IP 주소가 충분하지 않다는 오류 메시지를 받습니다.

SysOps 관리자가 더 많은 EC2 인스턴스를 배포하려면 무엇을 해야 합니까?

CIDR 블록을 /27로 변경하려면 개인 서브넷을 편집합니다.
두 번째 가용성 영역으로 확장하도록 개인 서브넷을 편집합니다.
개인 서브넷에 추가적인 Elastic IP 주소를 할당합니다.
필요한 EC2 인스턴스를 보관할 새로운 개인 서브넷을 만듭니다.



## 질문: 173
회사는 여러 지리적 위치에서 잠재적인 무단 AWS Management Console 로그인에 대해 AWS 계정을 자동으로 모니터링해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

Amazon Cognito를 구성하여 손상된 IAM 자격 증명을 감지합니다.
Amazon Inspector를 설정합니다. 승인되지 않은 로그인에 대한 리소스를 스캔하고 모니터링합니다.
AWS Config를 설정합니다. 계정에 iam-policy-blacklisted-check 관리 규칙을 추가합니다.
Amazon GuardDuty를 구성하여 UnauthorizedAccess:IAMUser/ConsoleLoginSuccess.B 발견 사항을 모니터링합니다.



## 질문: 174
한 회사에 Amazon RDS DB 인스턴스가 있습니다. 이 회사는 고가용성을 유지하면서 캐싱 서비스를 구현하고자 합니다.

어떤 작업 조합이 이러한 요구 사항을 충족할까요? (두 가지를 선택하세요.)

데이터 저장소에 자동 검색을 추가합니다.
Memcached용 Amazon ElastiCache 데이터 저장소를 만듭니다.
Redis용 Amazon ElastiCache 데이터 저장소를 만듭니다.
데이터 저장소에 대해 다중 AZ를 활성화합니다.
데이터 저장소에 대해 멀티스레딩을 활성화합니다.



## 질문: 175
한 회사가 AWS CloudTrail을 사용하여 계정 활동을 모니터링하고 있으며, 로그가 계정의 Amazon S3 버킷에 전달된 후 일부 로그 파일이 변조되는 것을 우려하고 있습니다.

앞으로 SysOps 관리자는 로그 파일이 S3 버킷에 전달된 후 수정되지 않았는지 어떻게 확인할 수 있습니까?

CloudTrail 로그를 Amazon CloudWatch Logs로 스트리밍하여 보조 위치에 로그를 저장합니다.
로그 파일 무결성 검증을 활성화하고 다이제스트 파일을 사용하여 로그 파일의 해시 값을 확인합니다.
여러 지역 간에 S3 로그 버킷을 복제하고 S3 관리 키로 로그 파일을 암호화합니다.
보안 감사를 위해 로그 버킷에 대한 요청을 추적하려면 S3 서버 액세스 로깅을 활성화합니다.



## 질문: 176
SysOps 관리자가 AWS Trusted Advisor 경고를 검토하고 오픈 액세스 권한이 있는 S3 버킷 정책에 대한 경고를 발견했습니다. 버킷 소유자와 문제를 논의하는 동안 관리자는 S3 버킷이 Amazon CloudFront 웹 배포의 출처임을 깨달았습니다.

사용자가 CloudFront URL만 사용하여 Amazon S3의 객체에 액세스하도록 하려면 관리자가 어떤 조치를 취해야 합니까?

Amazon S3 관리 키(SSE-S3)를 사용한 서버 측 암호화로 S3 버킷 콘텐츠를 암호화합니다.
원본 액세스 ID를 생성하고 S3 버킷의 객체를 읽을 수 있는 권한을 부여합니다.
CloudFront 배포에 IAM 사용자를 할당하고 S3 버킷 정책에서 사용자 권한을 부여합니다.
CloudFront 배포에 IAM 역할을 할당하고 S3 버킷 정책에서 역할 권한을 부여합니다.




## 질문: 177
SysOps 관리자가 AWS Trusted Advisor 권장 사항을 검토하고 있습니다. SysOps 관리자는 재무 애플리케이션의 모든 애플리케이션 서버가 Low Utilization Amazon EC2 Instances 검사에 나열되어 있음을 알아차렸습니다. 애플리케이션은 3개의 가용성 영역에 걸쳐 3개의 인스턴스에서 실행됩니다. SysOps 관리자는 애플리케이션의 가용성이나 디자인에 영향을 미치지 않으면서 애플리케이션 실행 비용을 줄여야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

애플리케이션 서버의 수를 줄이세요.
AWS Cost Explorer에서 적절한 크기 조정 권장 사항을 적용하여 인스턴스 크기를 줄입니다.
인스턴스 앞에 애플리케이션 로드 밸런서를 프로비저닝합니다.
애플리케이션 서버의 인스턴스 크기를 확장합니다



## 질문: 178
한 회사가 us-east-1 지역에 웹사이트를 호스팅합니다. 이 회사는 eu-central-1 지역에 웹사이트를 배포할 준비를 하고 있습니다. 유럽에 있는 웹사이트 방문자는 eu-central-1에 호스팅된 웹사이트에 액세스해야 합니다. 다른 모든 방문자는 us-east-1에 호스팅된 웹사이트에 액세스합니다. 이 회사는 Amazon Route 53을 사용하여 웹사이트의 DNS 레코드를 관리합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 Route 53 레코드 세트에 어떤 라우팅 정책을 적용해야 합니까?

지리적 위치 라우팅 정책
지근거리 라우팅 정책
지연 라우팅 정책
다중값 답변 라우팅 정책



## 질문: 179
대규모 IT 부서가 있는 조직에서 AWS로 마이그레이션하기로 결정했습니다. IT 부서의 직무 기능이 다르기 때문에 모든 사용자에게 모든 AWS 리소스에 대한 액세스 권한을 부여하는 것은 바람직하지 않습니다. 현재 조직은 LDAP 그룹 멤버십을 통해 액세스를 처리합니다.

현재 LDAP 자격 증명을 사용하여 액세스를 허용하는 가장 좋은 방법은 무엇입니까?

AWS Directory Service Simple AD를 만듭니다. 온프레미스 LDAP 디렉토리를 Simple AD로 복제합니다.
LDAP 그룹을 읽고 IAM 사용자 생성을 자동화하는 Lambda 함수를 만듭니다.
AWS CloudFormation을 사용하여 IAM 역할을 만듭니다. Direct Connect를 배포하여 온프레미스 LDAP 서버에 대한 액세스를 허용합니다.
SAML을 사용하여 LDAP 디렉토리를 IAM과 페더레이션합니다. 다른 LDAP 그룹에 대응하도록 다른 IAM 역할을 만들어 권한을 제한합니다.




## 질문: 180
SysOps 관리자가 us-east-1 지역에서 AWS CloudFormation 템플릿을 사용하여 Amazon EC2 인스턴스를 생성했습니다. 관리자는 이 템플릿이 us-west-2 지역에서 EC2 인스턴스를 생성하지 못했다는 것을 알게 되었습니다.

이 실패의 원인 중 하나는 무엇입니까?

CloudFormation 템플릿에 정의된 리소스 태그는 us-east-1 지역에만 적용됩니다.
CloudFormation 템플릿에서 참조된 Amazon Machine Image(AMI) ID를 us-west-2 지역에서 찾을 수 없습니다.
cfn-init 스크립트는 us-west-2 지역에서 리소스 프로비저닝 중에 실행되지 않았습니다.
지정된 지역에 IAM 사용자가 생성되지 않았습니다.



## 질문: 181
글로벌 게임 회사가 AWS에서 새로운 게임을 출시할 준비를 하고 있습니다. 이 게임은 Amazon EC2 인스턴스의 여러 AWS 지역에서 실행됩니다. 인스턴스는 각 지역의 Application Load Balancer(ALB) 뒤에 있는 Auto Scaling 그룹에 있습니다. 이 회사는 DNS 서비스에 Amazon Route 53을 사용할 계획입니다. DNS 구성은 사용자를 가장 가까운 지역으로 안내해야 하며 자동화된 장애 조치를 제공해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Route 53을 구성하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

각 지역의 ALB 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.
각 지역의 EC2 인스턴스 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.
각 지역의 EC2 인스턴스의 개인 IP 주소를 모니터링하는 상태 검사를 사용하여 Route 53 DNS 장애 조치를 구성합니다.
Route 53 지리적 근접 라우팅을 구성합니다. 인프라에 사용되는 지역을 지정합니다.
Route 53 단순 라우팅을 구성합니다. 인프라에 사용되는 대륙, 국가, 주 또는 지방을 지정합니다.



## 질문: 182
SysOps 관리자가 회사의 웹 애플리케이션의 성능 문제를 조사하고 있습니다. 이 애플리케이션은 Auto Scaling 그룹에 있는 Amazon EC2 인스턴스에서 실행됩니다. 이 애플리케이션은 하루 종일 무작위로 많은 트래픽이 증가합니다. 트래픽이 빠르게 증가하는 기간 동안 Auto Scaling 그룹은 용량을 충분히 빠르게 추가하지 않습니다. 그 결과 사용자는 성능이 저하됩니다.

이 회사는 웹 트래픽이 빠르게 급증할 때 사용자 경험에 부정적인 영향을 미치지 않으면서 비용을 최소화하고자 합니다. 이 회사는 작은 트래픽 증가보다 큰 트래픽 증가에 대해 Auto Scaling 그룹에 더 많은 용량을 추가하는 솔루션이 필요합니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Auto Scaling 그룹을 어떻게 구성해야 합니까?

시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 간단한 확장 정책을 만듭니다.
시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 단계별 확장 정책을 만듭니다.
시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 대상 추적 확장 정책을 만듭니다.
Amazon EC2 Auto Scaling 라이프사이클 후크를 사용합니다. 모든 스케일링 이벤트 후 Auto Scaling 그룹의 최대 인스턴스 수를 조정합니다.




## 질문: 183
어떤 회사에는 보안 그룹이 SSH 포트를 모든 IP 주소에 개방할 수 없다는 규정 준수 요구 사항이 있습니다. SysOps 관리자는 보안 그룹 규칙이 이 요구 사항을 위반할 때 회사의 SysOps 팀에 알리는 솔루션을 구현해야 합니다. 이 솔루션은 또한 보안 그룹 규칙을 자동으로 수정해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

보안 그룹이 변경될 때 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 보안 그룹의 규정 준수 여부를 평가하고, 모든 포트에서 모든 인바운드 보안 그룹 규칙을 제거하고, 보안 그룹이 규정을 준수하지 않는 경우 SysOps 팀에 알립니다.
보안 그룹 변경 사항에 대한 AWS CloudTrail 메트릭 필터를 만듭니다. 메트릭이 0보다 클 때 Amazon Simple Notification Service(Amazon SNS) 토픽을 통해 SysOps 팀에 알리는 Amazon CloudWatch 알람을 만듭니다. AWS Lambda 함수를 SNS 토픽에 구독하여 규칙을 제거하여 보안 그룹 규칙을 수정합니다.
AWS Config restricted-ssh 관리 규칙을 활성화합니다. AWS Systems Manager Automation AWS-DisablePublicAccessForSecurityGroup 런북을 사용하여 AWS Config 규칙에 자동 수정을 추가합니다. 규칙이 규정을 준수하지 않을 때 SysOps 팀에 알리기 위해 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.
보안 그룹 변경에 대한 AWS CloudTrail 메트릭 필터를 만듭니다. 메트릭이 0보다 큰 경우 Amazon CloudWatch 알람을 만듭니다. 알람이 ALARM 상태일 때 Systems Manager Automation AWS-DisablePublicAccessForSecurityGroup 런북을 사용하여 보안 그룹을 일시 중단하기 위해 CloudWatch 알람에 AWS Systems Manager 작업을 추가합니다. SysOps 팀에 알리기 위해 두 번째 대상으로 Amazon Simple Notification Service(Amazon SNS) 토픽을 추가합니다.



## 질문: 184
한 회사에는 Amazon EC2 Spot Instances에서만 실행되는 애플리케이션이 있습니다. 인스턴스는 예약된 스케일링 작업이 있는 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 그러나 용량은 항상 예약된 시간에 늘어나지 않으며 인스턴스는 하루에 여러 번 종료됩니다. SysOps 관리자는 인스턴스가 정시에 시작되고 중단이 적도록 해야 합니다.

어떤 작업이 이러한 요구 사항을 충족할까요?

Spot Instances에 대한 용량 최적화 할당 전략을 지정합니다. Auto Scaling 그룹에 더 많은 인스턴스 유형을 추가합니다.
Spot Instances에 대한 용량 최적화 할당 전략을 지정합니다. Auto Scaling 그룹의 인스턴스 크기를 늘립니다.
Spot Instances에 대한 최저 가격 할당 전략을 지정합니다. Auto Scaling 그룹에 더 많은 인스턴스 유형을 추가합니다.
Spot Instances에 대한 최저 가격 할당 전략을 지정합니다. Auto Scaling 그룹의 인스턴스 크기를 늘립니다.



## 질문: 185
한 회사가 Amazon Aurora MySQL DB 클러스터에 데이터베이스를 배포할 계획입니다. 데이터베이스는 데모 환경을 위한 데이터를 저장합니다. 데이터는 매일 재설정해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

데이터가 채워진 후 DB 클러스터의 수동 스냅샷을 만듭니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 스냅샷을 복원한 다음 이전 DB 클러스터를 삭제하도록 함수를 구성합니다.
DB 클러스터 생성 중에 Backtrack 기능을 활성화합니다. 48시간의 대상 백트랙 창을 지정합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 백트랙 작업을 수행하도록 함수를 구성합니다.
데이터가 채워진 후 DB 클러스터의 수동 스냅샷을 Amazon S3 버킷으로 내보냅니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. Amazon S3에서 스냅샷을 복원하도록 함수를 구성합니다.
DB 클러스터 백업 보존 기간을 2일로 설정합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 함수를 구성하여 DB 클러스터를 특정 시점으로 복원한 다음 이전 DB 클러스터를 삭제합니다.



## 질문: 186
SysOps 관리자가 기본 하드웨어 장애 발생 시 Amazon EC2 인스턴스를 복구하기 위한 자동화된 프로세스를 설정하고 있습니다. 복구된 인스턴스는 원래 인스턴스와 동일한 개인 IP 주소와 동일한 Elastic IP 주소를 가져야 합니다. SysOps 팀은 복구 프로세스가 시작될 때 이메일 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만들고 StatusCheckFailed_Instance 메트릭을 지정합니다. 인스턴스를 복구하기 위한 EC2 작업을 알람에 추가합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하기 위한 알람 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.
EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만들고 StatusCheckFailed_System 메트릭을 지정합니다. 인스턴스를 복구하기 위한 EC2 작업을 알람에 추가합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하기 위한 알람 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.
최소, 최대 및 원하는 크기가 1인 동일한 가용성 영역의 세 개의 서로 다른 서브넷에 걸쳐 자동 확장 그룹을 만듭니다. 개인 IP 주소와 탄력적 IP 주소를 지정하는 시작 템플릿을 사용하도록 자동 확장 그룹을 구성합니다. Amazon Simple Email Service(Amazon SES)를 통해 SysOps 팀에 이메일 메시지를 보내도록 자동 확장 그룹에 대한 활동 알림을 추가합니다.
최소, 최대, 원하는 크기가 1인 3개의 가용 영역에 걸쳐 자동 확장 그룹을 만듭니다. 개인 IP 주소와 탄력적 IP 주소를 지정하는 시작 템플릿을 사용하도록 자동 확장 그룹을 구성합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 자동 확장 그룹에 대한 활동 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.
 




## 질문: 187
한 회사에 최근에 문제가 발생한 공개 웹사이트가 있습니다. 일부 링크는 누락된 웹페이지로 이어졌고, 다른 링크는 잘못된 웹페이지로 이어졌습니다. 애플리케이션 인프라는 제대로 실행 중이었고, 제공된 모든 리소스는 정상이었습니다. 애플리케이션 로그와 대시보드에는 오류가 표시되지 않았고 모니터링 알람도 발생하지 않았습니다. 시스템 관리자는 최종 사용자가 문제를 보고할 때까지 문제를 알지 못했습니다.

회사는 앞으로 이러한 문제에 대해 웹사이트를 사전에 모니터링해야 하며 가능한 한 빨리 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요?

문제가 발생하면 애플리케이션 로그에 사용자 지정 오류를 표시하도록 애플리케이션을 다시 작성합니다. 오류에 대한 로그를 자동으로 구문 분석합니다. 문제가 감지되면 알림을 제공하는 Amazon CloudWatch 알람을 만듭니다.
웹사이트를 테스트하기 위한 AWS Lambda 함수를 만듭니다. 오류가 감지되면 Amazon CloudWatch 사용자 지정 메트릭을 내보내도록 Lambda 함수를 구성합니다. 문제가 감지되면 알림을 제공하도록 CloudWatch 알람을 구성합니다.
Amazon CloudWatch Synthetics 카나리아를 만듭니다. CloudWatch Synthetics Recorder 플러그인을 사용하여 카나리아 실행을 위한 스크립트를 생성합니다. 요구 사항에 따라 카나리아를 구성합니다. 문제가 감지되면 알림을 제공하는 알람을 만듭니다.
Amazon CloudWatch 콘솔에서 Application Insights를 켭니다. 문제가 감지되면 알림을 제공하기 위해 CloudWatch 알람을 만듭니다.




## 질문: 188
SysOps 관리자는 회사의 보안 그룹을 담당합니다. 회사는 보안 그룹에 대한 모든 변경 사항을 문서화하여 보관하고자 합니다. SysOps 관리자는 보안 그룹이 변경될 때마다 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

Amazon Detective를 설정하여 보안 그룹 변경 사항을 기록합니다. 구성 기록 로그를 저장할 Amazon CloudWatch Logs 로그 그룹을 지정합니다. 구성 변경에 대한 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 만듭니다. SysOps 관리자의 이메일 주소를 SQS 대기열에 구독합니다.
보안 그룹 변경 사항을 기록하도록 AWS Systems Manager Change Manager를 설정합니다. 구성 기록 로그를 저장할 Amazon CloudWatch Logs 로그 그룹을 지정합니다. 구성 변경 사항에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.
보안 그룹 변경 사항을 기록하도록 AWS Config를 설정합니다. 구성 스냅샷 및 기록 파일의 위치로 Amazon S3 버킷을 지정합니다. 구성 변경 사항에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.
Amazon Detective를 설정하여 보안 그룹 변경 사항을 기록합니다. 구성 스냅샷 및 기록 파일의 위치로 Amazon S3 버킷을 지정합니다. 구성 변경에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.
 




## 질문: 189
전자상거래 회사가 Amazon Aurora DB 클러스터를 사용하는 웹 애플리케이션을 구축했습니다. DB 클러스터에는 작성자 노드와 판독자 노드가 모두 있는 메모리 최적화 인스턴스 유형이 포함됩니다. 트래픽 볼륨은 하루 종일 변합니다. 트래픽이 갑자기 급증하는 동안 DB 클러스터에 대한 Amazon CloudWatch 메트릭은 높은 RAM 소비와 선택 대기 시간 증가를 나타냅니다.

SysOps 관리자는 DB 클러스터의 성능을 개선하기 위해 구성 변경을 구현해야 합니다. 변경은 다운타임을 최소화해야 하며 데이터 손실로 이어져서는 안 됩니다.

어떤 변경이 이러한 요구 사항을 충족할까요?

DB 클러스터에 Aurora Replica를 추가합니다.
DB 클러스터를 수정하여 DB 클러스터를 멀티 마스터 DB 클러스터로 변환합니다.
DB 클러스터의 스냅샷을 찍습니다. 해당 스냅샷에서 더 큰 메모리 최적화 인스턴스를 가진 새 DB 클러스터를 만듭니다.
DB 클러스터의 디스크 저장 용량을 기존 디스크 용량의 두 배로 늘립니다.



## 질문: 190
한 회사에는 eu-west-2 지역의 Elastic Load Balancer 뒤에 있는 일련의 Amazon EC2 인스턴스에서 실행되는 간단한 웹 애플리케이션이 있습니다. Amazon Route 53은 간단한 라우팅 정책으로 애플리케이션에 대한 DNS 레코드를 보관합니다. 전 세계의 사용자가 웹 브라우저를 통해 애플리케이션에 액세스합니다.

이 회사는 us-east-1 지역과 ap-south-1 지역에 애플리케이션의 추가 사본을 만들어야 합니다. 이 회사는 사용자가 애플리케이션을 로드할 때 가장 빠른 응답 시간을 제공하는 지역으로 사용자를 안내해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

각각의 새로운 지역에서 새로운 Elastic Load Balancer와 새로운 EC2 인스턴스 세트를 만들어 애플리케이션 사본을 실행합니다. 지리적 위치 라우팅 정책으로 전환합니다.
각 새 지역에서 새 EC2 인스턴스에 애플리케이션 사본을 만듭니다. 이 새 EC2 인스턴스를 eu-west-2의 Elastic Load Balancer에 추가합니다. 대기 시간 라우팅 정책으로 전환합니다.
각 새 지역에서 새 EC2 인스턴스에 애플리케이션 사본을 만듭니다. 이 새 EC2 인스턴스를 eu-west-2의 Elastic Load Balancer에 추가합니다. 다중값 라우팅 정책으로 전환합니다.
각각의 새로운 지역에서 새로운 Elastic Load Balancer와 새로운 EC2 인스턴스 세트를 만들어 애플리케이션 사본을 실행합니다. 대기 시간 라우팅 정책으로 전환합니다.



## 질문: 191
회사가 AWS Organizations를 사용하여 새 멤버 계정을 만듭니다. SysOps 관리자는 새 계정에 AWS Business Support를 추가해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

IAM 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다.
루트 사용자 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다.
AWS Support API를 사용하여 지원 플랜을 변경하세요.
루트 사용자 계정의 비밀번호를 재설정합니다.
새 계정에서 관리자 권한이 있는 IAM 사용자를 만듭니다.



## 질문: 192
SysOps 관리자가 회사의 AWS 계정에 두 개의 VPC(VPC1 및 VPC2)를 만듭니다. SysOps 관리자가 VPC1에 Linux Amazon EC2 인스턴스를 배포하고 VPC2에 Amazon RDS for MySQL DB 인스턴스를 배포합니다. DB 인스턴스는 프라이빗 서브넷에 배포됩니다. EC2 인스턴스에서 실행되는 애플리케이션은 데이터베이스에 연결해야 합니다.

SysOps 관리자는 EC2 인스턴스가 데이터베이스에 연결할 수 있도록 하기 위해 무엇을 해야 합니까?

DB 인스턴스 연결 문자열을 VPC1 경로 테이블에 입력합니다.
두 VPC 간에 VPC 피어링을 구성합니다.
두 VPC에 동일한 IPv4 CIDR 범위를 추가합니다.
DB 인스턴스의 공용 IP 주소를 사용하여 DB 인스턴스에 연결합니다.



## 질문: 193
한 회사가 Amazon S3 버킷을 사용하여 데이터 파일을 저장합니다. S3 버킷에는 수백 개의 객체가 들어 있습니다. 이 회사는 S3 버킷의 모든 객체에 있는 태그를 다른 태그로 교체해야 합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

S3 배치 작업을 사용합니다. 모든 객체 태그를 대체할 작업을 지정합니다.
AWS CLI를 사용하여 각 객체의 태그를 가져옵니다. 태그를 목록에 저장합니다. S3 Batch Operations를 사용합니다. 모든 객체 태그를 삭제하는 작업을 지정합니다. AWS CLI와 목록을 사용하여 객체에 태그를 다시 지정합니다.
AWS CLI를 사용하여 각 객체의 태그를 가져옵니다. 태그를 목록에 저장합니다. AWS CLI와 목록을 사용하여 객체 태그를 제거합니다. AWS CLI와 목록을 사용하여 객체에 태그를 다시 지정합니다.
AWS CLI를 사용하여 객체를 다른 S3 버킷으로 복사합니다. 복사된 객체에 새 태그를 추가합니다. 원래 객체를 삭제합니다.




## 질문: 194
회사에서 여러 Amazon EC2 인스턴스에서 실행 중인 애플리케이션의 인벤토리를 작성해야 합니다. 회사에서는 AWS Systems Manager에 대한 적절한 권한이 있는 사용자와 역할을 구성했습니다. Systems Manager Agent의 업데이트된 버전이 설치되어 모든 인스턴스에서 실행 중입니다. 인벤토리 컬렉션을 구성하는 동안 SysOps 관리자는 단일 서브넷의 모든 인스턴스가 Systems Manager에서 관리되지 않는다는 사실을 발견했습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

모든 EC2 인스턴스에 Systems Manager 액세스에 대한 올바른 태그가 있는지 확인하세요.
AWS Identity and Access Management Access Analyzer를 구성하여 문제를 파악하고 자동으로 해결합니다.
모든 EC2 인스턴스에 Systems Manager 액세스 권한이 있는 인스턴스 프로필이 있는지 확인하세요.
Systems Manager를 구성하여 인터페이스 VPC 엔드포인트를 사용합니다.



## 질문: 195
한 회사가 Amazon S3 버킷에 민감한 데이터를 저장합니다. 회사는 S3 버킷에 대한 모든 액세스 시도를 기록해야 합니다. 회사의 위험 팀은 모든 삭제 이벤트에 대한 즉각적인 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

감사 로그에 대한 S3 서버 액세스 로깅을 활성화합니다. S3 버킷에 대한 Amazon Simple Notification Service(Amazon SNS) 알림을 설정합니다. 알림 시스템의 이벤트 유형에 대해 DeleteObject를 선택합니다.
감사 로그에 대한 S3 서버 액세스 로깅을 활성화합니다. 알림 시스템에 대한 Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스에서 cron 작업을 실행하여 매일 액세스 로그를 다운로드하고 DeleteObject 이벤트를 스캔합니다.
감사 로그에는 Amazon CloudWatch Logs를 사용합니다. 알림 시스템에는 Amazon Simple Notification Service(Amazon SNS) 알림과 함께 Amazon CloudWatch 알람을 사용합니다.
감사 로그에는 Amazon CloudWatch Logs를 사용합니다. 알림 시스템에 Amazon EC2 인스턴스를 시작합니다. 매일 EC2 인스턴스에서 cron 작업을 실행하여 항목 목록을 전날 목록과 비교합니다. 항목이 누락된 경우 알림을 보내도록 cron 작업을 구성합니다.




## 질문: 196
SysOps 관리자가 Amazon GuardDuty로부터 Amazon EC2 인스턴스에서 의심스러운 네트워크 활동에 대한 알림을 받습니다. GuardDuty 발견 사항은 트래픽 대상으로 새 외부 IP 주소를 나열합니다. SysOps 관리자는 외부 IP 주소를 인식하지 못합니다. SysOps 관리자는 GuardDuty가 식별한 외부 IP 주소로의 트래픽을 차단해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

외부 IP 주소로의 트래픽을 차단하기 위해 새 보안 그룹을 만듭니다. 새 보안 그룹을 EC2 인스턴스에 할당합니다.
Amazon Athena에서 VPC 흐름 로그를 사용하여 외부 IP 주소로의 트래픽을 차단합니다.
네트워크 ACL을 만듭니다. 외부 IP 주소로의 트래픽에 대한 아웃바운드 거부 규칙을 추가합니다.
외부 IP 주소로의 트래픽을 차단하기 위해 새 보안 그룹을 만듭니다. 새 보안 그룹을 전체 VPC에 할당합니다.
 




## 질문: 197
15분이 걸리던 회사의 보고 작업이 이제 1시간이 걸립니다. 애플리케이션이 보고서를 생성합니다. 이 애플리케이션은 Amazon EC2 인스턴스에서 실행되고 Amazon RDS for MySQL 데이터베이스에서 데이터를 추출합니다.

SysOps 관리자가 RDS 인스턴스의 Amazon CloudWatch 대시보드를 확인하고 보고서가 실행되지 않을 때에도 Read IOPS 메트릭이 높다는 것을 알아챘습니다. SysOps 관리자는 RDS 인스턴스의 성능과 가용성을 개선해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

RDS 인스턴스 앞에 Amazon ElastiCache 클러스터를 구성합니다. ElastiCache 클러스터를 쿼리하도록 보고 작업을 업데이트합니다.
RDS 읽기 복제본을 배포합니다. 보고 작업을 업데이트하여 리더 엔드포인트를 쿼리합니다.
Amazon CloudFront 배포를 만듭니다. RDS 인스턴스를 원본으로 설정합니다. CloudFront 배포를 쿼리하도록 보고 작업을 업데이트합니다.
RDS 인스턴스의 크기를 늘립니다.
 




## 질문: 198
회사의 SysOps 관리자는 회사의 각 계정에서 AWS Personal Health Dashboard를 정기적으로 확인합니다. 계정은 AWS Organizations의 조직에 속합니다. 회사는 최근 조직에 10개의 계정을 추가했습니다. SysOps 관리자는 각 계정의 Personal Health Dashboard에서 알림을 통합해야 합니다.

어떤 솔루션이 최소한의 노력으로 이 요구 사항을 충족할까요?

AWS Health에서 조직 보기를 활성화합니다.
각 계정의 개인 건강 대시보드를 구성하여 이벤트를 중앙 AWS CloudTrail 로그로 전달합니다.
AWS Health API를 쿼리하고 모든 이벤트를 Amazon DynamoDB 테이블에 기록하는 AWS Lambda 함수를 생성합니다.
AWS Health API를 사용하여 Amazon DynamoDB 테이블에 이벤트를 기록합니다.



## 질문: 199
한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. EC2 인스턴스는 자동 확장 그룹에 있으며 애플리케이션 로드 밸런서(ALB) 뒤에서 실행됩니다. 총 요청이 초당 100건을 초과하면 애플리케이션에 오류가 발생합니다. SysOps 관리자는 요청이 이 임계값을 초과한 시점을 확인하기 위해 2주 기간 동안의 총 요청에 대한 정보를 수집해야 합니다.

SysOps 관리자는 이 데이터를 수집하기 위해 무엇을 해야 합니까?

ALB의 RequestCount 메트릭을 사용합니다. 2주와 1분의 기간을 구성합니다. 차트를 검토하여 최대 트래픽 시간과 볼륨을 확인합니다.
Amazon CloudWatch 메트릭 수학을 사용하여 2주 기간 동안 모든 EC2 인스턴스에 대한 요청 수의 합계를 생성합니다. 1분 간격으로 정렬합니다.
EC2 시작 구성 템플릿에서 Amazon CloudWatch 사용자 지정 메트릭을 만들어 모든 EC2 인스턴스에서 집계된 요청 메트릭을 생성합니다.
Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. EC2 요청을 기반으로 하는 메트릭을 만드는 EC2 이벤트 매칭 패턴을 구성합니다. 그래프에 데이터를 표시합니다.
 




## 질문: 200
한 회사가 최근 AWS의 VPC로 애플리케이션을 마이그레이션했습니다. AWS Site-to-Site VPN 연결은 회사의 온프레미스 네트워크를 VPC에 연결합니다. 애플리케이션은 온프레미스에 있는 다른 시스템에서 고객 데이터를 검색합니다. 애플리케이션은 온프레미스 DNS 서버를 사용하여 도메인 레코드를 확인합니다. 마이그레이션 후 애플리케이션은 이름 확인 오류로 인해 고객 데이터에 연결할 수 없습니다.

어떤 솔루션이 애플리케이션에 내부 도메인 이름을 확인할 수 있는 기능을 제공할까요?

VPC에서 EC2 인스턴스를 시작합니다. EC2 인스턴스에서 모든 DNS 요청을 온프레미스 DNS 서버로 전달하는 사용자 지정 DNS 포워더를 배포합니다. 이름 서버에 EC2 인스턴스를 사용하는 Amazon Route 53 프라이빗 호스팅 영역을 만듭니다.
Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 온프레미스 도메인에 대한 DNS 쿼리를 온프레미스 DNS 서버로 전달하도록 아웃바운드 엔드포인트를 구성합니다.
AWS 환경과 온프레미스 네트워크 간에 두 개의 AWS Direct Connect 연결을 설정합니다. 두 연결을 포함하는 링크 집계 그룹(LAG)을 설정합니다. 온프레미스 DNS 서버를 가리키도록 VPC 리졸버 주소를 변경합니다.
온프레미스 도메인에 대한 Amazon Route 53 퍼블릭 호스팅 존을 만듭니다. 온프레미스 도메인에 대한 DNS 요청을 Route 53 퍼블릭 호스팅 존으로 전달하도록 네트워크 ACL을 구성합니다.



## 질문: 201
회사의 웹 애플리케이션은 Amazon CloudFront 배포를 통해 사용할 수 있으며 인터넷 연결 Application Load Balancer(ALB)를 통해 직접 사용할 수 있습니다. SysOps 관리자는 CloudFront 배포를 통해서만 애플리케이션에 액세스할 수 있도록 해야 하며 ALB를 통해 직접 액세스할 수 있도록 해서는 안 됩니다. SysOps 관리자는 애플리케이션 코드를 변경하지 않고 이 변경을 해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

ALB 유형을 내부로 수정합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다.
Lambda@Edge 함수를 만듭니다. 요청의 사용자 지정 헤더 값을 저장된 비밀번호와 비교하고 일치하는 경우 요청을 원본으로 전달하도록 함수를 구성합니다. 함수를 배포와 연결합니다.
ALB를 새 내부 ALB로 교체합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다. 배포의 원점 설정에 사용자 지정 HTTP 헤더를 추가합니다. ALB 리스너에서 일치하는 사용자 지정 헤더와 헤더의 값을 포함하는 요청을 전달하는 규칙을 추가합니다. 고정된 응답 코드 403을 반환하는 기본 규칙을 추가합니다.
배포를 위한 원본 설정에 사용자 지정 HTTP 헤더를 추가합니다. ALB 리스너에서 일치하는 사용자 지정 헤더와 헤더의 값을 포함하는 요청을 전달하는 규칙을 추가합니다. 고정된 응답 코드 403을 반환하는 기본 규칙을 추가합니다.



## 질문: 202
한 회사가 AWS에서 여러 워크로드를 실행합니다. 이 회사는 특정 AWS 지역에서 모니터링할 5개의 AWS Trusted Advisor 서비스 할당량 지표를 식별합니다. 이 회사는 리소스 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 받고 싶어합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.
AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 지표를 모니터링합니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.
AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 메트릭을 모니터링합니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
 




## 질문: 203
회사에서 온프레미스 사용자를 위한 Windows 파일 공유를 호스팅하기 위해 관리형 파일 시스템을 구현해야 합니다. AWS 클라우드의 리소스도 이러한 파일 공유의 데이터에 액세스할 수 있어야 합니다. SysOps 관리자는 온프레미스에서 사용자 파일 공유를 제공하고 최소 지연 시간으로 사용자 파일 공유를 AWS에서 사용할 수 있도록 해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

Amazon S3 파일 게이트웨이를 설정합니다.
AWS Direct Connect 연결을 설정합니다.
AWS DataSync를 사용하여 기존 파일 서버와 AWS 간의 데이터 전송을 자동화합니다.
Amazon FSx 파일 게이트웨이를 설정합니다.



## 질문: 204
한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 이 회사는 Amazon RDS for PostgreSQL DB 인스턴스에서 데이터베이스를 호스팅하고 있습니다. 이 회사는 DB 인스턴스에 대한 모든 연결을 암호화하도록 요구합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자는 무엇을 해야 합니까?

인바운드 보안 그룹 규칙을 사용하여 데이터베이스에 대한 SSL 연결을 허용합니다.
AWS Key Management Service(AWS KMS) 암호화 키를 사용하여 데이터베이스를 암호화합니다.
사용자 정의 매개변수 그룹을 사용하여 데이터베이스에 대한 SSL 연결을 적용합니다.
사용자 정의 PostgreSQL 확장 기능을 사용하여 데이터베이스에 SSL/TLS 패치를 적용합니다.




## 질문: 205
한 회사가 최근에 Savings Plans를 구매했습니다. 이 회사는 회사의 활용도가 특정 날짜에 90% 미만으로 떨어지면 이메일 알림을 받고 싶어합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

AWS Trusted Advisor에서 Savings Plan 체크를 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 특정 날짜에 사용률이 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.
CloudWatch의 AWS/SavingsPlans 네임스페이스에서 SavingsPlansUtilization 메트릭을 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 특정 날짜에 사용률이 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.
Savings Plans 알림을 만들어 Savings Plans의 일일 사용률을 모니터링합니다. 사용률이 주어진 날의 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
AWS Budgets를 사용하여 Savings Plans 예산을 생성하여 Savings Plans의 일일 사용률을 추적합니다. 사용률이 주어진 날의 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
 




## 질문: 206
한 회사가 애플리케이션에서 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 사용합니다. 애플리케이션은 고유한 메시지 본문이 있는 메시지를 대기열로 보냅니다. 회사는 SQS FIFO 대기열로 전환하기로 결정했습니다.

회사는 SQS FIFO 대기열로 마이그레이션하기 위해 무엇을 해야 합니까?

새 SQS FIFO 대기열을 만듭니다. 새 FIFO 대기열에서 콘텐츠 기반 중복 제거를 켭니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다.
새 SQS FIFO 대기열을 만듭니다. DelaySeconds 매개변수를 메시지에 포함하도록 애플리케이션을 업데이트합니다.
대기열 유형을 SQS 표준에서 SQS FIFO로 수정합니다. 대기열에서 콘텐츠 기반 중복 제거를 끕니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다.
SQS 표준에서 SQS FIFO로 큐 유형을 수정합니다. 동일한 메시지 본문으로 메시지를 보내고 메시지에 DelaySeconds 매개변수를 포함하도록 애플리케이션을 업데이트합니다.



## 질문: 207
회사의 SysOps 관리자는 AWS 계정에서 시작된 모든 Amazon EC2 Windows 인스턴스에 타사 에이전트가 설치되어 있는지 확인해야 합니다. 타사 에이전트에는 .msi 패키지가 있습니다. 회사는 패치를 위해 AWS Systems Manager를 사용하고 Windows 인스턴스에 적절한 태그가 지정됩니다. 타사 에이전트는 새 버전이 출시됨에 따라 주기적 업데이트가 필요합니다. SysOps 관리자는 이러한 업데이트를 자동으로 배포해야 합니다.

어떤 단계 조합이 최소한의 운영 노력으로 이러한 요구 사항을 충족할 수 있을까요? (두 가지를 선택하세요.)

타사 에이전트에 대한 Systems Manager Distributor 패키지를 만듭니다.
Systems Manager Inventory가 구성되어 있는지 확인하세요. Systems Manager Inventory가 구성되어 있지 않으면 Windows에 적합한 태그 값을 기반으로 인스턴스에 대한 새 인벤토리를 설정하세요.
AWS-RunRemoteScript 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.
AWS-ConfigureAWSPackage 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.
Windows에 대한 태그 값으로 Systems Manager OpsItem을 만듭니다. Systems Manager Distributor 패키지를 OpsItem에 연결합니다. 패키지 배포에 특정한 유지 관리 기간을 만듭니다. 유지 관리 기간을 하루 24시간으로 구성합니다.



## 질문: 208
한 회사가 단일 AWS 리전에서 수백 개의 Amazon EC2 인스턴스를 실행합니다. 각 EC2 인스턴스에는 연결된 1GiB General Purpose SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨이 두 개 있습니다. 중요한 워크로드는 EBS 볼륨에서 사용 가능한 모든 IOPS 용량을 사용하는 것입니다.

회사 정책에 따라 회사는 회사의 애플리케이션이 제대로 작동하는지 확인하기 위한 긴 수락 테스트를 완료하지 않고는 인스턴스 유형이나 EBS 볼륨 유형을 변경할 수 없습니다. SysOps 관리자는 가능한 한 빨리 EBS 볼륨의 I/O 성능을 높여야 합니다. SysOps

관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1GiB EBS 볼륨의 크기를 늘립니다.
각 EC2 인스턴스에 두 개의 추가 탄력적 네트워크 인터페이스를 추가합니다.
해당 지역의 EBS 볼륨에서 전송 가속을 켭니다.
모든 EC2 인스턴스를 클러스터 배치 그룹에 추가합니다.




## 질문: 209
회사에서 AWS에 새로운 워크로드를 배포해야 합니다. 회사는 모든 저장 데이터를 암호화하고 매년 한 번씩 암호화 키를 순환해야 합니다. 워크로드는 데이터 저장을 위해 Amazon RDS for MySQL Multi-AZ 데이터베이스를 사용합니다.

어떤 구성 방식이 이러한 요구 사항을 충족할까요?

MySQL 구성 파일에서 Transparent Data Encryption(TDE)을 활성화합니다. 12개월마다 수동으로 키를 회전합니다.
Amazon RDS에 대한 AWS 관리 키를 사용하여 데이터베이스 생성 시 RDS 암호화를 활성화합니다.
새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. KMS 키를 사용하여 생성 시 데이터베이스에서 RDS 암호화를 활성화합니다.
새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. RDS DB 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에서 암호화를 활성화합니다.



## 질문: 210
한 회사에 액티브-패시브 구성으로 두 개의 AWS 리전에 배포된 애플리케이션이 있습니다. 이 애플리케이션은 각 리전의 애플리케이션 로드 밸런서(ALB) 뒤에 있는 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 각 리전의 Amazon EC2 자동 확장 그룹에 있습니다. 이 애플리케이션은 DNS에 Amazon Route 53 호스팅 영역을 사용합니다. SysOps 관리자는 보조 리전으로 자동 장애 조치를 구성해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

각 ALB를 가리키는 Route 53 별칭 레코드를 구성합니다. 장애 조치 라우팅 정책을 선택합니다. Evaluate Target Health를 Yes로 설정합니다.
각 AL을 가리키는 CNAME 레코드 구성 장애 조치 라우팅 정책 선택. 대상 상태 평가를 예로 설정.
Auto Scaling 그룹에 대한 Elastic Load Balancing(ELB) 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.
자동 확장 그룹에 대한 EC2 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.



## 질문: 211
한 회사가 머신 러닝을 기반으로 하는 모니터링 솔루션을 구현하고 있습니다. 모니터링 솔루션은 Amazon EC2 Auto Scaling에서 생성된 Amazon EventBridge(Amazon CloudWatch Events) 이벤트를 사용합니다. 모니터링 솔루션은 예상치 못한 확장 이벤트와 같은 비정상적인 동작을 감지하며 EventBridge(CloudWatch Events) API 대상으로 구성됩니다.

초기 테스트 중에 회사는 모니터링 솔루션이 이벤트를 수신하지 않는다는 것을 알게 됩니다. 그러나 Amazon CloudWatch는 EventBridge(CloudWatch Events) 규칙이 호출되고 있음을 보여줍니다. SysOps 관리자는 이 문제를 해결하기 위해 클라이언트 오류 세부 정보를 검색하는 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 노력으로 이러한 요구 사항을 충족할까요?

이벤트 패턴에 대한 EventBridge(CloudWatch Events) 아카이브를 만들어 이벤트를 재생합니다. 모니터링 솔루션에서 로깅을 늘립니다. replay를 사용하여 모니터링 솔루션을 호출합니다. 오류 세부 정보를 검토합니다.
대상의 배달 못한 편지 대기열로 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 추가합니다. 배달 못한 편지 대기열의 메시지를 처리하여 오류 세부 정보를 검색합니다.
AWS Lambda 함수를 대상으로 동일한 이벤트 패턴에 대한 두 번째 EventBridge(CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 모니터링 솔루션을 호출하고 Amazon CloudWatch Logs에 결과를 기록합니다. 로그에서 오류를 검사합니다.
Amazon Simple Notification Service(Amazon SNS) 주제에 오류 메시지를 보내도록 EventBridge(CloudWatch Events) 규칙을 구성합니다.
 




## 질문: 212
한 회사가 Amazon S3 버킷에 백업을 저장하고 있습니다. 백업은 백업이 생성된 후 최소 3개월 동안 삭제되어서는 안 됩니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

모든 사용자에 대해 s3:DeleteObject 작업을 거부하는 IAM 정책을 구성합니다. 객체가 작성된 후 3개월이 지나면 정책을 제거합니다.
규정 준수 모드에서 새 S3 버킷에 S3 개체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관 기간 3개월로 저장합니다.
기존 S3 버킷에서 S3 버전 관리를 활성화합니다. 백업을 보호하기 위해 S3 라이프사이클 규칙을 구성합니다.
거버넌스 모드에서 새 S3 버킷에 S3 객체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관하고 보관 기간은 3개월입니다.
 




## 질문: 213
SysOps 관리자는 AWS 리전 간 데이터 전송 비용을 추적해야 합니다. SysOps 관리자는 전송 비용이 특정 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내는 솔루션을 구현해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

AWS 비용 및 사용 보고서를 만듭니다. Amazon Athena에서 결과를 분석합니다. 비용이 임계값의 75%에 도달하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.
비용이 임계값의 75%에 도달하면 감지하도록 Amazon CloudWatch 청구 알람을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.
AWS Budgets를 사용하여 데이터 전송 비용에 대한 비용 예산을 만듭니다. 예산 금액의 75%에 알림을 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 예산을 구성합니다.
VPC 흐름 로그를 설정합니다. 데이터 전송을 분석하기 위해 AWS Lambda 함수에 구독 필터를 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 Lambda 함수를 구성합니다.



## 질문: 214
회사는 모든 감사 로그를 10년 동안 보관해야 합니다. 회사는 로그를 향후 편집으로부터 보호해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. AWS Key Management Service(AWS KMS) 암호화를 구성합니다.
Amazon S3 Glacier 볼트에 데이터를 저장합니다. WORM(write-once, read-many) 액세스에 대한 볼트 잠금 정책을 구성합니다.
Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 서버 측 암호화를 구성합니다.
Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 다중 요소 인증(MFA)을 구성합니다.
 




## 질문: 215
회사의 AWS Lambda 함수에서 성능 문제가 발생하고 있습니다. Lambda 함수는 많은 CPU 집약적 작업을 수행합니다. Lambda 함수가 충분히 빠르게 실행되지 않아 시스템에 병목 현상이 발생합니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

Lambda 함수의 CPU 시작 옵션에서 하이퍼스레딩을 활성화합니다.
AWS 관리 암호화를 끕니다.
Lambda 함수의 메모리 양을 늘립니다.
필요한 코드를 사용자 정의 레이어에 로드합니다.



## 질문: 216
한 회사가 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 웹 서버 로그는 Amazon CloudWatch Logs에 게시됩니다. 로그 이벤트는 동일한 구조를 가지고 있으며 사용자 요청과 관련된 HTTP 응답 코드를 포함합니다. 이 회사는 웹 서버가 HTTP 404 응답을 반환하는 횟수를 모니터링해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 메트릭 필터를 만듭니다.
웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 구독 필터를 만듭니다.
지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 AWS Lambda 함수를 만듭니다.
지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 스크립트를 만듭니다.
 




## 질문: 217
한 회사가 AWS 클라우드에서 비용을 관리하려고 합니다. SysOps 관리자는 청구 보고서에 표시될 리소스에 할당된 특정 회사 정의 태그가 필요합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

AWS에서 생성한 비용 할당 태그로 태그를 활성화합니다.
태그를 사용자 정의 비용 배분 태그로 활성화합니다.
새로운 비용 범주를 만듭니다. 계정 청구 차원을 선택합니다.
새로운 AWS 비용 및 사용 보고서를 만듭니다. 리소스 ID를 포함합니다.



## 질문: 218
한 회사가 전 세계적으로 확장 중이며 Amazon Elastic Block Store(Amazon EBS) 볼륨의 데이터를 다른 AWS 리전으로 백업해야 합니다. 데이터를 저장하는 대부분의 EBS 볼륨은 암호화되어 있지만 일부 EBS 볼륨은 암호화되지 않았습니다. 이 회사는 모든 EBS 볼륨의 백업 데이터를 암호화해야 합니다.

어떤 솔루션이 가장 적은 관리 오버헤드로 이러한 요구 사항을 충족할까요?

Amazon Data Lifecycle Manager(Amazon DLM)에서 수명 주기 정책을 구성하여 크로스 리전 백업이 활성화된 EBS 볼륨 스냅샷을 만듭니다. AWS Key Management Service(AWS KMS)를 사용하여 스냅샷 사본을 암호화합니다.
EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷 상태가 COMPLETED이면 스냅샷을 다른 Region으로 복사하고 Encrypted 매개변수를 False로 설정합니다.
EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷을 서버 측 암호화를 사용하는 Amazon S3 버킷에 복사합니다. S3 버킷에서 S3 Cross-Region Replication을 켭니다.
Python 런타임으로 AWS Lambda 함수를 예약합니다. Lambda 함수를 구성하여 EBS 볼륨 스냅샷을 만들고, 암호화되지 않은 스냅샷을 암호화하고, 스냅샷을 다른 리전으로 복사합니다.



## 질문: 219
SysOps 관리자가 AWS Fargate를 사용하는 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터를 만듭니다. 클러스터가 성공적으로 배포되었습니다. SysOps 관리자는 kubectl 명령줄 도구를 사용하여 클러스터를 관리해야 합니다.

kubectl이 클러스터 API 서버와 통신할 수 있도록 SysOps 관리자의 머신에서 다음 중 어떤 것을 구성해야 합니까?

kubeconfig 파일
kube-proxy Amazon EKS 추가 기능
Fargate 프로필
eks-connector.yaml 파일




## 질문: 220
한 회사가 분석에 사용할 애플리케이션에서 데이터를 수집하려고 합니다. 처음 90일 동안은 데이터에 자주 액세스하지 않지만 가용성은 높게 유지해야 합니다. 이 기간 동안 회사의 분석 팀은 밀리초 단위로 데이터에 액세스해야 합니다. 그러나 90일 후에는 회사에서 더 낮은 비용으로 장기간 데이터를 보관해야 합니다. 90일 후 검색 시간은 5시간 미만이어야 합니다.

이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

처음 90일 동안 S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 90일 후 S3 Glacier Flexible Retrieval로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
처음 90일 동안 S3 One Zone-Infrequent Access(S3 One Zone-IA)에 데이터를 저장합니다. 90일 후에 S3 Glacier Deep Archive로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
처음 90일 동안 S3 Standard에 데이터를 저장합니다. 90일 후 S3 Glacier Flexible Retrieval로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
처음 90일 동안 S3 Standard에 데이터를 저장합니다. 90일 후 S3 Glacier Deep Archive로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.



## 질문: 221
회사의 애플리케이션은 현재 모든 AWS 서비스에 대한 모든 액세스를 허용하는 IAM 역할을 사용합니다. SysOps 관리자는 회사의 IAM 정책이 애플리케이션에 필요한 권한만 허용하는지 확인해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하는 정책을 어떻게 만들 수 있습니까?

AWS CloudTrail을 켭니다. AWS Security Hub를 사용하여 정책을 생성합니다.
Amazon EventBridge(Amazon CloudWatch Events)를 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.
AWS CLI를 사용하여 AWS Identity and Access Management Access Analyzer에서 get-generated-policy 명령을 실행합니다.
AWS CloudTrail을 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.
 




## 질문: 222
한 회사에서 Amazon EC2 Amazon Machine Image(AMI)로 제공되는 타사 단위 테스트 솔루션을 배포하고 있습니다. 모든 시스템 구성 데이터는 Amazon DynamoDB에 저장됩니다. 테스트 결과는 Amazon S3에 저장됩니다.

제품을 작동하려면 최소 3개의 EC2 인스턴스가 필요합니다. 회사의 테스트 팀은 Spot Instance 가격이 특정 임계값에 도달하면 추가로 3개의 EC2 인스턴스를 사용하려고 합니다. SysOps 관리자는 이 기능을 제공하는 고가용성 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요?

시작 구성을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 구성에서 제공된 AMI를 사용합니다. 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성합니다. 시작 구성에서 최대 스팟 인스턴스 가격을 구성합니다.
시작 템플릿을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 템플릿에서 제공된 AMI를 사용합니다. 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성합니다. 시작 템플릿에서 최대 스팟 인스턴스 가격을 구성합니다.
시작 구성을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 구성에서 제공된 AMI를 사용합니다. 한 자동 확장 그룹에 대해 세 개의 온디맨드 인스턴스를 구성합니다. 다른 자동 확장 그룹에 대해 세 개의 스팟 인스턴스를 구성합니다. 스팟 인스턴스가 있는 자동 확장 그룹에 대해 시작 구성에서 최대 스팟 인스턴스 가격을 구성합니다.
시작 템플릿을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 템플릿에서 제공하는 AMI를 사용합니다. 한 자동 확장 그룹에 대해 세 개의 온디맨드 인스턴스를 구성합니다. 다른 자동 확장 그룹에 대해 세 개의 스팟 인스턴스를 구성합니다. 스팟 인스턴스가 있는 자동 확장 그룹에 대해 시작 템플릿에서 최대 스팟 인스턴스 가격을 구성합니다.




## 질문: 223
SysOps 관리자는 여러 AWS 리전에 배포할 수 있는 애플리케이션 스택을 정의하기 위해 AWS CloudFormation 템플릿을 만듭니다. SysOps 관리자는 또한 AWS Management Console을 사용하여 Amazon CloudWatch 대시보드를 만듭니다. 애플리케이션의 각 배포에는 고유한 CloudWatch 대시보드가 ​​필요합니다.

SysOps 관리자는 애플리케이션이 배포될 때마다 CloudWatch 대시보드 생성을 어떻게 자동화할 수 있습니까?

AWS CLI를 사용하여 대시보드 이름으로 aws cloudformation put-dashboard 명령을 실행하기 위해 스크립트를 만듭니다. 새 CloudFormation 스택이 생성될 때마다 명령을 실행합니다.
기존 CloudWatch 대시보드를 JSON으로 내보냅니다. CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. 내보낸 JSON을 리소스의 DashboardBody 속성에 포함합니다.
CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. Intrinsic Ref 함수를 사용하여 기존 CloudWatch 대시보드의 ID를 참조합니다.
CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. DashboardName 속성에 기존 대시보드의 이름을 지정합니다.



## 질문: 224
한 회사가 규제된 워크로드에 대한 클라우드 호스팅 준비를 명확히 하기 위해 보안 정책을 업데이트했습니다. 민감한 것으로 식별된 워크로드는 회사 내의 다른 고객이나 다른 AWS 계정과 공유되지 않는 하드웨어에서 실행되어야 합니다.

어떤 솔루션이 이 정책을 준수하도록 보장할까요?

전용 호스트에만 워크로드를 배포합니다.
전용 인스턴스에만 워크로드를 배포합니다.
예약 인스턴스에만 워크로드를 배포합니다.
모든 인스턴스를 전용 배치 그룹에 배치합니다.



## 질문: 225
한 회사가 호주 시드니에서 웹사이트를 운영합니다. 미국과 유럽의 사용자들은 이미지와 비디오가 로드되는 데 시간이 오래 걸린다고 보고하고 있습니다. 그러나 호주에서 실시한 로컬 테스트에서는 성능 문제가 나타나지 않았습니다. 웹사이트에는 Amazon S3에 저장된 이미지와 비디오 형태의 정적 콘텐츠가 대량으로 있습니다.

미국과 유럽 사용자의 사용자 경험을 가장 크게 개선할 수 있는 솔루션은 무엇일까요?

Amazon S3에 대한 AWS PrivateLink를 구성합니다.
S3 전송 가속을 구성합니다.
Amazon CloudFront 배포를 만듭니다. 정적 콘텐츠를 CloudFront 엣지 위치에 배포합니다.
각 AWS 리전에서 Amazon API Gateway API를 만듭니다. 로컬에서 콘텐츠를 캐시합니다.



## 질문: 226
SysOps 관리자가 Amazon Elastic Block Store(Amazon EBS) 볼륨이 연결된 Amazon EC2 인스턴스 세트에서 사용 가능한 디스크 공간을 모니터링하려고 합니다. SysOps 관리자는 EBS 볼륨의 사용된 디스크 공간이 임계값을 초과할 때 알림을 받고 싶지만 DiskReadOps 메트릭도 임계값을 초과할 때만 알림을 받고 싶어합니다. SysOps 관리자가 Amazon Simple Notification Service(Amazon SNS) 토픽을 설정했습니다. SysOps 관리자

가 두 메트릭이 모두 임계값을 초과할 때만 알림을 받을 수 있는 방법은 무엇입니까?

EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 각 알람을 구성하여 SNS 토픽에 알림을 게시합니다.
EBSByteBalance% 메트릭에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
EC2 인스턴스에 대한 자세한 모니터링을 구성합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
 




## 질문: 227
회사가 회사 계정의 Amazon S3 버킷에 있는 모든 데이터의 공개 노출을 금지하기 위해 보안 정책을 업데이트했습니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

계정 수준에서 S3 공개 액세스 차단을 켭니다.
모든 S3 객체가 비공개로 유지되도록 Amazon Event Bridge(Amazon CloudWatch Events) 규칙을 만듭니다.
Amazon Inspector를 사용하여 S3 버킷을 검색하고 공개 S3 버킷이 발견되면 S3 ACL을 자동으로 재설정합니다.
S3 객체 람다를 사용하여 S3 ACL을 조사하고 모든 공개 S3 ACL을 비공개로 변경합니다.



## 질문: 228
회사의 SysOps 관리자가 회사의 AWS 계정 중 하나에 대한 AWS 지원 플랜을 변경해야 합니다. 계정에는 다중 요소 인증(MFA)이 활성화되어 있고 MFA 장치가 분실되었습니다.

SysOps 관리자는 로그인하기 위해 무엇을 해야 합니까?

이메일 및 전화 인증을 사용하여 루트 사용자로 로그인합니다. 새 MFA 장치를 설정합니다. 루트 사용자 비밀번호를 변경합니다.
관리자 권한이 있는 IAM 사용자로 로그인합니다. IAM 콘솔을 사용하여 MFA 토큰을 다시 동기화합니다.
관리자 권한이 있는 IAM 사용자로 로그인합니다. 새 장치를 추가하여 루트 사용자에 대한 MFA 장치를 재설정합니다.
비밀번호 분실 절차를 사용하여 이메일 주소를 확인하세요. 새 비밀번호와 MFA 장치를 설정하세요.



## 질문: 229
회사에서 새로운 다중 계정 아키텍처를 만들고 있습니다. SysOps 관리자는 모든 AWS 계정에서 사용자 액세스 및 권한을 중앙에서 관리하는 로그인 솔루션을 구현해야 합니다. 이 솔루션은 AWS Organizations와 통합되어야 하며 타사 Security Assertion Markup Language(SAML) 2.0 ID 공급자(IdP)에 연결되어야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

Amazon Cognito 사용자 풀을 구성합니다. 사용자 풀을 타사 IdP와 통합합니다.
타사 IdP로 AWS Single Sign-On을 활성화하고 구성합니다.
조직의 각 AWS 계정에 대해 타사 IdP를 AWS Identity and Access Management(IAM)와 연합합니다.
타사 IdP를 AWS Organizations와 직접 통합합니다.



## 질문: 230
한 회사가 AWS Organizations에서 단일 조직을 사용하여 여러 계정을 관리하고 있습니다. 조직은 모든 ​​기능을 활성화했습니다. 회사는 조직의 모든 계정과 모든 AWS 지역에서 AWS Config를 켜고 싶어합니다.

SysOps 관리자는 이러한 요구 사항을 가장 운영적으로 효율적인 방식으로 충족하기 위해 무엇을 해야 합니까?

AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 켜는 스택 인스턴스를 배포할 수 있습니다.
AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 활성화하는 스택 정책을 배포할 수 있습니다.
SCP(서비스 제어 정책)를 사용하여 모든 계정과 모든 지역에서 AWS Config를 구성합니다.
조직의 모든 계정에서 AWS Config를 켜기 위해 AWS CLI를 사용하는 스크립트를 만듭니다. 조직의 관리 계정에서 스크립트를 실행합니다.



## 질문: 231
SysOps 관리자가 더 이상 사용하지 않는 AWS CloudFormation 스택을 삭제해야 합니다. CloudFormation 스택이 DELETE_FAILED 상태입니다. SysOps 관리자가 CloudFormation 스택을 삭제하는 데 필요한 권한을 검증했습니다.

다음 중 DELETE_FAILED 상태의 가능한 원인은 무엇입니까? (두 가지를 선택하십시오.)

스택을 삭제하기 위해 구성된 시간 제한이 너무 짧아 삭제 작업을 완료할 수 없습니다.
스택에는 중첩된 스택이 포함되어 있으므로 이를 먼저 수동으로 삭제해야 합니다.
스택은 --disable-rollback 옵션으로 배포되었습니다.
스택의 보안 그룹과 연관된 추가 리소스가 있습니다.
스택에 객체가 여전히 들어 있는 Amazon S3 버킷이 있습니다.
 




## 질문: 232
SysOps 관리자는 Amazon CloudFront를 통해 승인된 사용자 집합에 디지털 콘텐츠를 제공하는 솔루션을 구성해야 합니다. 승인되지 않은 사용자는 액세스가 제한되어야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. 서명된 URL을 사용하여 CloudFront를 통해 S3 버킷에 액세스합니다.
퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(원본 액세스 ID)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. CloudFront에서 서명된 URL로 S3 버킷 액세스를 제한합니다.
퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(Origin Access Identity)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. 필드 수준 암호화를 활성화합니다.
디지털 콘텐츠를 퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 저장합니다. CloudFront를 통한 콘텐츠의 제한된 전달을 위해 서명된 쿠키를 사용합니다.



## 질문: 233
SysOps 관리자는 회사의 Amazon EC2 인스턴스가 예상대로 자동 확장되도록 해야 합니다. SysOps 관리자는 Amazon EC2 자동 확장 수명 주기 후크를 구성하여 Amazon EventBridge(Amazon CloudWatch Events)로 이벤트를 전송한 다음 AWS Lambda 함수를 호출하여 EC2 인스턴스를 구성합니다. 구성이 완료되면 Lambda 함수가 complete-lifecycle-action 이벤트를 호출하여 EC2 인스턴스를 서비스에 넣습니다. 테스트에서 SysOps 관리자는 EC2 인스턴스가 자동 확장될 때 Lambda 함수가 호출되지 않는다는 것을 발견했습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 합니다.
라이프사이클 후크에 오류나 시간 초과가 발생하는 경우 라이프사이클 후크 작업을 CONTINUE로 변경합니다.
EventBridge(CloudWatch Events) 규칙에서 재시도 정책을 구성하여 실패 시 Lambda 함수 호출을 다시 시도합니다.
Lambda 함수 실행 역할을 업데이트하여 complete-lifecycle-action 이벤트를 호출할 수 있는 권한을 부여합니다.
 




## 질문: 234
한 회사에서는 모든 IAM 사용자에게 다중 인증(MFA)을 사용하도록 의무화했으며, 사용자는 CLI를 사용하여 모든 API 호출을 해야 합니다. 그러나 사용자는 MFA 토큰을 입력하라는 메시지를 받지 않으며, MFA 없이도 CLI 명령을 실행할 수 있습니다. 이 회사는 MFA를 시행하기 위해 MFA로 인증되지 않은 API 호출을 거부하는 IAM 정책을 모든 사용자에게 첨부했습니다.

API 호출이 MFA를 사용하여 인증되도록 하려면 어떤 추가 단계를 거쳐야 합니까?

IAM 역할에서 MFA를 활성화하고 IAM 사용자에게 역할 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.
CLI를 사용하여 API 호출을 하기 전에 IAM 사용자에게 MFA를 사용하여 AWS 관리 콘솔에 로그인하도록 요청합니다.
MFA는 CLI 사용에 지원되지 않으므로 IAM 사용자는 콘솔 사용으로 제한합니다.
사용자에게 get-session token 명령에서 임시 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.




## 질문: 235
SysOps 관리자가 모든 회사 Amazon S3 버킷에 대한 퍼블릭 액세스를 차단했습니다. SysOps 관리자는 S3 버킷이 미래에 공개적으로 읽을 수 있게 되면 알림을 받고 싶어합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

각 S3 버킷의 퍼블릭 액세스 설정을 주기적으로 확인하는 AWS Lambda 함수를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.
S3 API를 사용하여 각 S3 버킷의 퍼블릭 액세스 설정을 확인하는 cron 스크립트를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.
각 S3 버킷에 대해 S3 이벤트 알림을 활성화합니다. Amazon Simple Notification Service(Amazon SNS) 주제에 S3 이벤트 알림을 구독합니다.
AWS Config에서 s3-bucket-public-read-prohibited 관리형 규칙을 활성화합니다. AWS Config 규칙을 Amazon Simple Notification Service(Amazon SNS) 토픽에 구독합니다.
 




## 질문: 236
한 회사가 Amazon S3를 사용하여 도메인 example.com과 하위 도메인 www.example.com에서 정적 웹사이트를 출시할 계획입니다.

SysOps 관리자는 이 요구 사항을 어떻게 충족해야 합니까?

1. 도메인과 하위 도메인 모두에 대해 example.com이라는 이름의 S3 버킷을 하나 만듭니다.
2. 도메인과 하위 도메인 모두에 *.example.com이라는 와일드카드를 사용하여 하나의 S3 버킷을 생성합니다.
3. example.com과 www.example.com이라는 이름의 두 개의 S3 버킷을 만듭니다. 하위 도메인 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.
4. http://example.com과 http://*.example.com이라는 이름의 두 개의 S3 버킷을 만듭니다. 와일드카드(*) 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.
 

정적 웹사이트를 Amazon S3에서 호스팅하려면 SysOps 관리자는 다음과 같은 방법으로 요구 사항을 충족할 수 있습니다:

**3. `example.com`과 `www.example.com`이라는 이름의 두 개의 S3 버킷을 만듭니다. 하위 도메인 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.**

이유:
- **S3 버킷 네이밍 규칙**: Amazon S3에서 정적 웹사이트 호스팅 시 버킷 이름은 DNS 호환 도메인 이름이어야 합니다. 따라서 `example.com`과 `www.example.com`이라는 두 개의 S3 버킷이 필요합니다.
- **리디렉션 설정**: 일반적으로 `www.example.com`으로 들어오는 트래픽을 `example.com`으로 리디렉션합니다. 이를 위해 `www.example.com` S3 버킷을 리디렉션 버킷으로 설정하고, 실제 웹 콘텐츠는 `example.com` 버킷에서 호스팅합니다.
- **와일드카드 버킷 지원 없음**: Amazon S3는 와일드카드(*) 버킷을 지원하지 않으므로, 옵션 2나 4는 불가능합니다.

이 방법으로 도메인과 하위 도메인 모두에서 정적 웹사이트를 성공적으로 호스팅할 수 있습니다.

## 질문: 237
SysOps 관리자가 AWS Client VPN을 구성하여 기업 네트워크의 사용자를 VPC에서 실행 중인 AWS 리소스에 연결하고 있습니다. 규정 준수 요구 사항에 따라 VPC로 향하는 트래픽만 VPN 터널을 통과할 수 있습니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Client VPN을 어떻게 구성해야 합니까?

NAT 게이트웨이를 통한 인터넷 경로가 있는 개인 서브넷과 클라이언트 VPN 엔드포인트를 연결합니다.
클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켭니다.
클라이언트 VPN 엔드포인트에서 DNS 서버 IP 주소를 지정합니다.
VPN 클라이언트의 신원 인증서로 사용할 개인 인증서를 선택하세요.



## 질문: 238
SysOps 관리자가 5개의 Amazon EC2 인스턴스에 호스팅된 애플리케이션을 테스트하고 있습니다. 인스턴스는 Application Load Balancer(ALB) 뒤의 Auto Scaling 그룹에서 실행됩니다. 부하 테스트 중 CPU 사용률이 높아 Auto Scaling 그룹이 확장되고 있습니다. SysOps 관리자는 Auto Scaling 그룹이 확장되기 전에 CPU 사용률이 높은 근본 원인을 찾기 위해 문제를 해결해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

인스턴스 확장 보호를 활성화합니다.
인스턴스를 대기 상태로 전환합니다.
ALB에서 리스너를 제거합니다.
실행 및 종료 프로세스 유형을 일시 중단합니다



## 질문: 239
웹 애플리케이션은 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 여러 가용성 영역에 걸쳐 Auto Scaling 그룹에서 실행됩니다. SysOps 관리자는 이러한 EC2 인스턴스 중 일부가 Auto Scaling 그룹에서는 정상으로 표시되지만 ALB 대상 그룹에서는 비정상으로 표시된다는 것을 알아챘습니다.

이 문제의 가능한 이유는 무엇입니까?

보안 그룹은 ALB와 오류가 발생한 EC2 인스턴스 간의 트래픽을 허용하지 않습니다.
자동 크기 조정 그룹 상태 검사는 EC2 상태 검사를 위해 구성되었습니다.
EC2 인스턴스를 시작할 수 없고 EC2 상태 확인에도 실패합니다.
대상 그룹 상태 검사가 잘못된 포트 또는 경로로 구성되었습니다.



## 질문: 240
SysOps 관리자가 Amazon EC2 Auto Scaling 그룹의 확장 이벤트를 알아차렸습니다. Amazon CloudWatch는 연관된 Application Load Balancer의 RequestCount 메트릭에서 급증을 보여줍니다. 관리자는 요청 소스의 IP 주소를 알고 싶어합니다.

관리자는 이 정보를 어디에서 찾을 수 있습니까?

자동 크기 조정 로그
AWS CloudTrail 로그
EC2 인스턴스 로그
Elastic Load Balancer 액세스 로그




## 질문: 241
한 회사가 여러 개의 고성능 컴퓨팅(HPC) 가상 머신(VM)을 AWS의 Amazon EC2 인스턴스로 마이그레이션할 계획입니다. SysOps 관리자는 이 배포를 위한 배치 그룹을 식별해야 합니다. 이 전략은 네트워크 지연을 최소화하고 HPC VM 간의 네트워크 처리량을 최대화해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 전략을 선택해야 합니까?

하나의 가용성 영역에 있는 클러스터 배치 그룹에 인스턴스를 배포합니다.
두 개의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.
하나의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.
2개의 가용성 영역에 분산된 배치 그룹에 인스턴스를 배포합니다.




## 질문: 242
오류 프로세스는 전체 프로세서를 사용하고 100%로 실행되는 것으로 알려져 있습니다. SysOps 관리자는 문제가 2분 이상 발생할 때 Amazon EC2 인스턴스를 자동으로 다시 시작하려고 합니다.

어떻게 이를 달성할 수 있을까요?

기본 모니터링을 사용하여 EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만듭니다. 인스턴스를 다시 시작하는 작업을 추가합니다.
EC2 인스턴스에 대한 Amazon CloudWatch 알람을 자세한 모니터링과 함께 생성합니다. 인스턴스를 다시 시작하는 작업을 추가합니다.
2분마다 예약된 시간에 호출되는 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.
EC2 상태 확인을 통해 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.
 


## 질문: 243
한 회사가 Amazon S3 버킷에 많은 양의 민감한 데이터를 보관합니다. 회사의 보안팀은 SysOps 관리자에게 S3 버킷의 모든 현재 객체가 암호화되었는지 확인하도록 요청합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

S3 버킷에 대해 실행되고 각 객체의 상태를 출력하는 스크립트를 만듭니다.
S3 버킷에서 S3 인벤토리 구성을 만듭니다. 적절한 상태 필드를 포함합니다.
보안 팀에 S3 버킷에 대한 읽기 액세스 권한이 있는 IAM 사용자를 제공합니다.
AWS CLI를 사용하여 S3 버킷에 있는 모든 객체 목록을 출력합니다.



## 질문: 244
사용자는 관계형 데이터베이스에서 주기적으로 느린 응답 시간을 경험하고 있습니다. 데이터베이스는 350GB General Purpose SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨이 있는 버스트 가능한 Amazon EC2 인스턴스에서 실행됩니다. SysOps 관리자는 Amazon CloudWatch에서 EC2 인스턴스를 모니터링하고 느린 응답 기간 동안 VolumeReadOps 메트릭이 최고 값의 10% 미만으로 떨어지는 것을 관찰합니다.

SysOps 관리자는 지속적으로 높은 성능을 보장하기 위해 무엇을 해야 합니까?

gp2 볼륨을 일반 용도 SSD(gp3) EBS 볼륨으로 변환합니다.
gp2 볼륨을 Cold HDD(sc1) EBS 볼륨으로 변환합니다.
EC2 인스턴스를 메모리 최적화된 인스턴스 유형으로 변환합니다.
EC2 인스턴스에서 무제한 모드를 활성화합니다.



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



