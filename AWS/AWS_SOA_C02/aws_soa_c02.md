https://free-braindumps.com/amazon/free-soa-c02-braindumps.html?p=60#answerQ54
https://www.secexams.com/exams/Amazon/aws-certified-developer-associate-dva-c02/view/?utm_source=mail


## 질문 #1
한 회사에는 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 실행되는 지옥의 웹 애플리케이션이 있습니다. 

인스턴스는 단일 가용성 영역의 Amazon EC2 자동 확장 그룹에서 실행됩니다. SysOps 관리자는 애플리케이션을 고가용성으로 만들어야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

A. 최대 사용 시 필요한 용량을 충족시키기 위해 자동 크기 조정 그룹의 최대 인스턴스 수를 늘립니다.

B. 최대 사용 시 필요한 용량을 충족시키기 위해 자동 크기 조정 그룹의 최소 인스턴스 수를 늘립니다.

C. 동일한 AWS 지역의 두 번째 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다. 가장 많이 투표된

D. 두 번째 AWS 지역의 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다.

애플리케이션을 고가용성으로 만들기 위해 SysOps 관리자가 취해야 할 적절한 조치는 다음과 같습니다:

### **C. 동일한 AWS 지역의 두 번째 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다.**

#### 이유:
- **고가용성**: 두 개 이상의 가용성 영역(AZ)에서 인스턴스를 실행하면, 한 AZ에서 장애가 발생하더라도 다른 AZ에서 인스턴스가 계속 운영될 수 있습니다. 이로 인해 애플리케이션의 가용성이 크게 향상됩니다.
- **자동 확장 그룹의 업데이트**: 자동 확장 그룹을 구성하여 여러 AZ에서 인스턴스를 배포하면 수요 변화에 따라 자동으로 인스턴스 수를 조정할 수 있습니다.

### **다른 옵션 설명:**

A. **최대 사용 시 필요한 용량을 충족시키기 위해 자동 크기 조정 그룹의 최대 인스턴스 수를 늘립니다.**
   - 이는 자동 확장 그룹이 더 많은 인스턴스를 시작할 수 있게 하지만, 단일 AZ 내에서만 동작하므로 장애에 대한 내성이 부족합니다.

B. **최대 사용 시 필요한 용량을 충족시키기 위해 자동 크기 조정 그룹의 최소 인스턴스 수를 늘립니다.**
   - 이 방법은 더 많은 인스턴스를 유지하더라도 여전히 단일 AZ에서만 실행되므로 장애 내성을 제공하지 않습니다.

D. **두 번째 AWS 지역의 가용성 영역에서 새 인스턴스를 시작하도록 자동 크기 조정 그룹을 업데이트합니다.**
   - 다른 리전에서 인스턴스를 시작하는 것은 애플리케이션이 필요한 고가용성을 달성하는 데 적절하지 않습니다. 리전 간 데이터 전송 및 지연 문제를 고려할 때, 동일한 리전 내의 AZ를 사용하는 것이 더 효과적입니다.

따라서 **C** 옵션이 고가용성을 위한 가장 효과적인 접근 방식입니다.


## 질문 #2
한 회사가 Auto Scaling 그룹에서 실행되는 여러 Amazon EC2 인스턴스에 웹사이트를 호스팅합니다. 

사용자는 매주 주말 오후 6시부터 오후 11시 사이의 피크 타임에 느린 응답을 보고합니다. SysOps 관리자는 이러한 피크 타임에 성능을 개선하기 위한 솔루션을 구현해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 피크 시간 전에 원하는 용량을 늘리기 위해 AWS Lambda 함수를 호출하는 예약된 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
B. 피크 시간 전후에 원하는 용량을 변경하기 위한 반복 옵션을 사용하여 예약된 확장 작업을 구성합니다. 가장 많이 투표된
C. 메모리 사용률이 70%를 넘을 경우 더 많은 인스턴스를 추가하는 대상 추적 확장 정책을 만듭니다.
D. 자동 크기 조정 그룹의 쿨다운 기간을 구성하여 피크 시간 전후에 원하는 용량을 수정합니다.

정답: B. 피크 시간 전후에 원하는 용량을 변경하기 위한 반복 옵션을 사용하여 예약된 확장 작업을 구성합니다.

이유:
예약된 확장 작업을 통해 피크 시간 전에 인스턴스 용량을 미리 늘리고, 피크 시간이 끝난 후 용량을 줄일 수 있습니다. 이렇게 하면 사용량 패턴에 따라 EC2 인스턴스의 수를 자동으로 조정할 수 있어 피크 타임 동안의 성능을 보장하면서도 비용을 효율적으로 관리할 수 있습니다.
반복 옵션을 사용하면 매주 주말 오후 6시부터 오후 11시 사이에 자동으로 확장 및 축소 작업을 실행할 수 있습니다. 이는 시스템을 수동으로 관리할 필요 없이 성능을 개선하는 운영 효율적인 방법입니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: Lambda 함수와 EventBridge 규칙을 사용하는 것은 가능하지만, 예약된 확장 작업을 구성하는 것보다 복잡하며 운영 효율성이 떨어집니다.
C: 대상 추적 확장 정책은 실시간으로 확장하지만, 피크 시간에 대한 사전 대비 없이 메모리 사용률이 높아졌을 때만 반응할 수 있어 즉각적인 성능 개선이 어렵습니다.
D: 쿨다운 기간은 인스턴스 수를 확장 또는 축소한 후에 추가 작업을 지연시키기 위한 설정으로, 피크 시간 전에 미리 확장하는 데는 적합하지 않습니다.


## 질문 #3
한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹사이트를 운영하고 있습니다. 

이 회사는 Amazon CloudFront 배포를 구성하고 ALB를 원점으로 설정했습니다. 이 회사는 모든 트래픽을 CloudFront 배포를 통해 보내기 위해 Amazon Route 53 CNAME 레코드를 만들었습니다. 의도치 않은 부작용으로 모바일 사용자에게 이제 데스크톱 버전의 웹사이트가 제공됩니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치를 취해야 합니까?

A. CloudFront 배포 동작을 구성하여 User-Agent 헤더를 전달합니다.
B. CloudFront 배포 오리진 설정을 구성합니다. 오리진 사용자 지정 헤더 목록에 User-Agent 헤더를 추가합니다.
C. ALB에서 IPv6를 활성화합니다. CloudFront 배포 원본 설정을 업데이트하여 dualstack 엔드포인트를 사용합니다.
D. CloudFront 배포에서 IPv6를 활성화합니다. Route 53 레코드를 업데이트하여 dualstack 엔드포인트를 사용합니다.


이 문제는 모바일 사용자가 데스크톱 버전의 웹사이트를 받는 문제와 관련이 있습니다. 
이를 해결하기 위해서는 CloudFront가 User-Agent 헤더를 올바르게 전달하여 원본 서버가 사용자의 디바이스 유형(모바일, 데스크톱)에 따라 적절한 버전을 제공할 수 있도록 해야 합니다.

정답: A. CloudFront 배포 동작을 구성하여 User-Agent 헤더를 전달합니다.
이유:
User-Agent 헤더는 사용자가 모바일 기기인지 데스크톱 기기인지 등을 서버에 전달하는 중요한 정보입니다. CloudFront가 기본적으로 일부 헤더를 캐시하여 성능을 최적화하는데, User-Agent 헤더가 전달되지 않으면 원본 서버는 디바이스를 구분할 수 없고, 디바이스에 맞는 적절한 콘텐츠를 제공하지 못할 수 있습니다.
CloudFront 배포에서 User-Agent 헤더를 전달하면, 원본 서버(이 경우 Application Load Balancer 뒤의 Amazon EC2 인스턴스)는 각 디바이스 유형에 맞는 콘텐츠를 적절하게 반환할 수 있습니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

B: 오리진 사용자 지정 헤더 목록에 User-Agent를 추가하는 것은 일반적으로 캐시 구성을 제어하는 데 사용되지 않으며, 단순히 오리진으로 헤더를 추가하는 것만으로는 문제를 해결할 수 없습니다.
C와 D: IPv6를 활성화하는 것은 네트워크 수준에서 트래픽을 처리하는 방식일 뿐, 모바일과 데스크톱 사용자 간의 웹사이트 버전 문제와는 직접적인 관련이 없습니다.

## 질문 #4
SysOps 관리자가 AWS 계정에서 AWS CloudTrail을 활성화했습니다.

CloudTrail이 비활성화된 경우 즉시 다시 활성화해야 합니다.
SysOps 관리자는 사용자 지정 코드를 작성하지 않고도 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. AWS 계정을 AWS Organizations에 추가합니다. 관리 계정에서 CloudTrail을 활성화합니다.
B. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용합니다. 가장 많이 투표된
C. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. CloudTrail을 활성화하기 위해 AWS Lambda 함수를 호출하도록 규칙을 구성합니다.
D. AWS Systems Manager Automation 문서를 실행하고 CloudTrail을 활성화하기 위한 일정 패턴을 사용하여 Amazon EventBridge(Amazon CloudWatch Event) 시간별 규칙을 만듭니다.


SysOps 관리자가 AWS CloudTrail이 비활성화될 때 자동으로 다시 활성화되도록 하려면, 사용자 지정 코드를 작성하지 않고 AWS에서 제공하는 자동화된 솔루션을 사용할 수 있습니다.

정답: B. CloudTrail 구성이 변경될 때 호출되는 AWS Config 규칙을 만듭니다. AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용합니다.
이유:
AWS Config는 AWS 리소스 구성을 추적하고 모니터링하는 서비스로, CloudTrail과 같은 리소스의 구성이 변경되었을 때 규칙을 트리거할 수 있습니다.
AWS-ConfigureCloudTrailLogging 자동 수정 작업을 적용하면 CloudTrail이 비활성화되었을 때 자동으로 다시 활성화됩니다. 이 자동화된 작업은 사용자 정의 코드 없이도 CloudTrail 구성을 보장할 수 있는 매우 효율적인 방법입니다.
이 방법은 AWS에서 제공하는 기본 기능을 활용하므로 관리가 쉽고 확장 가능합니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: AWS Organizations의 관리 계정에서 CloudTrail을 활성화할 수 있지만, 이 방법은 비활성화된 CloudTrail을 자동으로 다시 활성화하는 요구 사항을 충족하지 않습니다.
C: Lambda 함수를 사용하는 방법도 가능하지만, 사용자 지정 코드를 작성해야 하므로 더 복잡하고 운영 오버헤드가 증가합니다.
D: EventBridge 시간별 규칙을 사용하면 주기적으로 CloudTrail을 활성화할 수 있지만, CloudTrail이 비활성화된 시점을 즉시 감지하여 다시 활성화하는 데는 적합하지 않습니다. Config 규칙을 사용하는 것이 더 효율적입니다.

## 질문 #5
한 회사가 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 웹사이트를 호스팅합니다. 

이 회사는 Amazon Route 53으로 DNS를 관리하고 도메인의 존 에이펙스를 웹사이트로 가리키고 싶어합니다.
이러한 요구 사항을 충족하려면 어떤 유형의 레코드를 사용해야 합니까?

A. 도메인의 존 정점에 대한 AAAA 레코드
B. 도메인의 영역 정점에 대한 A 레코드
C. 도메인의 존 정점에 대한 CNAME 레코드
D. 도메인의 존 정점에 대한 별칭 레코드

도메인의 존 에이펙스(Apex, 즉 example.com와 같은 최상위 도메인)를 Application Load Balancer(ALB)에 연결하려면, CNAME 레코드는 사용할 수 없습니다. 대신 Amazon Route 53에서 제공하는 별칭(Alìas) 레코드를 사용하는 것이 적합합니다.

정답: D. 도메인의 존 정점에 대한 별칭 레코드
이유:
**별칭 레코드(Alìas Record)**는 Route 53에서 제공하는 기능으로, 특정 AWS 리소스(예: Application Load Balancer, CloudFront 배포, S3 버킷 등)로 도메인을 연결할 수 있습니다.
도메인의 존 에이펙스에는 CNAME 레코드를 사용할 수 없으므로, 별칭 레코드가 가장 적합한 선택입니다. 별칭 레코드는 또한 A 레코드와 유사하게 작동하여 IP 주소로의 변환을 처리합니다.
별칭 레코드는 Route 53이 제공하는 자동화된 기능을 활용해 트래픽 라우팅을 효율적으로 관리하며, 비용도 발생하지 않습니다.
다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:

A: AAAA 레코드는 IPv6 주소를 가리키는 레코드입니다. ALB와 같은 AWS 리소스와 연결하는 데 일반적으로 사용되지 않습니다.
B: A 레코드는 IP 주소를 직접 가리키는 레코드로, AWS 리소스와 동적으로 연결할 수 없습니다.
C: CNAME 레코드는 존 정점(최상위 도메인)에 사용할 수 없으며, 하위 도메인(예: www.example.com)에서만 사용할 수 있습니다.

## 질문 #6
회사는 S3 버킷에 업로드된 모든 객체가 암호화되도록 해야 합니다.

다음 중 어떤 조치가 이 요구 사항을 충족할까요? (두 가지를 선택하세요.)

A. S3 버킷에 저장된 암호화되지 않은 객체로부터 보호하기 위해 AWS Shield를 구현합니다.
B. 암호화되지 않은 객체가 S3 버킷에 업로드되는 것을 거부하기 위해 객체 액세스 제어 목록(ACL)을 구현합니다.
C. Amazon S3 기본 암호화를 구현하여 업로드되는 모든 객체가 저장되기 전에 암호화되도록 합니다.
D. Amazon Inspector를 구현하여 S3 버킷에 업로드된 객체가 암호화되었는지 검사합니다.
E. 암호화되지 않은 객체가 버킷에 업로드되는 것을 거부하기 위해 S3 버킷 정책을 구현합니다.

Amazon S3 버킷에 업로드된 모든 객체가 암호화되도록 보장하기 위해서는 두 가지 방법을 사용할 수 있습니다: S3 기본 암호화와 버킷 정책을 통한 암호화 강제 적용입니다.

정답:
C. Amazon S3 기본 암호화를 구현하여 업로드되는 모든 객체가 저장되기 전에 암호화되도록 합니다.
E. 암호화되지 않은 객체가 버킷에 업로드되는 것을 거부하기 위해 S3 버킷 정책을 구현합니다.
이유:
C: Amazon S3 기본 암호화를 설정하면 모든 객체가 업로드될 때 자동으로 암호화됩니다. 기본 암호화는 객체가 저장되기 전에 암호화되므로, 사용자가 별도의 암호화 설정을 하지 않더라도 모든 객체가 보호됩니다.
E: S3 버킷 정책을 통해 특정 조건을 강제할 수 있습니다. 예를 들어, 객체가 업로드될 때 반드시 암호화 헤더가 포함되도록 요구하는 정책을 설정할 수 있으며, 이를 따르지 않는 업로드는 자동으로 거부됩니다. 이 방식은 S3 기본 암호화와 함께 사용될 때 더욱 효과적입니다.

다른 옵션들은 적합하지 않은 이유:
A: AWS Shield는 DDoS(분산 서비스 거부) 공격으로부터 보호하기 위한 서비스이며, 객체 암호화와는 관련이 없습니다.
B: 객체 ACL은 객체에 대한 읽기 및 쓰기 권한을 제어하는 것이며, 암호화 여부와 관련이 없습니다.
D: Amazon Inspector는 EC2 인스턴스, 컨테이너 이미지 등의 취약성을 검사하는 서비스로, S3 버킷 객체의 암호화 여부를 검사하는 기능은 제공하지 않습니다.


## 질문 #7
한 회사에는 Auto Scaling 그룹의 Amazon EC2 인스턴스에 호스팅된 상태 저장 웹 애플리케이션이 있습니다. 

인스턴스는 단일 대상 그룹이 있는 Application Load Balancer(ALB) 뒤에서 실행됩니다. ALB는 Amazon CloudFront 배포에서 원점으로 구성됩니다. 사용자는 웹 애플리케이션에서 무작위 로그아웃을 보고합니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. ALB 대상 그룹에서 가장 덜 처리된 요청 알고리즘으로 변경합니다.
B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.
C. CloudFront 배포 캐시 동작에서 헤더 전달을 구성합니다.
D. ALB 리스너 규칙에서 그룹 수준의 고정성을 활성화합니다.
E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.

무작위 로그아웃 문제는 세션이 EC2 인스턴스 간에 적절하게 유지되지 않기 때문에 발생할 수 있습니다. 특히 상태 저장 애플리케이션에서 세션 관리가 중요한데, 이는 스티키 세션(Sticky Session) 또는 세션 고정성을 통해 해결할 수 있습니다. 또한, CloudFront가 세션 관련 정보를 캐시하지 않도록 해야 합니다.

정답:
B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.
E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.

이유:
B. CloudFront 배포 캐시 동작에서 쿠키 전달을 구성합니다.

웹 애플리케이션이 세션 쿠키를 사용하여 사용자를 인증하고 세션을 유지한다면, CloudFront가 쿠키를 전달하지 않으면 세션 상태가 손실될 수 있습니다. CloudFront 배포에서 쿠키 전달을 구성하면, CloudFront가 세션 관련 정보를 제대로 처리하고 사용자에게 무작위 로그아웃 문제가 발생하지 않도록 할 수 있습니다.
E. ALB 대상 그룹에서 스티키 세션을 활성화합니다.

스티키 세션(세션 고정성)을 활성화하면 사용자가 동일한 EC2 인스턴스에 지속적으로 연결됩니다. 이는 상태 저장 애플리케이션에서 사용자의 세션 상태를 유지하는 데 필수적입니다. 스티키 세션을 활성화하면 특정 사용자가 같은 인스턴스로 계속 연결되므로 세션이 유지됩니다.
다른 옵션들은 적합하지 않은 이유:
A: 덜 처리된 요청 알고리즘으로 변경하는 것은 트래픽을 분산시키는 방법일 뿐, 세션 관련 문제 해결과는 관련이 없습니다.
C: 헤더 전달은 쿠키 전달보다 덜 중요하며, 헤더가 세션 문제에 직접적인 영향을 미치지 않을 수 있습니다.
D: 그룹 수준의 고정성은 특정 리스너 규칙에 의존하는 것이며, 대상 그룹의 세션 고정성 관리와는 무관합니다. ALB 대상 그룹의 스티키 세션 설정이 더 적합한 해결책입니다.

## 질문 #8
한 회사가 AWS Lambda에서 서버리스 애플리케이션을 실행하고 있습니다. 

이 애플리케이션은 Amazon RDS for MySQL DB 인스턴스에 데이터를 저장합니다. 사용량이 꾸준히 증가했고, 최근 Lambda 함수가 데이터베이스에 연결을 시도할 때 "연결이 너무 많음" 오류가 많이 발생했습니다. 이 회사는 이미 가능한 최대 max_connections 값을 사용하도록 데이터베이스를 구성했습니다.
SysOps 관리자는 이러한 오류를 해결하기 위해 무엇을 해야 합니까?

A. 데이터베이스의 읽기 복제본을 만듭니다. Amazon Route 53을 사용하여 두 데이터베이스를 모두 포함하는 가중 DNS 레코드를 만듭니다.
B. Amazon RDS Proxy를 사용하여 프록시를 만듭니다. Lambda 함수에서 연결 문자열을 업데이트합니다.
C. 데이터베이스가 사용하는 매개변수 그룹의 max_connect_errors 매개변수 값을 늘립니다.
D. Lambda 함수의 예약된 동시성을 더 높은 값으로 업데이트합니다.

Lambda 함수가 데이터베이스에 연결을 시도할 때 "연결이 너무 많음" 오류가 발생하는 문제는 데이터베이스 연결 수가 제한된 상황에서 흔히 발생하는 문제입니다. 이 문제를 해결하기 위해 Amazon RDS Proxy를 사용하는 것이 가장 적합한 방법입니다.

정답:
B. Amazon RDS Proxy를 사용하여 프록시를 만듭니다. Lambda 함수에서 연결 문자열을 업데이트합니다.

이유:
Amazon RDS Proxy는 데이터베이스 연결을 관리하여 여러 Lambda 함수가 데이터베이스에 동시에 연결하는 문제를 완화시켜줍니다. 프록시는 연결을 풀링(pooling)하여 Lambda 함수가 데이터베이스와 직접 연결하지 않고 프록시를 통해 연결을 관리함으로써 데이터베이스에 대한 연결 수를 줄일 수 있습니다. 이렇게 하면 데이터베이스에 대한 연결이 최적화되고, "연결이 너무 많음" 오류를 방지할 수 있습니다.
다른 옵션들이 적합하지 않은 이유:

A: 읽기 복제본을 만들고 Route 53 가중 DNS 레코드를 설정하는 것은 읽기 요청 분산에 적합하지만, 이 문제는 연결 수에 관련된 문제이므로 해결책이 되지 않습니다.
C: max_connect_errors 매개변수는 데이터베이스의 연결 시도 오류 허용 한도를 제어하는 매개변수로, 연결 수 제한 문제를 해결하지는 못합니다.
D: Lambda 함수의 동시성을 증가시키는 것은 Lambda 함수가 실행되는 빈도나 동시성을 조절하는 것이며, 이는 데이터베이스 연결 수 문제와 직접적으로 관련이 없습니다. 오히려 더 많은 동시성이 더 많은 연결을 생성할 수 있어 문제가 악화될 수 있습니다.
RDS Proxy는 연결 관리 문제를 해결하는 가장 적절한 방법입니다.

## 질문 #9
SysOps 관리자가 10개의 Amazon EC2 인스턴스에 애플리케이션을 배포하고 있습니다. 

애플리케이션은 고가용성이어야 합니다. 인스턴스는 별도의 기본 하드웨어에 배치되어야 합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 단일 AWS 지역의 클러스터 배치 그룹으로 인스턴스를 시작합니다.
B. 여러 AWS 지역의 파티션 배치 그룹으로 인스턴스를 시작합니다.
C. 여러 AWS 지역에 분산된 배치 그룹으로 인스턴스를 시작합니다.
D. 단일 AWS 지역의 분산된 배치 그룹으로 인스턴스를 시작합니다.

애플리케이션이 고가용성을 요구하고, 인스턴스가 별도의 기본 하드웨어에 배치되어야 한다면, 분산된 배치 그룹을 사용하는 것이 적합합니다. 분산된 배치 그룹은 인스턴스가 서로 다른 물리적 하드웨어에 배치되도록 보장하며, 장애를 격리하는 데 효과적입니다.

정답:
D. 단일 AWS 지역의 분산된 배치 그룹으로 인스턴스를 시작합니다.

이유:
분산된 배치 그룹은 EC2 인스턴스를 서로 다른 물리적 하드웨어에 배치하여 단일 하드웨어 장애가 여러 인스턴스에 영향을 미치지 않도록 설계되었습니다. 따라서 고가용성을 보장하면서 인스턴스가 서로 다른 기본 하드웨어에 배치됩니다.
이 옵션은 단일 AWS 지역에서 고가용성을 유지하기 위한 적절한 선택입니다.

다른 옵션들이 적합하지 않은 이유:
A. 클러스터 배치 그룹은 저지연 네트워크 통신을 위해 인스턴스를 물리적으로 가까운 위치에 배치하는 방식으로, 하드웨어 중복성과 고가용성 요구사항에는 적합하지 않습니다.
B. 여러 AWS 지역의 파티션 배치 그룹은 지역 간 배포를 의미하지만, 파티션 배치 그룹은 특정 리소스 간의 장애 격리에 중점을 둡니다. 또한 다수의 지역을 사용할 필요는 없습니다.
C. 여러 AWS 지역에 분산된 배치 그룹은 고가용성을 위해 지역 간 배포를 의미하지만, 다중 지역 배포는 복잡성을 증가시키며 질문에서 요구하는 것은 단일 지역 내에서의 고가용성입니다.
따라서 단일 AWS 지역의 분산된 배치 그룹이 요구 사항을 충족하는 가장 적합한 선택입니다.

## 질문 #10
SysOps 관리자가 여러 Amazon EC2 인스턴스가 생성되는 AWS CloudFormation 템플릿의 문제를 해결하고 있습니다. 

템플릿은 us-east-1에서 작동하지만 us-west-2에서는
AMI [ami-12345678]이 존재하지 않음 이라는 오류 코드와 함께 실패합니다.
관리자는 AWS CloudFormation 템플릿이 모든 지역에서 작동하는지 어떻게 확인해야 합니까?

A. 소스 지역의 Amazon Machine Image(AMI)를 대상 지역에 복사하고 동일한 ID를 할당합니다.
B. AWS CloudFormation 템플릿을 편집하여 정규화된 AMI ID의 일부로 지역 코드를 지정합니다.
C. AWS::EC2::AMI::ImageID 컨트롤을 사용하여 AWS CloudFormation 템플릿을 편집하여 사용자에게 모든 AMI의 드롭다운 목록을 제공합니다.
D. "매핑" 섹션에 AMI ID를 포함하여 AWS CloudFormation 템플릿을 수정합니다. 적절한 AMI ID에 대한 템플릿 내의 적절한 매핑을 참조하세요.

이 문제는 특정 지역에서 사용 가능한 AMI가 다르기 때문에 발생합니다. 각 AWS 리전에서 고유한 AMI ID가 있으므로, 모든 지역에서 AWS CloudFormation 템플릿이 작동하도록 하려면 지역별로 다른 AMI ID를 지정할 수 있는 방법을 사용해야 합니다. 이를 위해 AWS CloudFormation 템플릿의 매핑 섹션을 사용하여 지역마다 올바른 AMI ID를 참조하게 할 수 있습니다.

정답:
D. "매핑" 섹션에 AMI ID를 포함하여 AWS CloudFormation 템플릿을 수정합니다. 적절한 AMI ID에 대한 템플릿 내의 적절한 매핑을 참조하세요.
이유:
매핑(Mappings) 섹션은 AWS CloudFormation에서 리전 또는 다른 조건에 따라 값을 달리 지정할 수 있게 해줍니다. 각 리전에 맞는 AMI ID를 매핑에 정의하고, Fn::FindInMap 함수로 적절한 값을 참조하도록 수정하면 템플릿이 여러 리전에서 작동하도록 할 수 있습니다.

예시 매핑 코드:
```yaml

Mappings:
  RegionMap:
    us-east-1:
      AMI: ami-12345678
    us-west-2:
      AMI: ami-87654321

Resources:
  MyEC2Instance:
    Type: "AWS::EC2::Instance"
    Properties:
      ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", AMI]
```

다른 옵션들이 적합하지 않은 이유:
A: 소스 지역의 AMI를 복사하고 동일한 ID를 할당하는 것은 불가능합니다. AWS에서는 AMI를 복사할 수 있지만, 복사된 AMI는 다른 리전에서 새로운 ID를 갖게 되므로 동일한 ID를 사용할 수 없습니다.
B: CloudFormation 템플릿에서 지역 코드에 따라 정규화된 AMI ID를 지정하는 방식은 존재하지 않습니다. AMI ID는 리전별로 고유합니다.
C: AWS::EC2::AMI::ImageID라는 리소스 타입은 존재하지 않으며, 사용자에게 AMI 목록을 제공하는 기능도 없습니다.
따라서 매핑을 통해 리전별 AMI ID를 설정하는 D 옵션이 가장 적합한 해결책입니다.


## 질문 #11
SysOps 관리자가 여러 Amazon EC2 인스턴스에서 공유 스토리지를 제공하기 위해 Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝하고 있습니다. 

인스턴스는 모두 여러 가용 영역에 걸쳐 동일한 VPC에 있습니다. 각 가용 영역에는 두 개의 인스턴스가 있습니다. SysOps 관리자는 가능한 가장 낮은 지연 시간으로 각 인스턴스에서 파일 시스템에 액세스할 수 있도록 해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. VPC에서 EFS 파일 시스템에 대한 마운트 대상을 만듭니다. 마운트 대상을 사용하여 각 인스턴스에서 파일 시스템을 마운트합니다.
B. VPC의 한 가용성 영역에 EFS 파일 시스템에 대한 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 파일 시스템을 마운트합니다. 다른 인스턴스와 디렉토리를 공유합니다.
C. 각 인스턴스에 대한 마운트 대상을 만듭니다. 각 마운트 대상을 사용하여 각 인스턴스에 EFS 파일 시스템을 마운트합니다.
D. VPC의 각 가용성 영역에 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 EFS 파일 시스템을 마운트합니다.


주어진 요구 사항에 따라 Amazon Elastic File System (EFS) 파일 시스템에 대한 최적의 솔루션을 선택해야 합니다. 이 경우, 모든 Amazon EC2 인스턴스가 여러 가용 영역에 걸쳐 동일한 VPC에 있으므로 각 인스턴스에서 가능한 가장 낮은 지연 시간으로 EFS에 액세스할 수 있도록 해야 합니다.

정답: D.VPC의 각 가용성 영역에 마운트 대상을 만듭니다. 마운트 대상을 사용하여 해당 가용성 영역의 인스턴스에 EFS 파일 시스템을 마운트합니다.

이유:
- EFS는 여러 가용 영역에 걸쳐서 고가용성과 내구성을 제공할 수 있습니다.
- 각 가용 영역에 마운트 대상을 만들면, 해당 가용 영역의 인스턴스가 EFS 파일 시스템에 직접적으로 연결되어 가장 낮은 지연 시간으로 액세스할 수 있습니다.
- 마운트 대상을 각 가용 영역에 설정하면, 네트워크 지연을 최소화하고 각 인스턴스가 EFS 파일 시스템에 효과적으로 접근할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
- **A**: 모든 인스턴스가 단일 마운트 대상을 사용할 경우, 네트워크 지연이 발생할 수 있습니다.
- **B**: 한 가용 영역에만 마운트 대상을 두면 다른 가용 영역의 인스턴스에서 높은 지연 시간으로 EFS에 액세스해야 합니다.
- **C**: 각 인스턴스에 대해 별도의 마운트 대상을 만드는 것은 비효율적이며, EFS의 이점을 제대로 활용하지 못합니다.


## 질문 #12
SysOps 관리자가 AWS CloudFormation 템플릿을 사용하여 VPC를 성공적으로 배포했습니다. 

SysOps 관리자는 AWS Organizations를 통해 관리되는 여러 계정에 동일한 템플릿을 배포하려고 합니다.
어떤 솔루션이 가장 적은 운영 오버헤드로 이 요구 사항을 충족할까요?

A. 관리 계정에서 OrganizationAccountAccessRole IAM 역할을 맡습니다. 각 계정에 템플릿을 배포합니다.
B. 각 계정에서 역할을 맡을 AWS Lambda 함수를 만듭니다. AWS CloudFormation CreateStack API 호출을 사용하여 템플릿을 배포합니다.
C. 계정 목록을 쿼리하기 위한 AWS Lambda 함수를 만듭니다. AWS CloudFormation CreateStack API 호출을 사용하여 템플릿을 배포합니다.
D. 관리 계정의 AWS CloudFormation StackSets를 사용하여 각 계정에 템플릿을 배포합니다.


주어진 시나리오에서 SysOps 관리자가 AWS CloudFormation 템플릿을 여러 AWS Organizations 계정에 배포하려고 할 때, 가장 적은 운영 오버헤드로 이 요구 사항을 충족할 수 있는 솔루션은 다음과 같습니다.

정답: D. 관리 계정의 AWS CloudFormation StackSets를 사용하여 각 계정에 템플릿을 배포합니다.

이유:
- **AWS CloudFormation StackSets**를 사용하면 여러 AWS 계정 및 리전에서 CloudFormation 스택을 동시에 관리하고 배포할 수 있습니다. 
- StackSets를 사용하면 단일 템플릿을 기반으로 여러 계정에 변경 사항을 쉽게 적용할 수 있으며, 중앙에서 관리하므로 운영 오버헤드가 줄어듭니다.
- 또한, StackSets는 IAM 권한과 관련하여 각 계정에 적절한 역할을 자동으로 처리할 수 있어 관리가 용이합니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
- A: 역할을 맡아 개별적으로 템플릿을 배포하는 것은 운영 오버헤드가 크고 관리가 복잡합니다.
- B: 각 계정에서 Lambda 함수를 만들어야 하며, 관리해야 할 코드가 많아져 운영 오버헤드가 증가합니다.
- C: 계정 목록을 쿼리하는 Lambda 함수를 만드는 것은 여전히 복잡성을 증가시키고, 여러 계정에 대해 수동으로 API 호출을 해야 하므로 비효율적입니다.

## 질문 #13
한 회사에서 계산을 위해 20개의 Amazon EC2 인스턴스로 구성된 플릿을 관리하기 위해 분산 컴퓨팅 소프트웨어를 실행하고 있습니다. 

플릿에는 계산을 실행하기 위한 2개의 제어 노드와 18개의 작업 노드가 포함되어 있습니다. 제어 노드는 자동으로 작업 노드를 시작할 수 있습니다.
현재 모든 노드는 주문형으로 실행됩니다. 제어 노드는 주 7일, 하루 24시간 이용 가능해야 합니다. 작업 노드는 매일 4시간씩 실행됩니다. SysOps 관리자는 이 솔루션의 비용을 최적화해야 합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하세요.)

A. 제어 노드에 대한 EC2 인스턴스 절약 플랜을 구매합니다. 가장 많이 투표된
B. 제어 노드에 전용 호스트를 사용합니다.
C. 작업 노드에 예약 인스턴스를 사용합니다.
D. 제어 노드에 Spot Instances를 사용합니다. Spot 가용성이 없는 경우 On-Demand Instances를 사용합니다.
E. 작업 노드에 Spot 인스턴스를 사용합니다. Spot 가용성이 없는 경우 On-Demand 인스턴스를 사용합니다. 가장 많이 투표된

이 시나리오에서 비용을 최적화하기 위한 두 가지 주요 선택지는 다음과 같습니다:

 A. **제어 노드에 대한 EC2 인스턴스 절약 플랜을 구매합니다.**
- **이유**: 제어 노드는 24/7 가동되어야 하기 때문에, 주문형(On-Demand) 인스턴스를 계속 사용하면 비용이 많이 듭니다. 대신 **EC2 절약 플랜(Savings Plan)**을 구매하면 특정 인스턴스 유형에 대해 장기적으로 비용을 절감할 수 있습니다. 절약 플랜은 특정 인스턴스 유형에 고정되지 않고, 다른 인스턴스 유형이나 AWS 서비스에도 적용될 수 있기 때문에 유연성이 높습니다. 이 플랜은 항상 가동해야 하는 제어 노드에 적합한 선택입니다.

 E. **작업 노드에 Spot 인스턴스를 사용합니다. Spot 가용성이 없는 경우 On-Demand 인스턴스를 사용합니다.**
- **이유**: 작업 노드는 매일 4시간만 사용되기 때문에 **Spot 인스턴스**를 활용하여 비용을 크게 절감할 수 있습니다. Spot 인스턴스는 미사용 EC2 용량을 저렴하게 제공하며, 짧은 시간 동안의 작업에 적합합니다. Spot 인스턴스가 가용하지 않을 때는 **On-Demand 인스턴스**를 사용하여 작업을 보장할 수 있습니다. 이는 작업 노드의 가동 시간을 충분히 고려하면서 비용 절감을 극대화할 수 있는 전략입니다.


 다른 옵션에 대한 설명:

- **B. 제어 노드에 전용 호스트를 사용합니다.**
  - **이유**: 전용 호스트는 비용이 매우 높으며, 제어 노드에 꼭 필요하지 않습니다. 이 옵션은 보안이나 라이선스 요구 사항이 있을 때 사용되며, 비용 절감에 적합하지 않습니다.

- **C. 작업 노드에 예약 인스턴스를 사용합니다.**
  - **이유**: 예약 인스턴스는 작업 노드에 적합하지 않습니다. 예약 인스턴스는 장기간 일정한 시간 동안 사용될 때 적합한 옵션인데, 작업 노드는 하루 4시간씩만 사용되므로 Spot 인스턴스가 더 저렴한 선택입니다.

- **D. 제어 노드에 Spot 인스턴스를 사용합니다. Spot 가용성이 없는 경우 On-Demand 인스턴스를 사용합니다.**
  - **이유**: 제어 노드는 24/7 항상 가동되어야 하므로 **Spot 인스턴스**처럼 일시적으로 가용하지 않을 수 있는 인스턴스 유형은 적합하지 않습니다. 제어 노드는 항상 안정적으로 가동될 필요가 있기 때문에, 이 옵션은 권장되지 않습니다.

---

결론적으로, **A**(제어 노드에 절약 플랜)와 **E**(작업 노드에 Spot 인스턴스) 조합이 이 시나리오에서 비용을 최적화하는 데 가장 적합한 선택입니다.


## 질문 #14
회사는 Amazon S3 버킷에서 매 시간 데이터 파일을 수신해야 합니다. 

S3 이벤트 알림은 파일이 도착할 때마다 AWS Lambda 함수를 호출합니다. 이 함수는 애플리케이션에서 사용할 수 있도록 데이터를 처리합니다.
애플리케이션 팀은 때때로 파일이 도착하지 않는다는 것을 알아차립니다. 애플리케이션 팀은 파일이 도착하지 않을 때마다 알림을 받고 싶어합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 지난 1시간 동안 생성된 객체로 제한된 범위로 S3 버킷에 S3 수명 주기 규칙을 추가합니다. 전환된 객체 수가 0일 때 수명 주기 전환에 의해 호출되는 다른 S3 이벤트 알림을 구성합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하여 애플리케이션 팀에 알립니다.
B. Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Lambda 함수를 호출하도록 다른 S3 이벤트 알림을 구성합니다. 대기열의 ApproximateAgeOfOldestMessage 메트릭이 1시간보다 클 때 애플리케이션 팀에 알리기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다.
C. Lambda 함수의 Invocations 메트릭이 1시간 동안 0일 때 애플리케이션 팀에 경고하기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다. 누락된 데이터를 위반으로 처리하도록 알람을 구성합니다. 가장 많이 투표된
D. S3 버킷에서 가장 최신 파일의 타임스탬프를 가져오는 새 Lambda 함수를 만듭니다. 타임스탬프가 1시간 전이면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하여 애플리케이션 팀에 알립니다. 매시간 새 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.

가장 운영 효율적인 솔루션은 옵션 C입니다.

C. Lambda 함수의 Invocations 메트릭이 1시간 동안 0일 때 애플리케이션 팀에 경고하기 위해 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다. 누락된 데이터를 위반으로 처리하도록 알람을 구성합니다.

이 솔루션은 다음과 같은 이유로 적합합니다:

운영 효율성: Lambda 함수의 Invocations 메트릭을 사용해 파일이 도착하지 않을 때 알림을 받을 수 있습니다. Lambda 함수가 호출되지 않으면 알림이 생성되므로 추가적인 커스텀 코드를 작성할 필요가 없습니다.

간단한 구성: AWS Lambda와 CloudWatch는 이미 설정된 메트릭을 기반으로 경고를 설정할 수 있으므로 추가적인 구성이나 복잡한 시스템 모니터링을 필요로 하지 않습니다.

자동화된 알림: Lambda가 호출되지 않는 상황을 바로 감지하여 SNS를 통해 알림을 받을 수 있습니다.
다른 옵션들에 비해 이 방법이 가장 직관적이고 관리하기 쉬운 방식입니다.


## 질문 #15
한 회사가 최근에 다른 회사와 그 회사의 모든 AWS 계정을 인수했습니다. 재무 분석가는 이러한 계정의 비용 데이터가 필요합니다.

SysOps 관리자는 Cost Explorer를 사용하여 비용 및 사용 보고서를 생성합니다. SysOps 관리자는 "No Tagkey"가 월 비용의 20%를 차지한다는 것을 알아챘습니다.
SysOps 관리자는 "No Tagkey" 리소스에 태그를 지정하기 위해 무엇을 해야 합니까?

A. AWS Organizations에 계정을 추가합니다. 서비스 제어 정책(SCP)을 사용하여 태그가 지정되지 않은 모든 리소스에 태그를 지정합니다.
B. AWS Config 규칙을 사용하여 태그가 지정되지 않은 리소스를 찾습니다. 리소스를 종료하기 위한 수정 작업을 설정합니다.
C. 비용 탐색기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다.
D. 태그 편집기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다. 가장 많이 투표된

정답은 **D. 태그 편집기를 사용하여 태그가 지정되지 않은 모든 리소스를 찾아 태그를 지정합니다**입니다.

**태그 편집기(Tag Editor)**는 AWS Management Console에서 제공하는 도구로, 여러 AWS 리소스를 한 번에 태그할 수 있습니다. SysOps 관리자는 태그가 지정되지 않은 리소스를 검색하고, 해당 리소스에 태그를 적용하여 "No Tagkey" 문제를 해결할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 서비스 제어 정책(SCP)은 태그를 지정하도록 강제할 수 없으며, AWS Organizations는 리소스를 직접 태그 지정하는 데 사용되지 않습니다.
- **B**: AWS Config 규칙을 사용하면 태그가 없는 리소스를 감지할 수 있지만, 리소스를 종료하는 것은 적절한 조치가 아닙니다.
- **C**: 비용 탐색기는 비용과 사용량 데이터를 분석할 수 있지만, 리소스에 직접 태그를 지정하는 기능은 제공하지 않습니다.

따라서, 가장 효율적인 방법은 태그 편집기를 사용하는 것이므로 **D**가 맞습니다.


## 질문 #16
AWS 관리형 VPN 연결을 설정하는 동안 SysOps 관리자가 AWS에서 고객 게이트웨이 리소스를 만듭니다. 

고객 게이트웨이 장치는 NAT 게이트웨이가 앞에 있는 데이터 센터에 있습니다.
고객 게이트웨이 리소스를 만드는 데 어떤 주소를 사용해야 합니까?

A. 고객 게이트웨이 장치의 개인 IP 주소
B. 고객 게이트웨이 장비 앞의 NAT 장비의 MAC 주소
C. 고객 게이트웨이 장치의 공용 IP 주소
D. 고객 게이트웨이 장치 앞에 있는 NAT 장치의 공용 IP 주소 가장 많이 투표된

정답은 **D. 고객 게이트웨이 장치 앞에 있는 NAT 장치의 공용 IP 주소**입니다.

AWS 관리형 VPN 연결에서 **고객 게이트웨이**는 AWS와 고객의 온프레미스 네트워크 간의 터널을 설정하는 데 사용됩니다. 고객 게이트웨이가 NAT 장치 뒤에 있을 경우, AWS는 고객 게이트웨이에 대한 직접적인 접근이 불가능하기 때문에 **NAT 장치의 공용 IP 주소**를 사용하여 VPN 터널을 설정해야 합니다.

다른 선택지에 대한 설명:
- **A**: 고객 게이트웨이 장치의 개인 IP 주소는 AWS에서 접근할 수 없으므로 사용할 수 없습니다.
- **B**: MAC 주소는 VPN 설정에 필요하지 않습니다.
- **C**: NAT 장치가 앞에 있으므로 고객 게이트웨이 장치의 공용 IP 주소가 아니라, NAT 장치의 공용 IP 주소를 사용해야 합니다.

따라서, **D**가 정답입니다.

## 질문 #17
한 회사에 매일 밤 여러 번 성능 문제가 발생하는 웹 애플리케이션이 있습니다. 

근본 원인 분석 결과 Amazon EC2 Linux 인스턴스에서 5분 동안 지속되는 CPU 사용률의 갑작스러운 증가가 나타났습니다. SysOps 관리자는 CPU를 더 많이 사용하는 서비스 또는 프로세스의 프로세스 ID(PID)를 찾아야 합니다. SysOps
관리자는 최소한의 노력으로 프로세스 사용률 정보를 수집하기 위해 무엇을 해야 합니까?

A. Amazon CloudWatch 에이전트 procstat 플러그인을 구성하여 CPU 프로세스 메트릭을 캡처합니다. 가장 많이 투표된
B. PID를 캡처하고 알림을 보내기 위해 1분마다 실행되도록 AWS Lambda 함수를 구성합니다.
C. 매일 밤 .pem 키를 사용하여 EC2 인스턴스에 로그인합니다. 그런 다음 top 명령을 실행합니다.
D. 기본 Amazon CloudWatch CPU 사용률 지표를 사용하여 CloudWatch에서 PID를 캡처합니다.

정답은 **A. Amazon CloudWatch 에이전트 procstat 플러그인을 구성하여 CPU 프로세스 메트릭을 캡처합니다**입니다.

**procstat 플러그인**은 Amazon CloudWatch 에이전트에서 제공하는 기능으로, 개별 프로세스의 CPU, 메모리 등의 성능 지표를 수집할 수 있습니다. 이를 통해 특정 프로세스의 CPU 사용률과 관련된 상세한 데이터를 얻고, 문제의 근본 원인을 쉽게 파악할 수 있습니다.

다른 선택지에 대한 설명:
- **B**: AWS Lambda 함수는 일반적으로 이벤트 기반 작업에 사용되며, PID 정보를 수집하기 위해 매 분마다 Lambda를 실행하는 것은 비효율적입니다.
- **C**: 매일 밤 EC2에 로그인하고 수동으로 `top` 명령을 실행하는 것은 자동화가 부족하고, 장기적으로 비효율적인 방법입니다.
- **D**: 기본 CloudWatch CPU 사용률 지표는 EC2 인스턴스 수준에서만 제공되며, 개별 프로세스(PID) 수준의 정보를 제공하지 않습니다.

따라서, **A**가 최선의 선택입니다.


## 질문 #18
SysOps 관리자가 하나의 Amazon Elastic Block Store(Amazon EBS) 볼륨이 연결된 단일 Amazon EC2 인스턴스에서 스냅샷을 캡처하도록 AWS Backup을 구성했습니다. 

첫 번째 스냅샷에서 EBS 볼륨에는 10GiB의 데이터가 있습니다. 두 번째 스냅샷에서 EBS 볼륨에는 여전히 10GiB의 데이터가 있지만 4GiB
가 변경되었습니다. 세 번째 스냅샷에서 2GiB의 데이터가 볼륨에 추가되어 총 12GiB가 되었습니다.
이러한 스냅샷을 저장하는 데 필요한 총 스토리지는 얼마입니까?

1. 12기가바이트
2. 16기가바이트 가장 많이 투표된
3. 26기가바이트
4. 32기가바이트

정답은 **B. 16기가바이트**입니다.

스냅샷은 Amazon EBS 볼륨의 **증분 백업**을 수행합니다. 즉, 첫 번째 스냅샷은 전체 데이터를 저장하지만, 이후 스냅샷은 변경된 데이터만 저장합니다. 이 경우, 스토리지 계산은 다음과 같이 이루어집니다:

1. **첫 번째 스냅샷**: 전체 데이터인 10GiB가 저장됩니다.
2. **두 번째 스냅샷**: 변경된 데이터 4GiB만 저장됩니다.
3. **세 번째 스냅샷**: 추가된 2GiB의 데이터만 저장됩니다.

따라서, 총 저장되는 데이터는 **10GiB + 4GiB + 2GiB = 16GiB**입니다.

따라서, 정답은 **B. 16기가바이트**입니다.

## 질문 #19
한 팀이 AWS Organizations의 조직 구성원인 AWS 계정을 관리하고 있습니다. 

조직은 통합 청구 기능을 활성화했습니다. 계정은 여러 애플리케이션을 호스팅합니다.
SysOps 관리자가 환경을 반영하기 위해 계정 내 리소스에 태그를 적용했습니다. 팀에는 환경별 요금 내역 보고서가 필요합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 태그 편집기에서 리소스 그룹을 필터링, 매핑하고 분류합니다.
B. 조직의 서비스 제어 정책(SCP)이 비용 할당 태그에 대한 액세스를 허용하는지 확인합니다.
C. Cost Explorer에 액세스하는 데 사용되는 IAM 자격 증명에 태그별로 비용을 그룹화할 수 있는 권한이 있는지 확인하세요.
D. 조직의 관리 계정에서 비용 할당을 위한 태그 키를 활성화합니다. 가장 많이 투표된

정답은 **D. 조직의 관리 계정에서 비용 할당을 위한 태그 키를 활성화합니다**입니다.

AWS에서는 **비용 할당 태그**를 사용하여 비용을 태그별로 세분화하고 분석할 수 있습니다. SysOps 관리자는 태그를 사용하여 환경별 비용 보고서를 생성하려면, 먼저 AWS Organizations 관리 계정에서 비용 할당을 위한 태그 키를 활성화해야 합니다. 이렇게 하면 해당 태그를 사용해 리소스 비용을 Cost Explorer에서 그룹화하고 분석할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 태그 편집기는 리소스를 태그별로 그룹화하는 데 사용될 수 있지만, 비용 분석을 위해서는 Cost Explorer와 비용 할당 태그가 필요합니다.
- **B**: SCP는 태그 액세스와 직접적인 관련이 없으며, 비용 할당 태그 활성화에 필요하지 않습니다.
- **C**: IAM 권한이 중요하지만, 우선적으로 비용 할당 태그를 활성화해야 태그별 비용을 그룹화할 수 있습니다.

따라서, **D**가 정답입니다.

## 질문 #20
한 회사에서 AWS CloudFormation 템플릿을 사용하여 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스를 프로비저닝합니다. 

SysOps 관리자는 EC2 인스턴스가 시작되기 전에 DB 인스턴스가 생성되도록 템플릿을 업데이트해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 템플릿에 대기 조건을 추가합니다. EC2 인스턴스가 시작된 후 신호를 보내도록 EC2 인스턴스 사용자 데이터 스크립트를 업데이트합니다.
B. EC2 인스턴스 리소스에 DependsOn 특성을 추가하고 RDS 리소스의 논리적 이름을 제공합니다. 가장 많이 투표된
C. 템플릿에서 리소스 순서를 변경하여 RDS 리소스가 EC2 인스턴스 리소스보다 앞에 나열되도록 합니다.
D. 여러 템플릿을 만듭니다. AWS CloudFormation StackSets를 사용하여 두 번째 스택이 생성되기 전에 한 스택이 완료될 때까지 기다립니다.

정답은 **B. EC2 인스턴스 리소스에 DependsOn 특성을 추가하고 RDS 리소스의 논리적 이름을 제공합니다**입니다.

AWS CloudFormation에서는 **DependsOn 특성**을 사용하여 리소스 간의 종속성을 정의할 수 있습니다. 이를 통해 특정 리소스가 다른 리소스가 완전히 생성된 후에 시작되도록 할 수 있습니다. 이 경우, EC2 인스턴스 리소스에 DependsOn 특성을 추가하여 RDS DB 인스턴스가 먼저 생성된 후 EC2 인스턴스가 시작되도록 지정할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: 대기 조건과 신호는 리소스가 특정 상태에 도달했을 때까지 기다리도록 하는 방법이지만, 이 경우보다 간단하게 DependsOn을 사용하는 것이 더 적합합니다.
- **C**: 템플릿에서 리소스 순서를 변경하는 것은 리소스 생성 순서에 영향을 미치지 않습니다. CloudFormation은 리소스의 논리적 순서가 아닌 종속성을 기반으로 리소스를 생성합니다.
- **D**: 여러 템플릿을 만드는 것은 불필요하게 복잡한 방법이며, 하나의 템플릿 내에서 해결할 수 있습니다.

따라서, **B**가 가장 적절한 선택입니다.

## 질문 #21
한 회사가 Amazon S3에 정적 웹사이트를 호스팅합니다. 

이 웹사이트는 기본 TTL이 86,400초인 Amazon CloudFront 배포판에서 제공됩니다.
이 회사는 최근 웹사이트의 업데이트된 버전을 Amazon S3에 업로드했습니다. 그러나 사용자는 사이트를 새로 고칠 때 여전히 이전 콘텐츠를 봅니다. SysOps 관리자는 가능한 한 빨리 사용자에게 새 버전의 웹사이트를 표시해야 합니다.
이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. CloudFront 배포를 가리키는 DNS CNAME 레코드의 TTL 값을 조정합니다.

B. CloudFront 배포에서 이전 S3 객체에 대한 무효화를 생성합니다. 가장 많이 투표된

C. 새 CloudFront 배포를 만듭니다. DNS 레코드를 업데이트하여 새 CloudFront 배포를 가리킵니다.

D. 웹사이트의 DNS 레코드를 업데이트하여 S3 버킷을 가리키도록 합니다.


정답은 **B. CloudFront 배포에서 이전 S3 객체에 대한 무효화를 생성합니다**입니다.

Amazon CloudFront는 기본적으로 객체를 캐시하여 성능을 최적화합니다. 웹사이트를 업데이트한 후에도 사용자가 여전히 이전 콘텐츠를 보는 이유는 캐시된 콘텐츠가 만료되지 않았기 때문입니다. CloudFront에서 **무효화(invalidation)**를 생성하면 캐시된 객체를 제거하여 사용자에게 최신 콘텐츠를 제공할 수 있습니다. 

다른 선택지에 대한 설명:
- **A**: DNS CNAME 레코드의 TTL 값은 CloudFront 캐시와 관련이 없으며, 이를 조정해도 캐시된 콘텐츠 문제는 해결되지 않습니다.
- **C**: 새 CloudFront 배포를 만드는 것은 불필요하게 복잡한 작업입니다. 무효화를 통해 문제를 해결할 수 있습니다.
- **D**: S3 버킷을 직접 가리키도록 DNS를 업데이트하면 CloudFront의 캐싱 및 성능 이점을 잃게 됩니다. 이는 최선의 방법이 아닙니다.

따라서, **B**가 가장 적절한 솔루션입니다.


## 질문 #22
SysOps 관리자는 AWS CloudFormation을 사용하여 회사의 클라우드 인프라를 관리할 책임이 있습니다. 

SysOps 관리자는 여러 AWS 서비스로 구성된 단일 리소스를 만들어야 합니다. 리소스는 CloudFormation 콘솔을 통한 생성 및 삭제를 지원해야 합니다. SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 CloudFormation 리소스 유형을 만들어야 합니까?

A. cfn-init 헬퍼 스크립트가 있는 AWS::EC2::Instance
B. AWS::OpsWorks::인스턴스
C. AWS::SSM::문서
D. 사용자 정의::MyCustomType 가장 많이 투표된

정답은 **D. 사용자 정의::MyCustomType**입니다.

AWS CloudFormation에서 **사용자 정의 리소스**를 사용하면 여러 AWS 서비스로 구성된 복잡한 리소스를 만들 수 있습니다. 사용자 정의 리소스를 사용하면 CloudFormation 콘솔을 통해 리소스를 생성하고 삭제할 수 있으며, 필요에 따라 특정 로직이나 기능을 구현할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: `AWS::EC2::Instance`는 단일 EC2 인스턴스를 생성하는 리소스이며, 여러 AWS 서비스로 구성된 단일 리소스를 지원하지 않습니다.
- **B**: `AWS::OpsWorks::Instance`는 OpsWorks 서비스를 사용하는 인스턴스를 생성하는 리소스이지만, 여러 서비스로 구성된 리소스를 직접 지원하지는 않습니다.
- **C**: `AWS::SSM::Document`는 AWS Systems Manager에서 사용할 수 있는 문서 리소스를 생성하지만, CloudFormation 콘솔을 통한 리소스 생성 및 삭제의 요구 사항을 충족하지 않습니다.

따라서, 여러 AWS 서비스로 구성된 단일 리소스를 만들고 관리하기 위해서는 **D. 사용자 정의::MyCustomType**을 사용하는 것이 가장 적절합니다.

## 질문 #23
새로운 웹사이트는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 

Amazon Route 53은 DNS 레코드를 관리하는 데 사용됩니다.
웹사이트의 정점 도메인 이름(예: `company.com`)을 Application Load Balancer로 가리키기 위해 Route 53에 어떤 유형의 레코드를 설정해야 합니까?

1. CNAME
2. SOA
3. 텍스트
4. 별칭 가장 많이 투표된

정답은 **D. 별칭**입니다.

Amazon Route 53에서 **별칭 레코드**는 Route 53에서 제공하는 특별한 레코드 유형으로, Amazon Web Services(AWS) 리소스를 직접 가리킬 수 있습니다. Application Load Balancer(ALB)와 같은 AWS 리소스에 대해 별칭 레코드를 설정하면, ALB의 DNS 이름을 Route 53에서 가리킬 수 있으며, 사용자가 ALB를 통해 웹사이트에 접근할 수 있습니다. 

별칭 레코드는 루트 도메인(예: `company.com`)에서도 사용할 수 있어 CNAME 레코드보다 더 유용합니다. CNAME 레코드는 루트 도메인에 사용할 수 없기 때문입니다.

다른 선택지에 대한 설명:
- **A. CNAME**: CNAME 레코드는 서브도메인에 사용할 수 있지만, 루트 도메인에는 사용할 수 없습니다.
- **B. SOA**: SOA 레코드는 도메인 존의 시작을 나타내는 레코드로, DNS를 관리하는 데 필요하지만, ALB를 가리키기 위한 레코드는 아닙니다.
- **C. 텍스트**: TXT 레코드는 도메인에 대한 텍스트 정보를 저장하는 데 사용되며, ALB와는 관련이 없습니다.

따라서, 웹사이트의 정점 도메인 이름을 Application Load Balancer로 가리키기 위해서는 **D. 별칭** 레코드를 설정하는 것이 정답입니다.

## 질문 #24
한 회사가 AWS Trusted Advisor를 사용하여 보안 및 규정 준수를 구현하고 있습니다. 

회사의 SysOps 팀은 액세스할 수 있는 Trusted Advisor 검사 목록을 검증하고 있습니다.
사용 가능한 Trusted Advisor 검사의 양에 영향을 미치는 요소는 무엇입니까?

A. 최소한 하나의 Amazon EC2 인스턴스가 실행 상태인지 여부
B. AWS 지원 계획 가장 많이 투표된
C. AWS Organizations 서비스 제어 정책(SCP)
D. AWS 계정 루트 사용자가 다중 요소 인증(MFA)을 활성화했는지 여부

정답은 **B. AWS 지원 계획**입니다.

AWS Trusted Advisor의 기능은 고객이 선택한 **AWS 지원 계획**에 따라 다릅니다. 기본적인 지원 계획에서는 제한된 검사만 사용할 수 있지만, **Developer**, **Business**, 또는 **Enterprise** 지원 계획을 이용하면 더 많은 검사 및 권장 사항에 접근할 수 있습니다.

다른 선택지에 대한 설명:
- **A**: EC2 인스턴스의 실행 여부는 Trusted Advisor의 검사 수에 직접적인 영향을 미치지 않습니다.
- **C**: 서비스 제어 정책(SCP)은 AWS Organizations 내에서 계정의 권한을 관리하는 데 사용되지만, Trusted Advisor 검사 목록에 직접적인 영향을 주지는 않습니다.
- **D**: MFA 활성화 여부는 보안 측면에서 중요하지만, Trusted Advisor 검사 수와는 관련이 없습니다.

따라서, Trusted Advisor에서 사용할 수 있는 검사의 양에 영향을 미치는 요소는 **B. AWS 지원 계획**입니다.

## 질문 #25
SysOps 관리자가 MariaDB DB 인스턴스용 Amazon RDS에서 문제를 조사하고 있습니다. 

SysOps 관리자는 자세한 대기 이벤트로 분류된 데이터베이스 부하를 표시하려고 합니다.
SysOps 관리자는 어떻게 이 목표를 달성할 수 있습니까?

A. Amazon CloudWatch 대시보드를 만듭니다.
B. Amazon RDS 성능 통찰력을 활성화합니다. 가장 많이 투표된
C. 향상된 모니터링을 활성화하고 구성합니다.
D. Amazon CloudWatch Logs에서 데이터베이스 로그를 검토합니다.

정답은 **C. 향상된 모니터링을 활성화하고 구성합니다**입니다.

**향상된 모니터링**을 활성화하면 Amazon RDS에서 MariaDB DB 인스턴스의 상세한 대기 이벤트 및 메트릭을 수집할 수 있습니다. 이 기능을 사용하면 데이터베이스의 CPU, 메모리, I/O 및 대기 이벤트와 같은 여러 지표를 실시간으로 모니터링하고, DB 인스턴스의 성능 문제를 더 잘 이해할 수 있습니다.

다른 선택지에 대한 설명:
- **A. Amazon CloudWatch 대시보드를 만듭니다**: CloudWatch 대시보드는 여러 메트릭을 시각화하는 데 유용하지만, 대기 이벤트와 같은 상세한 성능 메트릭은 향상된 모니터링을 통해 얻는 것이 더 정확합니다.
- **B. Amazon RDS 성능 통찰력을 활성화합니다**: 성능 통찰력은 데이터베이스 성능을 분석하는 데 유용하지만, 대기 이벤트에 대한 세부 정보를 직접적으로 제공하지는 않습니다.
- **D. Amazon CloudWatch Logs에서 데이터베이스 로그를 검토합니다**: CloudWatch Logs는 로그 정보를 제공하지만, 대기 이벤트에 대한 실시간 모니터링 및 메트릭을 제공하지 않습니다.

따라서, MariaDB DB 인스턴스에서 자세한 대기 이벤트를 확인하기 위해서는 **C. 향상된 모니터링을 활성화하고 구성하는 것**이 가장 적절한 방법입니다.

## 질문 #26
한 회사가 여러 가용성 영역에 분산된 Amazon EC2 인스턴스 세트에서 애플리케이션을 호스팅할 계획입니다. 

애플리케이션은 매초 수백만 건의 요청으로 확장할 수 있어야 합니다.
SysOps 관리자는 트래픽을 EC2 인스턴스로 분산하는 솔루션을 설계해야 합니다. 솔루션은 각 가용성 영역에 단일 정적 IP 주소를 사용하면서 갑작스럽고 불안정한 트래픽 패턴을 처리하도록 최적화되어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. Amazon Simple Queue Service(Amazon SQS) 대기열
B. 애플리케이션 로드 밸런서
C. AWS 글로벌 엑셀러레이터
D. 네트워크 로드 밸런서 가장 많이 투표된

정답은 **D. 네트워크 로드 밸런서**입니다.

**네트워크 로드 밸런서(NLB)**는 고속 TCP 및 UDP 트래픽을 처리할 수 있으며, 각 가용성 영역(AZ)에 단일 정적 IP 주소를 제공하는 기능을 가지고 있습니다. 이는 트래픽이 EC2 인스턴스로 효과적으로 분산되도록 하며, 갑작스럽고 불안정한 트래픽 패턴을 처리하는 데 최적화되어 있습니다. 

다른 선택지에 대한 설명:
- **A. Amazon Simple Queue Service (Amazon SQS) 대기열**: SQS는 메시지 큐 서비스로, 메시지를 비동기적으로 처리하는 데 적합하지만, 실시간 트래픽 분산에는 적합하지 않습니다.
- **B. 애플리케이션 로드 밸런서**: 애플리케이션 로드 밸런서는 HTTP/HTTPS 트래픽을 처리하는 데 최적화되어 있지만, 단일 정적 IP 주소를 제공하는 기능은 없으며, TCP 트래픽 처리에 있어 NLB보다 성능이 떨어질 수 있습니다.
- **C. AWS 글로벌 엑셀러레이터**: 글로벌 엑셀러레이터는 전 세계에 분산된 애플리케이션의 성능을 향상시키기 위한 서비스이지만, EC2 인스턴스 간의 트래픽 분산에는 직접적인 영향을 주지 않습니다.

따라서, **D. 네트워크 로드 밸런서**가 이러한 요구 사항을 충족하는 최적의 솔루션입니다.

## 질문 #27
SysOps 관리자가 AWS CloudFormation StackSets를 사용하여 동일한 AWS 계정의 두 AWS 리전에 AWS 리소스를 만들고 있습니다. 

한 리전에서 스택 작업이 실패하고 스택 인스턴스 상태가 OUTDATED로 반환됩니다.
이 실패의 원인은 무엇입니까?

A. CloudFormation 템플릿이 로컬 디스크에서 변경되어 CloudFormation에 제출되지 않았습니다.
B. CloudFormation 템플릿은 고유하지 않은 글로벌 리소스를 만들려고 합니다. 가장 많이 투표된
C. 스택이 아직 해당 지역에 배포되지 않았습니다.
D. SysOps 관리자가 CloudFormation API의 이전 버전을 사용하고 있습니다.

정답은 **B. CloudFormation 템플릿은 고유하지 않은 글로벌 리소스를 만들려고 합니다**입니다.

AWS CloudFormation StackSets는 여러 AWS 리전 또는 계정에 리소스를 배포할 수 있는 기능을 제공하지만, 글로벌 리소스(예: IAM, Route 53, S3 등)는 특정 리전에 종속되지 않으며, 이를 여러 리전에서 동시에 생성하려고 하면 충돌이 발생할 수 있습니다. 이러한 이유로 인해 스택 작업이 실패하고 상태가 OUTDATED로 반환될 수 있습니다.

다른 선택지에 대한 설명:
- **A**: CloudFormation 템플릿이 로컬 디스크에서 변경된 경우, 이는 작업 실패의 원인이 되지 않습니다. 스택 인스턴스의 상태는 템플릿 변경과는 무관하게 업데이트되며, 실패한 스택 인스턴스는 OUTDATED 상태로 표시됩니다.
- **C**: 스택이 아직 해당 지역에 배포되지 않았다면, 스택 인스턴스 상태가 OUTDATED가 아닌 PENDING 상태일 것입니다.
- **D**: CloudFormation API의 이전 버전을 사용하고 있다고 해서 특정 리전에서 스택 작업이 실패하는 것은 아닙니다. 

따라서, **B**가 스택 작업 실패의 올바른 원인입니다.

## 질문 #28
SysOps 관리자는 Amazon S3를 구성하여 간단한 비생산 웹페이지를 호스팅해야 합니다.

SysOps 관리자는 AWS Management Console에서 빈 S3 버킷을 만들었습니다. S3 버킷에는 기본 구성이 있습니다.
SysOps 관리자는 이 프로세스를 완료하기 위해 어떤 작업 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. "객체에 대한 요청 리디렉션" 기능을 사용하여 버킷 루트 URL을 가리키도록 S3 버킷을 구성합니다.
B. "모든 퍼블릭 액세스 차단" 설정을 끕니다. <Permission>WEBSITE</Permission>가 포함된 버킷 ACL을 사용하여 퍼블릭 액세스를 허용합니다.
C. "모든 퍼블릭 액세스 차단" 설정을 끕니다. AuthenticatedUsers 수혜자에게 액세스를 허용하는 버킷 ACL을 사용하여 퍼블릭 액세스를 허용합니다.
D. "모든 퍼블릭 액세스 차단" 설정을 끕니다. "Principal"을 허용하는 버킷 정책을 설정합니다: s3:GetObject 작업. 가장 많이 투표된
E. index.html 문서를 만듭니다. 정적 웹사이트 호스팅을 구성하고 인덱스 문서를 S3 버킷에 업로드합니다. 가장 많이 투표된


정답은 **D. "모든 퍼블릭 액세스 차단" 설정을 끕니다. "Principal"을 허용하는 버킷 정책을 설정합니다: s3:GetObject 작업.**와 **E. index.html 문서를 만듭니다. 정적 웹사이트 호스팅을 구성하고 인덱스 문서를 S3 버킷에 업로드합니다.**입니다.

## 선택 이유:
1. **D**: S3 버킷에 대해 "모든 퍼블릭 액세스 차단" 설정을 끄고, **버킷 정책**을 설정하여 공개적으로 객체에 접근할 수 있도록 허용해야 합니다. 이 정책은 `s3:GetObject` 작업을 허용하여 사용자가 S3 버킷의 콘텐츠를 접근할 수 있게 합니다.

2. **E**: 정적 웹사이트 호스팅을 활성화하려면 `index.html` 문서를 생성하고 이를 S3 버킷에 업로드해야 합니다. 그런 다음 S3에서 정적 웹사이트 호스팅을 설정하여 `index.html`을 기본 문서로 지정해야 합니다.

## 다른 선택지:
- **A**: "객체에 대한 요청 리디렉션" 기능은 정적 웹사이트를 호스팅하는 데 필요하지 않으며, 기본 구성이 필요합니다.
- **B**: "모든 퍼블릭 액세스 차단"을 끄는 것은 맞지만, **버킷 ACL**로 퍼블릭 액세스를 설정하는 것은 최선의 방법이 아닙니다. **버킷 정책**을 사용하는 것이 더 권장됩니다.
- **C**: AuthenticatedUsers 수혜자에게 액세스를 허용하는 것은 비생산 웹페이지의 목적에 부합하지 않으며, 퍼블릭 액세스를 완전히 허용하지 않습니다.

따라서, 올바른 조합은 **D**와 **E**입니다.

## 질문 #29
한 회사에서는 point-in-time 복구, 백트래킹, 자동 백업이 활성화된 Amazon Aurora MySQL DB 클러스터를 사용하고 있습니다. 

SysOps 관리자는 DB 클러스터를 이전 72시간 내의 특정 복구 지점으로 롤백할 수 있어야 합니다. 복원은 동일한 프로덕션 DB 클러스터에서 완료해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?


A. Aurora Replica를 생성합니다. 복제본을 홍보하여 ​​기본 DB 인스턴스를 대체합니다.
B. 기존 DB 클러스터에 자동 백업을 복원하는 AWS Lambda 함수를 생성합니다.
C. 백트래킹을 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 되돌립니다. 가장 많이 투표된
D. 지정 시점 복구를 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 복원합니다.

정답은 **C. 백트래킹을 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 되돌립니다**입니다.

## 선택 이유:
- **C. 백트래킹**: Amazon Aurora MySQL의 백트래킹 기능을 사용하면 DB 클러스터를 특정 시점으로 쉽게 되돌릴 수 있습니다. 이 기능은 72시간 이내의 복구 지점으로 롤백할 수 있는 기능을 제공합니다. 백트래킹은 실제 데이터를 변경하지 않고 특정 시점으로 데이터베이스를 되돌리는 매우 유용한 방법입니다.

## 다른 선택지:
- **A. Aurora Replica를 생성합니다. 복제본을 홍보하여 기본 DB 인스턴스를 대체합니다**: 이 방법은 클러스터의 복제를 제공할 수 있지만, 특정 복구 지점으로 롤백하는 것은 아닙니다.
  
- **B. 기존 DB 클러스터에 자동 백업을 복원하는 AWS Lambda 함수를 생성합니다**: 자동 백업을 복원할 수 있지만, 이 경우 기존 DB 클러스터에서 직접 복원할 수는 없습니다. 새로운 DB 클러스터를 생성하게 됩니다.
  
- **D. 지정 시점 복구를 사용하여 기존 DB 클러스터를 원하는 복구 지점으로 복원합니다**: 지정 시점 복구는 새로운 DB 인스턴스를 생성하며, 기존 클러스터를 직접 복원하는 것이 아니기 때문에 요구 사항에 맞지 않습니다.

따라서, **C**가 요구 사항을 충족하는 최적의 솔루션입니다.

## 질문 #30
Amazon EC2 콘솔에서 작업하는 사용자가 Amazon EC2 Windows 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨의 크기를 늘렸습니다. 

변경 사항은 파일 시스템에 반영되지 않습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 운영 체제 수준 도구로 파일 시스템을 확장하여 새로운 저장 용량을 활용합니다. 가장 많이 투표된
B. EBS 볼륨을 EC2 인스턴스에 다시 연결합니다.
C. EBS 볼륨에 연결된 EC2 인스턴스를 재부팅합니다.
D. EBS 볼륨의 스냅샷을 찍습니다. 원래 볼륨을 스냅샷에서 생성된 볼륨으로 바꿉니다.


정답은 **A. 운영 체제 수준 도구로 파일 시스템을 확장하여 새로운 저장 용량을 활용합니다**입니다.

## 선택 이유:
- **A. 운영 체제 수준 도구로 파일 시스템을 확장**: Amazon EBS 볼륨의 크기를 늘린 후, 운영 체제의 파일 시스템도 해당 변경 사항을 인식하도록 확장해야 합니다. Windows에서는 Disk Management 도구를 사용하여 볼륨의 크기를 늘리거나 `diskpart` 명령어를 사용하여 크기를 조정할 수 있습니다. 이 단계를 수행해야만 새로 할당된 저장 용량을 사용할 수 있습니다.

## 다른 선택지:
- **B. EBS 볼륨을 EC2 인스턴스에 다시 연결합니다**: EBS 볼륨의 크기를 늘린 후에는 다시 연결할 필요가 없습니다. 이미 연결되어 있으므로 이 작업은 불필요합니다.
  
- **C. EBS 볼륨에 연결된 EC2 인스턴스를 재부팅합니다**: 인스턴스를 재부팅해도 파일 시스템의 크기는 자동으로 조정되지 않으며, 실제로는 운영 체제 수준에서 파일 시스템을 수동으로 확장해야 합니다.
  
- **D. EBS 볼륨의 스냅샷을 찍고 원래 볼륨을 스냅샷에서 생성된 볼륨으로 바꾼다**: 이 방법은 불필요한 작업입니다. EBS 볼륨 크기를 변경한 후 파일 시스템을 확장하는 것만으로도 충분합니다.

따라서, **A**가 문제를 해결하기 위한 올바른 방법입니다.


## 질문 #31
SysOps 관리자가 Amazon EC2 인스턴스를 사용하여 애플리케이션을 호스팅하고 있습니다. 

SysOps 관리자는 애플리케이션이 Amazon DynamoDB 테이블에 액세스할 수 있는 권한을 부여해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. DynamoDB 테이블에 액세스하기 위한 액세스 키를 만듭니다. 액세스 키를 EC2 인스턴스 프로필에 할당합니다.
B. DynamoDB 테이블에 액세스하기 위한 EC2 키 쌍을 만듭니다. 키 쌍을 EC2 인스턴스 프로필에 할당합니다.
C. DynamoDB 테이블에 액세스하기 위한 IAM 사용자를 만듭니다. EC2 인스턴스 프로필에 IAM 사용자를 할당합니다.
D. DynamoDB 테이블에 액세스하기 위한 IAM 역할을 만듭니다. EC2 인스턴스 프로필에 IAM 역할을 할당합니다. 가장 많이 투표된

정답은 **D. DynamoDB 테이블에 액세스하기 위한 IAM 역할을 만듭니다. EC2 인스턴스 프로필에 IAM 역할을 할당합니다**입니다.

## 선택 이유:
- **D. IAM 역할을 사용하여 EC2 인스턴스에 권한 부여**: IAM 역할은 AWS 서비스에 대한 권한을 관리하는 안전한 방법입니다. EC2 인스턴스에 IAM 역할을 할당하면, 해당 인스턴스에서 실행되는 애플리케이션이 IAM 역할에 부여된 권한을 사용하여 DynamoDB 테이블에 액세스할 수 있습니다. 이 방법은 보안성을 높이고, 액세스 키를 관리할 필요 없이 자동으로 자격 증명을 관리합니다.

## 다른 선택지:
- **A. 액세스 키를 만듭니다**: 액세스 키를 사용하면 보안 문제가 발생할 수 있습니다. 또한 EC2 인스턴스에 액세스 키를 직접 할당하는 것은 안전하지 않습니다.
  
- **B. EC2 키 쌍을 만듭니다**: 키 쌍은 EC2 인스턴스에 대한 SSH 액세스를 위한 것이지, DynamoDB에 대한 액세스 권한을 부여하지 않습니다.

- **C. IAM 사용자를 만듭니다**: IAM 사용자를 생성하는 것은 가능하지만, EC2 인스턴스에 IAM 사용자 권한을 직접 할당하는 것은 권장되지 않습니다. 대신 IAM 역할을 사용하는 것이 더 안전하고 관리하기 쉽습니다.

따라서, **D**가 가장 적절한 솔루션입니다.



## 질문 #32
SysOps 관리자가 Amazon S3 버킷의 객체를 실수로 덮어쓰거나 삭제하지 못하도록 보호하려고 합니다. 

현재가 아닌 객체는 90일 동안 보관한 다음 영구적으로 삭제해야 합니다. 객체는 원래 S3 버킷과 동일한 AWS 리전에 있어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. S3 버킷에 대한 Amazon Data Lifecycle Manager(Amazon DLM) 수명 주기 정책을 만듭니다. 90일 후에 비현재 객체를 삭제하는 규칙을 수명 주기 정책에 추가합니다.
B. S3 버킷에 대한 AWS 백업 정책을 만듭니다. 90일 후에 비현재 객체를 만료하는 라이프사이클을 포함하는 백업 규칙을 만듭니다.
C. S3 버킷에서 S3 크로스 리전 복제를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다.
D. S3 버킷에서 S3 버전 관리를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다. 가장 많이 투표된

가장 적합한 솔루션은 **D. S3 버킷에서 S3 버전 관리를 활성화합니다. 버킷에 대한 S3 라이프사이클 정책을 생성하여 90일 후에 현재가 아닌 객체를 만료합니다.**

이유:

1. **S3 버전 관리 활성화**:  
   S3 버전 관리를 활성화하면 객체가 실수로 덮어써지거나 삭제되는 것을 방지할 수 있습니다. 버전 관리가 활성화된 버킷에서는 객체가 수정되거나 삭제될 때 이전 버전이 보존되며, 이를 통해 의도하지 않은 수정이나 삭제를 복구할 수 있습니다.

2. **라이프사이클 정책**:  
   라이프사이클 정책을 사용하면 S3 버킷에서 **비현재(non-current) 객체**를 90일 동안 유지하고 이후에 자동으로 삭제할 수 있습니다. 이는 객체가 덮어쓰여지거나 삭제된 후에도 이전 버전을 90일 동안 유지하면서 비용을 절감하고, 수동 작업 없이 자동으로 오래된 객체를 삭제할 수 있습니다.


다른 선택지에 대한 설명:

- **A. S3 버킷에 대한 Amazon Data Lifecycle Manager(Amazon DLM) 수명 주기 정책**:
  - **Amazon DLM**은 EBS 볼륨의 스냅샷 관리에 주로 사용되며, S3 객체 관리에는 적합하지 않습니다.

- **B. S3 버킷에 대한 AWS 백업 정책**:
  - **AWS 백업**은 다양한 AWS 리소스의 백업 및 복구를 관리하는 서비스이지만, S3 객체에 대한 백업과 수명 주기 관리는 S3 라이프사이클 정책과 버전 관리로 처리하는 것이 더 적합합니다.

- **C. S3 버킷에서 S3 크로스 리전 복제를 활성화**:
  - 크로스 리전 복제는 객체를 다른 AWS 리전으로 복제하는 기능입니다. 그러나 이 시나리오에서는 동일한 리전 내에서 객체를 관리해야 하며, 이 방식은 요구사항과 일치하지 않습니다.

결론적으로, **D 옵션**은 S3 버전 관리를 통해 실수로 객체가 삭제되거나 덮어쓰여지는 것을 방지하고, 라이프사이클 정책을 통해 90일 후에 비현재 객체를 삭제하는 요구 사항을 충족합니다.


## 질문 #33
한 회사에 고객이 웹사이트에서 레코드를 검색하는 데 사용하는 애플리케이션이 있습니다. 

애플리케이션의 데이터는 Amazon Aurora DB 클러스터에 저장됩니다. 애플리케이션의 사용은 계절과 요일에 따라 다릅니다.
웹사이트의 인기가 증가하고 있으며, 활동이 가장 많은 기간에 DB 클러스터에 부하가 증가하여 웹사이트 성능이 저하되고 있습니다. 애플리케이션 로그에 따르면 성능 문제는 사용자가 정보를 검색할 때 발생합니다. 동일한 검색을 여러 번 수행하는 경우는 드뭅니다.
SysOps 관리자는 리소스 효율성을 극대화하는 솔루션을 사용하여 플랫폼의 성능을 개선해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. DB 클러스터 앞에 Amazon ElastiCache for Redis 클러스터를 배포합니다. 애플리케이션이 데이터베이스에 새 쿼리를 발행하기 전에 캐시를 확인하도록 애플리케이션을 수정합니다. 모든 쿼리의 결과를 캐시에 추가합니다.
B. DB 클러스터에 Aurora Replica를 배포합니다. 검색 작업에 리더 엔드포인트를 사용하도록 애플리케이션을 수정합니다. Aurora Auto Scaling을 사용하여 부하에 따라 복제본 수를 확장합니다. 가장 많이 투표된
C. DB 클러스터를 지원하는 스토리지 볼륨에서 프로비저닝된 IOPS를 사용하여 애플리케이션의 최대 부하를 지원할 수 있을 만큼 성능을 ​​향상시킵니다.
D. DB 클러스터의 인스턴스 크기를 애플리케이션의 최대 부하를 지원하기에 충분한 크기로 늘립니다. Aurora Auto Scaling을 사용하여 부하에 따라 인스턴스 크기를 조정합니다.

이 문제에서 성능 저하의 주요 원인은 데이터베이스에 대한 읽기 부하입니다. 애플리케이션 로그에 따르면, 사용자가 정보를 검색할 때 성능 문제가 발생하고, 동일한 검색이 여러 번 발생하지는 않습니다. 따라서 효율적으로 데이터를 캐싱하거나 읽기 성능을 확장할 수 있는 방법이 필요합니다.

가장 적합한 솔루션은 **B. DB 클러스터에 Aurora Replica를 배포합니다. 검색 작업에 리더 엔드포인트를 사용하도록 애플리케이션을 수정합니다. Aurora Auto Scaling을 사용하여 부하에 따라 복제본 수를 확장합니다.**

이유:

1. **Aurora Replica를 사용한 읽기 성능 확장**:
   - Aurora는 읽기 작업을 처리하기 위해 **읽기 전용 복제본(Replica)**을 추가할 수 있습니다. 복제본을 추가하면 읽기 요청을 이 복제본으로 분산시켜 DB 클러스터의 **읽기 부하를 완화**할 수 있습니다. 이는 사용자가 데이터를 검색할 때 성능 문제를 해결하는 데 매우 효과적입니다.
   
2. **Aurora Auto Scaling**:
   - Aurora는 **Auto Scaling**을 지원하므로, 복제본의 수를 자동으로 확장하거나 축소하여 애플리케이션의 부하에 맞춰 DB 성능을 최적화할 수 있습니다. 계절성과 요일에 따라 애플리케이션의 부하가 달라진다면 Auto Scaling이 유연한 확장 및 축소 기능을 제공합니다.
   
3. **리더 엔드포인트 사용**:
   - 애플리케이션에서 **리더 엔드포인트**를 사용하도록 수정하면 여러 Aurora 복제본으로 읽기 요청을 자동으로 라우팅할 수 있습니다. 이를 통해 데이터베이스의 부하를 분산시키고 성능을 개선할 수 있습니다.

---

다른 선택지에 대한 설명:

- **A. ElastiCache for Redis를 사용한 캐시 적용**:
  - ElastiCache는 자주 사용되는 데이터에 대해 캐시를 제공하여 성능을 개선할 수 있지만, 문제의 근본 원인이 동일한 쿼리가 자주 반복되지 않는 것이라서 이 옵션은 효율성이 떨어질 수 있습니다. 따라서 이 상황에서는 캐시보다는 Aurora 복제본을 사용하여 읽기 성능을 확장하는 것이 더 적합합니다.

- **C. 프로비저닝된 IOPS 사용**:
  - 프로비저닝된 IOPS는 주로 **쓰기 성능**을 향상시키기 위해 사용됩니다. 이 시나리오에서 성능 문제는 **읽기 작업**에 의해 발생하므로, 프로비저닝된 IOPS를 사용하는 것은 적절하지 않습니다.

- **D. 인스턴스 크기 증가 및 Auto Scaling**:
  - Aurora의 인스턴스 크기를 늘리는 것은 일시적으로 성능을 향상시킬 수 있지만, 부하가 변동하는 상황에서는 인스턴스 크기를 증가시키는 것만으로는 장기적인 해결책이 아닙니다. 복제본을 추가하여 읽기 작업을 분산하는 것이 더 효율적이고 비용 절감에도 유리합니다.


따라서 **B 옵션**은 부하를 효과적으로 분산시키고, Aurora의 자동 확장 기능을 통해 유동적인 트래픽 변화에 대응할 수 있으므로 가장 적합한 솔루션입니다.

## 질문 #34
한 회사가 AWS Organizations를 사용하여 여러 AWS 계정을 관리합니다. 

회사 정책에 따라 특정 AWS 지역만 고객 데이터를 저장하고 처리하는 데 사용할 수 있습니다. SysOps 관리자는 회사의 모든 사람이 승인되지 않은 지역에서 Amazon EC2 인스턴스를 프로비저닝하는 것을 방지해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 모든 리전에서 AWS CloudTrail을 구성하여 모든 API 활동을 기록합니다. 모든 승인되지 않은 리전에서 ec2:RunInstances 이벤트에 대한 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. AWS Lambda를 사용하여 시작된 EC2 인스턴스를 종료합니다.

B. 각 AWS 계정에서 Region 조건을 사용하여 모든 승인되지 않은 Region에서 ec2:RunInstances 작업을 거부하는 관리형 IAM 정책을 만듭니다. 이 정책을 각 AWS 계정의 모든 IAM 그룹에 연결합니다.

C. 각 AWS 계정에서 Region 조건을 사용하여 모든 승인되지 않은 Region에서 ec2:RunInstances 작업을 거부하는 IAM 권한 경계 정책을 만듭니다. 각 AWS 계정의 모든 IAM 사용자에게 권한 경계 정책을 연결합니다.

D. AWS Organizations에서 서비스 제어 정책(SCP)을 만들어 모든 승인되지 않은 Regions에서 ec2:RunInstances 작업을 거부합니다. 이 정책을 조직의 루트 수준에 연결합니다. 가장 많이 투표된


이 시나리오에서 회사의 모든 AWS 계정이 승인되지 않은 지역에서 Amazon EC2 인스턴스를 프로비저닝하는 것을 방지하기 위한 가장 운영 효율적인 솔루션은 
**D. AWS Organizations에서 서비스 제어 정책(SCP)을 만들어 모든 승인되지 않은 Regions에서 ec2:RunInstances 작업을 거부합니다. 이 정책을 조직의 루트 수준에 연결합니다.**

### 이유:

1. **서비스 제어 정책(SCP)**:
   - SCP는 AWS Organizations의 핵심 기능으로, 조직의 모든 계정에 적용할 수 있는 권한 정책입니다. SCP를 사용하면 특정 AWS 서비스 및 API 작업에 대한 액세스를 전역적으로 제어할 수 있습니다. 이 경우 EC2 인스턴스를 특정 지역에서만 실행할 수 있도록 제한하는 SCP를 설정할 수 있습니다.

2. **조직의 루트 수준에서 적용**:
   - SCP는 조직의 루트 수준에서 설정할 수 있으며, 모든 하위 계정에 일관되게 적용됩니다. 이렇게 하면 각 계정의 IAM 정책을 따로 관리할 필요 없이, 중앙 집중식으로 관리할 수 있어 운영 효율성이 높아집니다.

3. **정책 관리의 용이성**:
   - SCP를 사용하면 새로운 계정을 추가할 때마다 정책을 별도로 적용할 필요 없이 조직 내 모든 계정에 자동으로 적용됩니다. 이를 통해 정책 관리의 복잡성을 줄일 수 있습니다.

---

### 다른 선택지에 대한 설명:

- **A. 모든 리전에서 AWS CloudTrail을 구성하여 모든 API 활동을 기록**:
  - CloudTrail은 API 호출을 기록하는 도구로, 이를 통해 비승인 지역에서 인스턴스가 생성된 경우 로그를 통해 확인할 수는 있지만, 이를 막는 방법이 아닙니다. Lambda 함수를 통해 인스턴스를 종료하는 것도 운영적으로 복잡하고 실시간으로 방지할 수는 없습니다.

- **B. 각 AWS 계정에서 Region 조건을 사용하여 IAM 정책을 만들기**:
  - IAM 정책은 특정 계정에만 적용되며, 정책을 각 계정의 모든 IAM 그룹에 수동으로 연결해야 합니다. 여러 계정을 관리하는 환경에서는 관리가 복잡해질 수 있습니다.

- **C. IAM 권한 경계 정책 만들기**:
  - 권한 경계는 IAM 정책의 최대 권한을 정의하는 것이지만, 모든 계정에서 이를 관리해야 하며 SCP처럼 중앙 집중적으로 관리하기 어려워집니다.

---

결론적으로, **D 옵션**은 AWS Organizations의 SCP를 사용하여 모든 계정에서 승인되지 않은 지역에서 EC2 인스턴스를 실행하는 것을 효과적으로 차단할 수 있으며, 운영 효율성을 극대화하는 가장 적합한 솔루션입니다.


## 질문 #35
회사의 공개 웹사이트는 Amazon CloudFront 배포판 뒤에 있는 us-east-1 지역의 Amazon S3 버킷에 호스팅됩니다. 

회사는 웹사이트가 DDoS 공격으로부터 보호되도록 하려고 합니다. SysOps 관리자는 회사가 DDoS 보호가 적용되는 속도 제한을 제어할 수 있는 솔루션을 배포해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 기본 작업 허용을 사용하여 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다. 가장 많이 투표된
B. us-east-1에서 allow default action을 사용하여 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 S3 버킷과 연결합니다.
C. 블록 기본 작업으로 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 허용하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다.
D. us-east-1에서 block default action을 사용하여 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 허용하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 S3 버킷과 연결합니다.

가장 적합한 솔루션은 **A. 기본 작업 허용을 사용하여 글로벌 범위의 AWS WAF 웹 ACL을 배포합니다. 일치하는 트래픽을 차단하도록 AWS WAF 속도 기반 규칙을 구성합니다. 웹 ACL을 CloudFront 배포와 연결합니다.**

### 이유:

1. **CloudFront 배포와 AWS WAF의 통합**:
   - **Amazon CloudFront**는 DDoS 공격에 대한 첫 번째 방어선으로 사용될 수 있습니다. CloudFront는 전역적으로 분산된 엣지 네트워크를 통해 콘텐츠를 캐싱하고 전송하기 때문에 DDoS 공격으로부터 자연스럽게 보호합니다.
   - **AWS WAF(웹 애플리케이션 방화벽)**를 CloudFront와 함께 사용하면 웹사이트에 대한 트래픽을 제어하고 보호할 수 있습니다. CloudFront 배포에 AWS WAF 웹 ACL을 연결하면 DDoS 공격 시 특정 트래픽을 필터링하고 차단할 수 있습니다.

2. **속도 기반 규칙**:
   - **속도 기반 규칙**을 사용하면 IP 주소당 요청 수를 제한할 수 있습니다. DDoS 공격은 대량의 요청을 생성하므로, 속도 기반 규칙을 통해 일정량 이상의 요청을 감지하여 차단하는 것이 매우 효과적입니다.

3. **기본 작업 허용**:
   - 기본 작업을 "허용"으로 설정하면 일반적인 트래픽은 계속 허용되고, 속도 기반 규칙에 따라 과도한 트래픽만 차단됩니다. 이는 정상적인 사용자에게 영향을 최소화하면서 DDoS 공격을 방어할 수 있는 방식입니다.

---

### 다른 선택지에 대한 설명:

- **B. AWS WAF 웹 ACL을 S3 버킷에 연결**:
  - AWS WAF는 직접 S3 버킷과 통합되지 않으므로, WAF 웹 ACL을 S3 버킷과 연결하는 것은 불가능합니다. WAF는 CloudFront나 Application Load Balancer(ALB)와 같은 프런트엔드 서비스와 통합되어야 합니다.

- **C. 블록 기본 작업으로 글로벌 범위의 AWS WAF 웹 ACL을 배포**:
  - 기본 작업을 "차단"으로 설정하면 대부분의 트래픽이 차단되며, 이로 인해 정상적인 트래픽까지도 차단될 가능성이 있습니다. 이 옵션은 서비스 가용성에 부정적인 영향을 미칠 수 있습니다.

- **D. AWS WAF 웹 ACL을 us-east-1에 배포하고 S3 버킷과 연결**:
  - AWS WAF는 S3 버킷과 직접 연결할 수 없으며, CloudFront를 통해 웹 트래픽을 처리해야 합니다. 그리고 글로벌 배포가 아닌 리전에 종속된 배포는 CloudFront를 보호하는 데 적합하지 않습니다.

---

결론적으로, **A 옵션**은 CloudFront와 AWS WAF의 글로벌 범위 웹 ACL을 사용해 트래픽을 보호하고, 속도 기반 규칙을 통해 DDoS 공격으로부터 웹사이트를 효과적으로 방어할 수 있는 최적의 솔루션입니다.


## 질문 #36
SysOps 관리자가 AWS SDK를 사용하여 여러 유지 관리 작업을 수행하는 Python 스크립트를 개발했습니다.

스크립트는 매일 밤 자동으로 실행되어야 합니다.
이 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. Python 스크립트를 AWS Lambda 함수로 변환합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 매일 밤 함수를 호출합니다. 가장 많이 투표된
B. Python 스크립트를 AWS Lambda 함수로 변환합니다. AWS CloudTrail을 사용하여 매일 밤 함수를 호출합니다.
C. Python 스크립트를 Amazon EC2 인스턴스에 배포합니다. Amazon EventBride(Amazon CloudWatch Events)를 사용하여 인스턴스가 매일 밤 시작 및 중지되도록 예약합니다.
D. Python 스크립트를 Amazon EC2 인스턴스에 배포합니다. AWS Systems Manager를 사용하여 매일 밤 인스턴스가 시작되고 중지되도록 예약합니다.

가장 적합한 솔루션은 **A. Python 스크립트를 AWS Lambda 함수로 변환합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용하여 매일 밤 함수를 호출합니다.**

### 이유:

1. **AWS Lambda 함수**:
   - Lambda는 서버리스 방식으로 코드를 실행할 수 있는 서비스로, EC2 인스턴스를 프로비저닝하거나 관리할 필요 없이 코드를 실행할 수 있습니다. Python 스크립트를 Lambda 함수로 변환하면 인프라를 관리할 필요 없이 유지 관리 작업을 자동화할 수 있습니다.
   
2. **Amazon EventBridge(Amazon CloudWatch Events)**:
   - EventBridge는 지정된 일정에 따라 이벤트를 트리거할 수 있는 서비스로, 이를 사용하여 매일 밤 Lambda 함수를 호출하는 규칙을 생성할 수 있습니다. 이 방식은 매우 운영 효율적이고 관리가 간단합니다.

3. **운영 비용 효율성**:
   - Lambda는 사용한 만큼만 비용을 지불하는 모델로, EC2 인스턴스를 항상 실행하거나 관리할 필요 없이 Python 스크립트를 실행할 수 있어 비용 효율적입니다. 

---

### 다른 선택지에 대한 설명:

- **B. Lambda 함수와 CloudTrail 사용**:
  - **AWS CloudTrail**은 API 호출을 로깅하는 서비스로, Lambda 함수를 호출하는 데 적합하지 않습니다. 이를 대신 **EventBridge**를 사용해 매일 밤 자동 호출하는 것이 적절합니다.

- **C. Python 스크립트를 Amazon EC2 인스턴스에 배포**:
  - EC2 인스턴스를 사용하면 스크립트를 실행할 수는 있지만, EC2 인스턴스를 시작하고 종료하는 등의 작업이 필요하고, 인스턴스 관리 및 유지 보수 비용이 발생할 수 있습니다. Lambda를 사용하는 것이 더 운영 효율적입니다.

- **D. EC2 인스턴스와 AWS Systems Manager 사용**:
  - Systems Manager를 사용해 EC2 인스턴스를 제어하는 방식은 EC2 인스턴스를 지속적으로 관리해야 하고, Lambda를 사용하는 것에 비해 비용 및 운영 관리 측면에서 덜 효율적입니다.

---

결론적으로 **A 옵션**은 서버리스로 운영할 수 있으며, 유지 관리가 필요 없고 비용 효율적인 솔루션이므로 가장 적합한 선택입니다.

## 질문 #37
SysOps 관리자는 AWS Lambda 함수에 오류가 발생하면 소프트웨어 개발자에게 즉시 알리는 솔루션을 만들어야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?


A. 각 개발자에 대한 이메일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. Errors 메트릭과 Lambda 함수 이름을 차원으로 사용하여 Amazon CloudWatch 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다. 가장 많이 투표된
B. 각 개발자에 대한 모바일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. LambdaError를 이벤트 패턴으로, SNS 토픽 이름을 리소스로 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다.
C. Amazon Simple Email Service(Amazon SES)에서 각 개발자 이메일 주소를 확인합니다. LambdaError 메트릭과 개발자 이메일 주소를 차원으로 사용하여 Amazon CloudWatch 규칙을 만듭니다. 규칙 상태가 ALARM에 도달하면 Amazon SES를 통해 이메일을 보내도록 규칙을 구성합니다.
D. Amazon Simple Email Service(Amazon SES)에서 각 개발자 모바일 폰을 확인합니다. 이벤트 패턴으로 Error를 사용하고 리소스로 Lambda 함수 이름을 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 규칙 상태가 ALARM에 도달하면 Amazon SES를 통해 푸시 알림을 보내도록 규칙을 구성합니다.



가장 적합한 솔루션은 **A. 각 개발자에 대한 이메일 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. Errors 메트릭과 Lambda 함수 이름을 차원으로 사용하여 Amazon CloudWatch 알람을 만듭니다. 알람 상태가 ALARM에 도달하면 SNS 토픽에 알림을 보내도록 알람을 구성합니다.**

### 이유:

1. **CloudWatch 알람과 Lambda의 통합**:
   - Lambda 함수의 오류를 감지하는 가장 좋은 방법은 **Amazon CloudWatch**의 **Errors 메트릭**을 사용하는 것입니다. Lambda는 오류가 발생할 때마다 CloudWatch에 메트릭을 전송하므로 이를 통해 오류를 즉시 모니터링할 수 있습니다.

2. **SNS 토픽을 통한 알림**:
   - **Amazon SNS**는 다양한 구독자에게 이메일 또는 SMS를 통해 알림을 보낼 수 있는 서비스입니다. 각 개발자에게 이메일 구독을 추가하면 CloudWatch 알람이 발생할 때 즉시 이메일 알림을 받을 수 있습니다.

3. **운영 효율성**:
   - 이 솔루션은 CloudWatch와 SNS의 기본 통합을 활용하여 Lambda 오류를 실시간으로 모니터링하고, 개발자에게 즉시 알림을 보내는 운영 효율적인 방법입니다. 추가적인 커스텀 설정 없이도 빠르게 알림을 설정할 수 있습니다.

---

### 다른 선택지에 대한 설명:

- **B. SNS 및 EventBridge 알람 사용**:
   - **EventBridge**는 주로 이벤트 중심의 아키텍처를 위한 서비스로, Lambda 오류 알림과 같은 단순한 모니터링에는 **CloudWatch 알람**이 더 적합합니다. 또한, Lambda 함수의 오류를 모니터링하려면 **Errors 메트릭**이 더 직접적입니다.

- **C. Amazon SES를 사용하여 이메일 전송**:
   - **Amazon SES**는 이메일을 보내는 서비스이지만, Lambda 오류 알림에는 SNS를 사용하는 것이 더 적합합니다. SES는 대량 이메일 전송에 유용하지만, 알림 설정에 SNS를 사용하는 것이 더 일반적이고 설정도 간단합니다.

- **D. Amazon SES를 통해 푸시 알림**:
   - **SES**는 주로 이메일 전송용이므로, 모바일 푸시 알림을 보내기에는 부적합합니다. 푸시 알림에는 **SNS**가 더 적합하며, EventBridge는 복잡한 이벤트를 처리할 때 유리하지만 이 경우 CloudWatch를 사용하는 것이 더 적합합니다.

---

결론적으로 **A 옵션**이 가장 적합한 솔루션입니다. Lambda 함수 오류를 CloudWatch에서 감지하고 SNS를 통해 즉시 알림을 보내는 운영적으로 효율적이고 간단한 방법입니다.




## 질문 #38
한 회사에는 민감한 정보가 들어 있는 개인 Amazon S3 버킷이 있습니다. 

SysOps 관리자는 버킷의 객체에 액세스하려는 시도로 인해 발생하는 인증 실패의 IP 주소 로그를 보관해야 합니다. 로그는 90일 동안 덮어쓰거나 삭제할 수 없도록 저장해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. AWS CloudTrail 트레일을 만듭니다. Amazon CloudWatch Logs에 저장할 로그 파일을 구성합니다. 보관 기간이 90일인 로그 그룹을 구성합니다.
B. AWS CloudTrail 트레일을 만듭니다. 로그 파일을 다른 S3 버킷에 저장하도록 구성합니다. CloudTrail 로그 파일 무결성 검증을 90일 동안 켭니다.
C. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 Amazon CloudWatch Logs에 저장되도록 구성합니다. 보관 기간이 90일인 로그 그룹을 구성합니다.
D. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 두 번째 S3 버킷에 저장되도록 구성합니다. 두 번째 S3 버킷에서 S3 객체 잠금을 켜고 기본 보관 기간을 90일로 구성합니다. 가장 많이 투표된

가장 적합한 솔루션은 **D. S3 버킷에 대한 액세스 로깅을 켭니다. 액세스 로그가 두 번째 S3 버킷에 저장되도록 구성합니다. 두 번째 S3 버킷에서 S3 객체 잠금을 켜고 기본 보관 기간을 90일로 구성합니다.**

### 이유:

1. **S3 액세스 로깅**:
   - S3 버킷에 대한 액세스 로깅을 활성화하면, 버킷의 객체에 대한 요청(성공과 실패)을 로그 파일로 기록할 수 있습니다. 이러한 로그에는 IP 주소와 같은 중요한 정보가 포함됩니다.

2. **두 번째 S3 버킷에 로그 저장**:
   - 민감한 정보가 포함된 S3 버킷의 액세스 로그를 별도의 S3 버킷에 저장하면, 로그 데이터를 더 안전하게 관리할 수 있습니다. 로그가 원본 버킷과 분리되어 보관되므로 추가 보안 계층을 제공합니다.

3. **S3 객체 잠금 및 WORM(Write Once, Read Many)**:
   - **S3 객체 잠금**을 사용하면 로그 파일을 덮어쓰거나 삭제할 수 없도록 보호할 수 있습니다. 이를 통해 **90일 동안 로그 파일을 보호**하고 데이터 무결성을 유지할 수 있습니다. 이는 규정 준수 및 감사 요구 사항에 적합한 방식입니다.

4. **보관 기간 설정**:
   - S3 객체 잠금을 사용하여 **기본 보관 기간을 90일**로 설정하면, 로그 파일이 그 기간 동안 보호되며 그 이후에는 자동으로 삭제하거나 관리할 수 있습니다.

---

### 다른 선택지에 대한 설명:

- **A. CloudTrail 트레일과 CloudWatch Logs 사용**:
   - CloudTrail을 통해 인증 실패 로그를 수집하는 것은 가능하지만, 로그를 90일 동안 덮어쓰거나 삭제되지 않도록 보장하려면 CloudWatch Logs가 적절하지 않습니다. CloudWatch에서는 로그 그룹을 설정할 수 있지만, 로그 무결성 보장은 제공되지 않습니다.

- **B. CloudTrail 로그 파일을 다른 S3 버킷에 저장**:
   - CloudTrail 로그 파일의 무결성 검증을 활성화하는 것은 로그 파일이 변조되지 않았음을 확인하는 데 도움이 될 수 있지만, **객체 잠금**을 사용해 삭제 방지 및 보존을 보장하는 D 옵션이 더 적합합니다.

- **C. S3 액세스 로그를 CloudWatch Logs에 저장**:
   - CloudWatch Logs에 액세스 로그를 저장할 수 있지만, CloudWatch에서 데이터 무결성을 보장하는 방법은 제한적입니다. 로그를 90일 동안 삭제하지 못하도록 보장하려면 S3 객체 잠금이 더 적합합니다.

---

결론적으로, **D 옵션**은 **S3 객체 잠금을 사용해** 로그 파일이 90일 동안 보호되도록 하고, 로그 무결성 및 데이터 보존을 확실하게 관리할 수 있는 솔루션이므로 요구 사항을 가장 잘 충족합니다.

## 질문 #39
SysOps 관리자가 NAT 인스턴스를 NAT 게이트웨이로 마이그레이션합니다. 

마이그레이션 후 프라이빗 서브넷의 Amazon EC2 인스턴스에 호스팅된 애플리케이션은 인터넷에 액세스할 수 없습니다.
다음 중 이 문제의 가능한 이유는 무엇입니까? (두 가지를 선택하세요.)

A. 해당 애플리케이션은 NAT 게이트웨이가 지원하지 않는 프로토콜을 사용하고 있습니다. 가장 많이 투표된
B. NAT 게이트웨이가 보안 그룹에 없습니다.
C. NAT 게이트웨이가 지원되지 않는 가용성 영역에 있습니다.
D. NAT 게이트웨이가 사용 가능한 상태가 아닙니다. 가장 많이 투표된
E. 포트 포워딩 설정으로 인해 인터넷에서 내부 서비스에 접근할 수 없습니다.

이 문제의 가능한 원인으로는 **A. 해당 애플리케이션은 NAT 게이트웨이가 지원하지 않는 프로토콜을 사용하고 있습니다.**와 **D. NAT 게이트웨이가 사용 가능한 상태가 아닙니다.**가 가장 적합합니다.

### 이유:

1. **A. NAT 게이트웨이가 지원하지 않는 프로토콜 사용**:
   - **NAT 게이트웨이**는 TCP, UDP, ICMP 프로토콜을 지원합니다. 그러나 만약 애플리케이션이 다른 프로토콜(예: GRE 또는 IPSec)을 사용하고 있다면 NAT 게이트웨이에서는 이를 지원하지 않기 때문에 인터넷 액세스 문제가 발생할 수 있습니다.

2. **D. NAT 게이트웨이가 사용 가능한 상태가 아님**:
   - NAT 게이트웨이가 생성된 후에 사용 가능한 상태가 아닐 수 있습니다. NAT 게이트웨이가 준비되지 않거나 문제가 발생하면 인터넷 연결이 되지 않으므로, 이 상태를 확인하는 것이 중요합니다. NAT 게이트웨이의 상태가 `Available`이 아닌 경우 연결할 수 없습니다.

---

### 다른 선택지에 대한 설명:

- **B. NAT 게이트웨이가 보안 그룹에 없습니다**:
   - NAT 게이트웨이는 **보안 그룹을 사용하지 않습니다**. 대신, 라우팅 테이블을 통해 트래픽을 관리합니다. 따라서 보안 그룹의 부재는 이 문제와 관련이 없습니다.

- **C. NAT 게이트웨이가 지원되지 않는 가용성 영역에 있습니다**:
   - NAT 게이트웨이는 특정 가용성 영역(AZ) 내에서 생성되지만, 잘못된 AZ에 있더라도 연결에 실패하지는 않습니다. 가용성 영역 선택이 잘못된 경우를 제외하고는 문제가 발생하지 않습니다. 다만 프라이빗 서브넷과 같은 AZ에 NAT 게이트웨이가 있어야 최적의 연결 성능을 얻을 수 있습니다.

- **E. 포트 포워딩 설정으로 인해 인터넷에서 내부 서비스에 접근할 수 없습니다**:
   - NAT 게이트웨이는 **프라이빗 서브넷에서 인터넷으로 나가는 트래픽을 처리**하는 것이 주된 역할입니다. 반대로 외부에서 프라이빗 서브넷 내부로 들어오는 트래픽을 처리하지 않으므로, 포트 포워딩 설정은 이 문제와 관련이 없습니다.

---

### 결론:
가장 적절한 답변은 **A와 D**입니다. NAT 게이트웨이가 지원하지 않는 프로토콜을 사용할 가능성과 NAT 게이트웨이가 사용 가능한 상태가 아닌 것이 문제의 원인일 수 있습니다.


## 질문 #40
한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

SysOps 관리자가 수요 증가를 처리하기 위해 Auto Scaling 그룹과 Application Load Balancer(ALB)를 만듭니다. 하지만 EC2 인스턴스가 상태 검사에 실패합니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 자동 확장 그룹이 모든 AWS 지역을 사용하도록 구성되었는지 확인합니다.
B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인합니다. 가장 많이 투표된
C. ALB에서 리스너 우선순위를 확인합니다. 필요한 경우 우선순위를 변경합니다.
D. Auto Scaling 그룹의 최대 인스턴스 수를 확인합니다. 필요한 경우 숫자를 변경합니다.


이 문제를 해결하기 위해 가장 적절한 조치는 **B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인합니다**입니다.

### 이유:

1. **B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인합니다**:
   - **Application Load Balancer(ALB)**는 상태 검사에서 지정된 포트와 프로토콜을 사용하여 EC2 인스턴스의 애플리케이션 상태를 확인합니다. 만약 애플리케이션이 ALB 리스너가 기대하는 포트(예: HTTP 80, HTTPS 443)에서 실행되지 않거나 잘못된 프로토콜로 구성된 경우, 상태 검사에 실패할 수 있습니다. 따라서 ALB와 애플리케이션 간의 통신이 제대로 설정되었는지 확인하는 것이 중요합니다.

### 다른 선택지에 대한 설명:

- **A. 자동 확장 그룹이 모든 AWS 지역을 사용하도록 구성되었는지 확인합니다**:
   - Auto Scaling 그룹은 특정 가용성 영역(AZ)과 연결됩니다. 지역 간의 구성을 확인하는 것은 이 문제와 관련이 없습니다. 상태 검사 실패 문제는 주로 인스턴스와 ALB 간의 통신 문제에 기인합니다.

- **C. ALB에서 리스너 우선순위를 확인합니다**:
   - 리스너 우선순위는 특정 규칙을 기반으로 트래픽을 라우팅할 때 사용됩니다. 상태 검사 실패와는 관련이 없습니다. 이 문제는 애플리케이션의 상태와 상태 검사 설정 문제일 가능성이 높습니다.

- **D. Auto Scaling 그룹의 최대 인스턴스 수를 확인합니다**:
   - Auto Scaling 그룹의 인스턴스 수는 트래픽 증가 시 더 많은 인스턴스를 추가할 수 있도록 설정하는 옵션입니다. 상태 검사 실패와는 관련이 없으며, 애플리케이션이 제대로 실행되지 않으면 인스턴스 수가 많아도 문제가 해결되지 않습니다.

### 결론:
**B. 리스너가 예상하는 프로토콜과 포트에서 애플리케이션이 실행 중인지 확인**하는 것이 상태 검사 실패 문제를 해결하는 핵심 단계입니다.



## 질문 #41
SysOps 관리자가 AWS Service Catalog 포트폴리오를 생성하고 회사의 두 번째 AWS 계정과 포트폴리오를 공유했습니다. 

두 번째 계정은 다른 관리자가 제어합니다.
두 번째 계정의 관리자는 어떤 작업을 수행할 수 있습니까?

A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가합니다. 가장 많이 투표된
B. 가져온 포트폴리오에 새로운 제품을 추가합니다.
C. 가져온 포트폴리오에 포함된 제품에 대한 출시 역할을 변경합니다.
D. 가져온 포트폴리오의 제품을 맞춤화합니다.


두 번째 계정의 관리자가 할 수 있는 작업으로 가장 적절한 답변은 **A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가합니다**입니다.

### 이유:

- **A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가합니다**:
  - AWS Service Catalog를 통해 포트폴리오를 다른 계정과 공유하면, 해당 계정의 관리자는 공유된 포트폴리오에서 제품을 로컬 포트폴리오에 추가할 수 있습니다. 이렇게 하면 그 계정에서 제품을 사용하고 배포할 수 있습니다.

### 다른 선택지에 대한 설명:

- **B. 가져온 포트폴리오에 새로운 제품을 추가합니다**:
  - 포트폴리오에 제품을 추가하는 권한은 원래 포트폴리오를 소유한 관리자의 권한입니다. 두 번째 계정의 관리자는 가져온 포트폴리오에 제품을 추가할 수 없습니다.

- **C. 가져온 포트폴리오에 포함된 제품에 대한 출시 역할을 변경합니다**:
  - 출시 역할(Launch Role)을 설정하고 변경하는 권한은 원래 포트폴리오의 소유자에게만 있습니다. 두 번째 계정의 관리자는 공유된 포트폴리오의 출시 역할을 변경할 수 없습니다.

- **D. 가져온 포트폴리오의 제품을 맞춤화합니다**:
  - 두 번째 계정의 관리자는 포트폴리오의 제품을 직접 맞춤화할 수 없습니다. 제품의 템플릿과 설정은 원래 포트폴리오 소유자에 의해 정의되며, 관리자가 제공하는 설정에 따라 배포될 수 있습니다.

### 결론:
두 번째 계정의 관리자가 할 수 있는 작업은 **A. 가져온 포트폴리오의 제품을 로컬 포트폴리오에 추가**하는 것입니다.




## 질문 #42
한 회사가 애플리케이션을 AWS로 마이그레이션했습니다. 

이 회사는 여러 인스턴스 패밀리의 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다.
초기 테스트 중에 SysOps 관리자가 선택한 EC2 인스턴스에서 성능 문제를 식별합니다. 이 회사는 엄격한 예산 할당 정책을 가지고 있으므로
SysOps 관리자는 워크로드에 맞는 성능 특성을 가진 올바른 리소스 유형을 사용해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 즉각적인 비용 절감을 위해 지역별 예약 인스턴스(RI)를 구매합니다. Cost Explorer에서 EC2 적정 크기 조정 권장 사항을 검토하고 조치를 취합니다. 적정 크기 조정 후 RI를 최적의 인스턴스 패밀리로 교환합니다.
B. 기존 인스턴스에 대한 영역별 예약 인스턴스(RI)를 구매합니다. AWS Billing and Cost Management 콘솔에서 RI 활용도를 모니터링합니다. 활용도를 최적화하기 위해 인스턴스 크기를 조정합니다.
C. AWS Compute Optimizer 권장 사항을 검토하고 조치를 취합니다. 컴퓨팅 리소스를 실행하는 데 필요한 비용을 줄이기 위해 Compute Savings Plans를 구매합니다. 가장 많이 투표된
D. AWS 비용 및 사용 보고서에서 리소스 활용도 지표를 검토합니다. EC2 인스턴스를 적정 크기로 조정합니다. 적정 크기의 리소스에 대한 주문형 용량 예약을 만듭니다.

가장 적절한 솔루션은 **C. AWS Compute Optimizer 권장 사항을 검토하고 조치를 취합니다. 컴퓨팅 리소스를 실행하는 데 필요한 비용을 줄이기 위해 Compute Savings Plans를 구매합니다**입니다.

### 이유:

1. **C. AWS Compute Optimizer 권장 사항을 검토하고 조치를 취합니다**:
   - AWS Compute Optimizer는 EC2 인스턴스의 CPU, 메모리, 네트워크 사용량을 분석하여 성능을 최적화할 수 있는 권장 사항을 제공합니다. 이를 통해 워크로드에 맞는 성능 특성을 가진 EC2 인스턴스를 선택할 수 있습니다. Compute Optimizer는 비용 절감과 성능 향상을 위해 최적의 리소스 선택을 도와줍니다.
   - 또한, **Compute Savings Plans**는 특정 인스턴스 패밀리나 리전과 무관하게 다양한 EC2 인스턴스를 유연하게 사용할 수 있으면서도 비용 절감을 할 수 있는 옵션입니다.

### 다른 선택지에 대한 설명:

- **A. 즉각적인 비용 절감을 위해 지역별 예약 인스턴스(RI)를 구매합니다. Cost Explorer에서 EC2 적정 크기 조정 권장 사항을 검토하고 조치를 취합니다. 적정 크기 조정 후 RI를 최적의 인스턴스 패밀리로 교환합니다**:
   - 예약 인스턴스(RI)는 특정 인스턴스 타입에 대한 약정으로 비용을 절감할 수 있지만, 워크로드에 적합한 인스턴스를 선택하기 전에 RI를 구매하는 것은 성급한 결정입니다. RI는 특정 인스턴스에 종속적이기 때문에, Compute Optimizer와 같은 도구로 워크로드 분석 후에 결정을 내리는 것이 바람직합니다.

- **B. 기존 인스턴스에 대한 영역별 예약 인스턴스(RI)를 구매합니다. AWS Billing and Cost Management 콘솔에서 RI 활용도를 모니터링합니다. 활용도를 최적화하기 위해 인스턴스 크기를 조정합니다**:
   - 이 옵션은 이미 인스턴스 크기가 최적화되었다는 가정 하에 RI를 구매하는 방안입니다. 그러나 성능 문제가 발생한 상황에서는 먼저 적정 인스턴스 타입을 찾아야 하므로, 예약 인스턴스 구매는 성능 최적화 후에 고려하는 것이 맞습니다.

- **D. AWS 비용 및 사용 보고서에서 리소스 활용도 지표를 검토합니다. EC2 인스턴스를 적정 크기로 조정합니다. 적정 크기의 리소스에 대한 주문형 용량 예약을 만듭니다**:
   - 비용 및 사용 보고서는 리소스 활용도를 분석하는 데 도움을 줄 수 있지만, Compute Optimizer는 더 정교한 분석을 제공하여 성능과 비용 효율성을 극대화할 수 있습니다. 주문형 용량 예약은 특정 용량을 확보하는 방식이므로, 성능 최적화와 비용 절감을 위해서는 Compute Optimizer와 Savings Plans가 더 적합한 옵션입니다.

### 결론:
AWS Compute Optimizer는 성능 최적화와 비용 절감을 동시에 달성할 수 있는 강력한 도구이며, Compute Savings Plans는 다양한 EC2 인스턴스에 유연하게 적용할 수 있어 예산에 맞춘 비용 절감이 가능합니다.


## 질문 #43
SysOps 관리자는 회사의 인프라를 코드로 배포하는 업무를 맡고 있습니다. 

SysOps 관리자는 여러 환경에서 재사용할 수 있는 단일 템플릿을 작성하려고 합니다. SysOps 관리자는 AWS CloudFormation을 사용하여 솔루션을 만드는 방법은 무엇입니까?

A. CloudFormation 템플릿에서 Amazon EC2 사용자 데이터를 사용합니다.
B. 중첩된 스택을 사용하여 리소스를 프로비저닝합니다.
C. CloudFormation 템플릿에서 매개변수를 사용합니다. 가장 많이 투표된
D. 스택 정책을 사용하여 리소스를 프로비저닝합니다.

가장 적절한 솔루션은 **C. CloudFormation 템플릿에서 매개변수를 사용합니다**입니다.

### 이유:

**C. CloudFormation 템플릿에서 매개변수를 사용합니다**:
- **매개변수(Parameter)**를 사용하면 CloudFormation 템플릿을 다양한 환경에서 재사용할 수 있게 됩니다. 매개변수는 스택을 배포할 때 사용자로부터 입력을 받아 템플릿 내의 값(예: 인스턴스 타입, 리전, VPC ID 등)을 동적으로 변경할 수 있습니다. 이를 통해 동일한 템플릿을 여러 환경에서 유연하게 적용할 수 있으며, 환경마다 설정을 다르게 제공할 수 있습니다.

### 다른 선택지에 대한 설명:

- **A. CloudFormation 템플릿에서 Amazon EC2 사용자 데이터를 사용합니다**:
   - EC2 사용자 데이터(User Data)는 EC2 인스턴스에서 초기 설정을 자동으로 실행하는 데 사용됩니다. 이는 인스턴스 수준의 설정일 뿐, 전체 인프라를 재사용 가능한 방식으로 정의하는 데는 적합하지 않습니다.

- **B. 중첩된 스택을 사용하여 리소스를 프로비저닝합니다**:
   - **중첩된 스택(Nested Stacks)**는 리소스를 모듈식으로 관리하기 위한 방법으로, 여러 CloudFormation 템플릿을 계층 구조로 나누어 관리할 수 있게 합니다. 이는 복잡한 환경에서 재사용성을 높이지만, 템플릿을 여러 환경에서 재사용하기 위한 매개변수 설정과는 다른 방식입니다.

- **D. 스택 정책을 사용하여 리소스를 프로비저닝합니다**:
   - **스택 정책(Stack Policies)**는 CloudFormation 스택이 업데이트될 때 리소스를 보호하거나 제한하는 기능입니다. 이는 재사용 가능한 템플릿과는 관련이 없으며, 리소스의 변경이나 삭제를 방지하는 역할을 합니다.

### 결론:
**CloudFormation 매개변수**를 사용하면 템플릿의 유연성과 재사용성을 높일 수 있어 여러 환경에서 쉽게 사용할 수 있습니다. 이 방식은 다양한 인프라 구성에 적합한 값을 동적으로 입력받아 재사용 가능한 템플릿을 작성하는 데 이상적입니다.


## 질문 #44
SysOps 관리자는 Amazon EC2 인스턴스의 대규모 플릿을 담당하며, 다가올 하드웨어 유지 관리로 인해 인스턴스가 영향을 받을지 여부를 알아야 합니다.

어떤 옵션이 가장 적은 관리 오버헤드로 이 정보를 제공할까요?

A. 타사 모니터링 솔루션을 배포하여 실시간 EC2 인스턴스 모니터링을 제공합니다.
B. AWS Management Console을 사용하여 시스템 상태 검사에 실패한 모든 인스턴스를 나열합니다.
C. AWS CloudTrail에서 StopInstances API 호출을 모니터링합니다.
D. AWS 개인 건강 대시보드를 검토합니다. 가장 많이 투표된


가장 적절한 솔루션은 **D. AWS 개인 건강 대시보드를 검토합니다**입니다.

### 이유:

**D. AWS 개인 건강 대시보드를 검토합니다**:
- **AWS 개인 건강 대시보드**는 사용자의 AWS 계정에서 실행 중인 리소스에 영향을 미칠 수 있는 이벤트(예: 하드웨어 유지 관리, 서비스 장애)를 자동으로 모니터링하고 알림을 제공합니다. 이 대시보드는 EC2 인스턴스가 유지 관리로 인해 영향을 받을 때 자동으로 알림을 제공하여, SysOps 관리자가 대규모 플릿에 대해 빠르게 대응할 수 있도록 돕습니다. 관리 오버헤드가 매우 적고 AWS에서 제공하는 기본 기능이므로 별도의 설정 없이 쉽게 확인할 수 있습니다.

### 다른 선택지에 대한 설명:

- **A. 타사 모니터링 솔루션을 배포하여 실시간 EC2 인스턴스 모니터링을 제공합니다**:
   - 타사 솔루션은 추가적인 관리 오버헤드가 발생하며, AWS의 기본 유지 관리 알림이나 상태 정보를 확인하는 데 꼭 필요한 것은 아닙니다. AWS에서 제공하는 도구로 충분히 해결할 수 있는 문제입니다.

- **B. AWS Management Console을 사용하여 시스템 상태 검사에 실패한 모든 인스턴스를 나열합니다**:
   - 시스템 상태 검사는 EC2 인스턴스가 실행 중인 상태에서 발생하는 문제를 확인할 수 있지만, 유지 관리 알림을 사전에 받는 것과는 다릅니다. 이는 관리 오버헤드가 높고, 유지 관리 계획을 미리 확인할 수 없습니다.

- **C. AWS CloudTrail에서 StopInstances API 호출을 모니터링합니다**:
   - CloudTrail은 API 활동을 기록하는 서비스로, 이미 발생한 이벤트를 모니터링하는 데 적합합니다. 하지만 하드웨어 유지 관리로 인한 영향을 사전에 알리는 데는 적합하지 않으며, 필요한 정보를 제공하지 않습니다.

### 결론:
**AWS 개인 건강 대시보드**는 자동으로 유지 관리와 관련된 정보를 제공하므로, 관리 오버헤드가 적고 가장 적절한 해결책입니다.



## 질문 #45
SysOps 관리자가 AWS CloudFormation 템플릿을 사용하여 리소스를 배포하려고 합니다. 

템플릿에 정의된 Amazon EC2 인스턴스가 시작되지 않고 InsufficientInstanceCapacity 오류가 발생합니다.
SysOps 관리자는 이 오류를 해결하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. EC2 인스턴스에 대해 별도의 AWS CloudFormation 템플릿을 만듭니다.
B. EC2 인스턴스에 대한 가용성 영역을 지정하지 않도록 AWS CloudFormation 템플릿을 수정합니다. 가장 많이 투표된
C. AWS CloudFormation 템플릿을 수정하여 다른 EC2 인스턴스 유형을 사용합니다. 가장 많이 투표된
D. EC2 인스턴스에 다른 Amazon Machine Image(AMI)를 사용합니다.
E. 템플릿에서 스택을 생성하기 전에 AWS CLI의 validate-template 명령을 사용합니다.

**InsufficientInstanceCapacity** 오류는 AWS 리전이나 가용성 영역 내에서 요청한 EC2 인스턴스 유형에 대한 가용 용량이 부족할 때 발생합니다. 이 문제를 해결하기 위한 적절한 조치는 다음과 같습니다:

### 올바른 선택:

**B. EC2 인스턴스에 대한 가용성 영역을 지정하지 않도록 AWS CloudFormation 템플릿을 수정합니다.**
- 가용성 영역을 지정하지 않으면 AWS가 사용 가능한 가용성 영역에서 인스턴스를 자동으로 배포할 수 있어, 특정 가용성 영역의 용량 부족 문제를 우회할 수 있습니다.

**C. AWS CloudFormation 템플릿을 수정하여 다른 EC2 인스턴스 유형을 사용합니다.**
- 다른 EC2 인스턴스 유형을 사용하면 현재의 인스턴스 유형에 비해 더 많은 용량이 있는 인스턴스 유형으로 변경할 수 있어 문제를 해결할 수 있습니다.

### 다른 선택지에 대한 설명:

- **A. EC2 인스턴스에 대해 별도의 AWS CloudFormation 템플릿을 만듭니다.**
  - 별도의 템플릿을 만드는 것은 이 문제를 해결하는 데 도움이 되지 않습니다. InsufficientInstanceCapacity 오류는 인스턴스의 가용성 문제이므로 템플릿의 구조와는 관련이 없습니다.

- **D. EC2 인스턴스에 다른 Amazon Machine Image(AMI)를 사용합니다.**
  - AMI를 변경하는 것은 직접적으로 인스턴스 용량 문제와 관련이 없으며, InsufficientInstanceCapacity 오류를 해결하지 못합니다.

- **E. 템플릿에서 스택을 생성하기 전에 AWS CLI의 validate-template 명령을 사용합니다.**
  - 템플릿의 유효성을 검증하는 것은 좋은 습관이지만, 이 오류는 템플릿의 유효성 문제와는 관계가 없고, 인스턴스의 가용성과 관련된 문제입니다.

### 결론:
**B**와 **C**가 InsufficientInstanceCapacity 오류를 해결하는 데 적절한 조치입니다.



## 질문 #46
한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 

이 회사는 Amazon Route 53을 사용하여 트래픽을 라우팅합니다.
이 회사는 또한 Amazon S3 버킷에 구성된 정적 웹사이트를 가지고 있습니다.

SysOps 관리자는 정적 웹사이트를 웹 애플리케이션의 백업으로 사용해야 합니다. 정적 웹사이트로의 장애 조치는 완전히 자동화되어야 합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하십시오.)

A. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다.
B. 상태 검사에 실패하면 기본 웹사이트에서 보조 웹사이트로 전환하는 AWS Lambda 함수를 생성합니다.
C. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다. 가장 많이 투표된
D. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다.
E. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다. 가장 많이 투표된

이 시나리오에서 정적 웹사이트를 웹 애플리케이션의 백업으로 사용하고, 이를 완전히 자동화된 방식으로 장애 조치해야 하는 경우, 다음과 같은 조합이 적절합니다:

### 올바른 선택:

**C. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다.**
- 이 단계는 ALB에 대한 기본 경로를 설정하고, ALB에 문제가 발생할 경우 Route 53이 자동으로 상태 검사를 통해 이를 감지하여 장애 조치를 수행하도록 합니다.

**E. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다.**
- 이 단계는 ALB에 장애가 발생했을 때 Route 53이 정적 웹사이트로 자동으로 트래픽을 전환할 수 있도록 합니다.

### 다른 선택지에 대한 설명:

- **A. 기본 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 ALB로 구성합니다.**
  - 이 작업은 필요하지만, 상태 검사를 Route 53과 연결하는 것을 잊어서는 안 됩니다. 단독으로는 자동화된 장애 조치를 보장하지 않습니다.

- **B. 상태 검사에 실패하면 기본 웹사이트에서 보조 웹사이트로 전환하는 AWS Lambda 함수를 생성합니다.**
  - Lambda 함수를 사용한 장애 조치는 가능하지만, Route 53의 상태 검사와 기본적으로 연계되는 장애 조치 정책이 더 간단하고 효과적입니다.

- **D. 보조 장애 조치 라우팅 정책 레코드를 만듭니다. 값을 정적 웹사이트로 구성합니다. 레코드를 Route 53 상태 검사와 연결합니다.**
  - 이 옵션은 보조 레코드를 추가하는 것을 고려할 수 있지만, 실제로 ALB가 기본 레코드이므로 추가적인 설정이 필요합니다.

### 결론:
**C**와 **E**가 완전히 자동화된 장애 조치를 설정하는 데 가장 적합한 조합입니다. 이를 통해 ALB에서 장애가 발생했을 때 자동으로 정적 웹사이트로 트래픽이 전환될 수 있습니다.



## 질문 #47
데이터 분석 애플리케이션이 Amazon EC2 인스턴스에서 실행 중입니다. 

SysOps 관리자는 Amazon CloudWatch 에이전트가 수집한 메트릭에 사용자 지정 차원을 추가해야 합니다.
SysOps 관리자는 이 요구 사항을 어떻게 충족할 수 있습니까?

A. Amazon CloudWatch 에이전트를 사용하여 차원을 추출하고 메트릭을 수집하는 사용자 지정 셸 스크립트를 만듭니다.
B. 필요한 사용자 정의 차원을 평가하고 해당 지표를 Amazon Simple Notification Service(Amazon SNS)로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
C. AWS CloudTrail에서 지표를 수집하고 해당 지표를 Amazon CloudWatch Logs 그룹으로 전송하는 AWS Lambda 함수를 생성합니다.
D. Amazon CloudWatch 에이전트 구성 파일에 append_dimensions 필드를 만들어 메트릭을 수집합니다. 가장 많이 투표된

Amazon CloudWatch 에이전트에 사용자 정의 차원을 추가하여 메트릭을 수집하는 방법으로는 다음과 같은 옵션이 적합합니다:

### 올바른 선택:

**D. Amazon CloudWatch 에이전트 구성 파일에 append_dimensions 필드를 만들어 메트릭을 수집합니다.**
- 이 방법을 사용하면 CloudWatch 에이전트의 구성 파일에서 `append_dimensions` 필드를 설정하여 수집된 메트릭에 사용자 정의 차원을 추가할 수 있습니다. 이렇게 하면 특정 차원이 메트릭과 함께 자동으로 전송됩니다.

### 다른 선택지에 대한 설명:

- **A. Amazon CloudWatch 에이전트를 사용하여 차원을 추출하고 메트릭을 수집하는 사용자 지정 셸 스크립트를 만듭니다.**
  - 이 방법은 가능하지만, 복잡성과 유지 관리의 어려움이 있습니다. CloudWatch 에이전트의 기본 기능을 활용하는 것보다 비효율적입니다.

- **B. 필요한 사용자 정의 차원을 평가하고 해당 지표를 Amazon Simple Notification Service(Amazon SNS)로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.**
  - 이 방법은 차원 수집과 직접적인 연관이 없습니다. 메트릭 수집은 CloudWatch 에이전트의 기능을 통해 이루어져야 합니다.

- **C. AWS CloudTrail에서 지표를 수집하고 해당 지표를 Amazon CloudWatch Logs 그룹으로 전송하는 AWS Lambda 함수를 생성합니다.**
  - 이 방법은 CloudTrail의 기능과 관련이 있지만, 메트릭의 사용자 정의 차원을 추가하는 데 적합하지 않습니다. CloudTrail은 주로 API 호출 로그를 수집하는 데 사용됩니다.

### 결론:
**D** 선택이 가장 적합하며, CloudWatch 에이전트의 구성 파일을 통해 사용자 정의 차원을 쉽게 추가하고 메트릭을 수집할 수 있습니다.



## 질문 #48
한 회사가 Amazon S3 버킷에 데이터를 저장합니다. 

회사는 데이터를 분류하고 S3 파일에서 민감한 개인 정보를 찾아야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. S3 파일에서 민감한 개인 정보를 검색하고 이를 비준수로 표시하는 AWS Config 규칙을 생성합니다.
B. Amazon Rekognition을 사용하여 민감한 개인 정보를 분류하기 위한 S3 이벤트 기반 인공 지능/머신 러닝(AI/ML) 파이프라인을 생성합니다.
C. Amazon GuardDuty를 활성화합니다. Amazon S3 내부의 모든 데이터를 모니터링하도록 S3 보호를 구성합니다.
D. Amazon Macie를 활성화합니다. 관리되는 데이터 식별자를 사용하는 검색 작업을 만듭니다. 가장 많이 투표된

이 문제에서 요구하는 솔루션은 **민감한 개인 정보를 검색하고 이를 분류하는** 것입니다. 이와 관련하여 가장 적합한 선택지는 **D. Amazon Macie를 활성화합니다. 관리되는 데이터 식별자를 사용하는 검색 작업을 만듭니다.**입니다. 

### 선택지 D: Amazon Macie
- **이유**: Amazon Macie는 S3에 저장된 데이터를 자동으로 분석하고, 민감한 정보(예: 개인 식별 정보, 신용 카드 번호 등)를 식별하는 데 최적화되어 있습니다. Macie는 관리되는 데이터 식별자를 사용하여 검색 작업을 수행할 수 있으며, 이로써 민감한 데이터를 쉽게 찾아내고 분류할 수 있습니다. 이 서비스는 특히 개인정보 보호 및 규정 준수를 관리하는 데 유용합니다.

### 다른 선택지 설명

- **A. S3 파일에서 민감한 개인 정보를 검색하고 이를 비준수로 표시하는 AWS Config 규칙을 생성합니다.**
  - AWS Config는 리소스의 구성 변경을 추적하고 규정 준수 여부를 확인하는 서비스입니다. 하지만 S3 파일에서 민감한 정보를 검색하는 기능은 제공하지 않습니다. AWS Config는 규정 준수를 확인할 수는 있지만, 데이터를 분석하고 분류하는 데는 적합하지 않습니다.

- **B. Amazon Rekognition을 사용하여 민감한 개인 정보를 분류하기 위한 S3 이벤트 기반 인공 지능/머신 러닝(AI/ML) 파이프라인을 생성합니다.**
  - Amazon Rekognition은 이미지 및 비디오 분석에 적합한 서비스로, 주로 얼굴 인식이나 객체 인식 등에 사용됩니다. 텍스트 또는 개인 정보 검색에는 적합하지 않으므로, S3 파일에서 민감한 개인 정보를 찾는 데 사용할 수 없습니다.

- **C. Amazon GuardDuty를 활성화합니다. Amazon S3 내부의 모든 데이터를 모니터링하도록 S3 보호를 구성합니다.**
  - Amazon GuardDuty는 보안 위협 탐지 서비스로, 계정이나 리소스의 악의적인 활동을 모니터링하고 경고합니다. 하지만 GuardDuty는 데이터 내용 분석보다는 이상 징후를 탐지하는 데 중점을 두므로, S3 파일에서 민감한 정보를 검색하는 데는 적합하지 않습니다.

### 결론
따라서, **D** 선택이 가장 적합한 솔루션으로, Amazon Macie를 사용하여 S3에 저장된 민감한 개인 정보를 효과적으로 찾아내고 분류할 수 있습니다.


## 질문 #49
한 회사가 Amazon EC2 인스턴스에서 웹 포털을 호스팅합니다. 

웹 포털은 퍼블릭 DNS 서비스에 Elastic Load Balancer(ELB)와 Amazon Route 53을 사용합니다.
ELB와 EC2 인스턴스는 us-east-1 리전에서 단일 AWS CloudFormation 스택을 통해 배포됩니다. 웹 포털은 여러 리전에서 고가용성이어야 합니다.
이러한 요구 사항을 충족하는 구성은 무엇입니까?

A. us-west-2 지역에 스택 사본을 배포합니다. Route 53에 각 ELB의 IP 주소를 포함하는 단일 권한 시작(SOA) 레코드를 만듭니다. 상태 검사를 사용하여 SOA 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다.
B. us-west-2 Region에 스택 사본을 배포합니다. Route 53에 별칭 대상으로 us-west-2의 ELB를 포함하는 추가 A 레코드를 만듭니다. 장애 조치 라우팅 정책 및 상태 검사를 사용하여 A 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다. 가장 많이 투표된
C. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 새로운 EC2 인스턴스를 기존 ELB와 연결하고 모든 EC2 인스턴스에서 로드 밸런서 상태 검사를 구성합니다. us-west-2의 EC2 인스턴스가 상태 검사에 실패하면 Route 53을 업데이트하도록 ELB를 구성합니다.
D. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 각 지역의 모든 EC2 인스턴스에 EC2 상태 검사를 구성합니다. VPC 간에 피어링 연결을 구성합니다. us-east-1의 VPC를 기본 레코드로 사용하고 us-west-2의 VPC를 보조 레코드로 사용합니다.



고가용성을 위해 여러 리전에서 웹 포털을 배포하는 데 필요한 요구 사항을 충족하는 구성을 선택해야 합니다. 이와 관련하여 가장 적합한 선택지는 **B. us-west-2 Region에 스택 사본을 배포합니다. Route 53에 별칭 대상으로 us-west-2의 ELB를 포함하는 추가 A 레코드를 만듭니다. 장애 조치 라우팅 정책 및 상태 검사를 사용하여 A 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다.**입니다.

### 선택지 B 설명
- **장애 조치 라우팅**: 이 옵션은 Route 53의 장애 조치 라우팅 정책을 활용하여, 주 리전(us-east-1)에서 ELB가 실패할 경우 보조 리전(us-west-2)으로 트래픽을 자동으로 전환합니다.
- **상태 검사**: Route 53의 상태 검사를 사용하여 주 리전의 ELB가 비정상 상태일 때 보조 리전의 ELB로 트래픽을 전환합니다. 이는 높은 가용성을 보장합니다.
- **별칭 A 레코드**: 별칭을 사용하면 Route 53이 ELB의 DNS 이름을 사용하여 리전 간 트래픽을 유연하게 관리할 수 있습니다.

### 다른 선택지 설명

- **A. us-west-2 지역에 스택 사본을 배포합니다. Route 53에 각 ELB의 IP 주소를 포함하는 단일 권한 시작(SOA) 레코드를 만듭니다. 상태 검사를 사용하여 SOA 레코드를 구성합니다. us-east-1의 ELB를 기본 레코드로 사용하고 us-west-2의 ELB를 보조 레코드로 사용합니다.**
  - **문제점**: SOA 레코드는 DNS 관리와 관련이 있으며, 장애 조치와 같은 상황을 처리하는 데 적합하지 않습니다. IP 주소 기반으로 트래픽을 라우팅하는 것은 비효율적이며, ELB의 IP 주소는 동적으로 변할 수 있습니다.

- **C. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 새로운 EC2 인스턴스를 기존 ELB와 연결하고 모든 EC2 인스턴스에서 로드 밸런서 상태 검사를 구성합니다. us-west-2의 EC2 인스턴스가 상태 검사에 실패하면 Route 53을 업데이트하도록 ELB를 구성합니다.**
  - **문제점**: ELB가 EC2 인스턴스 상태 검사 실패를 Route 53에 직접 알릴 수는 없습니다. 또한 이 구성은 여러 리전에서 고가용성을 보장하는 방식이 아닙니다.

- **D. us-west-2 지역에 새로운 EC2 인스턴스 그룹을 배포합니다. 각 지역의 모든 EC2 인스턴스에 EC2 상태 검사를 구성합니다. VPC 간에 피어링 연결을 구성합니다. us-east-1의 VPC를 기본 레코드로 사용하고 us-west-2의 VPC를 보조 레코드로 사용합니다.**
  - **문제점**: VPC 피어링은 두 VPC 간의 네트워크 연결을 제공하지만, 웹 애플리케이션의 고가용성 요구 사항을 충족하기 위한 DNS 및 트래픽 라우팅 구성에는 적합하지 않습니다. 또한 EC2 상태 검사는 직접적으로 Route 53의 장애 조치 라우팅에 사용할 수 없습니다.

### 결론
따라서, **B** 선택지가 여러 리전에서의 고가용성과 트래픽 라우팅 요구 사항을 가장 잘 충족하는 방법입니다.




## 질문 #50
SysOps 관리자가 사용자가 RDP를 사용하여 홈 컴퓨터에서 Amazon EC2 Windows 인스턴스에서 실행되는 베스천 서버에 인터넷을 통해 연결할 수 없는 이유를 조사하고 있습니다.
다음 중 이 문제의 가능한 원인은 무엇입니까? (두 가지를 선택하세요.)


A. 요새 서브넷과 연결된 네트워크 ACL이 네트워크 트래픽을 차단하고 있습니다. 가장 많이 투표된
B. 인스턴스에 개인 IP 주소가 없습니다.
C. 배스천의 서브넷과 연결된 경로 테이블에 인터넷 게이트웨이로 가는 경로가 없습니다. 가장 많이 투표된
D. 인스턴스의 보안 그룹에 포트 22에 대한 인바운드 규칙이 없습니다.
E. 인스턴스의 보안 그룹에 포트 3389에 대한 아웃바운드 규칙이 없습니다.

사용자가 RDP(원격 데스크톱 프로토콜)를 사용하여 Amazon EC2 Windows 인스턴스에서 실행되는 배스천 서버에 연결할 수 없는 이유를 조사하는 데 있어, 올바른 선택지는 **A**와 **C**입니다.

### 올바른 선택지

- **A. 요새 서브넷과 연결된 네트워크 ACL이 네트워크 트래픽을 차단하고 있습니다.**
  - **설명**: 네트워크 ACL(Network Access Control List)은 서브넷 수준에서 트래픽을 제어합니다. ACL이 RDP(포트 3389) 트래픽을 차단하면 홈 컴퓨터에서 배스천 서버로의 연결이 실패합니다.

- **C. 배스천의 서브넷과 연결된 경로 테이블에 인터넷 게이트웨이로 가는 경로가 없습니다.**
  - **설명**: 배스천 호스트가 있는 서브넷의 경로 테이블에 인터넷 게이트웨이로의 경로가 없으면 외부 인터넷과 연결할 수 없습니다. 이로 인해 RDP 연결이 실패할 수 있습니다.

### 잘못된 선택지

- **B. 인스턴스에 개인 IP 주소가 없습니다.**
  - **설명**: Amazon EC2 인스턴스는 항상 개인 IP 주소를 가집니다. 배스천 서버는 퍼블릭 IP 주소를 가질 수 있으며, 개인 IP 주소가 없이는 정상적인 작동이 불가능합니다. 이 선택지는 문제의 원인이 아닙니다.

- **D. 인스턴스의 보안 그룹에 포트 22에 대한 인바운드 규칙이 없습니다.**
  - **설명**: RDP 연결에는 포트 3389가 필요하므로, 포트 22(SSH)는 이 경우와 관련이 없습니다. 이는 잘못된 선택지입니다.

- **E. 인스턴스의 보안 그룹에 포트 3389에 대한 아웃바운드 규칙이 없습니다.**
  - **설명**: RDP 연결을 설정할 때, 보안 그룹의 아웃바운드 규칙은 일반적으로 필요하지 않습니다. 인바운드 규칙이 없으면 연결이 실패할 수 있으며, 아웃바운드 규칙이 없다고 해서 연결이 안 되는 것은 아닙니다. 따라서 이 선택지는 잘못된 것입니다.

### 결론
따라서, **A**와 **C**가 문제의 원인으로 적절한 선택지입니다.


## 질문 #51
SysOps 관리자가 다음 AWS CloudFormation 템플릿을 검토하고 있습니다.

스택 생성이 실패하는 이유는 무엇일까요?
A. CloudFormation 템플릿의 출력 섹션이 생략되었습니다.
B. CloudFormation 템플릿의 매개변수 섹션이 생략되었습니다.
C. PrivateDnsName은 CloudFormation 템플릿에서 설정할 수 없습니다. 가장 많이 투표된
D. CloudFormation 템플릿에 VPC가 지정되지 않았습니다.


AWS CloudFormation 스택 생성 실패 원인 분석
AWS CloudFormation은 인프라를 코드로 관리할 수 있게 해주는 서비스입니다. 그러나 템플릿 작성 시 여러 가지 오류가 발생할 수 있으며, 이는 스택 생성 실패로 이어질 수 있습니다. 주어진 선택지들을 하나씩 검토하여 어떤 경우에 스택 생성이 실패할 수 있는지 살펴보겠습니다.

A. CloudFormation 템플릿의 출력 섹션이 생략되었습니다.
출력 섹션은 선택 사항입니다. 이 섹션은 스택 생성 후 반환되는 값을 정의합니다. 따라서 이 섹션이 생략되었다고 해서 스택 생성이 반드시 실패하는 것은 아닙니다.
B. CloudFormation 템플릿의 매개변수 섹션이 생략되었습니다.
매개변수 섹션도 선택 사항입니다. 이 섹션은 사용자로부터 입력받을 값을 정의합니다. 매개변수가 필요하지 않은 경우에는 생략해도 됩니다. 따라서 이 섹션이 생략되었다고 해서 스택 생성이 실패하는 것은 아닙니다.
C. PrivateDnsName은 CloudFormation 템플릿에서 설정할 수 없습니다.
PrivateDnsName은 특정 리소스의 속성으로, 일반적으로 EC2 인스턴스와 같은 리소스에 대해 설정됩니다. 그러나 이 속성을 잘못 설정하거나 지원되지 않는 경우 스택 생성이 실패할 수 있습니다. 예를 들어, VPC 내부에서만 유효한 DNS 이름을 외부에서 접근하려는 경우 문제가 될 수 있습니다.
D. CloudFormation 템플릿에 VPC가 지정되지 않았습니다.

**VPC (Virtual Private Cloud)**는 AWS 리소스를 격리된 네트워크 환경에서 실행하기 위한 가상 네트워크입니다. 많은 리소스는 VPC 내에서 동작해야 하며, VPC가 지정되지 않으면 해당 리소스가 올바르게 생성되지 않을 수 있습니다. 특히, 서브넷이나 보안 그룹과 같은 리소스는 반드시 VPC 내에서 정의되어야 합니다.

결론
주어진 선택지 중에서 스택 생성이 실패할 가능성이 높은 이유는 D. CloudFormation 템플릿에 VPC가 지정되지 않았습니다입니다. VPC는 많은 AWS 리소스가 올바르게 동작하기 위해 필수적인 요소이며, 이를 지정하지 않으면 리소스 생성이 실패할 수 있습니다.

따라서, SysOps 관리자는 템플릿에 VPC가 제대로 지정되었는지 확인해야 합니다. VPC가 지정되지 않았다면, 이를 추가하여 스택을 다시 생성해보는 것이 좋습니다.


## 질문 #52
새로운 애플리케이션이 Amazon EC2 인스턴스에서 실행되고 Amazon RDS 데이터베이스 인스턴스의 데이터에 액세스합니다. 


프로덕션에 완전히 배포되면 애플리케이션이 실패합니다. 데이터베이스는 배스천 호스트의 콘솔에서 쿼리할 수 있습니다. 웹 서버 로그를 살펴보면 다음 오류가 여러 번 반복됩니다.
*** 데이터베이스 연결 설정 오류
다음 중 연결 문제의 원인은 무엇일까요? (두 가지를 선택하세요.)


A. 데이터베이스의 보안 그룹에 데이터베이스에서 웹 서버로의 적절한 탈출 규칙이 없습니다.
B. 웹 서버에서 사용하는 인증서를 RDS 인스턴스에서 신뢰하지 않습니다.
C. 데이터베이스의 보안 그룹에 웹 서버에서 데이터베이스로의 적절한 유입 규칙이 없습니다. 가장 많이 투표된
D. 애플리케이션 개발자가 사용하는 포트가 RDS 구성에 지정된 포트와 일치하지 않습니다. 가장 많이 투표된
E. 데이터베이스가 아직 생성 중이므로 연결할 수 없습니다.

주어진 시나리오에서 애플리케이션이 Amazon EC2 인스턴스에서 실행되고 Amazon RDS 데이터베이스 인스턴스에 연결할 수 없는 이유를 분석할 때, 다음 두 가지가 문제의 원인일 가능성이 높습니다:

### **정답:**
1. **C. 데이터베이스의 보안 그룹에 웹 서버에서 데이터베이스로의 적절한 유입 규칙이 없습니다.**
   - 이 항목은 웹 서버가 RDS 데이터베이스에 연결하기 위한 인바운드 규칙이 보안 그룹에 설정되지 않았음을 나타냅니다. 따라서, 웹 서버에서 데이터베이스로의 트래픽이 차단되어 연결할 수 없습니다.

2. **D. 애플리케이션 개발자가 사용하는 포트가 RDS 구성에 지정된 포트와 일치하지 않습니다.**
   - 이 항목은 애플리케이션이 RDS 인스턴스와 연결하는 데 사용하는 포트가 RDS 인스턴스의 설정에 지정된 포트와 일치하지 않아 발생할 수 있는 문제를 설명합니다. 기본적으로 RDS 인스턴스는 MySQL의 경우 3306, PostgreSQL의 경우 5432와 같은 특정 포트를 사용합니다. 포트가 일치하지 않으면 연결 오류가 발생합니다.

### **잘못된 선택:**
- **A. 데이터베이스의 보안 그룹에 데이터베이스에서 웹 서버로의 적절한 탈출 규칙이 없습니다.**
  - 데이터베이스에서 웹 서버로의 아웃바운드 규칙은 일반적으로 문제가 되지 않으며, 연결 문제의 주된 원인이 아닙니다.

- **B. 웹 서버에서 사용하는 인증서를 RDS 인스턴스에서 신뢰하지 않습니다.**
  - 이 문제는 SSL 연결을 사용할 때 문제가 될 수 있지만, 일반적인 데이터베이스 연결 오류의 주된 원인은 아닙니다. 인증서 문제는 별도의 오류 메시지로 나타날 수 있습니다.

- **E. 데이터베이스가 아직 생성 중이므로 연결할 수 없습니다.**
  - 데이터베이스가 생성 중일 경우 일반적으로 연결 시도가 실패하지만, 로그에 명시된 "데이터베이스 연결 설정 오류"는 주로 보안 그룹 또는 포트 문제로 인한 것일 가능성이 더 큽니다.

따라서, 올바른 선택은 **C**와 **D**입니다.

## 질문 #53
규정 준수 팀은 Amazon RDS DB 인스턴스의 모든 관리자 비밀번호를 최소 1년에 한 번 변경하도록 요구합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족합니까?

A. AWS Secrets Manager에 데이터베이스 자격 증명을 저장합니다. 365일마다 비밀에 대한 자동 로테이션을 구성합니다. 가장 많이 투표된
B. 데이터베이스 자격 증명을 RDS 매개변수 그룹의 매개변수로 저장합니다. 365일마다 비밀번호를 회전하는 데이터베이스 트리거를 만듭니다.
C. 데이터베이스 자격 증명을 개인 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 예약하여 365일마다 새로운 자격 증명 세트를 생성합니다.
D. AWS Systems Manager Parameter Store에 데이터베이스 자격 증명을 안전한 문자열 매개변수로 저장합니다. 365일마다 매개변수에 대한 자동 로테이션을 구성합니다.

주어진 시나리오에서 Amazon RDS DB 인스턴스의 관리자 비밀번호를 최소 1년에 한 번 변경하는 요구 사항을 운영적으로 효율적으로 충족하기 위한 가장 적합한 솔루션은 다음과 같습니다:

### **정답:**
**A. AWS Secrets Manager에 데이터베이스 자격 증명을 저장합니다. 365일마다 비밀에 대한 자동 로테이션을 구성합니다.**
- AWS Secrets Manager는 데이터베이스 자격 증명을 안전하게 저장하고, 자동 로테이션을 구성할 수 있는 기능을 제공합니다. 이를 통해 규정 준수 팀의 요구 사항인 비밀번호를 매년 변경하는 것을 쉽게 관리할 수 있습니다.

### **잘못된 선택:**
- **B. 데이터베이스 자격 증명을 RDS 매개변수 그룹의 매개변수로 저장합니다. 365일마다 비밀번호를 회전하는 데이터베이스 트리거를 만듭니다.**
  - RDS 매개변수 그룹은 데이터베이스 구성에 대한 설정을 관리하지만, 비밀번호 로테이션을 자동으로 관리할 수는 없습니다. 또한 데이터베이스 트리거는 비밀번호 변경을 트리거할 수 없으므로 효율적이지 않습니다.

- **C. 데이터베이스 자격 증명을 개인 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 예약하여 365일마다 새로운 자격 증명 세트를 생성합니다.**
  - S3에 자격 증명을 저장하는 것은 보안상 위험할 수 있으며, Lambda 함수를 사용하여 자격 증명을 생성하는 과정은 관리가 복잡하고 비효율적입니다.

- **D. AWS Systems Manager Parameter Store에 데이터베이스 자격 증명을 안전한 문자열 매개변수로 저장합니다. 365일마다 매개변수에 대한 자동 로테이션을 구성합니다.**
  - Systems Manager Parameter Store는 자격 증명을 저장할 수 있지만, 자동 로테이션 기능이 Secrets Manager만큼 강력하지 않으며, 매개변수를 수동으로 업데이트해야 할 수 있습니다.

결론적으로, AWS Secrets Manager를 사용하는 것이 가장 안전하고 운영적으로 효율적인 방법입니다.


## 질문 #54
SysOps 관리자는 Amazon EC2 인스턴스 플릿을 관리할 책임이 있습니다. 

이러한 EC2 인스턴스는 빌드 아티팩트를 타사 서비스에 업로드합니다. 타사 서비스는 최근 모든 빌드 업로드가 단일 IP 주소에서 이루어져야 하는 엄격한 IP 허용 목록을 구현했습니다.
시스템 관리자는 이 새로운 요구 사항을 준수하기 위해 기존 빌드 플릿에 어떤 변경을 해야 합니까?


A. 모든 EC2 인스턴스를 NAT 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다. 가장 많이 투표된
B. 모든 EC2 인스턴스를 인터넷 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.
C. 모든 EC2 인스턴스를 단일 가용성 영역으로 이동하고 가용성 영역 IP 주소를 서비스에 제공합니다.
D. 모든 EC2 인스턴스를 피어링된 VPC로 이동하고 VPC IP 주소를 서비스에 제공합니다.


주어진 시나리오에서 EC2 인스턴스 플릿이 타사 서비스에 빌드 아티팩트를 업로드할 때, 서비스가 단일 IP 주소에서 업로드를 요구하고 있습니다. 이를 충족하기 위해 SysOps 관리자가 해야 할 가장 적절한 변경 사항은 다음과 같습니다:

### **정답:**
**A. 모든 EC2 인스턴스를 NAT 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.**
- NAT 게이트웨이를 사용하면 모든 EC2 인스턴스에서 인터넷으로 나가는 트래픽이 NAT 게이트웨이를 통해 전송되며, 이 경우 모든 인스턴스의 외부 IP 주소가 NAT 게이트웨이의 IP 주소로 통일됩니다. 따라서 타사 서비스는 단일 IP 주소에서 오는 모든 요청을 허용할 수 있습니다.

### **잘못된 선택:**
- **B. 모든 EC2 인스턴스를 인터넷 게이트웨이 뒤로 옮기고 게이트웨이 IP 주소를 서비스에 제공합니다.**
  - 인터넷 게이트웨이를 사용하면 각 EC2 인스턴스가 고유한 공인 IP 주소를 가지므로, 타사 서비스의 요구 사항인 단일 IP 주소를 충족하지 못합니다.

- **C. 모든 EC2 인스턴스를 단일 가용성 영역으로 이동하고 가용성 영역 IP 주소를 서비스에 제공합니다.**
  - 가용성 영역 IP 주소를 서비스에 제공하는 것은 가용성 영역의 IP 주소가 고정된 것이 아니기 때문에 단일 IP 요구 사항을 충족하지 않습니다.

- **D. 모든 EC2 인스턴스를 피어링된 VPC로 이동하고 VPC IP 주소를 서비스에 제공합니다.**
  - 피어링된 VPC의 IP 주소를 사용하는 것은 해당 VPC 내에서만 적용될 수 있으며, 외부와의 통신에는 영향을 미치지 않기 때문에 단일 IP 요구 사항을 충족하지 않습니다.

따라서 NAT 게이트웨이를 사용하여 모든 인스턴스의 출발 IP를 통일하는 것이 최선의 해결책입니다.


## 질문 #55
한 회사가 Amazon CloudFront 배포를 사용하여 웹사이트를 제공합니다. 

웹사이트의 트래픽 로그는 중앙에 저장되어야 하며 모든 데이터는 저장 시 암호화되어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?


A. 기본 AWS 관리형 고객 마스터 키(CMK)를 사용하는 인터넷 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용하도록 CloudFront를 구성합니다.
B. AES-256을 사용하는 VPC 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. CloudFront를 구성하여 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용합니다.
C. AES-256을 사용하는 기본 서버 측 암호화로 구성된 Amazon S3 버킷을 만듭니다. S3 버킷을 로그 대상으로 사용하도록 CloudFront를 구성합니다. 가장 많이 투표된
D. 기본 암호화 없이 구성된 Amazon S3 버킷을 만듭니다. CloudFront 배포에서 암호화를 활성화하고 S3 버킷을 로그 대상으로 사용합니다.


주어진 요구 사항에 따라 웹사이트의 트래픽 로그를 중앙에서 저장하고 저장 시 암호화해야 합니다. 이러한 요구 사항을 충족하는 최적의 솔루션은 다음과 같습니다:

### **정답:**
**C. AES-256을 사용하는 기본 서버 측 암호화로 구성된 Amazon S3 버킷을 만듭니다. S3 버킷을 로그 대상으로 사용하도록 CloudFront를 구성합니다.**
- Amazon S3는 데이터를 안전하게 저장할 수 있는 서비스이며, 서버 측 암호화를 사용하여 저장 시 데이터 암호화를 자동으로 처리할 수 있습니다. AES-256 암호화를 사용하면 데이터가 저장될 때 자동으로 암호화되므로 보안 요구 사항을 충족합니다. CloudFront의 로그를 S3 버킷에 저장하도록 구성하면 중앙 로그 저장소도 쉽게 관리할 수 있습니다.

### **잘못된 선택:**
- **A. 기본 AWS 관리형 고객 마스터 키(CMK)를 사용하는 인터넷 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용하도록 CloudFront를 구성합니다.**
  - OpenSearch Service는 로그 데이터를 저장할 수 있지만, 일반적으로 CloudFront 로그의 경우 Amazon S3를 사용하는 것이 더 일반적입니다. 추가적인 관리와 복잡성이 발생할 수 있습니다.

- **B. AES-256을 사용하는 VPC 액세스 및 서버 측 암호화를 갖춘 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 만듭니다. CloudFront를 구성하여 Amazon OpenSearch Service(Amazon Elasticsearch Service) 도메인을 로그 대상으로 사용합니다.**
  - OpenSearch를 사용하는 것이 가능하나, S3에 비해 로그 저장 및 관리의 복잡성이 증가합니다. 

- **D. 기본 암호화 없이 구성된 Amazon S3 버킷을 만듭니다. CloudFront 배포에서 암호화를 활성화하고 S3 버킷을 로그 대상으로 사용합니다.**
  - S3 버킷에서 기본 암호화를 활성화하지 않고 생성하는 것은 저장된 데이터의 암호화 요건을 충족하지 않으므로 이 선택지는 적합하지 않습니다.

따라서 Amazon S3 버킷을 사용하여 기본 서버 측 암호화(AES-256)를 구성하는 것이 요구 사항을 가장 잘 충족합니다.

## 질문 #56
한 조직에서 파일 시스템 ID가 fs-85ba41fc인 Amazon Elastic File System(Amazon EFS) 볼륨을 생성했고, 10개의 Amazon EC2 호스트에서 활발하게 사용되고 있습니다. 

이 조직은 파일 시스템이 암호화되지 않은 것에 대해 우려하고 있습니다.
이를 어떻게 해결할 수 있을까요?


A. Amazon EFS 볼륨에 대한 각 호스트 연결에서 암호화를 활성화합니다. 암호화가 적용되려면 각 연결을 다시 만들어야 합니다.
B. AWS 명령줄 인터페이스를 사용하여 기존 EFS 볼륨에서 암호화를 활성화합니다.
C. 각 호스트의 로컬 드라이브에서 암호화를 활성화합니다. 각 호스트를 다시 시작하여 드라이브를 암호화합니다.
D. 새로 생성된 볼륨에서 암호화를 활성화하고 원래 볼륨에서 모든 데이터를 복사합니다. 각 호스트를 새 볼륨에 다시 연결합니다. 가장 많이 투표된


Amazon Elastic File System (Amazon EFS) 볼륨이 암호화되지 않은 것에 대한 우려를 해결하는 가장 적절한 방법은 다음과 같습니다:

### **정답:**
**D. 새로 생성된 볼륨에서 암호화를 활성화하고 원래 볼륨에서 모든 데이터를 복사합니다. 각 호스트를 새 볼륨에 다시 연결합니다.**
- EFS는 기존 파일 시스템에서 암호화를 활성화하는 기능을 제공하지 않으므로, 암호화된 새 EFS 볼륨을 생성하고 기존 데이터를 복사하여 각 EC2 호스트를 새 볼륨에 다시 연결하는 방법이 가장 안전하고 효과적입니다.

### **잘못된 선택:**
- **A. Amazon EFS 볼륨에 대한 각 호스트 연결에서 암호화를 활성화합니다. 암호화가 적용되려면 각 연결을 다시 만들어야 합니다.**
  - EFS는 특정 연결에서 암호화를 활성화하는 것이 아니라, EFS 파일 시스템 자체에서 암호화를 활성화해야 합니다. 기존 파일 시스템에서 암호화를 활성화할 수는 없습니다.

- **B. AWS 명령줄 인터페이스를 사용하여 기존 EFS 볼륨에서 암호화를 활성화합니다.**
  - 기존 EFS 볼륨에서 암호화를 활성화할 수 있는 방법은 없으며, 암호화를 활성화하려면 새 파일 시스템을 생성해야 합니다.

- **C. 각 호스트의 로컬 드라이브에서 암호화를 활성화합니다. 각 호스트를 다시 시작하여 드라이브를 암호화합니다.**
  - 이는 EFS와 관련이 없는 방법이며, EFS 자체의 데이터 보호와는 관계가 없습니다. EFS 볼륨의 암호화는 EFS 파일 시스템 레벨에서 관리됩니다.

따라서, 암호화된 EFS 볼륨을 만들고 데이터를 복사하는 방법이 가장 적합합니다.


## 질문 #57
한 회사가 AWS Service Catalog 포트폴리오를 사용하여 리소스를 만들고 관리합니다.

SysOps 관리자는 새 AWS 계정에서 회사의 기존 AWS 인프라의 복제본을 만들어야 합니다.
이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. 새로운 AWS 계정에서 AWS Service Catalog 포트폴리오를 사용하려면 AWS CloudFormation 템플릿을 만듭니다.
B. 새로운 AWS 계정에서 원래 포트폴리오를 복제하는 AWS Service Catalog 포트폴리오를 수동으로 생성합니다.
C. AWS Lambda 함수를 실행하여 DescribePortfolio API 작업의 출력을 기반으로 새로운 AWS Service Catalog 포트폴리오를 생성합니다.
D. AWS Service Catalog 포트폴리오를 새 AWS 계정과 공유합니다. 포트폴리오를 새 AWS 계정으로 가져옵니다. 가장 많이 투표된

AWS Service Catalog 포트폴리오를 사용하여 리소스를 생성하고 관리하는 경우, 기존 인프라의 복제본을 새 AWS 계정에 효율적으로 만드는 방법은 다음과 같습니다:

### **정답:**
**D. AWS Service Catalog 포트폴리오를 새 AWS 계정과 공유합니다. 포트폴리오를 새 AWS 계정으로 가져옵니다.**
- 이 방법은 기존 포트폴리오를 새 계정과 공유하고 가져오는 과정으로, 기존 리소스를 수동으로 재구성할 필요 없이 효율적으로 기존 인프라를 복제할 수 있습니다.

### **잘못된 선택:**
- **A. 새로운 AWS 계정에서 AWS Service Catalog 포트폴리오를 사용하려면 AWS CloudFormation 템플릿을 만듭니다.**
  - CloudFormation 템플릿을 만들고 관리하는 것은 가능하지만, 이는 수작업으로 템플릿을 작성해야 하므로 운영 효율성이 떨어질 수 있습니다.

- **B. 새로운 AWS 계정에서 원래 포트폴리오를 복제하는 AWS Service Catalog 포트폴리오를 수동으로 생성합니다.**
  - 수동으로 포트폴리오를 복제하는 것은 시간이 많이 걸리고 오류가 발생할 수 있으므로 비효율적입니다.

- **C. AWS Lambda 함수를 실행하여 DescribePortfolio API 작업의 출력을 기반으로 새로운 AWS Service Catalog 포트폴리오를 생성합니다.**
  - Lambda 함수를 사용하는 방법은 가능하지만, API 호출 및 처리 로직을 작성해야 하므로, 운영 효율성 측면에서 불필요하게 복잡할 수 있습니다.

따라서, 기존 포트폴리오를 새 계정과 공유하여 가져오는 것이 가장 운영 효율적인 방법입니다.


## 질문 #58
SysOps 관리자는 AWS 계정의 보안을 관리해야 합니다. 

최근에 IAM 사용자의 액세스 키가 실수로 공개 코드 저장소에 업로드되었습니다.
SysOps 관리자는 이 액세스 키를 사용하여 변경된 모든 것을 식별해야 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?


A. 모든 IAM 이벤트를 분석을 위해 AWS Lambda 함수로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
B. Amazon CloudWatch Logs Insights를 사용하여 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 Amazon EC2 로그를 쿼리합니다.
C. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 AWS CloudTrail 이벤트 기록을 검색합니다. 가장 많이 투표된
D. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 VPC 흐름 로그를 검색합니다.


AWS 계정의 보안을 관리하고 손상된 IAM 사용자의 액세스 키를 통해 발생한 변경 사항을 식별하기 위해 SysOps 관리자는 다음 방법을 사용해야 합니다:

### **정답:**
**C. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 AWS CloudTrail 이벤트 기록을 검색합니다.**
- AWS CloudTrail은 AWS 계정의 API 호출을 기록하고, 특정 IAM 사용자의 액세스 키로 실행된 모든 작업을 추적할 수 있습니다. 따라서 손상된 키로 시작된 이벤트를 검색하여 어떤 변경이 있었는지 식별할 수 있습니다.

### **잘못된 선택:**
- **A. 모든 IAM 이벤트를 분석을 위해 AWS Lambda 함수로 전송하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.**
  - EventBridge를 통해 IAM 이벤트를 처리할 수 있지만, 이 방법은 이미 발생한 이벤트를 식별하는 데는 적합하지 않습니다.

- **B. Amazon CloudWatch Logs Insights를 사용하여 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 Amazon EC2 로그를 쿼리합니다.**
  - EC2 로그는 AWS 서비스의 인스턴스 활동을 추적하지만, IAM 액세스 키와 관련된 이벤트를 파악하는 데 적합하지 않습니다.

- **D. 의심되는 기간 내에 손상된 액세스 키로 시작된 모든 이벤트에 대해 VPC 흐름 로그를 검색합니다.**
  - VPC 흐름 로그는 네트워크 트래픽을 기록하지만 IAM 이벤트에 대한 정보를 제공하지 않으므로 이 목적에는 적합하지 않습니다.

따라서, CloudTrail 이벤트 기록을 검색하는 것이 손상된 액세스 키로 발생한 모든 변경 사항을 식별하는 가장 효과적인 방법입니다.


## 질문 #59
한 회사가 Application Load Balancer(ALB) 뒤의 여러 Amazon EC2 인스턴스에서 리테일 웹사이트를 운영합니다. 

이 회사는 HTTPS 연결을 통해 웹사이트로의 트래픽을 보호해야 합니다.
이러한 요구 사항을 충족하기 위해 SysOps 관리자는 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. 각 EC2 인스턴스에 인증서를 첨부합니다.
B. ALB에 인증서를 첨부합니다. 가장 많이 투표된
C. AWS Certificate Manager(ACM)에서 개인 인증서를 만듭니다.
D. AWS Certificate Manager(ACM)에서 공용 인증서를 만듭니다. 가장 많이 투표된
E. 인증서를 내보내어 웹사이트에 첨부합니다.

HTTPS 연결을 통해 웹사이트로의 트래픽을 보호하기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### **정답:**
1. **B. ALB에 인증서를 첨부합니다.**
   - Application Load Balancer(ALB)에 SSL/TLS 인증서를 첨부하면 ALB가 HTTPS 요청을 처리하고, 클라이언트와 ALB 간의 트래픽을 암호화할 수 있습니다. ALB가 SSL 종료를 수행하게 되면, 뒤에 있는 EC2 인스턴스는 HTTP로 통신할 수 있습니다.

2. **D. AWS Certificate Manager(ACM)에서 공용 인증서를 만듭니다.**
   - AWS Certificate Manager(ACM)를 사용하여 공용 SSL/TLS 인증서를 생성하고 관리할 수 있습니다. ACM에서 생성된 인증서는 ALB에 쉽게 연결할 수 있으며, SSL/TLS 암호화를 지원합니다.

### **잘못된 선택:**
- **A. 각 EC2 인스턴스에 인증서를 첨부합니다.**
  - ALB가 SSL 종료를 수행하는 경우, 각 EC2 인스턴스에 인증서를 첨부할 필요는 없습니다. ALB가 HTTPS 요청을 처리하므로, EC2 인스턴스는 HTTP로 통신할 수 있습니다.

- **C. AWS Certificate Manager(ACM)에서 개인 인증서를 만듭니다.**
  - 일반적으로 공용 인증서가 HTTPS 연결을 위한 목적에 적합합니다. 개인 인증서는 일반적으로 내부 네트워크에서 사용됩니다.

- **E. 인증서를 내보내어 웹사이트에 첨부합니다.**
  - ALB에 인증서를 첨부하는 것이 더 효율적이며, 내보내는 방식은 필요하지 않습니다. 

따라서 ALB에 인증서를 첨부하고 ACM에서 공용 인증서를 만드는 것이 HTTPS 연결을 보호하는 데 가장 효과적인 조합입니다.

## 질문 #60
시뮬레이션 -

지침 -
환경에서 복사-붙여넣기 기능이 작동하지 않는 경우 VM 데스크톱의 지침 파일을 참조하고 Ctrl+C, Ctrl+V 또는 Command-C,
Command-V를 사용합니다.
다음 요구 사항을 충족하도록 Amazon EventBridge를 구성합니다.

1. 모든 리소스에 us-east-2 리전을 사용합니다.
2. 아래에 지정되지 않은 경우 기본 구성 설정을 사용합니다.
3. 아래에 리소스 이름이 지정되지 않은 경우 고유한 리소스 명명을 사용합니다.
4. 기본 이벤트 버스의 모든 Amazon EC2 이벤트가 지난 45일 동안 재생 가능한지 확인합니다.
5. RunFunction이라는 규칙을 만들어 15분마다 정확한 메시지 {"name":"example")를 LogEventFunction이라는 기존 AWS Lambda 함수로 보냅니다.
6. SpotWarning이라는 규칙을 만들어 Amazon EC2 Spot Instance가 중단될 때마다 TopicEvents라는 새 표준 Amazon SNS 토픽으로 알림을 보냅니다. 토픽 구독을 만들지 마십시오. 알림은 다음 구조와 일치해야 합니다.
7. 
입력 경로:
{`instance`:`detail.instance-id}
입력 템플릿:
`EC2 Spot 인스턴스 <instance>가 중단되었습니다.`
중요: 다음 버튼을 클릭하여 이 랩을 완료하고 다음 랩으로 넘어가세요. 다음 버튼을 클릭하면 이 랩으로 돌아갈 수 없습니다.


## 질문 #61
한 회사가 단일 xlarge 범용 Amazon EC2 온디맨드 인스턴스에서 상태가 유지되는 장기 실행 워크로드를 보유하고 있습니다. 

메트릭은 서비스가 항상 사용 가능한 메모리의 80%와 사용 가능한 CPU의 40%를 사용하고 있음을 보여줍니다. SysOps 관리자는 성능에 부정적인 영향을 미치지 않으면서 서비스 비용을 줄여야 합니다.
이러한 요구 사항을 충족하는 인스턴스 유형의 변경은 무엇입니까?

A. 하나의 대규모 컴퓨팅 최적화 온디맨드 인스턴스로 변경합니다.
B. 대용량 메모리 최적화된 단일 온디맨드 인스턴스로 변경합니다. 가장 많이 투표된
C. 하나의 xlarge 범용 스팟 인스턴스로 변경합니다.
D. 두 개의 대규모 일반 용도 온디맨드 인스턴스로 변경합니다.

#### 결론
가장 적합한 옵션은 B. 대용량 메모리 최적화된 단일 온디맨드 인스턴스로 변경하는 것입니다. 이 옵션은 현재 워크로드의 높은 메모리 사용률을 충족하면서도, CPU 사용률이 낮아지는 것을 감안해도 성능 저하 없이 비용을 절감할 수 있습니다.

참고: 실제로는 워크로드의 특성과 예측되는 변화에 따라 최적의 인스턴스 유형을 선택하는 것이 중요합니다. 필요시 AWS Cost Explorer와 같은 도구를 사용하여 비용 분석을 진행하는 것도 좋은 방법입니다.

## 질문 #62
한 회사에서 SysOps 관리자에게 AWS CloudTrail 파일이 생성된 후 변조되지 않도록 해달라고 요청했습니다. 

현재 이 회사는 AWSIdentity and Access Management(IAM)를 사용하여 특정 트레일에 대한 액세스를 제한합니다. 이 회사의 보안 팀은 각 파일의 무결성을 추적할 수 있어야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 새 파일이 전달될 때 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 파일에서 MD5 해시 검사를 계산하고 결과를 Amazon DynamoDB 테이블에 저장합니다. 보안 팀은 DynamoDB에 저장된 값을 사용하여 전달된 파일의 무결성을 확인할 수 있습니다.
B. CloudTrail 버킷에 새 파일이 전달될 때마다 호출되는 AWS Lambda 함수를 만듭니다. Lambda 함수를 구성하여 파일에 대한 MD5 해시 검사를 계산하고 결과를 Amazon 53 객체의 태그로 저장합니다. 보안 팀은 태그의 정보를 사용하여 전달된 파일의 무결성을 확인할 수 있습니다.
C. Amazon S3 버킷에서 CloudTrail 파일 무결성 기능을 활성화합니다. 보안 팀에 S3 버킷에 저장된 파일 무결성 로그에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다.
D. 트레일에서 CloudTrail 파일 무결성 기능을 활성화합니다. 보안 팀은 CloudTrail에서 생성한 다이제스트 파일을 사용하여 전달된 파일의 무결성을 확인할 수 있습니다. 가장 많이 투표된

AWS CloudTrail 파일의 변조를 방지하고 무결성을 추적하기 위한 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **정답:**
**D. 트레일에서 CloudTrail 파일 무결성 기능을 활성화합니다. 보안 팀은 CloudTrail에서 생성한 다이제스트 파일을 사용하여 전달된 파일의 무결성을 확인할 수 있습니다.**
- CloudTrail은 파일 무결성 기능을 제공하여 각 로그 파일에 대한 SHA-256 해시 다이제스트 파일을 생성합니다. 이 다이제스트 파일을 사용하면 보안 팀이 로그 파일의 무결성을 검증할 수 있습니다. 이 방법은 CloudTrail과 직접 통합되어 있어 운영 효율적이며, 추가적인 AWS Lambda 함수나 외부 저장소가 필요하지 않습니다.

### **잘못된 선택:**
- **A.** Lambda 함수를 사용하여 MD5 해시를 계산하는 방법은 실시간으로 무결성을 검사할 수 있지만, CloudTrail의 기본 기능과 비교할 때 더 복잡하고 관리해야 할 요소가 많습니다.
  
- **B.** S3 객체의 태그로 MD5 해시를 저장하는 방법은 실용적이지 않으며, S3 태그를 사용하여 무결성을 확인하는 것은 비효율적입니다. 또한 태그는 객체의 무결성을 직접적으로 검증하는 데 적합하지 않습니다.

- **C.** CloudTrail 파일 무결성 기능을 S3에서 활성화하는 것이 아니라, CloudTrail 트레일 자체에서 직접 활성화해야 합니다. 이 선택은 잘못된 정보입니다.

따라서, **D**가 가장 효율적이고 신뢰할 수 있는 솔루션입니다.

## 질문 #63
AWS 클라우드 인프라에서 조직에 영향을 미칠 수 있는 이벤트가 발생하는 경우, 어떤 AWS 서비스를 사용하여 조직의 어떤 리소스가 영향을 받는지 확인할 수 있습니까?

A. AWS 서비스 상태 대시보드
B. AWS 신뢰할 수 있는 고문
C. AWS 개인 건강 대시보드 가장 많이 투표된
D. AWS 시스템 관리자

조직에 영향을 미칠 수 있는 이벤트가 발생하는 경우, 어떤 AWS 리소스가 영향을 받는지 확인할 수 있는 서비스는 다음과 같습니다:

### **정답:**
**C. AWS 개인 건강 대시보드**
- AWS Personal Health Dashboard는 AWS에서 발생하는 이벤트에 대한 조직의 리소스에 대한 영향을 모니터링하고 알려주는 서비스를 제공합니다. 이 대시보드는 AWS 서비스의 상태와 관련된 정보를 제공하며, 특정 계정 및 리소스에 영향을 미치는 이벤트에 대한 경고를 받을 수 있습니다.

### **잘못된 선택:**
- **A. AWS 서비스 상태 대시보드**: 이 대시보드는 AWS 서비스의 전반적인 상태를 보여주지만, 특정 고객의 리소스에 대한 영향은 보여주지 않습니다.
  
- **B. AWS 신뢰할 수 있는 고문**: AWS Trusted Advisor는 모범 사례에 따라 리소스를 최적화하는 데 도움을 주는 서비스입니다. 서비스 상태와는 관계가 없습니다.
  
- **D. AWS 시스템 관리자**: AWS Systems Manager는 관리 작업을 자동화하는 도구이지만, 특정 이벤트에 대한 리소스 영향을 추적하는 기능은 없습니다.

따라서, **C**가 올바른 선택입니다.

## 질문 #64
한 회사에서 가져온 키 자료가 있는 AWS KMS 고객 마스터 키(CMK)를 사용하고 있습니다. 

이 회사는 Java 애플리케이션에서 별칭으로 CMK를 참조하여 데이터를 암호화합니다. CMK는 6개월마다 순환해야 합니다.
키를 순환하는 프로세스는 무엇입니까?

A. CMK에 대해 자동 키 회전을 활성화하고 6개월 기간을 지정합니다.
B. 새로 가져온 자료로 새 CMK를 만들고 키 별칭을 업데이트하여 새 CMK를 가리키도록 합니다. 가장 많이 투표된
C. 현재 키 자료를 삭제하고 새 자료를 기존 CMK로 가져옵니다.
D. 기존 키 자료의 사본을 백업용으로 새 CMK로 가져오고, 순환 일정을 6개월로 설정합니다.


AWS KMS 고객 마스터 키(CMK)를 사용하여 데이터를 암호화하는 경우, CMK의 순환 프로세스는 다음과 같이 수행해야 합니다:

### **정답:**
**B. 새로 가져온 자료로 새 CMK를 만들고 키 별칭을 업데이트하여 새 CMK를 가리키도록 합니다.**
- CMK는 AWS KMS에서 자동으로 회전할 수 없습니다. 따라서, 새 CMK를 생성하고 별칭을 업데이트하여 새로운 CMK가 사용되도록 하는 방법이 필요합니다.

### **잘못된 선택:**
- **A. CMK에 대해 자동 키 회전을 활성화하고 6개월 기간을 지정합니다.**
  - KMS는 자동으로 키 회전 기능을 제공하지만, 이 기능은 연간 키 회전만 지원하며, 6개월 주기는 지원하지 않습니다.

- **C. 현재 키 자료를 삭제하고 새 자료를 기존 CMK로 가져옵니다.**
  - KMS는 기존 키 자료를 삭제하는 방식으로 키 회전을 지원하지 않습니다. 기존 CMK에 대한 암호화된 데이터는 영향을 받지 않습니다.

- **D. 기존 키 자료의 사본을 백업용으로 새 CMK로 가져오고, 순환 일정을 6개월로 설정합니다.**
  - KMS는 암호화된 키 자료를 백업하는 기능을 제공하지 않으며, 키 회전 일정 설정은 별도로 지원되지 않습니다.

따라서 **B**가 올바른 선택입니다.

## 질문 #65
보안팀은 환경에서 사용되는 AWS Identity and Access Management(IAM) 정책의 수가 증가하고 있기 때문에 우려하고 있습니다. 

팀은 SysOps 관리자에게 현재 사용 중인 IAM 정책의 수와 사용 가능한 총 IAM 정책에 대해 보고하도록 했습니다.
관리자는 현재 IAM 정책 사용량을 현재 서비스 한도와 비교하기 위해 어떤 AWS 서비스를 사용해야 합니까?

A. AWS 신뢰할 수 있는 고문 가장 많이 투표된
B. 아마존 인스펙터
C. AWS 구성
D. AWS 조직


AWS IAM 정책 사용량 모니터링: 적절한 서비스 선택
AWS Identity and Access Management(IAM)는 AWS 리소스에 대한 액세스를 제어하는 중요한 서비스입니다. 보안팀이 현재 사용 중인 IAM 정책의 수와 사용 가능한 총 IAM 정책에 대해 보고를 요청한 상황에서, SysOps 관리자는 이를 효율적으로 모니터링하고 관리할 수 있는 도구를 선택해야 합니다.

옵션 분석
A. AWS 신뢰할 수 있는 고문
AWS 신뢰할 수 있는 고문: AWS 환경의 최적화 및 모범 사례 준수를 위한 권장 사항을 제공하는 서비스입니다.
IAM 정책 분석: 현재 사용 중인 IAM 정책의 수와 서비스 한도를 비교하여 보고할 수 있습니다.
자동화된 모니터링: IAM 정책 사용량을 지속적으로 평가하고, 필요 시 알림을 제공합니다.
강점: AWS 환경 전반에 걸친 모범 사례 준수와 최적화를 지원합니다.

B. 아마존 인스펙터
아마존 인스펙터: AWS 리소스의 보안 및 규정 준수 상태를 평가하는 서비스입니다.
보안 평가: 주로 보안 취약점과 규정 준수 문제를 식별하는 데 중점을 둡니다.
제한 사항: IAM 정책 사용량 모니터링보다는 보안 평가에 더 적합합니다.

C. AWS 구성
AWS 구성: AWS 리소스의 구성 정보를 기록하고 관리하는 서비스입니다.
구성 기록: 리소스의 구성 변경 사항을 추적하고, 현재 상태를 기록합니다.
제한 사항: IAM 정책 사용량 모니터링보다는 리소스 구성 관리에 더 적합합니다.

D. AWS 조직
AWS 조직: 여러 AWS 계정을 중앙에서 관리할 수 있는 서비스입니다.
계정 관리: 다수의 AWS 계정을 통합하여 관리할 수 있습니다.
제한 사항: IAM 정책 사용량 모니터링보다는 계정 관리에 더 적합합니다.

#### 결론
현재 사용 중인 IAM 정책의 수와 사용 가능한 총 IAM 정책에 대해 보고하기 위해 가장 적합한 서비스는 A. AWS 신뢰할 수 있는 고문입니다. 이 서비스는 AWS 환경의 IAM 정책 사용량을 자동으로 모니터링하고, 현재 서비스 한도와 비교하여 보고할 수 있는 기능을 제공합니다. 이를 통해 SysOps 관리자는 IAM 정책 사용 현황을 효율적으로 파악하고 관리할 수 있습니다.


## 질문 #66
SysOps 관리자가 Amazon S3에 호스팅된 웹사이트로 트래픽을 라우팅하기 위해 Amazon Route 53 도메인 이름을 설정하려고 합니다. 

웹사이트의 도메인 이름은 www.example.com이고 S3 버킷 이름은 DOC-EXAMPLE-BUCKET입니다. Route 53에서 레코드 세트를 설정한 후 도메인 이름 www.anycompany.com이 작동하지 않는 듯하고 정적 웹사이트가 브라우저에 표시되지 않습니다.
다음 중 어떤 것이 원인일까요?

A. S3 버킷은 먼저 Amazon CloudFront로 구성되어야 합니다.
B. Route 53 레코드 세트에는 S3 버킷에 대한 액세스를 허용하는 IAM 역할이 있어야 합니다.
C. Route 53 레코드 세트는 S3 버킷과 동일한 지역에 있어야 합니다.
D. S3 버킷 이름은 Route 53의 레코드 세트 이름과 일치해야 합니다. 가장 많이 투표된


Amazon S3에 호스팅된 웹사이트에 대한 트래픽을 라우팅하기 위해 Amazon Route 53 도메인 이름을 설정하는 과정에서 웹사이트가 작동하지 않는 이유는 다음과 같습니다.

### **정답:**
**D. S3 버킷 이름은 Route 53의 레코드 세트 이름과 일치해야 합니다.**
- S3에서 정적 웹사이트 호스팅을 설정할 때, S3 버킷 이름은 사용하려는 도메인 이름과 일치해야 합니다. 즉, `www.example.com`을 호스팅하기 위한 S3 버킷은 `www.example.com`으로 명명되어야 합니다. 현재 버킷 이름이 `DOC-EXAMPLE-BUCKET`인 경우, Route 53의 레코드 세트가 이 버킷과 연결되지 않아 웹사이트가 표시되지 않습니다.

### **잘못된 선택:**
- **A. S3 버킷은 먼저 Amazon CloudFront로 구성되어야 합니다.**
  - S3 버킷은 CloudFront 없이도 직접 정적 웹사이트를 호스팅할 수 있습니다. CloudFront는 선택 사항입니다.

- **B. Route 53 레코드 세트에는 S3 버킷에 대한 액세스를 허용하는 IAM 역할이 있어야 합니다.**
  - Route 53 레코드 세트는 IAM 역할을 요구하지 않습니다. S3 버킷의 퍼블릭 액세스를 적절히 설정하면 됩니다.

- **C. Route 53 레코드 세트는 S3 버킷과 동일한 지역에 있어야 합니다.**
  - Route 53은 전 세계적으로 DNS 서비스를 제공하므로 레코드 세트와 S3 버킷이 동일한 리전에 있을 필요는 없습니다.

따라서 **D**가 문제의 원인입니다.

## 질문 #67
SysOps 관리자가 AWS CloudFormation을 사용하여 서버리스 애플리케이션을 프로덕션 VPC에 배포했습니다. 

이 애플리케이션은 AWS Lambda 함수, Amazon DynamoDB 테이블, Amazon API Gateway API로 구성되어 있습니다. SysOps 관리자는 DynamoDB 테이블을 삭제하지 않고 AWS CloudFormation 스택을 삭제해야 합니다.
SysOps 관리자는 AWS CloudFormation 스택을 삭제하기 전에 어떤 조치를 취해야 합니까?

A. AWS CloudFormation 스택의 DynamoDB 리소스에 보존 삭제 정책을 추가합니다. 가장 많이 투표된
B. AWS CloudFormation 스택의 DynamoDB 리소스에 스냅샷 삭제 정책을 추가합니다.
C. AWS CloudFormation 스택에서 종료 보호를 활성화합니다.
D. dynamodb:DeleteTable 작업에 대한 Deny 문으로 애플리케이션의 IAM 정책을 업데이트합니다.

#### 결론
가장 적합한 방법은 A. AWS CloudFormation 스택의 DynamoDB 리소스에 보존 삭제 정책을 추가하는 것입니다. 이를 통해 DynamoDB 테이블을 삭제하지 않고 AWS CloudFormation 스택을 삭제할 수 있습니다. CloudFormation 템플릿에서 DeletionPolicy 속성을 Retain으로 설정하여 이 작업을 수행할 수 있습니다.

## 질문 #68
SysOps 관리자는 Amazon EC2 인스턴스가 응답을 멈췄다는 알림을 받습니다. 

AWS Management Console은 시스템 검사가 실패하고 있다고 표시합니다.
이 문제를 해결하기 위해 관리자는 먼저 무엇을 해야 합니까?

A. EC2 인스턴스를 재부팅하여 새 호스트에서 시작할 수 있도록 합니다.
B. EC2 인스턴스를 중지한 다음 다시 시작하여 새 호스트에서 시작할 수 있도록 합니다. 가장 많이 투표된
C. EC2 인스턴스를 종료하고 다시 시작합니다.
D. AWS CloudTrail 로그를 보고 EC2 인스턴스에서 어떤 변경 사항이 발생했는지 조사합니다.

AWS Management Console에서 EC2 인스턴스의 시스템 검사가 실패하고 있다는 알림을 받았을 때, 문제를 해결하기 위해 관리자가 먼저 수행해야 할 가장 적절한 조치는 다음과 같습니다.

### **정답:**
**B. EC2 인스턴스를 중지한 다음 다시 시작하여 새 호스트에서 시작할 수 있도록 합니다.**
- 시스템 검사 실패는 일반적으로 인스턴스가 물리적 하드웨어 또는 호스트 시스템에 문제가 있음을 나타냅니다. 인스턴스를 중지한 후 다시 시작하면 EC2가 새로운 호스트에서 인스턴스를 시작하게 되어 이 문제를 해결할 수 있습니다.

### **잘못된 선택:**
- **A. EC2 인스턴스를 재부팅하여 새 호스트에서 시작할 수 있도록 합니다.**
  - 단순한 재부팅은 인스턴스가 동일한 호스트에서 다시 시작되므로 문제를 해결하지 못할 수 있습니다.

- **C. EC2 인스턴스를 종료하고 다시 시작합니다.**
  - 인스턴스를 종료하면 모든 데이터가 사라질 수 있습니다. (EBS 볼륨이 아닌 인스턴스 스토어에서 실행 중인 경우) 이 방법은 비즈니스 요구 사항에 따라 바람직하지 않을 수 있습니다.

- **D. AWS CloudTrail 로그를 보고 EC2 인스턴스에서 어떤 변경 사항이 발생했는지 조사합니다.**
  - 로그를 조사하는 것은 도움이 될 수 있지만, 인스턴스의 시스템 검사가 실패한 문제를 해결하는 데 즉각적인 조치는 아닙니다. 먼저 인스턴스를 다시 시작하여 문제를 해결하는 것이 우선입니다.

따라서 **B**가 문제를 해결하기 위한 가장 적절한 조치입니다.

## 질문 #69
소프트웨어 개발 회사에는 동일한 제품을 작업하는 여러 개발자가 있습니다. 

각 개발자는 자체 개발 환경을 가져야 하며 이러한 개발 환경은 동일해야 합니다. 각 개발 환경은 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스로 구성됩니다. 개발 환경은 필요할 때만 만들어야 하며 비용을 최소화하기 위해 매일 밤 종료해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

A. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 각 개발 인스턴스에서 매일 밤 cron 작업을 예약하여 실행 중인 모든 프로세스를 중지하고 CPU 사용률을 거의 0으로 줄입니다.

B. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 AWS CloudFormation 스택을 삭제합니다. 가장 많이 투표된

C. 개발자에게 CLI 명령을 제공하여 필요할 때 자체 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 모든 EC2 인스턴스와 DB 인스턴스를 종료합니다.

D. 개발자에게 CLI 명령을 제공하여 필요할 때 자체 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS CloudFormation이 모든 개발 환경 리소스를 삭제하도록 합니다.

주어진 시나리오에서 소프트웨어 개발 회사의 요구 사항을 충족하기 위해 가장 운영 효율적인 솔루션은 다음과 같습니다.

### **정답:**
**B. 개발자에게 동일한 AWS CloudFormation 템플릿에 대한 액세스 권한을 제공하여 필요할 때 개발 환경을 프로비저닝할 수 있도록 합니다. 매일 밤 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 예약하여 AWS Lambda 함수를 호출하여 AWS CloudFormation 스택을 삭제합니다.**

### **이유:**
- **일관성:** CloudFormation 템플릿을 사용하면 모든 개발자가 동일한 환경을 쉽게 프로비저닝할 수 있습니다. 이는 환경 간 일관성을 보장합니다.
  
- **비용 효율성:** 매일 밤 CloudFormation 스택을 삭제함으로써 모든 리소스를 제거하고 비용을 절감할 수 있습니다. 필요한 경우에만 환경을 재구성하므로 리소스를 항상 유지하지 않아도 됩니다.

- **자동화:** EventBridge 규칙을 사용하면 매일 밤 자동으로 Lambda 함수를 호출하여 스택을 삭제하는 프로세스를 자동화할 수 있습니다. 이는 관리자가 직접 개입할 필요 없이 효율적으로 작업할 수 있게 합니다.

### **잘못된 선택:**
- **A.** EC2 인스턴스에서 cron 작업을 사용하는 방법은 인스턴스를 계속 유지하게 되어 비용을 증가시킬 수 있습니다. 또한, 프로비저닝 및 삭제를 위한 수동 작업이 필요할 수 있습니다.

- **C.** CLI 명령을 통해 EC2 인스턴스와 DB 인스턴스를 종료할 수 있지만, 모든 리소스를 자동으로 제거하지는 않습니다. 필요할 때마다 수동으로 프로비저닝해야 하며, 매일 밤 실행 중인 인스턴스를 종료하는 방식은 개발 환경을 완전히 삭제하지 않으므로 비용 효율적이지 않을 수 있습니다.

- **D.** AWS CloudFormation이 모든 개발 환경 리소스를 삭제하도록 하여 CLI 명령을 제공하는 것은 유용하지만, 개발자가 템플릿을 기반으로 환경을 쉽게 재구성할 수 있는 유연성을 고려할 때, CloudFormation 스택을 삭제하는 것보다 필요할 때 프로비저닝하는 것이 더 효율적입니다.

따라서 **B**가 모든 요구 사항을 가장 효율적으로 충족하는 방법입니다.


## 질문 #70
회사가 외부 공급업체와 협력하여 데이터 처리 서비스를 제공하고 있습니다. 

이 통합을 위해 공급업체는 공급업체의 AWS 계정에서 Amazon S3 버킷에 회사 데이터를 호스팅해야 합니다. 공급업체는 회사가 AWS Key Management Service(AWS KMS) 키를 제공하여 회사 데이터를 암호화하도록 허용합니다. 공급업체는 이 통합을 위해 회사에 IAM 역할 Amazon Resources Name(ARN)을 제공했습니다.
SysOps 관리자는 이 통합을 구성하기 위해 무엇을 해야 합니까?

A. 새 KMS 키를 만듭니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 새 KMS 키 ARN을 제공합니다. 가장 많이 투표된

B. 새 KMS 키를 만듭니다. 새 IAM 키를 만듭니다. 공급업체의 IAM 역할 ARN을 IAM 사용자에게 연결된 인라인 정책에 추가합니다. 공급업체에 새 IAM 사용자 ARN을 제공합니다.

C. KMS 관리형 S3 키를 사용하여 암호화를 구성합니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 KMS 관리형 S3 키 ARN을 제공합니다.

D. KMS 관리 S3 키를 사용하여 암호화를 구성합니다. S3 버킷을 만듭니다. 공급업체의 IAM 역할 ARN을 S3 버킷 정책에 추가합니다. 공급업체에 S3 버킷 ARN을 제공합니다.

이 통합을 구성하기 위해 SysOps 관리자가 수행해야 하는 가장 적절한 조치는 다음과 같습니다:

### **A. 새 KMS 키를 만듭니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 새 KMS 키 ARN을 제공합니다.**

#### **설명**:
- **KMS 키 생성**: 새로운 AWS KMS 키를 생성하면 회사 데이터에 대한 암호화를 제공할 수 있습니다.
- **IAM 역할 ARN 추가**: 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가하면 해당 역할이 이 KMS 키를 사용하여 데이터를 암호화하거나 복호화할 수 있게 됩니다.
- **KMS 키 ARN 제공**: 마지막으로, 공급업체에게 KMS 키 ARN을 제공하여 공급업체가 해당 키를 사용하여 암호화된 데이터에 접근할 수 있도록 합니다.

### **기타 옵션 설명**:
B. **새 KMS 키를 만듭니다. 새 IAM 키를 만듭니다. 공급업체의 IAM 역할 ARN을 IAM 사용자에게 연결된 인라인 정책에 추가합니다. 공급업체에 새 IAM 사용자 ARN을 제공합니다.**
- IAM 사용자 및 인라인 정책을 만드는 것은 불필요하게 복잡하며, KMS 키를 통한 직접적인 권한 부여가 필요합니다.

C. **KMS 관리형 S3 키를 사용하여 암호화를 구성합니다. 공급업체의 IAM 역할 ARN을 KMS 키 정책에 추가합니다. 공급업체에 KMS 관리형 S3 키 ARN을 제공합니다.**
- KMS 관리형 S3 키는 특정한 경우에만 사용되며, 직접적인 데이터 처리와 관련된 암호화 작업에는 적합하지 않을 수 있습니다.

D. **KMS 관리 S3 키를 사용하여 암호화를 구성합니다. S3 버킷을 만듭니다. 공급업체의 IAM 역할 ARN을 S3 버킷 정책에 추가합니다. 공급업체에 S3 버킷 ARN을 제공합니다.**
- S3 버킷 정책에 IAM 역할 ARN을 추가하는 것은 데이터 접근 제어를 위한 방법이지만, KMS 키를 통한 암호화를 명시적으로 설정하는 것이 더 중요합니다.

결론적으로, **A**가 가장 효과적인 접근 방법입니다. 새로운 KMS 키를 생성하고 공급업체의 IAM 역할 ARN을 추가하여 암호화에 대한 적절한 권한을 제공함으로써, 회사 데이터를 안전하게 관리할 수 있습니다.


## 질문 #71
SysOps 관리자가 AWS Systems Manager Patch Manager를 사용하여 Amazon EC2 인스턴스 플릿에 패치를 적용하고 있습니다. 

SysOps 관리자는 패치 기준선과 유지 관리 기간을 구성했습니다. SysOps 관리자는 또한 인스턴스 태그를 사용하여 패치할 인스턴스를 식별했습니다. SysOps 관리자는 Systems Manager에 EC2 인스턴스에 액세스할 수 있는 권한을 부여해야 합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자가 수행해야 하는 추가 작업은 무엇입니까?

A. 인스턴스 보안 그룹에 인바운드 규칙을 추가합니다.
B. Systems Manager에 대한 액세스 권한이 있는 IAM 인스턴스 프로필을 인스턴스에 연결합니다. 가장 많이 투표된
C. Systems Manager 활성화를 만듭니다. 그런 다음 인스턴스 플릿을 활성화합니다.
D. 태그 기반 선택을 사용하는 대신 패치할 인스턴스를 수동으로 지정합니다.


이 요구 사항을 충족하기 위해 SysOps 관리자가 수행해야 하는 추가 작업은 다음과 같습니다:

### **B. Systems Manager에 대한 액세스 권한이 있는 IAM 인스턴스 프로필을 인스턴스에 연결합니다.**

#### **설명**:
- **IAM 인스턴스 프로필**: Amazon EC2 인스턴스가 AWS Systems Manager와 상호 작용할 수 있도록 하려면 해당 인스턴스에 적절한 IAM 역할을 부여해야 합니다. 이 역할은 Systems Manager에 대한 액세스를 포함해야 하며, 이를 통해 인스턴스가 패치 작업을 수행할 수 있습니다.
- **역할 연결**: 인스턴스 프로필을 인스턴스에 연결하면, 해당 인스턴스가 Systems Manager API를 호출할 수 있는 권한을 갖게 됩니다.

### **기타 옵션 설명**:
A. **인스턴스 보안 그룹에 인바운드 규칙을 추가합니다.**
- 이 작업은 일반적으로 필요하지 않으며, Systems Manager는 인스턴스와의 연결을 위해 인바운드 규칙을 요구하지 않습니다. Systems Manager는 주로 HTTPS를 사용하여 AWS 서비스와 통신합니다.

C. **Systems Manager 활성화를 만듭니다. 그런 다음 인스턴스 플릿을 활성화합니다.**
- 활성화는 Systems Manager의 기능 중 하나이지만, 인스턴스에 권한을 부여하는 데 직접적으로 관련이 없습니다.

D. **태그 기반 선택을 사용하는 대신 패치할 인스턴스를 수동으로 지정합니다.**
- 태그 기반 선택을 사용하는 것이 더 유연하고 관리하기 쉬운 방법입니다. 수동으로 지정하는 것은 비효율적이며 관리 부담을 증가시킵니다.

결론적으로, **B**가 올바른 선택입니다. IAM 인스턴스 프로필을 인스턴스에 연결함으로써 AWS Systems Manager에 대한 액세스를 제공하고, EC2 인스턴스에서 패치를 적용할 수 있는 권한을 보장할 수 있습니다.


## 질문 #72
한 회사가 us-east-1 지역의 Amazon EC2 인스턴스에 웹사이트를 호스팅합니다. 

이 회사는 웹사이트를 eu-central-1 지역으로 확장할 준비를 하고 있지만, 데이터베이스는 us-east-1에만 있어야 합니다. 배포 후 eu-central-1의 EC2 인스턴스는 us-east-1의 데이터베이스에 연결할 수 없습니다.
이 연결 문제를 해결할 가장 운영 효율적인 솔루션은 무엇입니까?

A. 두 지역 간에 VPC 피어링 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다. 가장 많이 투표된
B. 두 지역 간에 VPC 피어링 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
C. 두 지역 간에 VPN 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.
D. 두 지역 간에 VPN 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.


이 문제를 해결하기 위해 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **A. 두 지역 간에 VPC 피어링 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.**

#### **설명**:
- **VPC 피어링 연결**: 두 개의 Amazon VPC(Virtual Private Cloud)를 서로 연결하여 인스턴스가 서로 통신할 수 있도록 하는 방법입니다. 이는 전용 네트워크 경로를 생성하여 낮은 지연 시간과 높은 대역폭을 제공합니다.
- **보안 그룹 규칙**: us-east-1에 있는 데이터베이스의 보안 그룹에 eu-central-1의 EC2 인스턴스의 개인 IP 주소 범위를 인바운드 규칙으로 추가하면, 해당 인스턴스가 데이터베이스에 접근할 수 있는 권한을 부여합니다.

### **기타 옵션 설명**:
B. **두 지역 간에 VPC 피어링 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.**
- 아웃바운드 규칙은 트래픽이 EC2 인스턴스에서 나가는 방향을 정의하며, 데이터베이스에 접근하기 위한 인바운드 규칙을 설정하는 것이 필요합니다.

C. **두 지역 간에 VPN 연결을 만듭니다. 인스턴스의 개인 IP 주소 범위를 데이터베이스 보안 그룹의 아웃바운드 규칙에 추가합니다.**
- VPN 연결은 두 네트워크 간의 보안을 강화할 수 있지만, VPC 피어링이 더 간단하고 관리하기 쉬운 솔루션입니다. 또한 보안 그룹 규칙은 아웃바운드가 아닌 인바운드 규칙을 설정해야 합니다.

D. **두 지역 간에 VPN 연결을 만듭니다. eu-central-1의 인스턴스 보안 그룹을 데이터베이스 보안 그룹의 인바운드 규칙에 추가합니다.**
- VPN 연결을 사용하는 것은 복잡성을 추가하며, VPC 피어링이 이 경우 더 효율적입니다.

결론적으로, **A**가 올바른 선택입니다. VPC 피어링을 설정하고 보안 그룹의 인바운드 규칙을 업데이트하여 eu-central-1의 인스턴스가 us-east-1의 데이터베이스에 연결할 수 있도록 합니다.

## 질문 #73
한 회사에서는 AWS Organizations에서 관리하는 모든 계정에 대해 자동화된 솔루션을 만들어 인바운드 트래픽의 소스 주소로 0.0.0.0/0을 사용하는 모든 보안 그룹을 감지하려고 합니다. 

또한 회사는 회사 인트라넷과 일치하는 특정 CIDR 블록에 대한 액세스를 제한하여 모든 비준수 보안 그룹을 자동으로 수정하려고 합니다.
SysOps 관리자는 솔루션을 만들기 위해 어떤 작업을 수행해야 합니까?

A. 규정을 준수하지 않는 보안 그룹을 감지하기 위한 AWS Config 규칙을 만듭니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다. 가장 많이 투표된
B. 소스 주소가 0.0.0.0/0인 보안 그룹 생성을 거부하는 IAM 정책을 만듭니다. 이 IAM 정책을 회사의 모든 사용자에게 첨부합니다.
C. 새 보안 그룹과 기존 보안 그룹을 검사하기 위한 AWS Lambda 함수를 만듭니다. 비준수 0.0.0.0/0 소스 주소를 확인하고 소스 주소를 승인된 CIDR 블록으로 변경합니다.
D. 조직 단위(OU)에 대한 서비스 제어 정책(SCP)을 만들어 0.0.0.0/0 소스 주소가 있는 보안 그룹 생성을 거부합니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다.

이 요구 사항을 충족하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### **A. 규정을 준수하지 않는 보안 그룹을 감지하기 위한 AWS Config 규칙을 만듭니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다.**

#### **설명**:
- **AWS Config 규칙**: AWS Config를 사용하여 특정 리소스의 구성 상태를 평가하고 지속적으로 모니터링할 수 있습니다. 이를 통해 인바운드 트래픽 소스 주소가 `0.0.0.0/0`인 보안 그룹을 감지할 수 있습니다.
- **자동 수정**: AWS Config 규칙을 설정하여 비준수 보안 그룹을 자동으로 수정하도록 지정할 수 있습니다. 이 자동 수정 프로세스를 통해 0.0.0.0/0 소스 주소를 회사 인트라넷에 맞는 승인된 CIDR 블록으로 변경할 수 있습니다.

### **기타 옵션 설명**:
B. **소스 주소가 0.0.0.0/0인 보안 그룹 생성을 거부하는 IAM 정책을 만듭니다. 이 IAM 정책을 회사의 모든 사용자에게 첨부합니다.**
- IAM 정책으로 보안 그룹 생성을 차단할 수 있지만, 이미 존재하는 보안 그룹을 수정할 수는 없습니다. 이미 생성된 보안 그룹에 대한 접근성을 관리할 수는 없습니다.

C. **새 보안 그룹과 기존 보안 그룹을 검사하기 위한 AWS Lambda 함수를 만듭니다. 비준수 0.0.0.0/0 소스 주소를 확인하고 소스 주소를 승인된 CIDR 블록으로 변경합니다.**
- AWS Lambda 함수를 사용하여 비준수 보안 그룹을 검사하고 수정하는 것은 가능하지만, 관리 및 유지보수의 복잡성을 증가시킵니다. AWS Config를 사용하면 보다 간단하게 자동화할 수 있습니다.

D. **조직 단위(OU)에 대한 서비스 제어 정책(SCP)을 만들어 0.0.0.0/0 소스 주소가 있는 보안 그룹 생성을 거부합니다. 0.0.0.0/0 소스 주소를 승인된 CIDR 블록으로 변경하기 위한 자동 수정을 설정합니다.**
- SCP를 사용하여 조직의 모든 계정에 대해 보안 그룹 생성을 제한할 수는 있지만, 이미 생성된 보안 그룹에 대한 수정은 SCP로는 해결할 수 없습니다.

결론적으로, **A**가 올바른 선택입니다. AWS Config 규칙을 설정하여 비준수 보안 그룹을 감지하고, 자동 수정 기능을 통해 이들 보안 그룹을 조정하여 요구 사항을 충족합니다.

## 질문 #74
회사에서는 AWS 계정의 모든 활동을 AWS CloudTrail을 사용하여 기록해야 합니다. 

또한 SysOps 관리자는 CloudTrail 로그 파일이 수정되거나 삭제되는 시점을 알아야 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?


A. 로그 파일 무결성 검증을 활성화합니다. AWS CLI를 사용하여 로그 파일을 검증합니다. 가장 많이 투표된
B. 로그 파일 무결성 검증을 활성화합니다. AWS CloudTrail Processing Library를 사용하여 로그 파일을 검증합니다.
C. CloudTrail Insights를 사용하여 로그 파일의 수정 사항을 모니터링합니다.
D. Amazon CloudWatch Logs를 사용하여 로그 파일의 수정 사항을 모니터링합니다.

이 요구 사항을 충족하기 위한 가장 적합한 솔루션은 다음과 같습니다:

### **B. 로그 파일 무결성 검증을 활성화합니다. AWS CloudTrail Processing Library를 사용하여 로그 파일을 검증합니다.**

#### **설명**:
- **로그 파일 무결성 검증**: CloudTrail에서 로그 파일 무결성 검증을 활성화하면, CloudTrail은 각 로그 파일에 대한 해시를 생성하여 로그 파일이 수정되지 않았음을 보장합니다. 이를 통해 로그 파일이 안전하게 유지되고 있다는 것을 확인할 수 있습니다.
- **AWS CloudTrail Processing Library**: 이 라이브러리를 사용하면 로그 파일을 검증하고, 무결성을 확인하는 데 필요한 프로세스를 자동화할 수 있습니다. 이를 통해 수동 검증의 필요성을 줄이고, 로그 파일의 수정 여부를 보다 쉽게 확인할 수 있습니다.

### **기타 옵션 설명**:
A. **로그 파일 무결성 검증을 활성화합니다. AWS CLI를 사용하여 로그 파일을 검증합니다.**
- AWS CLI를 사용하여 로그 파일을 검증할 수 있지만, CloudTrail Processing Library를 사용하면 더 효율적이고 안전하게 검증할 수 있습니다.

C. **CloudTrail Insights를 사용하여 로그 파일의 수정 사항을 모니터링합니다.**
- CloudTrail Insights는 비정상적인 활동을 감지하는 데 유용하지만, 로그 파일의 무결성을 보장하지 않으며, 직접적인 수정 사항을 모니터링하는 데는 적합하지 않습니다.

D. **Amazon CloudWatch Logs를 사용하여 로그 파일의 수정 사항을 모니터링합니다.**
- CloudWatch Logs는 로그의 모니터링 및 알림을 설정할 수 있지만, CloudTrail 로그 파일의 무결성을 검증하거나 직접적인 수정 사항을 확인하는 데는 사용할 수 없습니다.

결론적으로, **B**가 올바른 선택입니다. 로그 파일 무결성 검증을 활성화하고 AWS CloudTrail Processing Library를 사용하여 로그 파일을 검증함으로써 수정이나 삭제 여부를 확인할 수 있습니다.

## 질문 #75
한 회사가 AWS에서 상태 저장 웹 기반 애플리케이션을 호스팅할 계획입니다. 

SysOps 관리자가 Amazon EC2 인스턴스의 자동 확장 그룹을 사용하고 있습니다. 웹 애플리케이션은 연중무휴 24시간 실행됩니다. 회사는 트래픽 및 사용 패턴에 따라 올해 말에 동일한 인스턴스 패밀리 내에서 인스턴스 유형을 변경할 수 있어야 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족할 EC2 인스턴스 구매 옵션은 무엇입니까?

A. 변환 가능한 예약 인스턴스 가장 많이 투표된
B. 주문형 인스턴스
C. 스팟 인스턴스
D. 표준 예약 인스턴스

이러한 요구 사항을 가장 비용 효율적으로 충족할 EC2 인스턴스 구매 옵션은 다음과 같습니다:

### **A. 변환 가능한 예약 인스턴스**

#### **설명**:
- **변환 가능한 예약 인스턴스**는 특정 인스턴스 유형에 대한 예약 인스턴스이지만, 필요에 따라 동일한 인스턴스 패밀리 내에서 다른 인스턴스 유형으로 변환할 수 있는 유연성을 제공합니다. 따라서 회사는 트래픽 및 사용 패턴에 따라 인스턴스 유형을 변경할 수 있으며, 이러한 변경은 동일한 인스턴스 패밀리 내에서 가능합니다.
- 이는 연중무휴 24시간 실행되는 애플리케이션에 적합하며, 예측 가능한 사용량에 따라 비용을 절감할 수 있습니다.

### **기타 옵션 설명**:
B. **주문형 인스턴스**:
- 주문형 인스턴스는 사용한 만큼만 비용을 지불하는 유연한 옵션이지만, 장기적으로 비용이 더 많이 발생할 수 있으며 인스턴스 유형 변경의 유연성이 없습니다.

C. **스팟 인스턴스**:
- 스팟 인스턴스는 저렴한 가격으로 사용할 수 있지만, AWS의 수요와 공급에 따라 인스턴스가 종료될 수 있어 연중무휴 24시간 안정적인 서비스 제공에는 적합하지 않습니다.

D. **표준 예약 인스턴스**:
- 표준 예약 인스턴스는 특정 인스턴스 유형에 대해 1년 또는 3년 동안 예약할 수 있지만, 변경할 수 있는 유연성이 없으므로 이 요구 사항에 적합하지 않습니다.

따라서, **A. 변환 가능한 예약 인스턴스**가 요구 사항을 가장 비용 효율적으로 충족할 수 있는 옵션입니다.

## 질문 #76
애플리케이션은 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 

EC2 인스턴스에 새 기능을 배포한 후 일부 인스턴스가 비정상으로 표시되고 Auto Scaling 그룹으로 대체되었습니다. SysOps 관리자가 상태 변경의 원인을 파악하기 전에 EC2 인스턴스가 종료되었습니다. 이 문제를 해결하기 위해 SysOps 관리자는 이 상황에서 AWS Lambda 함수가 호출되도록 하려고 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?

A. Auto Scaling 그룹에 대한 인스턴스 축소 보호 설정을 활성화합니다. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출합니다.
B. Auto Scaling 그룹에 대한 인스턴스 축소 보호 설정을 활성화합니다. Amazon Route 53을 통해 Lambda 함수를 호출합니다.
C. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 라이프사이클 후크를 추가합니다. 가장 많이 투표된
D. Amazon Route 53을 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 수명 주기 후크를 추가합니다.

이러한 요구 사항을 충족하기 위한 최선의 방법은 다음과 같습니다:

### **C. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 라이프사이클 후크를 추가합니다.**

#### **설명**:
- **라이프사이클 후크**는 Auto Scaling 그룹의 인스턴스가 종료되기 전에 특정 작업을 수행할 수 있는 기회를 제공합니다. 이 후크를 사용하여 EC2 인스턴스가 종료되기 전에 Lambda 함수를 호출할 수 있습니다.
- 이를 통해 SysOps 관리자는 인스턴스가 비정상으로 표시되었을 때 상태 변경의 원인을 파악하기 위해 추가적인 로깅이나 알림 기능을 수행할 수 있습니다.
- EventBridge(이전의 CloudWatch Events)는 라이프사이클 후크와 함께 Lambda 함수를 트리거하는 데 적합합니다.

### **기타 옵션 설명**:
A. **Auto Scaling 그룹에 대한 인스턴스 축소 보호 설정을 활성화합니다**:
- 축소 보호는 인스턴스가 종료되지 않도록 보호할 수 있지만, 이 경우 이미 종료되었거나 종료될 예정인 인스턴스에 대해 어떤 작업을 수행하지 않습니다.

B. **Amazon Route 53을 통해 Lambda 함수를 호출합니다**:
- Route 53은 DNS 서비스로, Auto Scaling 그룹과 Lambda 간의 직접적인 트리거를 제공하지 않습니다.

D. **Amazon Route 53을 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 수명 주기 후크를 추가합니다**:
- Route 53은 라이프사이클 후크와 직접 관련이 없습니다. Lambda 호출을 위해서는 EventBridge를 사용하는 것이 적합합니다.

따라서, **C. Amazon EventBridge(Amazon CloudWatch Events)를 통해 Lambda 함수를 호출하기 위해 Auto Scaling 그룹에 라이프사이클 후크를 추가합니다.**가 가장 적절한 선택입니다.


## 질문 #77
한 회사가 여러 클라이언트의 중요 데이터를 호스팅하는 애플리케이션을 실행합니다. 

이 회사는 AWS CloudTrail을 사용하여 다양한 AWS 리소스에서 사용자 활동을 추적합니다. 새로운 보안 요구 사항을 충족하기 위해 이 회사는 CloudTrail 로그 파일이 수정, 삭제 또는 위조되지 않도록 보호해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. CloudTrail 로그 파일 무결성 검증을 활성화합니다. 가장 많이 투표된
B. CloudTrail 로그 파일이 저장된 S3 버킷에서 Amazon S3 MFA Delete를 사용합니다.
C. Amazon S3 버전 관리를 사용하여 CloudTrail 로그 파일의 모든 버전을 보관합니다.
D. AWS Key Management Service(AWS KMS) 보안 키를 사용하여 CloudTrail 로그 파일을 보호합니다.


#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

로그 파일 무결성 검증: CloudTrail 로그 파일 무결성 검증을 활성화하면 로그 파일이 수정되었는지 여부를 쉽게 확인할 수 있습니다.
무결성 보장: 로그 파일의 무결성을 보장하여 수정이나 위조를 방지할 수 있습니다.
따라서, 회사는 CloudTrail 로그 파일 무결성 검증을 활성화하여 로그 파일이 수정, 삭제 또는 위조되지 않도록 보호해야 합니다. 이를 통해 보안 요구 사항을 충족할 수 있습니다.


## 질문 #78
글로벌 기업이 5개의 AWS 지역에서 운영됩니다. 

SysOps 관리자가 회사의 모든 태그가 지정되고 지정되지 않은 Amazon EC2 인스턴스를 식별하려고 합니다.
이 회사는 인스턴스 ID와 태그를 표시하는 출력이 필요합니다.

SysOps 관리자가 이러한 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. AWS 리소스 그룹에서 태그 기반 리소스 그룹을 만듭니다.
B. AWS Trusted Advisor를 사용합니다. Trusted Advisor에서 EC2 On-Demand Instances 확인 결과를 내보냅니다.
C. Cost Explorer를 사용합니다. EC2-Instances의 서비스 유형을 선택하고 리소스별로 그룹화합니다.
D. AWS 리소스 그룹에서 태그 편집기를 사용합니다. 모든 리전을 선택하고 AWS::EC2::Instance의 리소스 유형을 선택합니다. 가장 많이 투표된

이 요구 사항을 충족하기 위한 최선의 방법은 다음과 같습니다:

### **D. AWS 리소스 그룹에서 태그 편집기를 사용합니다. 모든 리전을 선택하고 AWS::EC2::Instance의 리소스 유형을 선택합니다.**

#### **설명**:
- **AWS 리소스 그룹의 태그 편집기**를 사용하면 여러 리전의 리소스를 동시에 검색하고 태그를 검토할 수 있습니다.
- 모든 리전에서 EC2 인스턴스를 선택하고, 각 인스턴스에 대한 태그를 확인하여 태그가 지정된 인스턴스와 지정되지 않은 인스턴스를 쉽게 식별할 수 있습니다.
- 결과를 CSV 형식으로 내보낼 수 있으므로 태그와 인스턴스 ID를 출력하는 데 유용합니다.

### **기타 옵션 설명**:
A. **AWS 리소스 그룹에서 태그 기반 리소스 그룹을 만듭니다**:
- 태그 기반 리소스 그룹은 태그가 지정된 리소스에만 적용되므로, 태그가 지정되지 않은 인스턴스를 식별하는 데 도움이 되지 않습니다.

B. **AWS Trusted Advisor를 사용합니다**:
- Trusted Advisor는 EC2 인스턴스에 대한 몇 가지 확인을 제공하지만, 모든 태그가 지정된 인스턴스와 지정되지 않은 인스턴스를 표시하는 데 필요한 상세한 정보는 제공하지 않습니다.

C. **Cost Explorer를 사용합니다**:
- Cost Explorer는 비용 분석 도구로, 태그 정보를 제공하지만 인스턴스 ID와 태그를 직접적으로 표시하는 기능은 제한적입니다.

따라서, **D. AWS 리소스 그룹에서 태그 편집기를 사용합니다. 모든 리전을 선택하고 AWS::EC2::Instance의 리소스 유형을 선택합니다.**가 가장 적절한 선택입니다.

## 질문 #79
회사는 매일 기가바이트의 파일을 업로드해야 합니다. 

회사는 Amazon S3에 더 높은 처리량과 업로드 속도를 달성해야 합니다.
이 요구 사항을 충족하기 위해 SysOps 관리자는 어떤 조치를 취해야 합니까?


A. GET HTTP 메서드를 허용하고 S3 버킷을 원본으로 하여 Amazon CloudFront 배포를 생성합니다.
B. Amazon ElastiCache 클러스터를 생성하고 S3 버킷에 대한 캐싱을 활성화합니다.
C. AWS Global Accelerator를 설정하고 S3 버킷으로 구성합니다.
D. S3 전송 가속을 활성화하고 파일을 업로드할 때 가속 엔드포인트를 사용합니다. 가장 많이 투표된

회사가 Amazon S3에 더 높은 처리량과 업로드 속도를 달성하기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### **D. S3 전송 가속을 활성화하고 파일을 업로드할 때 가속 엔드포인트를 사용합니다.**

#### **설명**:
- **S3 전송 가속**은 Amazon CloudFront의 엣지 로케이션을 활용하여 데이터 전송 속도를 높이는 기능입니다. 이를 통해 사용자는 가까운 엣지 로케이션에 파일을 먼저 업로드하고, 이후 이 파일이 S3 버킷으로 전송됩니다.
- 이 방식은 장거리 데이터 전송 시의 지연을 줄이고, 특히 대용량 파일의 업로드에 있어 성능을 크게 개선할 수 있습니다.

### **기타 옵션 설명**:
A. **GET HTTP 메서드를 허용하고 S3 버킷을 원본으로 하여 Amazon CloudFront 배포를 생성합니다**:
- CloudFront는 콘텐츠 배포에 유용하지만, 파일 업로드 속도를 향상시키기 위한 직접적인 방법이 아닙니다.

B. **Amazon ElastiCache 클러스터를 생성하고 S3 버킷에 대한 캐싱을 활성화합니다**:
- ElastiCache는 주로 데이터베이스 쿼리 결과 캐싱에 사용되며, S3 파일 업로드 성능 향상에는 직접적인 영향을 미치지 않습니다.

C. **AWS Global Accelerator를 설정하고 S3 버킷으로 구성합니다**:
- Global Accelerator는 애플리케이션의 가용성과 성능을 향상시키기 위한 서비스이지만, S3 버킷에 대한 파일 업로드 성능을 직접적으로 개선하는 데는 적합하지 않습니다.

따라서, **D. S3 전송 가속을 활성화하고 파일을 업로드할 때 가속 엔드포인트를 사용합니다.**가 가장 적절한 선택입니다.

## 질문 #80
SysOps 관리자는 회사의 AWS 계정의 보안 및 규정 준수를 유지합니다. 

회사의 Amazon EC2 인스턴스가 회사 정책을 따르도록 하기 위해 SysOps 관리자는 부서 태그가 없는 모든 EC2 인스턴스를 종료하려고 합니다. 규정을 준수하지 않는 리소스는 거의 실시간으로 종료해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 필수 태그 관리 규칙으로 AWS Config 규칙을 만들어 비준수 리소스를 식별합니다. AWS-TerminateEC2Instance 자동화 문서를 실행하여 비준수 리소스를 종료하도록 자동 수정을 구성합니다. 가장 많이 투표된
B. 새로운 EC2 인스턴스가 생성될 때 모니터링하기 위한 새로운 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 자동 수정을 위해 이벤트를 Simple Notification Service(Amazon SNS) 토픽으로 보냅니다.
C. EC2 인스턴스를 생성할 수 있는 모든 사용자에게 ec2:CreateTags 및 ec2:DescribeTags 작업을 사용할 수 있는 권한도 있는지 확인합니다. 인스턴스의 종료 동작을 종료로 변경합니다.
D. AWS Systems Manager Compliance가 EC2 인스턴스를 관리하도록 구성되어 있는지 확인합니다. AWS-StopEC2Instances 자동화 문서를 호출하여 비준수 리소스를 중지합니다.


SysOps 관리자가 부서 태그가 없는 모든 EC2 인스턴스를 종료하여 보안 및 규정 준수를 유지하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### **A. 필수 태그 관리 규칙으로 AWS Config 규칙을 만들어 비준수 리소스를 식별합니다. AWS-TerminateEC2Instance 자동화 문서를 실행하여 비준수 리소스를 종료하도록 자동 수정을 구성합니다.**

#### **설명**:
- **AWS Config**를 사용하여 리소스의 구성을 평가하고 규정 준수를 확인할 수 있습니다. 필수 태그를 확인하는 규칙을 설정하면 태그가 없는 EC2 인스턴스를 쉽게 식별할 수 있습니다.
- **자동 수정** 기능을 활용하여 비준수 리소스를 자동으로 종료할 수 있는 AWS 자동화 문서인 `AWS-TerminateEC2Instance`를 실행할 수 있습니다. 이를 통해 거의 실시간으로 비준수 리소스를 종료할 수 있습니다.

### **기타 옵션 설명**:
B. **새로운 EC2 인스턴스가 생성될 때 모니터링하기 위한 새로운 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 자동 수정을 위해 이벤트를 Simple Notification Service(Amazon SNS) 토픽으로 보냅니다**:
- 이 접근 방식은 인스턴스 생성 시점에만 대응할 수 있으며, 기존 비준수 인스턴스에 대해 즉각적으로 종료할 수 없습니다.

C. **EC2 인스턴스를 생성할 수 있는 모든 사용자에게 ec2:CreateTags 및 ec2:DescribeTags 작업을 사용할 수 있는 권한도 있는지 확인합니다. 인스턴스의 종료 동작을 종료로 변경합니다**:
- 이 방법은 태그가 없는 인스턴스를 종료하는 직접적인 접근법이 아니며, 기존 인스턴스에 대한 자동화된 처리를 제공하지 않습니다.

D. **AWS Systems Manager Compliance가 EC2 인스턴스를 관리하도록 구성되어 있는지 확인합니다. AWS-StopEC2Instances 자동화 문서를 호출하여 비준수 리소스를 중지합니다**:
- 이 접근은 비준수 인스턴스를 중지하는 것이지 종료하는 것이 아니므로, 요구 사항을 완전히 충족하지 않습니다.

따라서, **A. 필수 태그 관리 규칙으로 AWS Config 규칙을 만들어 비준수 리소스를 식별합니다. AWS-TerminateEC2Instance 자동화 문서를 실행하여 비준수 리소스를 종료하도록 자동 수정을 구성합니다.**가 가장 적절한 선택입니다.

## 질문 #81
한 회사가 S3 버전 관리가 활성화된 Amazon S3 버킷에 웹사이트 파일을 업로드했습니다. 

이 회사는 S3 버킷을 원본으로 하는 Amazon CloudFront 배포판을 사용합니다. 이 회사는 최근에 파일을 수정했지만 객체 이름은 동일하게 유지되었습니다. 사용자들은 오래된 콘텐츠가 여전히 웹사이트에 표시된다고 보고합니다.
SysOps 관리자는 이 문제를 어떻게 해결해야 합니까?

A. CloudFront 무효화를 생성하고 업데이트된 파일의 경로를 추가합니다. 가장 많이 투표된
B. CloudFront 서명 URL을 생성하여 각 객체를 즉시 업데이트합니다.
C. S3 원본 액세스 ID(OAI)를 구성하여 사용자에게 업데이트된 파일만 표시합니다.
D. S3 버킷에서 S3 버전 관리를 비활성화하여 업데이트된 파일이 이전 파일을 대체할 수 있도록 합니다.


사용자들이 오래된 콘텐츠를 여전히 웹사이트에서 보고하는 문제를 해결하기 위해 SysOps 관리자가 취할 수 있는 가장 적절한 조치는 다음과 같습니다:

### **A. CloudFront 무효화를 생성하고 업데이트된 파일의 경로를 추가합니다.**

#### **설명**:
- **CloudFront 무효화**는 캐시된 콘텐츠를 삭제하고 업데이트된 콘텐츠를 가져오는 방법입니다. S3 버킷에서 파일이 수정되었더라도, CloudFront가 해당 파일을 캐시하고 있을 경우 사용자는 여전히 이전 버전의 파일을 보게 됩니다.
- 따라서, CloudFront 무효화를 생성하여 업데이트된 파일의 경로를 추가하면 캐시된 콘텐츠를 무효화하고 사용자가 최신 파일을 볼 수 있게 됩니다.

### **기타 옵션 설명**:
B. **CloudFront 서명 URL을 생성하여 각 객체를 즉시 업데이트합니다.**
- 서명된 URL은 보안 액세스를 제공하지만, 캐시된 콘텐츠를 무효화하는 데는 도움이 되지 않습니다.

C. **S3 원본 액세스 ID(OAI)를 구성하여 사용자에게 업데이트된 파일만 표시합니다.**
- OAI는 CloudFront가 S3 버킷에 액세스할 수 있도록 하는 방법이지만, 오래된 콘텐츠를 표시하는 문제를 해결하지 않습니다.

D. **S3 버킷에서 S3 버전 관리를 비활성화하여 업데이트된 파일이 이전 파일을 대체할 수 있도록 합니다.**
- S3 버전 관리를 비활성화하면 이전 버전의 파일이 삭제되지만, 이는 데이터 손실을 초래할 수 있으며, 이 문제를 해결하는 최선의 방법이 아닙니다.

결론적으로, **A**가 가장 효과적인 해결책입니다. CloudFront 무효화를 통해 사용자가 최신 콘텐츠를 즉시 볼 수 있게 됩니다.



## 질문 #82
한 회사에 VPC A와 VPC B라는 두 개의 VPC 네트워크가 있습니다. 

VPC A CIDR 블록은 10.0.0.0/16이고 VPC B CIDR 블록은 172.31.0.0/16입니다. 이 회사는 두 VPC 사이에 pcx-12345라는 VPC 피어링 연결을 설정하려고 합니다.
구성 후 VPC A의 경로 테이블에 어떤 규칙이 나타나야 합니까? (두 가지를 선택하세요.)

A. 목적지: 10.0.0.0/16, 타겟: 로컬 가장 많이 투표된
B. 목적지: 172.31.0.0/16, 타겟: 로컬
C. 대상: 10.0.0.0/16, 대상: pcx-12345
D. 목적지: 172.31.0.0/16, 타겟: pcx-12345 가장 많이 투표된
E. 대상: 10.0.0.0/16, 대상: 172.31.0.0/16

VPC A와 VPC B 간의 VPC 피어링 연결을 설정한 후, VPC A의 경로 테이블에 나타나야 할 규칙은 다음과 같습니다:

### **정답:**
1. **C. 목적지: 10.0.0.0/16, 타겟: pcx-12345**
2. **D. 목적지: 172.31.0.0/16, 타겟: pcx-12345**

### **설명:**

- **C. 목적지: 10.0.0.0/16, 타겟: pcx-12345**:
  - VPC A의 CIDR 블록인 10.0.0.0/16에 대한 트래픽은 VPC A 내부에서 처리되므로, 해당 목적지는 "로컬"을 사용할 수 있습니다. 그러나, VPC 피어링이 설정된 경우, 피어링 연결을 통해 VPC A의 자원에서 VPC B의 자원으로 트래픽을 보낼 수 있도록 하는 경로가 필요합니다.

- **D. 목적지: 172.31.0.0/16, 타겟: pcx-12345**:
  - VPC B의 CIDR 블록인 172.31.0.0/16에 대한 트래픽은 VPC B로 전달되어야 하므로, 이 경로는 VPC A에서 VPC B로의 피어링 연결을 통해 트래픽을 전달하는 역할을 합니다.

### **잘못된 선택:**
- **A. 목적지: 10.0.0.0/16, 타겟: 로컬**:
  - 이 경로는 VPC A 내부 트래픽을 나타내므로 필요하지만, 질문에서 요구하는 두 가지 선택 중 하나가 아닙니다.

- **B. 목적지: 172.31.0.0/16, 타겟: 로컬**:
  - 이 경로는 VPC A에서 VPC B로의 트래픽을 처리하지 않으며, 필요하지 않습니다.

- **E. 대상: 10.0.0.0/16, 대상: 172.31.0.0/16**:
  - 이 선택은 두 CIDR 블록을 나열하지만, 경로 테이블에서 사용되는 형태가 아닙니다.

따라서, 정답은 **C**와 **D**입니다.


## 질문 #83
한 회사가 고객의 판매 데이터를 분석합니다. 

고객이 회사의 Amazon S3 버킷 중 하나에 파일을 업로드하면 Amazon Simple Queue Service(Amazon SQS) 대기열에 Amazon Resource Name(ARN) 개체가 게시됩니다. Amazon EC2 인스턴스에서 실행되는 애플리케이션이 대기열을 폴링하고 메시지를 처리합니다. 처리 시간은 파일 크기에 따라 다릅니다.
고객이 파일 처리가 지연된다고 보고합니다. SysOps 관리자가 첫 번째 단계로 Amazon EC2 Auto Scaling을 구성하기로 결정했습니다. SysOps
관리자가 기존 EC2 인스턴스를 기반으로 하는 Amazon Machine Image(AMI)를 만듭니다. SysOps 관리자는 또한 AMI를 참조하는 시작 템플릿을 만듭니다. SysOps
관리자는 응답 시간을 개선하기 위해 Auto Scaling 정책을 어떻게 구성해야 합니까?

A. 시작 템플릿에 여러 다른 인스턴스 크기를 추가합니다. ApproximateNumberOfMessagesVisible 메트릭을 기반으로 자동 크기 조정 정책을 만들어 큐의 메시지 수에 따라 인스턴스 크기를 선택합니다.
B. 대기열에 있는 지연된 메시지 수에 따라 인스턴스 수를 조정하기 위해 ApproximateNumberOfMessagesDelayed 메트릭을 기반으로 자동 크기 조정 정책을 만듭니다.
C. ASGAverageCPUUtilization 메트릭과 Auto Scaling 그룹의 GroupPendingInstances 메트릭을 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다.
D. ApproximateNumberOfMessagesVisible 메트릭과 Auto Scaling 그룹의 InService 상태 인스턴스 수를 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다. 가장 많이 투표된

고객의 파일 처리 지연 문제를 해결하기 위해 Amazon EC2 Auto Scaling을 구성하는 가장 효과적인 방법은 다음과 같습니다:

### **B. 대기열에 있는 지연된 메시지 수에 따라 인스턴스 수를 조정하기 위해 ApproximateNumberOfMessagesDelayed 메트릭을 기반으로 자동 크기 조정 정책을 만듭니다.**

#### **설명**:
- **ApproximateNumberOfMessagesDelayed 메트릭**은 SQS 대기열에 지연된 메시지의 수를 나타냅니다. 이 메트릭을 사용하여 대기열에 지연된 메시지가 많을수록 추가 인스턴스를 시작하도록 자동 확장 정책을 설정할 수 있습니다. 
- 지연된 메시지가 많다는 것은 처리할 메시지가 많고, 현재 인스턴스의 처리 능력이 부족하다는 것을 의미하므로, 이 메트릭을 기반으로 인스턴스를 추가로 실행하면 지연을 줄일 수 있습니다.

### **기타 옵션 설명**:
A. **시작 템플릿에 여러 다른 인스턴스 크기를 추가합니다. ApproximateNumberOfMessagesVisible 메트릭을 기반으로 자동 크기 조정 정책을 만들어 큐의 메시지 수에 따라 인스턴스 크기를 선택합니다.**
- 이 방법은 큐의 전체 메시지 수에 따라 인스턴스를 크기를 조정하려고 하지만, 지연된 메시지 수가 문제의 핵심이므로 효과적이지 않을 수 있습니다.

C. **ASGAverageCPUUtilization 메트릭과 Auto Scaling 그룹의 GroupPendingInstances 메트릭을 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다.**
- CPU 사용량은 처리가 지연되는 직접적인 원인이 아닐 수 있으므로 이 옵션은 적절하지 않을 수 있습니다.

D. **ApproximateNumberOfMessagesVisible 메트릭과 Auto Scaling 그룹의 InService 상태 인스턴스 수를 기반으로 사용자 지정 메트릭을 만듭니다. 메트릭을 계산하고 1분마다 Amazon CloudWatch에 메트릭을 게시하도록 애플리케이션을 수정합니다. 이 메트릭을 기반으로 Auto Scaling 정책을 만들어 인스턴스 수를 확장합니다.**
- Visible 메시지 수는 대기열에 대기 중인 메시지 수를 의미하지만, 지연된 메시지 수를 다루지 않기 때문에 처리 지연 문제를 완전히 해결하지는 못할 수 있습니다.

따라서 **B**가 가장 적합한 솔루션입니다.



## 질문 #84
한 회사가 us-east-1 지역의 한 가용성 영역에 두 개의 Amazon EC2 인스턴스가 있는 다중 계층 웹 애플리케이션을 실행합니다. 

SysOps 관리자는 EC2 인스턴스 중 하나를 새 가용성 영역으로 마이그레이션해야 합니다.
어떤 솔루션이 이를 달성할까요?


A. EC2 인스턴스를 다른 가용성 영역으로 복사합니다. 원래 인스턴스를 종료합니다.
B. EC2 인스턴스에서 Amazon Machine Image(AMI)를 생성하고 다른 가용성 영역에서 시작합니다. 원래 인스턴스를 종료합니다. 가장 많이 투표된
C. AWS CLI를 사용하여 EC2 인스턴스를 다른 가용성 영역으로 이동합니다.
D. EC2 인스턴스를 중지하고 가용성 영역을 수정한 다음 인스턴스를 시작합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 B입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 데이터 일관성 유지: AMI를 사용하여 인스턴스의 상태와 데이터를 완벽히 복제할 수 있습니다.
* 신뢰성: AMI를 통해 새로운 인스턴스를 시작하면 기존 인스턴스와 동일한 환경을 보장할 수 있습니다.
* 유연성: 다른 가용성 영역에서 새로운 인스턴스를 시작할 수 있어 유연성이 높습니다.
* 따라서, SysOps 관리자는 EC2 인스턴스에서 Amazon Machine Image(AMI)를 생성하고 다른 가용성 영역에서 시작한 후 원래 인스턴스를 종료하는 방법을 사용하여 인스턴스를 새 가용성 영역으로 마이그레이션해야 합니다.

## 질문 #85
한 회사가 트래픽 증가가 예상되기 전에 Amazon EC2 인스턴스의 플릿을 확장하고 있습니다. 

SysOps 관리자가 인스턴스를 더 추가하려고 하면 InstanceLimitExceeded 오류가 반환됩니다.
SysOps 관리자는 이 오류를 해결하기 위해 무엇을 해야 합니까?

A. VPC에 추가 CIDR 블록을 추가합니다.
B. 다른 가용성 영역에서 EC2 인스턴스를 시작합니다.
C. 다른 VPC에서 새로운 EC2 인스턴스를 시작합니다.
D. 서비스 할당량을 사용하여 EC2 할당량 증가를 요청합니다. 가장 많이 투표된

##### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 D입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

근본적인 해결책: EC2 인스턴스 할당량을 늘림으로써 문제를 근본적으로 해결할 수 있습니다.
공식적인 절차: AWS Support를 통해 할당량 증가를 요청하는 공식적인 절차를 따릅니다.
확장성: 향후 트래픽 증가에 대비하여 더 많은 인스턴스를 확보할 수 있습니다.
따라서, SysOps 관리자는 서비스 할당량을 사용하여 EC2 할당량 증가를 요청함으로써 InstanceLimitExceeded 오류를 해결하고 인스턴스 플릿을 성공적으로 확장할 수 있습니다.

## 질문 #86
한 회사가 개발자가 특정 Amazon EC2 인스턴스 패밀리를 사용하는 것을 금지하려고 합니다. 

이 회사는 AWS Organizations를 사용하고 여러 계정에 제한을 적용하려고 합니다.
이 회사가 이러한 요구 사항을 충족하기 위해 서비스 제어 정책(SCP)을 적용하는 가장 운영 효율적인 방법은 무엇입니까?


A. 조직 단위(OU)에 계정을 추가합니다. OU에 SCP를 적용합니다. 가장 많이 투표된
B. AWS Resource Groups의 리소스 그룹에 계정을 추가합니다. SCP를 리소스 그룹에 적용합니다.
C. 각 개발자 계정에 SCP 적용
D. AWS Control Tower에 계정을 등록합니다. AWS Control Tower 관리 계정에 SCP를 적용합니다.


#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 조직 단위 활용: AWS Organizations의 조직 단위를 활용하여 여러 계정에 일괄적으로 정책을 적용할 수 있습니다.
* 관리 효율성: 조직 구조를 활용하여 정책 관리가 용이하며, 일관된 정책 적용이 가능합니다.
* 확장성: 조직 단위 내에 더 많은 계정을 추가할 수 있어 확장성이 뛰어납니다.
따라서, 회사는 조직 단위(OU)에 계정을 추가하고 OU에 SCP를 적용함으로써 특정 Amazon EC2 인스턴스 패밀리의 사용을 금지하는 정책을 효율적으로 관리할 수 있습니다.


## 질문 #87

애플리케이션은 기본 DHCP 옵션이 설정된 VPC의 Amazon EC2 인스턴스에서 실행 중입니다. 

애플리케이션은 DNS 이름 mssql.example.com을 사용하여 온프레미스 Microsoft SQL Server 데이터베이스에 연결합니다 . 애플리케이션은 데이터베이스 DNS 이름을 확인할 수 없습니다.
어떤 솔루션이 이 문제를 해결할까요?


A. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 전달 규칙을 추가합니다. 전달 규칙을 VPC와 연결합니다.
B. Amazon Route 53 Resolver 인바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 시스템 규칙을 추가합니다. 시스템 규칙을 VPC와 연결합니다.
C. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 전달 규칙을 추가합니다. 전달 규칙을 VPC와 연결합니다. 가장 많이 투표된
D. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 도메인 example.com에 대한 시스템 규칙을 추가합니다. 시스템 규칙을 VPC와 연결합니다.

Amazon Route 53 Resolver: DNS 문제 해결
애플리케이션이 기본 DHCP 옵션이 설정된 VPC의 Amazon EC2 인스턴스에서 실행 중이며, DNS 이름 mssql.example.com을 사용하여 온프레미스 Microsoft SQL Server 데이터베이스에 연결하려고 합니다. 그러나 애플리케이션은 데이터베이스 DNS 이름을 확인할 수 없는 문제가 발생했습니다. 이 문제를 해결하기 위한 방법을 살펴보겠습니다.

주요 고려 사항
DNS 조회 문제: 애플리케이션이 외부 DNS 이름을 확인할 수 없습니다.
온프레미스와의 통합: 온프레미스 DNS 서버와 VPC 간의 DNS 조회가 원활하게 이루어져야 합니다.
Route 53 Resolver 사용: AWS Route 53 Resolver를 사용하여 DNS 조회 문제를 해결할 수 있습니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 C입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

아웃바운드 엔드포인트 사용: VPC 내부에서 외부 DNS 서버로의 쿼리를 처리할 수 있습니다.
전달 규칙 설정: 도메인 example.com에 대한 전달 규칙을 추가하여 온프레미스 DNS 서버로 쿼리를 전달할 수 있습니다.
VPC와의 연결: 전달 규칙을 VPC와 연결하여 애플리케이션이 외부 DNS 이름을 확인할 수 있도록 합니다.
따라서, 회사는 Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만들고, 도메인 example.com에 대한 전달 규칙을 추가하여 VPC와 연결함으로써 DNS 조회 문제를 해결할 수 있습니다.


## 질문 #88
회사의 애플리케이션은 app.example.com에서 인터넷 제공자에 의해 호스팅됩니다. 

회사는 Amazon Route 53으로 소유하고 관리하는 www.company.com을 사용하여 애플리케이션에 액세스하려고 합니다.
이를 해결하기 위해 어떤 Route 53 레코드를 만들어야 합니까?


A. 기록
B. 별칭 기록
C. CNAME 레코드 가장 많이 투표된
D. 포인터(PTR) 레코드


Amazon Route 53: 도메인 재지정
회사의 애플리케이션은 app.example.com에서 인터넷 제공자에 의해 호스팅되고 있습니다. 회사는 Amazon Route 53으로 소유하고 관리하는 www.company.com을 사용하여 애플리케이션에 액세스하려고 합니다. 이를 해결하기 위해 적절한 Route 53 레코드를 설정해야 합니다.

주요 고려 사항
도메인 재지정: www.company.com을 app.example.com으로 재지정해야 합니다.
DNS 레코드 유형: 올바른 DNS 레코드 유형을 선택하여 도메인 재지정을 구현해야 합니다.
옵션 분석
각 옵션의 특징과 장단점을 비교해 보겠습니다:

* 옵션 A: 기록

설명: 일반적인 A 레코드는 특정 도메인 이름을 IPv4 주소로 매핑합니다.
장점: IP 주소를 직접 지정할 수 있습니다.
단점: 도메인 이름 간의 재지정에는 적합하지 않습니다.

* 옵션 B: 별칭 기록

설명: AWS에서 제공하는 별칭 레코드는 한 AWS 리소스를 다른 AWS 리소스로 매핑할 수 있습니다.
장점: AWS 리소스 간의 매핑에 유용합니다.
단점: 외부 도메인과의 재지정에는 적합하지 않습니다.

* 옵션 C: CNAME 레코드

설명: CNAME 레코드는 하나의 도메인 이름을 다른 도메인 이름으로 매핑합니다.
장점: 도메인 이름 간의 재지정에 적합합니다.
단점: 루트 도메인(company.com)에는 사용할 수 없습니다.

* 옵션 D: 포인터(PTR) 레코드

설명: PTR 레코드는 IP 주소를 도메인 이름으로 매핑하는 역방향 DNS 조회를 지원합니다.
장점: 역방향 DNS 조회에 유용합니다.
단점: 도메인 이름 간의 재지정에는 적합하지 않습니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 C입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

도메인 이름 재지정: CNAME 레코드는 www.company.com을 app.example.com으로 재지정하는 데 적합합니다.
간편한 설정: CNAME 레코드를 사용하면 도메인 이름 간의 매핑이 간편합니다.
따라서, 회사는 CNAME 레코드를 만들어 www.company.com을 app.example.com으로 재지정함으로써 애플리케이션에 액세스할 수 있습니다.


## 질문 #89
한 회사가 전 세계 청중에게 서비스를 제공하기 위해 웹 애플리케이션을 확장했습니다. 

SysOps 관리자가 모든 프로덕션 인프라에 대해 다중 지역 AWS 배포를 구현했습니다. SysOps 관리자는 리소스의 위치를 ​​기반으로 트래픽을 라우팅해야 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 Amazon Route 53 라우팅 정책을 사용해야 합니까?


A. 지리적 위치 라우팅 정책
B. 지근거리 라우팅 정책 가장 많이 투표된
C. 지연 기반 라우팅 정책
D. 다중값 답변 라우팅 정책


Amazon Route 53: 다중 지역 AWS 배포를 위한 라우팅 정책
한 회사가 전 세계 청중에게 서비스를 제공하기 위해 웹 애플리케이션을 확장했습니다. SysOps 관리자는 모든 프로덕션 인프라에 대해 다중 지역 AWS 배포를 구현했습니다. 이제 리소스의 위치를 기반으로 트래픽을 라우팅해야 합니다. 이를 위해 적절한 Amazon Route 53 라우팅 정책을 선택해야 합니다.

주요 고려 사항
리소스 위치 기반 라우팅: 사용자의 지리적 위치에 따라 가까운 리소스로 트래픽을 라우팅해야 합니다.
글로벌 서비스 제공: 전 세계 사용자에게 최적의 성능을 제공해야 합니다.
라우팅 정책 선택: Route 53에서 제공하는 다양한 라우팅 정책 중 적절한 것을 선택해야 합니다.
옵션 분석
각 옵션의 특징과 장단점을 비교해 보겠습니다:

* 옵션 A: 지리적 위치 라우팅 정책

설명: 지리적 위치 라우팅 정책은 사용자의 지리적 위치(국가 또는 대륙)에 따라 트래픽을 라우팅합니다.
장점: 특정 국가나 대륙의 사용자를 특정 리소스로 라우팅할 수 있습니다.
단점: 더 세밀한 위치 기반 라우팅이 필요할 경우 한계가 있을 수 있습니다.

* 옵션 B: 지근거리 라우팅 정책

설명: 지근거리 라우팅 정책은 사용자의 위치와 가장 가까운 AWS 리전으로 트래픽을 라우팅합니다.
장점: 사용자의 물리적 위치와 가장 가까운 리전으로 트래픽을 라우팅하여 지연 시간을 최소화할 수 있습니다.
단점: 특정 국가나 대륙 단위의 라우팅보다 더 세밀한 제어가 가능하지만, 설정이 복잡할 수 있습니다.

* 옵션 C: 지연 기반 라우팅 정책

설명: 지연 기반 라우팅 정책은 사용자가 가장 낮은 지연 시간을 경험할 수 있는 리소스로 트래픽을 라우팅합니다.
장점: 지연 시간을 최소화하여 사용자 경험을 최적화할 수 있습니다.
단점: 지리적 위치보다는 네트워크 지연 시간에 초점을 맞추므로, 위치 기반 라우팅이 필요할 경우 적합하지 않을 수 있습니다.

* 옵션 D: 다중값 답변 라우팅 정책

설명: 다중값 답변 라우팅 정책은 여러 리소스의 IP 주소를 반환하여 클라이언트가 가장 가까운 리소스로 연결할 수 있도록 합니다.
장점: 여러 리소스를 동시에 제공하여 가용성을 높일 수 있습니다.
단점: 위치 기반 라우팅보다는 가용성에 중점을 둡니다.

##### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 B입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

리소스 위치 기반 라우팅: 사용자의 물리적 위치와 가장 가까운 AWS 리전으로 트래픽을 라우팅하여 지연 시간을 최소화할 수 있습니다.
글로벌 서비스 최적화: 전 세계 사용자에게 최적의 성능을 제공할 수 있습니다.
세밀한 제어: 특정 국가나 대륙 단위의 라우팅보다 더 세밀한 제어가 가능합니다.
따라서, SysOps 관리자는 지근거리 라우팅 정책을 사용하여 리소스의 위치를 기반으로 트래픽을 라우팅함으로써 전 세계 사용자에게 최적의 성능을 제공할 수 있습니다.


## 질문 #90
SysOps 관리자가 온프레미스에서 Amazon S3 버킷으로 멀티파트 업로드를 사용하여 1TB 크기의 파일을 업로드하려고 합니다.
SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?


A. S3 콘솔을 사용하여 파일을 업로드합니다.
B. s3api copy-object 명령을 사용합니다.
C. s3api put-object 명령을 사용합니다.
D. s3 cp 명령을 사용합니다. 가장 많이 투표된

Amazon S3: 멀티파트 업로드를 통한 대용량 파일 전송
SysOps 관리자가 온프레미스에서 Amazon S3 버킷으로 1TB 크기의 파일을 업로드하려고 합니다. 이 작업을 효율적으로 수행하기 위해 멀티파트 업로드를 사용해야 합니다. 멀티파트 업로드는 대용량 파일을 작은 부분으로 나누어 병렬로 업로드함으로써 전송 속도를 높이고 중단된 업로드를 쉽게 재개할 수 있게 합니다.

주요 고려 사항
* 멀티파트 업로드 사용: 대용량 파일을 업로드할 때는 멀티파트 업로드가 필수적입니다.
* CLI 도구 사용: AWS CLI(Command Line Interface)를 사용하여 멀티파트 업로드를 수행할 수 있습니다.
* 자동화 및 편의성: AWS CLI 명령어를 통해 업로드 과정을 자동화하고 관리할 수 있습니다.
옵션 분석
각 옵션의 특징과 장단점을 비교해 보겠습니다:

* 옵션 A: S3 콘솔을 사용하여 파일을 업로드합니다.

설명: AWS Management Console을 통해 파일을 업로드합니다.
장점: GUI 환경에서 쉽게 파일을 업로드할 수 있습니다.
단점: 대용량 파일 업로드에는 비효율적이며, 멀티파트 업로드를 지원하지 않습니다.

* 옵션 B: s3api copy-object 명령을 사용합니다.

설명: AWS CLI의 copy-object 명령을 사용하여 객체를 복사합니다.
장점: S3 객체 간의 복사를 지원합니다.
단점: 온프레미스에서 S3로의 업로드에는 적합하지 않습니다.

* 옵션 C: s3api put-object 명령을 사용합니다.

설명: AWS CLI의 put-object 명령을 사용하여 객체를 업로드합니다.
장점: S3에 객체를 업로드할 수 있습니다.
단점: 멀티파트 업로드를 직접 지원하지 않으며, 대용량 파일 업로드에는 비효율적입니다.

* 옵션 D: s3 cp 명령을 사용합니다.

설명: AWS CLI의 cp 명령을 사용하여 파일을 업로드합니다.
장점: aws s3 cp 명령은 멀티파트 업로드를 자동으로 처리하여 대용량 파일 업로드에 적합합니다.
단점: 특별한 단점이 없으며, 대용량 파일 업로드에 가장 적합한 방법입니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 D입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

멀티파트 업로드 지원: aws s3 cp 명령은 멀티파트 업로드를 자동으로 처리하여 대용량 파일 업로드에 적합합니다.
편리성: CLI 명령어를 통해 업로드 과정을 쉽게 관리하고 자동화할 수 있습니다.
효율성: 대용량 파일 업로드 시 병렬 처리를 통해 전송 속도를 높일 수 있습니다.
따라서, SysOps 관리자는 s3 cp 명령을 사용하여 1TB 크기의 파일을 Amazon S3 버킷으로 업로드하는 것이 가장 효율적입니다.

## 질문 #91
애플리케이션 팀은 SysOps 관리자와 협력하여 애플리케이션에 대한 Amazon CloudWatch 알람을 정의하고 있습니다. 

애플리케이션 팀은 애플리케이션의 예상 사용량이나 예상 성장을 알지 못합니다.
SysOps 관리자는 어떤 솔루션을 추천해야 합니까?

A. 이상 감지를 기반으로 CloudWatch 알람을 생성합니다. 가장 많이 투표된
B. 복합 알람 세트를 사용하여 CloudWatch 알람을 만듭니다.
C. 정적 임계값을 사용하여 CloudWatch 경보를 만듭니다.
D. 누락된 데이터를 침해로 처리하는 CloudWatch 알람을 생성합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 이상 감지 기능: CloudWatch Anomaly Detection 기능을 사용하여 정상적인 메트릭 패턴에서 벗어난 이상을 자동으로 감지하고 알람을 생성할 수 있습니다.
* 유연성: 예측 불가능한 사용량에도 유연하게 대응할 수 있습니다.
* 자동화: 자동으로 이상을 감지하여 알람을 생성하므로, 수동 설정의 부담이 줄어듭니다.

따라서, SysOps 관리자는 이상 감지를 기반으로 CloudWatch 알람을 생성하는 것을 추천해야 합니다. 이를 통해 애플리케이션의 예측 불가능한 사용량에도 효과적으로 대응할 수 있습니다.

## 질문 #92
한 회사가 Amazon EC2 인스턴스에 호스팅된 상태 없는 애플리케이션을 실행합니다. 

사용자들이 성능 문제를 보고하고 있습니다. SysOps 관리자가
애플리케이션에 대한 Amazon CloudWatch 메트릭을 검토하고 인스턴스의 CPU 사용률이 업무 시간 동안 자주 90%에 도달한다는 것을 알아챘습니다.
애플리케이션의 응답성을 개선할 가장 운영 효율적인 솔루션은 무엇입니까?


A. EC2 인스턴스에서 CloudWatch 로깅을 구성합니다. CPU 사용률이 90%를 넘을 때 SysOps 관리자에게 경고하도록 CPU 사용률에 대한 CloudWatch 알람을 구성합니다.
B. 애플리케이션 사용자가 EC2 인스턴스 개인 IP 주소에 직접 연결하여 지연 시간을 줄일 수 있도록 AWS 클라이언트 VPN 연결을 구성합니다.
C. 자동 스케일링 그룹을 만들고 이를 애플리케이션 로드 밸런서에 할당합니다. 자동 스케일링 그룹의 평균 CPU 사용률을 기반으로 하는 대상 추적 스케일링 정책을 구성합니다. 가장 많이 투표된
D. EC2 인스턴스의 CPU 사용률이 80%를 넘을 때 활성화되는 CloudWatch 알람을 만듭니다. 인스턴스를 수직으로 확장하는 AWS Lambda 함수를 호출하도록 알람을 구성합니다.

##### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 C입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 자동 스케일링 그룹: 필요에 따라 인스턴스를 자동으로 추가하거나 제거할 수 있습니다.
* 대상 추적 스케일링 정책: 평균 CPU 사용률을 기준으로 인스턴스 수를 조정하여 성능을 유지할 수 있습니다.
* 로드 밸런서와의 통합: 애플리케이션 로드 밸런서(ALB)와 통합하여 트래픽을 효율적으로 분산할 수 있습니다.

따라서, SysOps 관리자는 자동 스케일링 그룹을 만들고 이를 애플리케이션 로드 밸런서에 할당한 후, 평균 CPU 사용률을 기반으로 하는 대상 추적 스케일링 정책을 구성하는 것이 가장 운영 효율적인 솔루션입니다.

## 질문 #93
전자상거래 회사는 쇼핑 사이트에서 인기 있는 제품 쿼리의 메모리 내 캐싱을 위해 Amazon ElastiCache for Memcached 클러스터를 사용합니다. 

ElastiCache 클러스터에 대한 최근 Amazon CloudWatch 메트릭 데이터를 볼 때 SysOps 관리자는 많은 수의 퇴거를 알아차립니다.
다음 중 어떤 조치가 이러한 퇴거를 줄일 수 있을까요? (두 가지를 선택하세요.)


A. ElastiCache 클러스터에 추가 노드를 추가합니다. 가장 많이 투표된
B. ElastiCache의 TTL(수명)을 늘립니다.
C. ElastiCache 클러스터 내의 개별 노드 크기를 늘립니다. 가장 많이 투표된
D. ElastiCache 클러스터 앞에 Elastic Load Balancer를 배치합니다.
E. Amazon Simple Queue Service(Amazon SQS)를 사용하여 ElastiCache 클러스터를 분리합니다.

Amazon ElastiCache for Memcached: 퇴거(Evictions) 문제 해결
전자상거래 회사는 쇼핑 사이트에서 인기 있는 제품 쿼리의 메모리 내 캐싱을 위해 Amazon ElastiCache for Memcached 클러스터를 사용하고 있습니다. 최근 Amazon CloudWatch 메트릭 데이터를 검토한 결과, 많은 수의 퇴거(eviction)가 발생하고 있음을 SysOps 관리자가 발견했습니다. 퇴거란 캐시 메모리가 가득 찼을 때 오래된 항목을 제거하고 새로운 항목을 추가하는 과정을 의미합니다. 이를 줄이기 위한 조치를 살펴보겠습니다.

주요 고려 사항
* 퇴거 감소: 캐시 메모리에서 항목이 너무 자주 제거되는 것을 방지해야 합니다.
* 캐시 용량 확장: 캐시 메모리의 용량을 늘려 더 많은 데이터를 저장할 수 있도록 해야 합니다.
* 노드 구성 최적화: 클러스터 내의 노드 크기와 수를 조정하여 성능을 최적화해야 합니다.


##### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A와 옵션 C입니다. 이 두 가지 옵션은 다음과 같은 이유로 가장 적절합니다:

* 옵션 A: ElastiCache 클러스터에 추가 노드를 추가합니다.

캐시 용량 확장: 더 많은 노드를 추가하여 캐시 용량을 확장함으로써 퇴거를 줄일 수 있습니다.
부하 분산: 여러 노드로 트래픽을 분산시켜 클러스터의 부하를 줄일 수 있습니다.
옵션 C: ElastiCache 클러스터 내의 개별 노드 크기를 늘립니다.

* 노드 용량 증가: 각 노드의 메모리 크기를 늘려 더 많은 데이터를 저장할 수 있도록 함으로써 퇴거를 줄일 수 있습니다.
성능 최적화: 노드 크기를 늘림으로써 클러스터의 전체 성능을 향상시킬 수 있습니다.
따라서, SysOps 관리자는 ElastiCache 클러스터에 추가 노드를 추가하고, 클러스터 내의 개별 노드 크기를 늘리는 조치를 통해 퇴거를 줄일 수 있습니다.

## 질문 #94
SysOps 관리자가 여러 IAM 사용자에게 IAM 정책을 연결하여 AWS 서비스에 대한 액세스를 제공하려고 합니다. 

SysOps 관리자는 또한 정책을 변경하고 새 버전을 만들 수 있기를 원합니다.
이러한 요구 사항을 충족하는 작업의 조합은 무엇입니까? (두 가지를 선택하십시오.)

A. 사용자를 IAM 서비스 연결 역할에 추가합니다. 정책을 역할에 연결합니다.
B. 사용자를 IAM 사용자 그룹에 추가합니다. 정책을 그룹에 연결합니다. 가장 많이 투표된
C. AWS 관리 정책을 생성합니다.
D. 고객 관리 정책을 만듭니다. 가장 많이 투표된
마. 인라인 정책을 만듭니다.

AWS IAM: 사용자 그룹 및 정책 관리
SysOps 관리자가 여러 IAM 사용자에게 AWS 서비스에 대한 액세스를 제공하고, 정책을 변경하고 새 버전을 만들 수 있도록 하기 위해 적절한 작업의 조합을 선택해야 합니다. 이를 위해 IAM 사용자 그룹과 정책을 활용하는 방법을 살펴보겠습니다.

주요 고려 사항
IAM 사용자 그룹: 여러 사용자에게 공통된 권한을 부여하기 위해 사용자 그룹을 사용합니다.
정책 연결: 사용자 그룹에 정책을 연결하여 권한을 부여합니다.
정책 관리: 정책을 변경하고 새 버전을 만들 수 있어야 합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 B와 옵션 D입니다. 이 두 가지 옵션은 다음과 같은 이유로 가장 적절합니다:

* 옵션 B: 사용자를 IAM 사용자 그룹에 추가합니다. 정책을 그룹에 연결합니다.

사용자 그룹 관리: 여러 사용자에게 공통된 권한을 쉽게 부여할 수 있습니다.
정책 적용: 그룹에 정책을 연결하여 사용자 그룹 전체에 적용할 수 있습니다.

* 옵션 D: 고객 관리 정책을 만듭니다.

정책 커스터마이즈: 필요에 따라 정책 내용을 자유롭게 정의할 수 있습니다.
정책 변경 및 버전 관리: 정책을 변경하고 새 버전을 만들 수 있습니다.
따라서, SysOps 관리자는 사용자를 IAM 사용자 그룹에 추가하고 정책을 그룹에 연결하며, 고객 관리 정책을 생성함으로써 여러 사용자에게 AWS 서비스에 대한 액세스를 제공하고 정책을 효율적으로 관리할 수 있습니다.

## 질문 #95
한 회사가 Amazon S3 버킷에 중요한 데이터를 저장합니다. 

SysOps 관리자는 모든 S3 API 활동을 기록하는 솔루션을 구축해야 합니다.
어떤 작업이 이 요구 사항을 충족할까요?

A. S3 버킷 메트릭을 구성하여 객체 액세스 로그를 기록합니다.
B. 모든 S3 객체에 대한 데이터 이벤트를 기록하기 위한 AWS CloudTrail 트레일을 생성합니다. 가장 많이 투표된
C. 각 S3 버킷에 대해 S3 서버 액세스 로깅을 활성화합니다.
D. Amazon S3용 AWS IAM Access Analyzer를 사용하여 객체 액세스 로그를 저장합니다.


Amazon S3: 모든 S3 API 활동 기록
한 회사가 Amazon S3 버킷에 중요한 데이터를 저장하고 있으며, SysOps 관리자는 모든 S3 API 활동을 기록하는 솔루션을 구축해야 합니다. 이를 위해 적절한 작업을 선택해야 합니다.

주요 고려 사항
API 활동 기록: 모든 S3 API 호출을 기록해야 합니다.
보안 및 감사: 보안 및 감사 목적으로 API 활동을 추적할 수 있어야 합니다.
중앙 집중식 관리: 중앙에서 모든 활동을 관리하고 모니터링할 수 있어야 합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 B입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

* 포괄적인 기록: 모든 S3 API 호출을 상세히 기록할 수 있습니다.
* 보안 및 감사: 보안 및 감사 목적으로 유용하며, 중앙에서 모든 활동을 관리하고 모니터링할 수 있습니다.
* AWS CloudTrail 사용: AWS CloudTrail을 사용하여 데이터 이벤트를 기록함으로써, S3 API 활동을 체계적으로 추적할 수 있습니다.
따라서, SysOps 관리자는 모든 S3 객체에 대한 데이터 이벤트를 기록하기 위한 AWS CloudTrail 트레일을 생성함으로써 모든 S3 API 활동을 기록하는 솔루션을 구축할 수 있습니다.


## 질문 #96
한 회사가 Amazon EC2 인스턴스에서 MySQL 데이터베이스를 사용하는 애플리케이션을 실행합니다. 

EC2 인스턴스에는 General Purpose SSD Amazon Elastic Block
Store(Amazon EBS) 볼륨이 있습니다. 이 회사는 애플리케이션 코드를 변경했고 이제 코드 변경의 영향을 평가하기 위해 부하 테스트를 수행하려고 합니다.
SysOps 관리자는 기존 프로덕션 인스턴스의 스냅샷에서 새 MySQL 인스턴스를 만들어야 합니다. 이 새 인스턴스는 프로덕션 인스턴스와 가능한 한 비슷하게 수행되어야 합니다.
이러한 요구 사항을 충족하는 복원 옵션은 무엇입니까?

A. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성합니다. 가장 많이 투표된
B. EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 프로비저닝된 IOPS SSD EBS 볼륨을 생성합니다.
C. EBS 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성합니다.
D. EBS 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 Provisioned IOPS SSD EBS 볼륨을 생성합니다.

#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

빠른 스냅샷 복원: EBS 빠른 스냅샷 복원을 사용하여 빠르게 볼륨을 생성할 수 있습니다.
범용 SSD: 범용 SSD는 비용 효율적이며, 대부분의 일반적인 워크로드에 적합합니다.
프로덕션 인스턴스와 유사한 성능: 범용 SSD는 프로덕션 인스턴스와 유사한 성능을 제공할 수 있습니다.
따라서, SysOps 관리자는 EBS 빠른 스냅샷 복원을 사용하여 프로덕션 스냅샷에서 새로운 범용 SSD EBS 볼륨을 생성함으로써 부하 테스트를 위한 새 MySQL 인스턴스를 준비할 수 있습니다.

## 질문 #97
대기 엔지니어 팀은 문제를 해결하고 명령을 실행하기 위해 프라이빗 서브넷의 Amazon EC2 인스턴스에 자주 연결해야 합니다. 

인스턴스는 최신 AWS 제공 Windows Amazon Machine Images(AMI) 또는 Amazon Linux AMI를 사용합니다.
팀에는 권한 부여를 위한 기존 1AM 역할이 있습니다. SysOps 관리자는 이 역할에 IAM 권한을 부여하여 팀에 인스턴스에 대한 액세스 권한을 제공해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. 인스턴스에서 ssm:StartSession 작업을 허용하기 위해 1AM 역할 정책에 명령문을 추가합니다. 팀에 AWS Systems Manager Session Manager를 사용하여 가정된 IAM 역할을 사용하여 인스턴스에 연결하도록 지시합니다. 가장 많이 투표된
B. 각 인스턴스에 Elastic IP 주소와 보안 그룹을 연결합니다. 엔지니어의 IP 주소를 보안 그룹 인바운드 규칙에 추가합니다. 팀이 인스턴스에 연결할 수 있도록 ec2:AuthorizeSecurityGrouplngress 작업을 허용하는 IAM 역할 정책에 명령문을 추가합니다.
C. EC2 인스턴스로 배스천 호스트를 만들고 배스천 호스트를 VPC와 연결합니다. 배스천 호스트에서 ec2:CreateVpnConnection 작업을 허용하도록 1AM 역할 정책에 명령문을 추가합니다. 팀에 배스천 호스트 엔드포인트를 사용하여 인스턴스에 연결하도록 지시합니다.
D. 인터넷 연결 네트워크 로드 밸런서를 만듭니다. 두 개의 리스너를 사용합니다. 포트 22를 Linux 인스턴스의 대상 그룹으로 전달합니다. 포트 3389를 Windows 인스턴스의 대상 그룹으로 전달합니다. 팀이 인스턴스에 연결할 수 있도록 ec2:CreateRoute 작업을 허용하는 IAM 역할 정책에 명령문을 추가합니다.

Amazon EC2: 프라이빗 서브넷 인스턴스에 대한 접근
대기 엔지니어 팀이 프라이빗 서브넷의 Amazon EC2 인스턴스에 자주 연결해야 하는 상황입니다. 인스턴스는 최신 AWS 제공 Windows Amazon Machine Images(AMI) 또는 Amazon Linux AMI를 사용합니다. 팀에는 권한 부여를 위한 기존 IAM 역할이 있으며, SysOps 관리자는 이 역할에 IAM 권한을 부여하여 팀에 인스턴스에 대한 액세스 권한을 제공해야 합니다. 이를 위해 적절한 솔루션을 선택해야 합니다.

주요 고려 사항
프라이빗 서브넷 접근: 프라이빗 서브넷에 있는 인스턴스에 안전하게 접근할 수 있어야 합니다.
IAM 역할 및 정책: 기존 IAM 역할에 적절한 권한을 부여하여 팀이 인스턴스에 접근할 수 있도록 해야 합니다.
보안 및 편의성: 보안성을 유지하면서도 팀이 쉽게 접근할 수 있는 방법이어야 합니다.


#### 결론
위의 요구 사항을 충족하기 위해 가장 적합한 옵션은 옵션 A입니다. 이 옵션은 다음과 같은 이유로 가장 적절합니다:

프라이빗 서브넷 접근: AWS Systems Manager Session Manager를 사용하여 프라이빗 서브넷의 인스턴스에 안전하게 접근할 수 있습니다.
IAM 역할 및 정책: 기존 IAM 역할에 ssm:StartSession 작업을 허용하는 정책을 추가하여 팀이 인스턴스에 접근할 수 있도록 합니다.
보안 및 편의성: 추가적인 네트워크 설정 없이도 안전하게 접근할 수 있으며, AWS 관리형 서비스를 활용하여 편리하게 관리할 수 있습니다.
따라서, SysOps 관리자는 AWS Systems Manager Session Manager를 사용하여 인스턴스에 연결하도록 지시하고, IAM 역할에 ssm:StartSession 작업을 허용하는 정책을 추가하는 것이 가장 적합한 솔루션입니다.





## 질문 #98
한 회사는 AWS에 배포된 25개 애플리케이션에 대한 예산을 엄격히 준수해야 합니다. 

별도의 팀이 스토리지, 컴퓨팅 및 데이터베이스 비용을 담당합니다. SysOps 관리자는 재무 부서에서 설정한 분기별 금액을 예상 지출이 초과할 경우 각 팀에 경고하는 자동화된 솔루션을 구현해야 합니다. 이 솔루션은 추가 컴퓨팅, 스토리지 또는 데이터베이스 비용을 발생시킬 수 없습니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. AWS 비용 및 사용 보고서를 구성하여 Amazon S3 버킷에 일일 보고서를 보냅니다. 서비스별 지출을 평가하고 Amazon Simple Notification Service(Amazon SNS) 알림을 사용하여 각 팀에 알리는 AWS Lambda 함수를 만듭니다. 보고서가 S3 버킷에 배치되면 Lambda 함수를 호출합니다.
B. AWS 비용 및 사용 보고서를 구성하여 Amazon S3 버킷에 일일 보고서를 보냅니다. Amazon EventBridge(Amazon CloudWatch Events)에서 서비스별 지출을 평가하고 비용 임계값을 초과하면 Amazon Simple Queue Service(Amazon SQS)를 사용하여 각 팀에 알리는 규칙을 만듭니다.
C. AWS Budgets를 사용하여 하나의 비용 예산을 만들고 사용 중인 각 서비스를 선택합니다. 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다. 예산에 대한 적절한 이메일 수신자를 입력합니다.
D. AWS Budgets를 사용하여 각 팀에 대한 비용 예산을 만들고, 팀이 소유한 서비스로 필터링합니다. 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다. 각 예산에 대한 적절한 이메일 수신자를 입력합니다. 가장 많이 투표된


각 팀에 대한 예산을 관리하고 경고를 자동화하는 데 가장 적합한 솔루션은 다음과 같습니다:

### **D. AWS Budgets를 사용하여 각 팀에 대한 비용 예산을 만들고, 팀이 소유한 서비스로 필터링합니다. 재무 부서에서 정의한 예산 금액과 예상 비용 임계값을 지정합니다. 각 예산에 대한 적절한 이메일 수신자를 입력합니다.**

#### 이유:
- **팀별 예산 관리**: 각 팀에 대해 별도의 예산을 설정할 수 있어, 각 팀의 책임과 지출을 명확히 할 수 있습니다.
- **자동 경고**: AWS Budgets는 비용 임계값이 초과될 경우 이메일 알림을 자동으로 발송할 수 있습니다. 이를 통해 팀은 미리 경고를 받을 수 있으며, 추가 비용이 발생하지 않도록 조치를 취할 수 있습니다.
- **비용 발생 없음**: AWS Budgets는 서비스 사용량에 따라 비용이 발생하지 않으므로 예산 관리와 경고를 추가 비용 없이 효율적으로 수행할 수 있습니다.

### **다른 옵션 설명:**

A. **AWS 비용 및 사용 보고서를 구성하여 Amazon S3 버킷에 일일 보고서를 보냅니다. Lambda 함수를 통해 알림을 받는 방법.**
   - 이 방법은 AWS Lambda를 사용하여 추가적인 비용을 발생시킬 수 있으며, 자동화 설정이 복잡할 수 있습니다.

B. **Amazon EventBridge를 사용하여 알림을 SQS로 보내는 방법.**
   - 이 방법은 EventBridge와 SQS를 설정하는 데 추가적인 관리 작업이 필요하고, 이로 인해 간접적으로 추가 비용이 발생할 수 있습니다.

C. **하나의 비용 예산을 만들어 모든 서비스에 대해 설정하는 방법.**
   - 모든 서비스에 대한 단일 예산으로 관리하게 되면, 개별 팀의 책임을 분리하기 어려워 각 팀의 예산을 효과적으로 관리할 수 없습니다.

따라서 **D** 옵션이 각 팀의 예산 관리와 경고 자동화를 가장 효과적으로 지원하는 솔루션입니다.


## 질문 #99
한 회사가 Amazon S3에 정적 웹사이트를 호스팅합니다. 

Amazon CloudFront 배포판은 이 사이트를 글로벌 사용자에게 제공합니다. 이 회사는 Managed-CachingDisabled CloudFront 캐시 정책을 사용합니다. 이 회사의 개발자는 Amazon S3의 파일을 새 정보로 자주 업데이트한다고 확인합니다.
사용자는 웹사이트가 처음 파일을 로드할 때 올바른 정보를 제공한다고 보고합니다. 그러나 사용자의 브라우저는 새로 고침 후 업데이트된 파일을 검색하지 않습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 권장해야 합니까?

A. S3 객체에 max-age=0인 Cache-Control 헤더 필드를 추가합니다. 가장 많이 투표된
B. CloudFront 캐시 정책을 Managed-CachingOptimized로 변경합니다.
C. S3 버킷 구성에서 버킷 버전 관리를 비활성화합니다.
D. CloudFront 구성에서 콘텐츠 압축을 활성화합니다.

이 문제를 해결하기 위해 권장하는 방법은 다음과 같습니다:

### **A. S3 객체에 max-age=0인 Cache-Control 헤더 필드를 추가합니다.**

#### 이유:
- **Cache-Control 헤더**: `max-age=0`을 설정하면 브라우저가 항상 서버에서 최신 정보를 확인하도록 강제할 수 있습니다. 이로 인해 브라우저가 캐시된 버전 대신 S3에서 직접 최신 파일을 요청하게 됩니다.
- **파일 업데이트**: S3의 파일이 자주 업데이트되므로, Cache-Control 헤더를 통해 브라우저가 업데이트된 정보를 항상 받아올 수 있도록 설정하는 것이 중요합니다.

### **다른 옵션 설명:**

B. **CloudFront 캐시 정책을 Managed-CachingOptimized로 변경합니다.**
   - 이 옵션은 캐시 최적화를 통해 성능을 개선할 수 있지만, 캐시 무효화의 문제를 직접적으로 해결하지는 않습니다.

C. **S3 버킷 구성에서 버킷 버전 관리를 비활성화합니다.**
   - 버전 관리를 비활성화하면 이전 버전의 객체에 대한 접근이 불가능해지므로, 문제를 해결하는 데 도움이 되지 않습니다.

D. **CloudFront 구성에서 콘텐츠 압축을 활성화합니다.**
   - 콘텐츠 압축은 페이지 로딩 속도를 개선할 수 있지만, 파일 업데이트가 반영되지 않는 문제와는 관련이 없습니다.

따라서 **A** 옵션이 가장 적합하며, 이를 통해 브라우저가 업데이트된 정보를 제대로 반영하도록 할 수 있습니다.


## 질문 #100
어떤 회사에서는 모든 Amazon EC2 인스턴스에 특정 태그 집합이 있어야 한다는 정책을 가지고 있습니다. 

EC2 인스턴스에 필수 태그가 없으면, 규정을 준수하지 않는 인스턴스를 종료해야 합니다.
이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?


A. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 모든 EC2 인스턴스 상태 변경 사항을 AWS Lambda 함수로 전송하여 각 인스턴스가 규정을 준수하는지 확인합니다. 규정을 준수하지 않는 인스턴스는 모두 종료합니다.
B. 모든 EC2 인스턴스 태그 요구 사항을 적용하는 IAM 정책을 만듭니다. 인스턴스에 필요한 태그가 없으면 정책은 비준수 인스턴스를 종료합니다.
C. 각 EC2 인스턴스가 규정을 준수하는지 확인하고 규정을 준수하지 않는 경우 인스턴스를 종료하는 AWS Lambda 함수를 만듭니다. Lambda 함수가 5분마다 호출되도록 예약합니다.
D. 필수 태그가 있는지 확인하기 위해 AWS Config 규칙을 만듭니다. EC2 인스턴스가 비준수인 경우 AWS Systems Manager Automation 문서를 호출하여 인스턴스를 종료합니다. 가장 많이 투표된

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **D. 필수 태그가 있는지 확인하기 위해 AWS Config 규칙을 만듭니다. EC2 인스턴스가 비준수인 경우 AWS Systems Manager Automation 문서를 호출하여 인스턴스를 종료합니다.**

#### 이유:
- **AWS Config**: AWS Config를 사용하면 리소스의 구성을 지속적으로 모니터링하고 평가할 수 있습니다. 이 서비스는 특정 규칙을 정의하고, 리소스가 이러한 규칙을 준수하는지 여부를 자동으로 검사할 수 있습니다.
- **비준수 인스턴스 종료**: EC2 인스턴스가 필수 태그를 충족하지 않는 경우 AWS Config가 이를 감지하고, AWS Systems Manager를 사용하여 자동으로 인스턴스를 종료하는 작업을 수행할 수 있습니다.
- **자동화 및 운영 효율성**: 이 접근 방식은 수동으로 인스턴스를 확인하고 종료할 필요가 없으므로 운영 효율성을 높이고 오류 가능성을 줄입니다.

### **다른 옵션 설명:**

A. **Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 모든 EC2 인스턴스 상태 변경 사항을 AWS Lambda 함수로 전송하여 각 인스턴스가 규정을 준수하는지 확인합니다. 규정을 준수하지 않는 인스턴스는 모두 종료합니다.**
   - 이 방법도 가능하지만, AWS Config가 제공하는 내장된 모니터링 및 평가 기능에 비해 수동적인 접근 방식이므로 운영 효율성이 떨어집니다.

B. **모든 EC2 인스턴스 태그 요구 사항을 적용하는 IAM 정책을 만듭니다. 인스턴스에 필요한 태그가 없으면 정책은 비준수 인스턴스를 종료합니다.**
   - IAM 정책은 리소스의 태그 요구 사항을 강제하는 데 사용될 수 없으며, 이미 생성된 인스턴스에 대해 실행할 수 없습니다.

C. **각 EC2 인스턴스가 규정을 준수하는지 확인하고 규정을 준수하지 않는 경우 인스턴스를 종료하는 AWS Lambda 함수를 만듭니다. Lambda 함수가 5분마다 호출되도록 예약합니다.**
   - 이 방법도 작동하지만, 수동으로 Lambda 함수를 예약하고 실행해야 하므로 운영 효율성이 떨어집니다.

결론적으로, **D** 옵션이 가장 적합하며 자동화된 규정 준수 관리를 통해 운영 효율성을 극대화할 수 있습니다.


## 질문 #101
SysOps 관리자가 AWS Elastic Beanstalk로 웹 서버 애플리케이션을 관리하려고 합니다. 

Elastic Beanstalk 서비스는 항상 새로운 배포에 대한 전체 용량을 유지해야 합니다.
어떤 배포 정책이 이 요구 사항을 충족합니까? (두 가지를 선택하세요.)

A. 한꺼번에
B. 불변 가장 많이 투표된
C. 재건
D. 롤링
E. 추가 배치로 롤링 가장 많이 투표된

AWS Elastic Beanstalk에서 새로운 배포에 대한 전체 용량을 유지하기 위한 적절한 배포 정책은 다음 두 가지입니다:

### **B. 불변 (Immutable)**
- **설명**: 불변 배포 정책은 새로운 인스턴스를 임시로 생성하여 배포하는 방식입니다. 기존 인스턴스는 유지되고, 새로운 인스턴스가 준비되면 트래픽이 이 새로운 인스턴스로 전환됩니다. 이를 통해 배포 중에 서비스 가용성을 높일 수 있습니다.

### **D. 롤링 (Rolling)**
- **설명**: 롤링 배포 정책은 기존 인스턴스를 점진적으로 업데이트합니다. 즉, 일부 인스턴스를 업데이트하면서 나머지 인스턴스는 계속해서 서비스를 제공하게 됩니다. 이렇게 하면 배포 중에도 서비스 가용성을 유지할 수 있습니다.

### **기타 옵션 설명**:
A. **한꺼번에 (All-at-once)**:
- 모든 인스턴스를 동시에 업데이트하므로 가용성이 일시적으로 중단될 수 있습니다.

C. **재건 (Rebuild)**:
- 기존 인스턴스를 제거하고 새 인스턴스를 만드는 방식으로, 이 경우도 가용성이 중단될 수 있습니다.

E. **추가 배치로 롤링 (Rolling with additional batch)**:
- 롤링 배포 방식에 추가 인스턴스를 함께 배포하여 가용성을 높이는 방식입니다. 하지만 기존 인스턴스의 가용성을 반드시 유지한다고 보장할 수 없기 때문에 이 옵션은 항상 전체 용량을 유지하는 데 최선은 아닙니다.

결론적으로, **B (불변)** 및 **D (롤링)**이 요구 사항을 충족하는 최적의 선택입니다.

## 질문 #102
한 회사에는 평균 CPU 사용률에 따라 확장되는 Amazon EC2 인스턴스의 Auto Scaling 그룹이 있습니다. 

Auto Scaling 그룹 이벤트 로그는 InsufficientInstanceCapacity 오류를 나타냅니다.
SysOps 관리자는 이 문제를 해결하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. 회사에서 사용 중인 인스턴스 유형을 변경합니다.
B. 다양한 가용성 영역에서 자동 크기 조정 그룹을 구성합니다. 
C. 다양한 Amazon Elastic Block Store(Amazon EBS) 볼륨 크기를 사용하도록 자동 크기 조정 그룹을 구성합니다.
D. 자동 크기 조정 그룹의 최대 크기를 늘립니다.
E. 인스턴스 서비스 할당량 증가를 요청합니다.

Amazon EC2 인스턴스의 Auto Scaling 그룹에서 **InsufficientInstanceCapacity** 오류를 해결하기 위한 두 가지 적절한 조치는 다음과 같습니다:

### **A. 회사에서 사용 중인 인스턴스 유형을 변경합니다.**
- **설명**: 현재 사용 중인 인스턴스 유형에 대한 가용성이 부족할 수 있습니다. 다른 인스턴스 유형으로 변경하면 해당 유형의 가용성이 더 높을 수 있으므로 오류를 해결하는 데 도움이 됩니다.

### **B. 다양한 가용성 영역에서 자동 크기 조정 그룹을 구성합니다.**
- **설명**: Auto Scaling 그룹을 여러 가용성 영역(AZ)으로 확장하면 인스턴스가 다양한 위치에 분산되어 가용성이 증가합니다. 이는 특정 AZ에서 인스턴스를 사용할 수 없는 경우에도 다른 AZ에서 인스턴스를 사용할 수 있게 해줍니다.

### **기타 옵션 설명**:
C. **다양한 Amazon Elastic Block Store(Amazon EBS) 볼륨 크기를 사용하도록 자동 크기 조정 그룹을 구성합니다.**
- EBS 볼륨 크기는 인스턴스의 가용성에 영향을 주지 않습니다. 이는 CPU 사용률 문제와 직접적인 연관이 없습니다.

D. **자동 크기 조정 그룹의 최대 크기를 늘립니다.**
- 최대 크기를 늘려도 현재 가용성이 부족하다면 문제를 해결할 수 없습니다. 오히려 다른 문제를 유발할 수 있습니다.

E. **인스턴스 서비스 할당량 증가를 요청합니다.**
- 서비스 할당량이 문제인 경우 유용할 수 있지만, 인스턴스 가용성 문제를 직접적으로 해결하지는 않습니다. 현재 상황에서 가용성을 높이는 즉각적인 조치로는 적합하지 않습니다.

결론적으로, **A (인스턴스 유형 변경)** 및 **B (다양한 가용성 영역 구성)**이 InsufficientInstanceCapacity 오류를 해결하는 데 가장 효과적인 조치입니다.


## 질문 #103
SysOps 관리자는 AWS Systems Manager Session Manager를 사용하여 Amazon EC2 인스턴스 그룹에 대한 액세스를 제어해야 합니다. 

EC2 인스턴스의 특정 태그는 이미 추가되었습니다.
관리자는 액세스를 제어하기 위해 어떤 추가 조치를 취해야 합니까? (두 가지를 선택하세요.)

A. EC2 인스턴스에 액세스해야 하는 사용자 또는 그룹에 IAM 정책을 연결합니다. 가장 많이 투표된
B. EC2 인스턴스에 대한 액세스를 제어하기 위해 IAM 역할을 연결합니다.
C. EC2 인스턴스에 대한 배치 그룹을 만들고 특정 태그를 추가합니다.
D. 서비스 계정을 생성하여 제어해야 하는 EC2 인스턴스에 연결합니다.
E. Condition 요소에 지정된 태그가 있는 모든 EC2 인스턴스에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다. 가장 많이 투표된

AWS Systems Manager Session Manager를 사용하여 Amazon EC2 인스턴스 그룹에 대한 액세스를 제어하기 위해 SysOps 관리자가 취해야 할 두 가지 추가 조치는 다음과 같습니다:

### **A. EC2 인스턴스에 액세스해야 하는 사용자 또는 그룹에 IAM 정책을 연결합니다.**
- **설명**: IAM 정책을 통해 특정 사용자나 그룹이 EC2 인스턴스에 접근할 수 있도록 권한을 부여합니다. 이를 통해 사용자가 Session Manager를 통해 인스턴스에 액세스할 수 있는 권한을 설정할 수 있습니다.

### **E. Condition 요소에 지정된 태그가 있는 모든 EC2 인스턴스에 대한 액세스 권한을 부여하는 IAM 정책을 만듭니다.**
- **설명**: IAM 정책의 Condition 요소를 사용하여 특정 태그를 가진 EC2 인스턴스에 대한 액세스를 세밀하게 제어할 수 있습니다. 이렇게 하면 지정된 태그가 있는 인스턴스에만 접근할 수 있게 되어, 보안성을 높이고 관리 효율성을 개선합니다.

### **기타 옵션 설명**:
B. **EC2 인스턴스에 대한 액세스를 제어하기 위해 IAM 역할을 연결합니다.**
- IAM 역할은 인스턴스에 연결할 수 있지만, 사용자 액세스 제어와는 관련이 없습니다. Session Manager에서 액세스를 제어하는 데 직접적인 도움이 되지 않습니다.

C. **EC2 인스턴스에 대한 배치 그룹을 만들고 특정 태그를 추가합니다.**
- 배치 그룹은 EC2 인스턴스의 배치 방법을 정의하지만, 액세스 제어와는 직접적인 관련이 없습니다.

D. **서비스 계정을 생성하여 제어해야 하는 EC2 인스턴스에 연결합니다.**
- 서비스 계정은 Kubernetes와 관련된 개념으로, EC2 인스턴스에 직접 연결할 필요가 없습니다. 이 옵션은 현재 상황에 적합하지 않습니다.

결론적으로, **A (IAM 정책을 사용자 또는 그룹에 연결)** 및 **E (Condition 요소에 지정된 태그를 사용한 IAM 정책 생성)**가 EC2 인스턴스 그룹에 대한 액세스를 제어하는 데 가장 효과적인 조치입니다.

## 질문 #104
한 회사가 계정 A에 AWS Lambda 함수를 가지고 있습니다. 

Lambda 함수는 계정 B의 Amazon S3 버킷에 있는 객체를 읽어야 합니다. SysOps 관리자는 두 계정 모두에 해당 IAM 역할을 만들어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 계정 A에서 계정 B의 역할을 맡을 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다. 가장 많이 투표된
B. 계정 A에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 맡을 수 있는 역할을 만듭니다.
C. 계정 A에서 함수가 맡을 수 있는 역할을 만듭니다. 계정 B에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다.
D. 계정 A에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다. 계정 B에서 계정 A의 역할을 맡을 Lambda 실행 역할을 만듭니다.

계정 A의 AWS Lambda 함수가 계정 B의 Amazon S3 버킷에 있는 객체를 읽기 위해 필요한 IAM 역할을 설정하는 가장 효과적인 솔루션은 다음과 같습니다:

### **A. 계정 A에서 계정 B의 역할을 맡을 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다.**

#### **설명**:
1. **계정 A에서 Lambda 실행 역할 생성**:
   - 계정 A에 Lambda 함수를 실행하는 역할을 생성하고, 이 역할이 계정 B의 IAM 역할을 맡을 수 있는 권한을 부여합니다.

2. **계정 B에서 IAM 역할 생성**:
   - 계정 B에서 Lambda 함수가 S3 버킷에 액세스할 수 있도록 권한을 가진 IAM 역할을 생성합니다. 이 역할은 필요한 S3 읽기 권한을 포함해야 하며, `trust policy`를 설정하여 계정 A의 Lambda 함수가 이 역할을 맡을 수 있도록 합니다.

이 접근 방식을 통해 계정 A의 Lambda 함수는 계정 B의 S3 버킷에 대한 권한을 안전하게 사용하여 객체를 읽을 수 있습니다.

### **기타 옵션 설명**:
B. **계정 A에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다. 계정 B에서 함수가 맡을 수 있는 역할을 만듭니다.**
- 이 옵션은 계정 A의 Lambda 함수가 계정 B의 IAM 역할을 맡는 것을 명시적으로 정의하지 않아, 필요한 권한이 없을 수 있습니다.

C. **계정 A에서 함수가 맡을 수 있는 역할을 만듭니다. 계정 B에서 S3 버킷에 대한 액세스를 제공하는 Lambda 실행 역할을 만듭니다.**
- 이 옵션은 계정 A의 Lambda 함수가 계정 B의 역할을 직접적으로 맡지 않기 때문에 요구 사항을 충족하지 않습니다.

D. **계정 A에서 함수가 S3 버킷에 액세스할 수 있는 역할을 만듭니다. 계정 B에서 계정 A의 역할을 맡을 Lambda 실행 역할을 만듭니다.**
- 이 옵션은 잘못된 방향입니다. 계정 B에서 계정 A의 역할을 맡는 것은 필요하지 않으며, 계정 A의 Lambda가 S3에 액세스할 수 있도록 설정해야 합니다.

따라서 **A**가 가장 적합한 솔루션입니다.


#### 참고 
AWS Lambda 함수가 회사의 공유 AWS 계정에서 실행 중입니다. 이 함수는 회사의 개발 계정을 대상으로 하는 추가 ec2:DescribeInstances 작업을 수행해야 합니다. 개발자는 계정 전체에서 필요한 권한을 구성해야 합니다.

개발자는 최소 권한 원칙을 준수하기 위해 어떻게 권한을 구성해야 합니까?

B. 개발 계정에서 IAM 역할을 만듭니다. 역할에 ec2:DescribeInstances 권한을 추가합니다. 이 역할에 대한 공유 계정과 신뢰 관계를 설정합니다. iam:AssumeRole 권한을 추가하여 공유 계정에서 Lambda 함수 IAM 역할을 업데이트합니다.



## 질문 #105
AWS Lambda 함수가 하루에 여러 번 간헐적으로 실패합니다. 

SysOps 관리자는 지난 7일 동안 이 오류가 얼마나 자주 발생했는지 알아내야 합니다.
어떤 조치가 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족할까요?

A. Amazon Athena를 사용하여 Lambda 함수와 관련된 Amazon CloudWatch 로그를 쿼리합니다.
B. Amazon Athena를 사용하여 Lambda 함수와 연결된 AWS CloudTrail 로그를 쿼리합니다.
C. Amazon CloudWatch Logs Insights를 사용하여 연관된 Lambda 함수 로그를 쿼리합니다. 가장 많이 투표된
D. Amazon OpenSearch Service(Amazon Elasticsearch Service)를 사용하여 Lambda 함수에 대한 Amazon CloudWatch 로그를 스트리밍합니다.


정답은 **C. Amazon CloudWatch Logs Insights를 사용하여 연관된 Lambda 함수 로그를 쿼리합니다.**

**이유:**
- **Amazon CloudWatch Logs Insights**는 CloudWatch 로그 그룹에 저장된 로그 데이터를 효율적으로 쿼리하고 분석할 수 있는 강력한 도구입니다. Lambda 함수의 로그는 기본적으로 CloudWatch Logs에 저장되므로, 바로 로그 데이터를 분석할 수 있습니다. 이를 통해 실패한 호출이나 오류 패턴을 쉽게 식별할 수 있으며, 간헐적으로 발생하는 문제를 조사하기에 적합합니다.
  
**다른 선택지 분석:**
- **A. Amazon Athena를 사용하여 Lambda 함수와 관련된 Amazon CloudWatch 로그를 쿼리**는 가능하나, 데이터를 Athena로 전송하고 스키마를 정의하는 추가적인 작업이 필요해 운영적으로 복잡해집니다.
- **B. Amazon Athena를 사용하여 Lambda 함수와 연결된 AWS CloudTrail 로그를 쿼리**는 Lambda 호출과 관련된 이벤트를 추적할 수 있지만, CloudTrail은 주로 API 호출 로그를 수집하므로 함수 실행 중 발생한 세부 오류를 찾는 데는 적합하지 않습니다.
- **D. Amazon OpenSearch Service를 사용하여 로그를 스트리밍**하는 것은 복잡한 설정이 필요하며, 간헐적 오류 조사 목적으로는 과도한 해결책일 수 있습니다.



## 질문 #106
한 회사가 Amazon CloudFront를 사용하여 웹 애플리케이션의 정적 콘텐츠를 사용자에게 제공하고 있습니다. 

CloudFront 배포는 기존 온프레미스 웹사이트를 사용자 지정 오리진으로 사용합니다.
이 회사는 CloudFront와 오리진 서버 간에 TLS를 사용해야 합니다. 이 구성은 몇 달 동안 예상대로 작동했습니다. 그러나 이제 사용자는 CloudFront 배포의 콘텐츠가 포함된 웹 페이지를 볼 때 HTTP 502(잘못된 게이트웨이) 오류를 경험하고 있습니다.
SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

A. 원본 사이트의 인증서 만료일을 검사합니다. 인증서가 만료되지 않았는지 확인합니다. 필요한 경우 인증서를 교체합니다. 가장 많이 투표된
B. 원본 사이트의 인증서에서 호스트 이름을 검사합니다. 호스트 이름이 CloudFront 배포의 호스트 이름 중 하나와 일치하는지 확인합니다. 필요한 경우 인증서를 교체합니다.
C. 원본 서버와 연관된 방화벽 규칙을 검사합니다. 인터넷에서 들어오는 트래픽에 대해 포트 443이 열려 있는지 확인합니다. 필요한 경우 인바운드 규칙을 만듭니다.
D. CloudFront 배포와 연관된 네트워크 ACL 규칙을 검토합니다. 포트 443이 오리진 서버로의 아웃바운드 트래픽에 열려 있는지 확인합니다. 필요한 경우 아웃바운드 규칙을 만듭니다.



정답은 **A. 원본 사이트의 인증서 만료일을 검사합니다. 인증서가 만료되지 않았는지 확인합니다. 필요한 경우 인증서를 교체합니다.**

**이유:**
- **HTTP 502(잘못된 게이트웨이) 오류**는 CloudFront가 사용자 지정 오리진 서버에 연결할 수 없을 때 발생하는 일반적인 오류입니다. CloudFront와 오리진 서버 간의 TLS 연결에서 발생하는 문제는 자주 인증서 만료 또는 잘못된 인증서로 인해 발생할 수 있습니다. 인증서가 만료되면 CloudFront가 오리진 서버와의 TLS 연결을 설정할 수 없으므로 502 오류가 발생할 수 있습니다. 따라서 인증서의 만료 여부를 먼저 확인하는 것이 합리적입니다.

**다른 선택지 분석:**
- **B. 호스트 이름 검사**는 중요할 수 있지만, 몇 달 동안 문제없이 작동했던 시스템에서 새로운 호스트 이름 불일치는 가능성이 낮습니다.
- **C. 원본 서버의 방화벽 규칙 검사**는 TLS 연결이 이미 설정되어 잘 작동하고 있었다면 문제가 되지 않았을 가능성이 큽니다.
- **D. 네트워크 ACL 규칙 검토**는 문제가 발생한 원인일 가능성이 낮습니다. ACL 규칙은 일반적으로 설정 후 자주 변경되지 않으며, 몇 달 동안 문제없이 동작했다면 다른 원인을 먼저 확인하는 것이 바람직합니다.
- 


## 질문 #107
Amazon CloudFront 배포판에는 단일 Amazon S3 버킷이 원본으로 있습니다. 

SysOps 관리자는 사용자가 CloudFront 엔드포인트의 요청을 통해서만 S3 버킷에 액세스할 수 있도록 해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. S3 버킷에서 S3 Block Public Access를 구성합니다. CloudFront 배포에서만 GetObject 작업을 허용하도록 S3 버킷 정책을 업데이트합니다.
B. CloudFront 배포에서 Origin Shield를 구성합니다. CloudFront 오리진을 업데이트하여 사용자 지정 Origin_Shield 헤더를 포함합니다.
C. 원본 액세스 ID(OAI)를 만듭니다. OAI를 CloudFront 배포에 할당합니다. S3 버킷 정책을 업데이트하여 OAI에 대한 액세스를 제한합니다. 가장 많이 투표된
D. 원본 액세스 ID(OAI)를 만듭니다. S3 버킷에 OAI를 할당합니다. CloudFront 원본을 업데이트하여 OAI 값이 있는 사용자 지정 원본 헤더를 포함합니다.

정답은 **C. 원본 액세스 ID(OAI)를 만듭니다. OAI를 CloudFront 배포에 할당합니다. S3 버킷 정책을 업데이트하여 OAI에 대한 액세스를 제한합니다.**

**이유:**
- **원본 액세스 ID(OAI)**는 CloudFront 배포를 통해서만 Amazon S3 버킷에 액세스할 수 있도록 제한하는 데 사용됩니다. OAI를 생성하고 CloudFront에 할당한 후, S3 버킷 정책을 OAI에 맞게 설정하면 S3 버킷에 직접적인 공용 액세스를 차단하고 CloudFront를 통해서만 콘텐츠를 제공할 수 있게 됩니다.

**다른 선택지 분석:**
- **A. S3 Block Public Access를 구성**하는 것은 S3 버킷의 공용 액세스를 차단하는 데 도움이 되지만, CloudFront를 통해서만 액세스하는 기능을 구현하려면 OAI를 사용해야 합니다.
- **B. Origin Shield**는 캐싱 성능을 개선하는 기능으로, S3 버킷에 대한 접근 제한과는 관련이 없습니다.
- **D. OAI를 사용한 사용자 지정 원본 헤더**는 잘못된 방법입니다. OAI를 S3 버킷에 직접 할당하고, CloudFront 배포에 OAI를 적용하는 것이 표준적인 방법입니다.

## 질문 #108
SysOps 관리자가 Amazon RDS for PostgreSQL DB 인스턴스에 대한 솔루션을 설계하고 있습니다. 

데이터베이스 자격 증명은 매월 저장하고 순환해야 합니다. DB 인스턴스에 연결하는 애플리케이션은 가변적인 클라이언트 연결로 쓰기 집약적 트래픽을 전송하며, 이는 때때로 단시간에 크게 증가합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 선택해야 합니까?

A. AWS Key Management Service(AWS KMS)를 구성하여 DB 인스턴스의 키를 자동으로 순환합니다. RDS Proxy를 사용하여 데이터베이스 연결 증가를 처리합니다.
B. AWS Key Management Service(AWS KMS)를 구성하여 DB 인스턴스의 키를 자동으로 순환합니다. RDS 읽기 복제본을 사용하여 데이터베이스 연결 증가를 처리합니다.
C. AWS Secrets Manager를 구성하여 DB 인스턴스의 자격 증명을 자동으로 회전합니다. RDS Proxy를 사용하여 데이터베이스 연결 증가를 처리합니다. 가장 많이 투표된
D. AWS Secrets Manager를 구성하여 DB 인스턴스의 자격 증명을 자동으로 순환합니다. RDS 읽기 복제본을 사용하여 데이터베이스 연결 증가를 처리합니다.

정답은 **C. AWS Secrets Manager를 구성하여 DB 인스턴스의 자격 증명을 자동으로 회전합니다. RDS Proxy를 사용하여 데이터베이스 연결 증가를 처리합니다.**

**이유:**
- **AWS Secrets Manager**는 데이터베이스 자격 증명을 안전하게 저장하고 자동으로 회전할 수 있는 기능을 제공합니다. 매월 자격 증명을 순환하는 요구 사항을 충족하기에 적합합니다.
- **RDS Proxy**는 애플리케이션의 가변적인 연결을 관리하고, 데이터베이스에 대한 연결 풀링을 통해 갑작스러운 트래픽 급증을 효율적으로 처리할 수 있는 기능을 제공합니다. 이는 특히 쓰기 집약적인 트래픽을 처리할 때 도움이 됩니다.

**다른 선택지 분석:**
- **A. AWS KMS**는 데이터 암호화 키를 관리하지만, 자격 증명 회전에는 적합하지 않습니다. 또한 RDS Proxy를 사용하는 것은 맞지만 KMS는 자격 증명 회전 요구 사항을 해결하지 못합니다.
- **B. KMS와 RDS 읽기 복제본**은 자격 증명 관리와 쓰기 트래픽 처리에는 적합하지 않습니다. 읽기 복제본은 읽기 성능을 향상시키지만, 쓰기 집약적 트래픽에는 적합하지 않습니다.
- **D. Secrets Manager와 RDS 읽기 복제본**의 조합은 자격 증명 회전에는 맞지만, 쓰기 집약적 트래픽 처리에는 적합하지 않습니다. 읽기 복제본은 쓰기 성능을 향상시키지 않습니다.
- 

## 질문 #109
회사는 언제든지 완료할 수 있는 작업의 비용을 줄이고자 합니다. 

현재 작업은 여러 Amazon EC2 On-Demand 인스턴스를 사용하여 실행되고 있으며 작업을 완료하는 데 약 2시간도 걸리지 않습니다. 어떤 이유로든 작업이 중단되면 처음부터 다시 시작해야 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. 작업에 대한 예약 인스턴스를 구매합니다.
B. 해당 작업에 대한 일회성 스팟 인스턴스에 대한 요청을 제출합니다.
C. 작업에 대해 정의된 기간으로 스팟 인스턴스에 대한 요청을 제출합니다. 가장 많이 투표된
D. 작업에 대해 온디맨드 인스턴스와 스팟 인스턴스를 혼합하여 사용합니다.

정답은 **C. 작업에 대해 정의된 기간으로 스팟 인스턴스에 대한 요청을 제출합니다.**

**이유:**
- **정의된 기간 스팟 인스턴스**는 일정 시간 동안 인스턴스가 중단되지 않을 것을 보장받으면서도 비용 절감을 할 수 있는 옵션입니다. 이 회사의 작업은 약 2시간이 걸리며, 작업이 중단되면 처음부터 다시 시작해야 하므로, 중단 위험이 없는 기간 정의된 스팟 인스턴스가 가장 적합한 선택입니다. 이는 **비용 효율적**이면서도 **작업 중단을 방지**할 수 있는 좋은 방법입니다.

**다른 선택지 분석:**
- **A. 예약 인스턴스**는 장기적인 사용 시 비용 절감에 유리하지만, 짧은 작업에 대해서는 비용 효율적이지 않습니다.
- **B. 일회성 스팟 인스턴스**는 중단될 수 있어 작업이 중간에 실패하면 다시 시작해야 하기 때문에 이 작업에는 적합하지 않습니다.
- **D. 온디맨드 인스턴스와 스팟 인스턴스를 혼합**하는 것은 중단 위험을 줄일 수 있지만, 스팟 인스턴스가 중단될 수 있는 가능성을 여전히 감안해야 하므로 확실한 비용 절감과 중단 방지를 보장하지 않습니다.
- 

## 질문 #110
환경은 100개의 Amazon EC2 Windows 인스턴스로 구성되어 있습니다. 

Amazon CloudWatch 에이전트는 모든 EC2 인스턴스에 배포되어 실행 중이며, 로그 파일을 캡처하기 위한 기준 구성 파일이 있습니다. 인스턴스 50개에 있는 DHCP 로그 파일을 캡처해야 하는 새로운 요구 사항이 있습니다.
이 새로운 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

A. DHCP 로그를 캡처하기 위해 추가 CloudWatch 에이전트 구성 파일을 만듭니다. AWS Systems Manager Run Command를 사용하여 각 EC2 인스턴스에서 CloudWatch 에이전트를 다시 시작하고 append-config 옵션을 사용하여 추가 구성 파일을 적용합니다. 가장 많이 투표된
B. 관리자 권한으로 각 EC2 인스턴스에 로그인합니다. 필요한 기준 로그 파일과 DHCP 로그 파일을 CloudWatch에 푸시하는 PowerShell 스크립트를 만듭니다.
C. 각 EC2 인스턴스에서 CloudWatch 에이전트 구성 파일 마법사를 실행합니다. 기준 로그 파일이 포함되어 있는지 확인하고 마법사 생성 프로세스 중에 DHCP 로그 파일을 추가합니다.
D. 각 EC2 인스턴스에서 CloudWatch 에이전트 구성 파일 마법사를 실행하고 고급 세부 정보 수준을 선택합니다. 이렇게 하면 운영 체제 로그 파일이 캡처됩니다.


정답은 **A. DHCP 로그를 캡처하기 위해 추가 CloudWatch 에이전트 구성 파일을 만듭니다. AWS Systems Manager Run Command를 사용하여 각 EC2 인스턴스에서 CloudWatch 에이전트를 다시 시작하고 append-config 옵션을 사용하여 추가 구성 파일을 적용합니다.**

**이유:**
- **AWS Systems Manager Run Command**는 중앙에서 여러 인스턴스에 명령을 실행할 수 있는 기능을 제공합니다. 이를 통해 50개의 EC2 인스턴스에 대해 DHCP 로그 파일을 추가할 수 있으며, 각 인스턴스에 수동으로 로그인할 필요 없이 효율적으로 에이전트를 다시 시작할 수 있습니다.
- **append-config 옵션**을 사용하면 기존 CloudWatch 에이전트 구성을 유지하면서도 추가적인 로그 파일을 캡처하는 설정을 적용할 수 있습니다. 이는 운영 효율성을 극대화하는 방법입니다.

**다른 선택지 분석:**
- **B. PowerShell 스크립트**를 각 인스턴스에 배포하는 것은 수작업이 많아 운영 효율성이 떨어집니다.
- **C. 구성 파일 마법사를 수동으로 실행**하는 것은 시간이 많이 소요되며, 50개 인스턴스에서 수동 작업이 필요하므로 비효율적입니다.
- **D. 고급 세부 정보 수준 선택**은 DHCP 로그 파일을 특정하지 않으며, 운영 시스템의 모든 로그 파일을 캡처하게 되어 불필요한 데이터가 전송될 수 있습니다.
- 

## 질문: 111
한 회사가 프로덕션 계정에 Amazon EC2 인스턴스 10개를 보유하고 있습니다. 

SysOps 관리자는 EC2 인스턴스 상태가 변경될 때마다 이메일 알림이 관리자에게 전송되도록 해야 합니다.
어떤 솔루션이 이 요구 사항을 충족할까요?

A. EC2 인스턴스 상태가 변경될 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon Route 53 단순 라우팅 정책을 구성합니다. 그러면 이 SNS 토픽이 이메일 구독자에게 알림을 보냅니다.
B. EC2 인스턴스 상태가 변경될 때 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Amazon Route 53 단순 라우팅 정책을 구성합니다. 그런 다음 이 SQS 대기열은 이메일 구독자에게 알림을 보냅니다.
C. EC2 인스턴스 상태가 변경될 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 그러면 이 SNS 토픽이 이메일 구독자에게 알림을 보냅니다.
D. EC2 인스턴스 상태가 변경될 때 Amazon Simple Queue Service(Amazon SQS) 대기열에 메시지를 게시하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 그런 다음 이 SQS 대기열은 이메일 구독자에게 알림을 보냅니다.


정답은 **C. EC2 인스턴스 상태가 변경될 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. 그러면 이 SNS 토픽이 이메일 구독자에게 알림을 보냅니다.**

**이유:**
- **Amazon EventBridge(Amazon CloudWatch Events)**는 EC2 인스턴스의 상태 변경 이벤트(예: 시작, 중지, 재부팅 등)를 감지할 수 있습니다. EventBridge 규칙을 사용하여 상태 변경 이벤트가 발생할 때 특정 작업을 수행하도록 설정할 수 있습니다.
- **Amazon SNS**는 이벤트 발생 시 이메일 알림을 전송할 수 있는 서비스입니다. EventBridge 규칙이 EC2 상태 변경 이벤트를 감지하고, 해당 이벤트에 대한 알림을 SNS 토픽에 게시함으로써 이메일 구독자에게 전송할 수 있습니다.
  
**다른 선택지 분석:**
- **A와 B. Amazon Route 53 단순 라우팅 정책**은 EC2 상태 변경과 관련이 없습니다. Route 53은 DNS 관련 서비스를 제공하며, 인스턴스 상태와는 관련이 없습니다.
- **D. Amazon SQS 대기열을 사용**하는 것은 이메일 전송보다는 메시지 큐잉을 위한 방식으로, 이메일 구독자에게 직접적으로 알림을 보내기에는 적합하지 않습니다. SQS는 메시지를 큐에 저장하고 처리해야 하므로 불필요한 복잡성을 추가하게 됩니다.


## 질문: 112
한 회사에는 Elastic Load Balancer 뒤에 있는 Amazon EC2 인스턴스 플릿에서 실행되는 애플리케이션이 있습니다. 

인스턴스는 Auto Scaling 그룹에서 실행됩니다. 애플리케이션의 성능은 매일 대부분 일관되게 유지됩니다. 그러나 사용자 트래픽이 증가하면 매일 같은 4시간 동안 성능이 느려집니다.
이 문제를 해결할 가장 운영 효율적인 솔루션은 무엇입니까?

1. 가중치 라우팅 정책을 사용하여 Auto Scaling 그룹 앞에 두 번째 Elastic Load Balancer를 구성합니다.
2. 사용자 트래픽 증가를 지원하기 위해 더 큰 인스턴스 유형에서 실행되도록 EC2 인스턴스 플릿을 구성합니다.
3. 사용자 트래픽이 증가하기 직전에 EC2 인스턴스 수를 확장하기 위해 예약된 확장 작업을 만듭니다.
4. 사용자 트래픽 증가에 대응하기 위해 Auto Scaling 그룹에 몇 개의 EC2 인스턴스를 수동으로 추가합니다.

가장 운영 효율적인 솔루션은 **3. 사용자 트래픽이 증가하기 직전에 EC2 인스턴스 수를 확장하기 위해 예약된 확장 작업을 만듭니다.**

**이유:**
- **예약된 확장 작업**은 트래픽이 예상되는 시간에 맞춰 Auto Scaling 그룹의 인스턴스 수를 미리 확장하여, 트래픽 증가로 인한 성능 저하를 방지할 수 있는 효율적인 방법입니다. 매일 같은 시간에 트래픽 증가가 발생하므로, 이 시간대에 맞춰 EC2 인스턴스 수를 증가시키면 성능 문제를 예방할 수 있습니다.
- 이 방법은 **자동화된 확장**으로 관리 부담을 줄이면서 비용 효율성을 유지할 수 있으며, 트래픽 패턴이 반복될 때 적합합니다.

**다른 선택지 분석:**
1. **가중치 라우팅 정책을 사용한 두 번째 ELB 구성**은 복잡도를 높이지만 트래픽 문제를 해결하지는 못합니다.
2. **더 큰 인스턴스 유형으로 전환**하면 비용이 증가할 수 있으며, 일시적인 성능 문제 해결에 적합하지 않습니다.
4. **EC2 인스턴스 수동 추가**는 매일 트래픽 증가에 대응해야 하므로 비효율적이고 운영 부담이 큽니다.

## 질문: 113
한 회사가 단일 AWS 리전의 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 

이 애플리케이션은 비 HTTP TCP 트래픽과 HTTP 트래픽에 대한 지원이 필요합니다.
이 회사는 AWS 네트워크를 활용하여 낮은 지연 시간으로 콘텐츠를 제공하려고 합니다. 또한 이 회사는 Elastic Load Balancer가 있는 Auto Scaling 그룹을 구현하려고 합니다.
SysOps 관리자는 이러한 요구 사항을 어떻게 충족해야 합니까?

1. Application Load Balancer(ALB)로 자동 확장 그룹을 만듭니다. ALB를 원본으로 하는 Amazon CloudFront 배포를 추가합니다.
2. Application Load Balancer(ALB)로 자동 스케일링 그룹을 만듭니다. ALB를 엔드포인트로 사용하여 AWS Global Accelerator로 가속기를 추가합니다.
3. 네트워크 로드 밸런서(NLB)로 자동 확장 그룹을 만듭니다. NLB를 원본으로 하는 Amazon CloudFront 배포를 추가합니다.
4. 네트워크 로드 밸런서(NLB)로 자동 스케일링 그룹을 만듭니다. NLB를 엔드포인트로 사용하여 AWS Global Accelerator로 가속기를 추가합니다.

가장 적합한 솔루션은 **4. 네트워크 로드 밸런서(NLB)로 자동 스케일링 그룹을 만듭니다. NLB를 엔드포인트로 사용하여 AWS Global Accelerator로 가속기를 추가합니다.**

**이유:**
- **네트워크 로드 밸런서(NLB)**는 비 HTTP TCP 트래픽과 HTTP 트래픽 모두를 지원하며, 높은 처리량과 낮은 지연 시간을 제공합니다. NLB는 TCP, UDP 및 기타 비 HTTP 프로토콜을 처리할 수 있기 때문에 비 HTTP 트래픽을 다루는 데 적합합니다.
- **AWS Global Accelerator**는 사용자로부터의 트래픽을 AWS 글로벌 네트워크를 통해 라우팅하여 지연 시간을 줄이고 성능을 향상시킬 수 있습니다. 이를 통해 전 세계 사용자에게 빠르게 콘텐츠를 제공할 수 있습니다.
- NLB와 **Global Accelerator**의 조합은 비 HTTP 트래픽 및 HTTP 트래픽에 대한 최적의 지연 시간을 제공하는 동시에, Auto Scaling 그룹을 사용하여 트래픽 증가에 대응할 수 있는 유연성도 확보할 수 있습니다.

**다른 선택지 분석:**
1. **ALB와 CloudFront**는 HTTP/HTTPS 트래픽에 최적화되어 있지만, 비 HTTP 트래픽을 지원하지 않습니다.
2. **ALB와 Global Accelerator**는 HTTP/HTTPS 트래픽에 적합하지만, 비 HTTP 트래픽을 처리하기에는 적합하지 않습니다.
3. **NLB와 CloudFront**는 비 HTTP 트래픽을 지원하지만, CloudFront는 주로 HTTP 기반 콘텐츠를 캐싱하는 데 사용됩니다. 비 HTTP 트래픽에는 적합하지 않습니다.


## 질문: 114
SysOps 관리자는 암호화된 Amazon Machine Image(AMI)를 배포하는 데 사용되는 AWS CloudFormation 템플릿을 가지고 있습니다. 

CloudFormation 템플릿은 두 번째 계정에서 사용되므로 SysOps 관리자는 암호화된 AMI를 두 번째 계정에 복사합니다. 두 번째 계정에서 새 CloudFormation 스택을 시작하면 실패합니다.
SysOps 관리자는 문제를 해결하기 위해 어떤 조치를 취해야 합니까?

1. AMI 권한을 변경하여 AMI를 공개로 표시합니다.
2. 소스 계정에서 AMI 등록을 해제합니다.
3. 대상 계정의 AWS Key Management Service(AWS KMS) 키로 대상 AMI를 다시 암호화합니다.
4. 대상 계정의 AMI ID로 CloudFormation 템플릿을 업데이트합니다.

가장 적합한 솔루션은 **4. 대상 계정의 AMI ID로 CloudFormation 템플릿을 업데이트합니다.**

**이유:**
- 암호화된 AMI를 복사할 때, 복사된 AMI는 새로 생성된 AMI ID를 갖습니다. 두 번째 계정에서 CloudFormation 스택을 생성하려면, 해당 계정의 AMI ID를 사용해야 합니다.
- 따라서, 원본 CloudFormation 템플릿에 있는 소스 계정의 AMI ID를 두 번째 계정의 새 AMI ID로 **업데이트**해야 스택 생성이 성공할 수 있습니다.

**다른 선택지 분석:**
1. **AMI를 공개로 표시**하는 것은 보안 문제가 될 수 있고, 암호화된 AMI에서는 필요하지 않습니다.
2. **소스 계정에서 AMI 등록 해제**는 문제 해결과 관련이 없으며, 오히려 AMI를 사용할 수 없게 만들 수 있습니다.
3. **AWS KMS 키로 대상 AMI를 다시 암호화**하는 것은 필요하지 않습니다. 이미 두 번째 계정으로 복사된 AMI가 암호화된 상태로 존재하므로, 키 관련 문제는 아닙니다.4. 

## 질문: 115
회사의 SysOps 관리자가 표준 Amazon Linux 2 Amazon Machine Image(AMI)를 사용하여 4개의 새로운 Amazon EC2 인스턴스를 배포합니다. 

회사는 AWS Systems Manager를 사용하여 인스턴스를 관리할 수 있어야 합니다. SysOps 관리자는 인스턴스가 Systems Manager 콘솔에 나타나지 않는다는 것을 알아챘습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1. SSH를 사용하여 각 인스턴스에 연결합니다. 각 인스턴스에 Systems Manager Agent를 설치합니다. 인스턴스가 시작될 때 Systems Manager Agent가 자동으로 시작되도록 구성합니다.
2. AWS Certificate Manager(ACM)를 사용하여 TLS 인증서를 만듭니다. 인증서를 각 인스턴스로 가져옵니다. Systems Manager Agent를 구성하여 보안 통신에 TLS 인증서를 사용합니다.
3. SSH를 사용하여 각 인스턴스에 연결합니다. ssm-user 계정을 만듭니다. ssm-user 계정을 /etc/sudoers.d 디렉토리에 추가합니다.
4. 인스턴스에 IAM 인스턴스 프로필을 연결합니다. 인스턴스 프로필에 AmazonSSMManagedInstanceCore 정책이 포함되어 있는지 확인합니다.

가장 적합한 솔루션은 **4. 인스턴스에 IAM 인스턴스 프로필을 연결합니다. 인스턴스 프로필에 AmazonSSMManagedInstanceCore 정책이 포함되어 있는지 확인합니다.**

**이유:**
- **AWS Systems Manager**는 인스턴스가 AWS 계정에 등록되고 관리될 수 있도록 IAM 역할(인스턴스 프로필)을 통해 권한을 부여받아야 합니다. `AmazonSSMManagedInstanceCore` 정책은 Systems Manager의 필수 권한을 제공하며, 이 정책이 있는 IAM 인스턴스 프로필이 EC2 인스턴스에 연결되어 있어야 합니다.
- 또한, EC2 인스턴스에 **Systems Manager Agent (SSM Agent)**가 기본적으로 설치되어 있어야 하며, 표준 Amazon Linux 2 AMI에는 SSM Agent가 미리 설치되어 있습니다. 하지만 IAM 인스턴스 프로필이 없다면 Systems Manager 콘솔에 나타나지 않습니다.

**다른 선택지 분석:**
1. **SSM Agent를 설치**하는 것은 필요하지 않습니다. Amazon Linux 2 AMI에는 기본적으로 설치되어 있으므로, 이 방법은 비효율적입니다.
2. **AWS Certificate Manager(ACM)**와 TLS 인증서는 Systems Manager와의 통신과 관련이 없으며, 이 문제 해결에 필요하지 않습니다.
3. **ssm-user 계정을 만드는 것**은 SSM 기능과는 관련이 없으며, IAM 인스턴스 프로필을 통해 권한을 부여하는 것이 적절합니다.


## 질문: 116
SysOps 관리자가 Amazon CloudFront 웹 배포, Application Load Balancer(ALB), Amazon RDS, Amazon EC2를 VPC에 사용하여 웹 애플리케이션을 유지 관리하고 있습니다. 

모든 서비스에서 로깅이 활성화되어 있습니다. 관리자는 웹 애플리케이션의 HTTP Layer 7 상태 코드를 조사해야 합니다.

어떤 로그 소스에 상태 코드가 포함되어 있습니까? (두 가지를 선택하세요.)

1. VPC 흐름 로그
2. AWS CloudTrail 로그
3. ALB 액세스 로그
4. CloudFront 액세스 권한
5. RDS 로그

웹 애플리케이션의 HTTP Layer 7 상태 코드를 조사하기 위해 다음 두 가지 로그 소스를 선택해야 합니다:

**3. ALB 액세스 로그**  
**4. CloudFront 액세스 로그**

### 이유:
- **ALB 액세스 로그**: Application Load Balancer의 액세스 로그에는 HTTP 요청에 대한 상태 코드가 포함되어 있습니다. 각 요청의 처리 결과를 반영하는 상태 코드를 확인할 수 있습니다.

- **CloudFront 액세스 로그**: Amazon CloudFront의 액세스 로그 역시 요청에 대한 상태 코드를 포함하고 있습니다. 이는 CloudFront 배포를 통해 서비스되는 모든 HTTP 요청에 대한 정보를 제공합니다.

### 다른 선택지 분석:
1. **VPC 흐름 로그**: VPC 흐름 로그는 네트워크 트래픽에 대한 메타데이터(예: 소스 및 대상 IP, 포트 번호, 프로토콜 등)를 포함하지만, HTTP 상태 코드는 포함하지 않습니다.
2. **AWS CloudTrail 로그**: AWS CloudTrail 로그는 AWS 리소스에 대한 API 호출 기록을 저장하며, HTTP 상태 코드를 포함하지 않습니다.
5. **RDS 로그**: Amazon RDS 로그는 데이터베이스와 관련된 로그로, HTTP 상태 코드와는 관련이 없습니다.



## 질문: 117
한 회사가 AWS 계정 내에서 IAM CreateUser API 호출이 이루어질 때 이메일로 알림을 받고 싶어합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. 이벤트 소스로 AWS CloudTrail을, 이벤트 패턴에 대한 특정 API 호출로 IAM CreateUser를 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
2. 이벤트 소스로 Amazon CloudSearch를 지정하고 이벤트 패턴에 대한 특정 API 호출로 IAM CreateUser를 지정하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
3. AWS IAM Access Analyzer를 이벤트 소스로, IAM CreateUser를 이벤트 패턴에 대한 특정 API 호출로 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
4. 이메일 구독을 통해 Amazon Simple Notification Service(Amazon SNS) 주제를 이벤트 대상으로 사용합니다.
5. 이메일 구독을 통해 Amazon Simple Email Service(Amazon SES) 알림을 이벤트 대상으로 사용합니다.

이 요구 사항을 충족하기 위해 선택해야 할 두 가지 조치는 다음과 같습니다:

**1. 이벤트 소스로 AWS CloudTrail을, 이벤트 패턴에 대한 특정 API 호출로 IAM CreateUser를 사용하여 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.**  
**4. 이메일 구독을 통해 Amazon Simple Notification Service(Amazon SNS) 주제를 이벤트 대상으로 사용합니다.**

### 이유:

1. **AWS CloudTrail을 이벤트 소스로 사용**: AWS CloudTrail은 AWS 계정 내의 API 호출을 기록하고, 이를 EventBridge와 통합하여 특정 이벤트를 감지할 수 있습니다. IAM `CreateUser` API 호출이 이루어질 때 이 이벤트를 감지하는 규칙을 생성할 수 있습니다.

4. **Amazon SNS 주제를 이벤트 대상으로 사용**: EventBridge 규칙을 사용하여 감지한 `CreateUser` 이벤트를 Amazon SNS 주제로 전송할 수 있습니다. SNS 주제에 이메일 구독자를 추가하면, 해당 이벤트가 발생할 때마다 이메일로 알림을 받을 수 있습니다.

### 다른 선택지 분석:

2. **Amazon CloudSearch를 이벤트 소스로 지정하는 것은 올바르지 않습니다.** CloudSearch는 검색 엔진 서비스이며 이벤트를 생성하는 데 사용되지 않습니다.

3. **AWS IAM Access Analyzer를 이벤트 소스로 사용하는 것은 적절하지 않습니다.** Access Analyzer는 IAM 정책을 분석하는 도구이며 API 호출에 대한 이벤트를 생성하지 않습니다.

5. **Amazon SES를 이벤트 대상으로 사용하기는 적절하지 않습니다.** SES는 이메일 발송 서비스이지만, EventBridge와 직접 연결되어 이벤트를 수신할 수 없습니다. SNS를 통해 이메일 알림을 처리하는 것이 더 일반적입니다.



## 질문: 118
데이터베이스가 Amazon RDS Multi-AZ DB 인스턴스에서 실행 중입니다. 

최근 보안 감사에서 데이터베이스가 암호화되지 않았기 때문에 규정을 준수하지 않는 것으로 나타났습니다.

어떤 접근 방식으로 암호화 요구 사항을 해결할 수 있을까요?

1. RDS 콘솔에 로그인하고 암호화 상자를 선택하여 데이터베이스를 암호화합니다.
2. 새로운 암호화된 Amazon EBS 볼륨을 생성하여 인스턴스에 연결합니다.
3. 보조 가용성 영역의 대기 복제본을 암호화하고 기본 인스턴스로 승격시킵니다.
4. RDS 인스턴스의 스냅샷을 찍고, 스냅샷을 복사하고 암호화한 다음, 새 RDS 인스턴스로 복원합니다.

데이터베이스의 암호화 요구 사항을 해결하기 위한 적절한 접근 방식은 **4. RDS 인스턴스의 스냅샷을 찍고, 스냅샷을 복사하고 암호화한 다음, 새 RDS 인스턴스로 복원합니다.**입니다.

### 이유:
- **RDS 인스턴스의 스냅샷을 찍고 복사하는 과정**에서 암호화 옵션을 선택할 수 있습니다. 이를 통해 기존 RDS 인스턴스를 유지하면서 암호화된 새로운 인스턴스를 생성할 수 있습니다.
- **새 RDS 인스턴스로 복원**하는 과정에서 Multi-AZ 설정도 유지할 수 있으므로 가용성 요구 사항도 충족됩니다.

### 다른 선택지 분석:
1. **RDS 콘솔에 로그인하고 암호화 상자를 선택하여 데이터베이스를 암호화하는 것은 불가능합니다.** RDS 인스턴스를 생성할 때만 암호화를 설정할 수 있으며, 기존 인스턴스에 대해 직접적으로 암호화를 활성화할 수는 없습니다.
  
2. **새로운 암호화된 Amazon EBS 볼륨을 생성하여 인스턴스에 연결하는 것은 RDS와 관련이 없습니다.** Amazon RDS는 EBS 볼륨을 관리하며 사용자가 EBS 볼륨을 직접 연결하거나 수정할 수 없습니다.

3. **보조 가용성 영역의 대기 복제본을 암호화하는 방법은 Multi-AZ 구성을 지원하지 않으며**, 대기 복제본을 직접적으로 암호화할 수 없습니다. 대신, 복제본을 생성할 때 암호화를 설정해야 합니다.



## 질문: 119
AWS Organizations를 사용하는 회사에서는 프로덕션 계정의 Amazon S3 버킷을 절대 삭제해서는 안 됩니다.

SysOps 관리자가 해당 계정의 S3 버킷을 절대 삭제하지 않도록 하기 위해 취할 수 있는 가장 간단한 방법은 무엇입니까?

1. 버킷이 삭제되는 것을 방지하려면 모든 S3 버킷에 MFA 삭제를 설정합니다.
2. 서비스 제어 정책을 사용하여 프로덕션 계정의 모든 버킷에서 s3:DeleteBucket 작업을 거부합니다.
3. 프로덕션 계정의 모든 버킷에 대해 s3:DeleteBucket 작업을 거부하는 IAM 정책이 있는 IAM 그룹을 생성합니다.
4. AWS Shield를 사용하여 모든 S3 버킷이 아닌 AWS 계정에서만 s3:DeleteBucket 작업을 거부합니다.

S3 버킷의 삭제를 방지하기 위해 SysOps 관리자가 취할 수 있는 가장 간단한 방법은 **2. 서비스 제어 정책을 사용하여 프로덕션 계정의 모든 버킷에서 s3:DeleteBucket 작업을 거부합니다.**입니다.

### 이유:
- **서비스 제어 정책(SCP)**는 AWS Organizations의 구성원 계정에서 허용되는 작업을 중앙 집중식으로 관리할 수 있는 강력한 도구입니다. SCP를 사용하여 특정 작업, 이 경우 `s3:DeleteBucket`을 거부함으로써 해당 계정의 모든 사용자가 S3 버킷을 삭제하지 못하도록 강제할 수 있습니다.
- SCP는 계정의 모든 IAM 사용자 및 역할에 적용되므로, 해당 계정의 모든 버킷에 대한 삭제를 효과적으로 방지합니다.

### 다른 선택지 분석:
1. **MFA 삭제를 설정하는 것은 효과적일 수 있지만,** 사용자 또는 IAM 역할이 MFA를 사용하지 않으면 여전히 삭제할 수 있습니다. 또한, MFA 삭제는 버킷의 객체에 대해만 작동하고 버킷 자체에는 적용되지 않습니다.

3. **IAM 정책을 생성하는 것은 특정 사용자 또는 그룹에 대한 권한을 제한하는 데 사용할 수 있지만,** 새로운 사용자나 역할이 추가될 경우 모든 사용자에게 일관되게 적용되기 어려울 수 있습니다. SCP를 사용하는 것이 더 효과적입니다.

4. **AWS Shield는 DDoS 공격으로부터 보호하는 서비스로,** S3 버킷의 삭제와는 관련이 없습니다. 따라서 이 옵션은 문제 해결에 도움이 되지 않습니다.



## 질문: 120
한 회사에 VPC의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 

이 애플리케이션은 인터넷에서 소프트웨어 업데이트를 다운로드할 수 있는 액세스 권한이 필요합니다. VPC에는 퍼블릭 서브넷과 프라이빗 서브넷이 있습니다. 이 회사의 보안 정책에 따라 모든 EC2 인스턴스는 프라이빗 서브넷에 배포해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. VPC에 인터넷 게이트웨이를 추가합니다. 프라이빗 서브넷의 경로 테이블에서 인터넷 게이트웨이로의 경로를 추가합니다.
2. 개인 서브넷에 NAT 게이트웨이를 추가합니다. 개인 서브넷의 경로 테이블에서 NAT 게이트웨이로의 경로를 추가합니다.
3. 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. 프라이빗 서브넷의 경로 테이블에서 NAT 게이트웨이로의 경로를 추가합니다.
4. VPC에 두 개의 인터넷 게이트웨이를 추가합니다. 프라이빗 서브넷과 퍼블릭 서브넷의 경로 테이블에서 각 인터넷 게이트웨이에 대한 경로를 추가합니다.

SysOps 관리자가 애플리케이션이 인터넷에서 소프트웨어 업데이트를 다운로드할 수 있도록 하려면 **3. 퍼블릭 서브넷에 NAT 게이트웨이를 추가합니다. 프라이빗 서브넷의 경로 테이블에서 NAT 게이트웨이로의 경로를 추가합니다.**를 선택해야 합니다.

### 이유:
- **NAT 게이트웨이(NAT Gateway)**는 프라이빗 서브넷의 EC2 인스턴스가 인터넷과 통신할 수 있도록 해주는 서비스입니다. NAT 게이트웨이를 퍼블릭 서브넷에 배치하면, 프라이빗 서브넷의 EC2 인스턴스가 소프트웨어 업데이트를 다운로드하기 위해 NAT 게이트웨이를 통해 인터넷에 접근할 수 있습니다.
- NAT 게이트웨이는 EC2 인스턴스의 IP 주소를 숨기고 인터넷에 대한 요청을 프라이빗 서브넷에서 처리할 수 있게 해주므로 보안 정책을 준수하는 데도 적합합니다.

### 다른 선택지 분석:
1. **인터넷 게이트웨이를 추가하고 프라이빗 서브넷에서 경로를 설정하는 것은** 잘못된 접근 방식입니다. 프라이빗 서브넷은 인터넷과 직접 연결될 수 없으므로, 퍼블릭 서브넷에 있는 NAT 게이트웨이를 통해 인터넷에 접근해야 합니다.

2. **프라이빗 서브넷에 NAT 게이트웨이를 추가하는 것은** 불가능합니다. NAT 게이트웨이는 퍼블릭 서브넷에 위치해야만 외부 인터넷과의 연결이 가능하므로, 이 방법은 올바르지 않습니다.

4. **두 개의 인터넷 게이트웨이를 추가하는 것은** 불필요하며, 하나의 VPC에 여러 개의 인터넷 게이트웨이를 추가하는 것은 지원되지 않습니다.

## 질문: 121
개발팀은 최근 웹 애플리케이션의 새 버전을 프로덕션에 배포했습니다. 

출시 후 침투 테스트에서 사용자 데이터를 노출할 수 있는 크로스 사이트 스크립팅 취약성이 드러났습니다.

어떤 AWS 서비스가 이 문제를 완화할까요?

1. AWS Shield 표준
2. AWS 웹 애플리케이션 방화벽
3. 탄력적 부하 분산
4. 아마존 코그니토

정답은 **2. AWS 웹 애플리케이션 방화벽(AWS WAF)**입니다.

## 선택 이유:
- **AWS WAF**: AWS WAF는 웹 애플리케이션에 대한 HTTP(S) 요청을 필터링하고 모니터링하는 서비스로, 크로스 사이트 스크립팅(XSS) 같은 일반적인 웹 공격으로부터 애플리케이션을 보호할 수 있습니다. 개발팀이 배포한 웹 애플리케이션에서 XSS 취약성이 발견되었으므로, WAF를 사용하여 해당 공격 패턴을 탐지하고 차단할 수 있습니다.

## 다른 선택지:
- **1. AWS Shield 표준**: AWS Shield는 주로 DDoS(Distributed Denial of Service) 공격을 방어하는 데 사용되며, 크로스 사이트 스크립팅 같은 애플리케이션 레벨의 취약성을 완화하지는 않습니다.
  
- **3. 탄력적 부하 분산(ELB)**: ELB는 트래픽 분산과 확장성에 중점을 두며, 보안 기능이 있지만 XSS와 같은 웹 애플리케이션의 취약성을 직접적으로 보호하지는 않습니다.
  
- **4. 아마존 코그니토**: Amazon Cognito는 인증 및 사용자 관리에 사용되며, XSS 공격 방어와는 관련이 없습니다.

따라서, 크로스 사이트 스크립팅 취약성을 완화하려면 **AWS WAF**를 사용하는 것이 적절한 해결책입니다.

## 질문: 122
SysOps 관리자는 고성능 컴퓨팅(HPC) 애플리케이션을 위해 Amazon EC2 인스턴스의 복원성 계층을 구성해야 합니다. 

HPC 애플리케이션은 노드 간에 최소 지연 시간이 필요합니다.
SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

1. Amazon Elastic File System(Amazon EFS) 파일 시스템을 만듭니다. 사용자 데이터를 사용하여 파일 시스템을 EC2 인스턴스에 마운트합니다.
2. EC2 인스턴스 앞에 다중 AZ 네트워크 로드 밸런서를 생성합니다.
3. EC2 인스턴스를 단일 서브넷 내의 자동 확장 그룹에 배치합니다.
4. EC2 인스턴스를 클러스터 배치 그룹으로 시작합니다.
5. EC2 인스턴스를 파티션 배치 그룹으로 시작합니다.

SysOps 관리자가 고성능 컴퓨팅(HPC) 애플리케이션의 복원성 계층을 구성하기 위해 취해야 할 조치는 **3. EC2 인스턴스를 단일 서브넷 내의 자동 확장 그룹에 배치합니다.**와 **4. EC2 인스턴스를 클러스터 배치 그룹으로 시작합니다.**입니다.

### 이유:
1. **EC2 인스턴스를 단일 서브넷 내의 자동 확장 그룹에 배치합니다.**
   - 단일 서브넷 내에서 인스턴스를 배치하면 노드 간의 지연 시간을 최소화할 수 있습니다. 이는 데이터 전송 및 통신이 같은 서브넷 내에서 이루어지기 때문에 지연 시간이 줄어드는 결과를 가져옵니다.

2. **EC2 인스턴스를 클러스터 배치 그룹으로 시작합니다.**
   - 클러스터 배치 그룹은 HPC와 같은 낮은 지연 시간과 높은 대역폭이 필요한 애플리케이션에 최적화되어 있습니다. 클러스터 배치 그룹을 사용하면 인스턴스가 물리적으로 가까운 위치에 배치되어 서로 간의 네트워크 지연 시간을 최소화할 수 있습니다.

### 다른 선택지 분석:
1. **Amazon Elastic File System(Amazon EFS) 파일 시스템을 만듭니다.**
   - EFS는 공유 스토리지로, 성능이 높은 컴퓨팅 환경에서는 필요한 최소 지연 시간을 보장하지 못할 수 있습니다. EFS는 지연 시간이 더 높을 수 있기 때문에 HPC에 적합하지 않습니다.

2. **EC2 인스턴스 앞에 다중 AZ 네트워크 로드 밸런서를 생성합니다.**
   - 다중 AZ 네트워크 로드 밸런서는 고가용성을 제공하지만, HPC 애플리케이션에서는 노드 간의 최소 지연 시간이 더 중요합니다. 로드 밸런서 사용은 오히려 추가적인 지연 시간을 초래할 수 있습니다.

5. **EC2 인스턴스를 파티션 배치 그룹으로 시작합니다.**
   - 파티션 배치 그룹은 스토리지 대역폭을 분산하여 활용하는 데 적합하지만, HPC 애플리케이션의 경우는 클러스터 배치 그룹이 더 적합합니다. 파티션 배치 그룹은 성능을 보장하지 않으므로 이 요구 사항에 맞지 않습니다.


 

## 질문: 123
한 회사의 고객이 Amazon S3에서 정적 웹 콘텐츠에 액세스하는 동안 지연 시간이 증가했다고 보고하고 있습니다. SysOps 관리자가 특정 S3 버킷에서 매우 높은 읽기 작업률을 관찰했습니다.

S3 버킷의 부하를 줄여서 지연 시간을 최소화하려면 어떻게 해야 할까요?

1. S3 버킷을 최종 사용자의 지리적 위치에 더 가까운 지역으로 마이그레이션합니다.
2. 교차 지역 복제를 사용하여 모든 데이터를 다른 지역으로 복제합니다.
3. S3 버킷을 원본으로 하는 Amazon CloudFront 배포를 생성합니다.
4. Amazon S3에서 제공되는 데이터를 캐시하려면 Amazon ElastiCache를 사용하세요.

정답: **3. S3 버킷을 원본으로 하는 Amazon CloudFront 배포를 생성합니다.**

### 이유:
- **CloudFront는 콘텐츠 전송 네트워크(CDN)**로, 전 세계에 분산된 엣지 로케이션에서 S3의 정적 웹 콘텐츠를 캐시합니다. 이를 통해 사용자가 콘텐츠에 접근할 때 S3 버킷이 아닌 가까운 엣지 로케이션에서 요청이 처리되어, 지연 시간이 줄어듭니다.
- **부하 분산**: 높은 읽기 작업률로 인한 S3 버킷의 부하를 줄이고, 대규모 트래픽을 효과적으로 관리할 수 있습니다. 

다른 옵션들은 S3의 지연 시간을 직접적으로 개선하는 데 효과적이지 않습니다. 

- **1. S3 버킷을 최종 사용자의 지리적 위치에 더 가까운 지역으로 마이그레이션**: 이동이 필요할 수 있지만, 이미 S3에서 콘텐츠를 제공하는 방법에는 영향을 미치지 않습니다.
  
- **2. 교차 지역 복제를 사용하여 모든 데이터를 다른 지역으로 복제**: 데이터의 가용성을 높일 수는 있지만, 지연 시간을 개선하지는 않습니다.
  
- **4. Amazon S3에서 제공되는 데이터를 캐시하려면 Amazon ElastiCache를 사용하세요**: S3는 파일 저장소이므로 ElastiCache는 적합하지 않습니다. ElastiCache는 일반적으로 데이터베이스 쿼리 결과나 자주 조회되는 데이터에 사용됩니다.


## 질문: 124
SysOps 관리자는 이메일 알림을 제공하고 Amazon S3 버킷에 파일이 들어갈 때마다 데이터베이스에 레코드를 삽입하는 솔루션을 개발해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 하는 S3 이벤트 알림을 설정합니다. SNS 주제에 대한 두 개의 구독을 만듭니다. 한 구독을 사용하여 이메일 알림을 보냅니다. 다른 구독을 사용하여 레코드를 데이터베이스에 삽입하는 AWS Lambda 함수를 호출합니다.
2. S3 버킷에 객체가 생성될 때마다 ALARM 상태로 전환되는 Amazon CloudWatch 알람을 설정합니다. 이메일 알림을 보내고 레코드를 데이터베이스에 삽입하는 AWS Lambda 함수를 호출하도록 알람을 구성합니다.
3. S3 버킷에서 새 객체가 감지될 때마다 이메일 알림을 보내고 데이터베이스에 레코드를 삽입하는 AWS Lambda 함수를 만듭니다. Amazon EventBridge(Amazon CloudWatch Events) 예약된 규칙으로 1분마다 함수를 호출합니다.
4. 두 개의 S3 이벤트 알림을 설정합니다. 각 알림에 별도의 AWS Lambda 함수를 타겟팅합니다. 한 함수는 이메일 알림을 보내도록 구성합니다. 다른 함수는 레코드를 데이터베이스에 삽입하도록 구성합니다.


정답: **1. Amazon Simple Notification Service(Amazon SNS) 주제를 대상으로 하는 S3 이벤트 알림을 설정합니다. SNS 주제에 대한 두 개의 구독을 만듭니다. 한 구독을 사용하여 이메일 알림을 보냅니다. 다른 구독을 사용하여 레코드를 데이터베이스에 삽입하는 AWS Lambda 함수를 호출합니다.**

### 이유:
- **운영 효율성**: SNS를 사용하면 여러 소비자에게 메시지를 전송할 수 있으며, 이메일 알림과 데이터베이스 레코드 삽입을 동일한 이벤트 소스에서 쉽게 관리할 수 있습니다. 두 개의 구독을 통해 각 작업을 독립적으로 처리할 수 있으므로 코드와 리소스를 재사용할 수 있습니다.
- **간결함**: 이 접근 방식은 이벤트 발생 시 SNS 주제에 메시지를 게시하는 간단한 방법으로, S3와 Lambda, SNS 간의 통합을 활용하여 효율성을 높입니다.
- **유연성**: 필요에 따라 추가 구독을 추가하거나 수정하기 쉽기 때문에 요구 사항이 변경될 때 유연하게 대응할 수 있습니다.

다른 옵션들의 단점은 다음과 같습니다:

- **2. Amazon CloudWatch 알람을 설정하는 방법**: S3 버킷의 객체 생성 이벤트를 감지하는 데 적합하지 않으며, CloudWatch는 주로 메트릭과 로그에 기반하여 작동하므로 이 솔루션은 과도한 설정과 복잡성을 초래합니다.

- **3. AWS Lambda 함수를 EventBridge로 예약 호출하는 방법**: 이 방법은 S3 객체가 생성될 때마다 즉시 반응하지 않으며, 1분마다 호출하기 때문에 비효율적입니다.

- **4. 두 개의 S3 이벤트 알림을 설정하는 방법**: 이 방법은 기능적으로는 맞지만, SNS를 사용하는 것이 더 효율적이며 관리가 용이합니다. 이벤트에 대한 별도의 설정이 필요하고, 유지 관리 측면에서 더 복잡해질 수 있습니다.


## 질문: 125
한 회사가 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 인스턴스는 Amazon EC2 Auto Scaling 그룹에 있습니다. 애플리케이션은 공개 URL로 액세스합니다.

SysOps 관리자는 애플리케이션의 가용성을 확인하고 고객과 동일한 경로와 작업을 따르는 모니터링 솔루션을 구현해야 합니다. 모니터링 실행의 95% 미만에서 오류가 발견되지 않으면 SysOps 관리자는 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 고객 경로를 따르는 스크립트로 Amazon CloudWatch Synthetics 카나리아를 만듭니다. 카나리아가 반복 일정에 따라 실행되도록 예약합니다. SuccessPercent 메트릭이 95% 미만일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 CloudWatch 알람을 만듭니다.
2. 엔드포인트의 가용성을 모니터링하는 Amazon Route 53 상태 확인을 만듭니다. HealthCheckPercentageHealthy 지표가 95% 미만일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 Amazon CloudWatch 알람을 만듭니다.
3. 각 고객 경로에 대해 엔드포인트를 사용할 수 있는지 확인하기 위해 단일 AWS Lambda 함수를 만듭니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 Lambda 함수를 예약합니다. 엔드포인트가 오류를 반환하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 Lambda 함수를 구성합니다.
4. 각 고객 경로에 대해 AWS Lambda 함수를 만들어 해당 엔드포인트를 사용할 수 있는지 확인합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 Lambda 함수를 예약합니다. 각 Lambda 함수를 구성하여 엔드포인트 상태에 대한 사용자 지정 메트릭을 Amazon CloudWatch에 게시합니다. 각 사용자 지정 메트릭을 기반으로 CloudWatch 알람을 만들어 알람이 ALARM 상태일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시합니다.
 

정답: **1. 고객 경로를 따르는 스크립트로 Amazon CloudWatch Synthetics 카나리아를 만듭니다. 카나리아가 반복 일정에 따라 실행되도록 예약합니다. SuccessPercent 메트릭이 95% 미만일 때 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하는 CloudWatch 알람을 만듭니다.**

### 이유:
- **고객 경로 모니터링**: Amazon CloudWatch Synthetics 카나리아를 사용하면 고객이 실제로 사용하는 경로와 동일한 경로를 따라 애플리케이션의 가용성을 모니터링할 수 있습니다. 이는 사용자의 경험을 정확하게 반영합니다.
- **자동화된 스케줄링**: 카나리아는 정기적으로 실행될 수 있도록 예약할 수 있으며, 이에 따라 지속적인 모니터링이 가능합니다.
- **상황에 맞는 알림**: SuccessPercent 메트릭이 95% 미만일 때 SNS를 통해 알림을 받을 수 있어, 문제를 신속하게 인지하고 대응할 수 있습니다.

다른 옵션들의 단점은 다음과 같습니다:

- **2. Amazon Route 53 상태 확인**: 이 방법은 URL 가용성 모니터링에 적합하지만, 고객 경로에 대한 구체적인 테스트는 수행하지 않으므로 모니터링의 정확성이 떨어질 수 있습니다.

- **3. 단일 AWS Lambda 함수 사용**: 이 방법은 고객 경로를 따르지 않으며, Lambda 함수를 별도로 작성해야 하므로 관리의 복잡성이 증가합니다.

- **4. 사용자 지정 메트릭을 사용하는 AWS Lambda 함수**: 이 방법은 고객 경로를 따르긴 하지만, 구현과 관리가 더 복잡하며, 단일 Lambda 함수 대신 여러 함수를 생성해야 할 수 있습니다. 또한 사용자 지정 메트릭을 CloudWatch에 게시하는 것은 추가적인 오버헤드를 초래할 수 있습니다.


## 질문: 126
SysOps 관리자는 AWS Systems Manager Session Manager를 사용하여 인스턴스에 연결합니다. 

SysOps 관리자가 새 Amazon EC2 인스턴스를 시작한 후 EC2 인스턴스는 연결 가능한 시스템의 Session Manager 목록에 나타나지 않습니다. SysOps 관리자는 Systems Manager Agent가 EC2 인스턴스에 설치, 업데이트 및 실행 중인지 확인합니다.

이 문제의 이유는 무엇입니까?

1. SysOps 관리자는 연결에 필요한 키 쌍에 액세스할 수 없습니다.
2. SysOps 관리자가 포트 22에서 SSH를 허용하기 위해 EC2 인스턴스에 보안 그룹을 연결하지 않았습니다.
3. EC2 인스턴스에는 Session Manager가 EC2 인스턴스에 연결할 수 있도록 허용하는 연결된 IAM 역할이 없습니다.
4. EC2 인스턴스 ID가 세션 관리자 구성에 입력되지 않았습니다.

정답: **3. EC2 인스턴스에는 Session Manager가 EC2 인스턴스에 연결할 수 있도록 허용하는 연결된 IAM 역할이 없습니다.**

### 이유:
- **IAM 역할 필수**: AWS Systems Manager Session Manager를 사용하여 EC2 인스턴스에 연결하려면, 해당 인스턴스에 적절한 IAM 역할이 연결되어 있어야 합니다. 이 역할은 Systems Manager가 인스턴스에 연결할 수 있도록 허용하는 정책을 포함해야 합니다. 예를 들어, `AmazonSSMManagedInstanceCore` 정책이 필요합니다.
  
- **Agent 설치 여부와는 무관**: SysOps 관리자가 SSM Agent가 설치되어 있고 실행 중인 것을 확인했더라도, IAM 역할이 없으면 Session Manager를 통해 인스턴스에 연결할 수 없습니다. 

다른 옵션들의 단점은 다음과 같습니다:

1. **키 쌍 문제**: Session Manager는 SSH 연결을 사용하지 않으므로, 키 쌍이 없거나 액세스할 수 없는 것은 문제가 되지 않습니다.

2. **SSH 보안 그룹**: Session Manager는 SSH를 사용하지 않기 때문에, 포트 22에서 SSH를 허용하기 위한 보안 그룹 설정은 관련이 없습니다.

4. **EC2 인스턴스 ID 문제**: Session Manager는 EC2 인스턴스 ID를 따로 등록할 필요가 없으며, IAM 역할이 올바르게 설정되면 인스턴스는 자동으로 Session Manager에 표시됩니다.

## 질문: 127
SysOps 관리자가 VPC에 사용 가능한 프라이빗 IPv4 주소가 없기 때문에 Amazon EC2 인스턴스를 VPC로 시작할 수 없습니다.

SysOps 관리자가 인스턴스를 시작하기 위해 취해야 하는 작업 조합은 무엇입니까? (두 가지를 선택하세요.)

1. VPC에 보조 IPv4 CIDR 블록을 연결합니다.
2. 기본 IPv6 CIDR 블록을 VPC에 연결합니다.
3. VP에 대한 새 서브넷을 만듭니다.
4. VPC의 CIDR 블록을 수정합니다.
5. 인스턴스와 연관된 서브넷의 CIDR 블록을 수정합니다.

정답: 
**1. VPC에 보조 IPv4 CIDR 블록을 연결합니다.**  
**4. VPC의 CIDR 블록을 수정합니다.**

### 이유:
1. **보조 IPv4 CIDR 블록 연결**:
   - VPC에 보조 IPv4 CIDR 블록을 추가하면 사용할 수 있는 프라이빗 IPv4 주소의 수를 증가시킬 수 있습니다. 이를 통해 더 많은 EC2 인스턴스를 시작할 수 있습니다.

2. **CIDR 블록 수정**:
   - VPC의 CIDR 블록을 수정하면 기본적으로 사용 가능한 IPv4 주소 범위를 확장할 수 있습니다. 그러나 VPC의 CIDR 블록은 처음 생성할 때 정의되며, 수정 시에는 제한 사항이 있을 수 있지만 필요할 경우 이 방법을 통해도 사용할 수 있는 주소를 늘릴 수 있습니다.

### 다른 옵션들:
- **2. 기본 IPv6 CIDR 블록 연결**: IPv6 CIDR 블록을 추가하면 IPv4 주소에는 영향을 미치지 않으므로, 현재 IPv4 주소 부족 문제를 해결하지 못합니다.

- **3. 새 서브넷 만들기**: 새 서브넷을 생성하더라도 서브넷의 CIDR 블록이 기존 VPC의 CIDR 블록 내에 있어야 하며, 여전히 사용할 수 있는 IPv4 주소가 부족할 수 있습니다.

- **5. 인스턴스와 연관된 서브넷의 CIDR 블록 수정**: 서브넷의 CIDR 블록을 수정할 수는 있지만, 이미 사용 중인 주소 범위가 있을 경우 수정이 불가능하며, 서브넷의 CIDR 블록이 VPC의 CIDR 블록 내에 있어야 하므로 이 방법은 기존 주소 부족 문제를 해결하지 못할 수 있습니다.

## 질문: 128
SysOps 관리자가 새 AWS 계정에서 Amazon EC2 Auto Scaling 그룹을 만들고 있습니다. 

인스턴스를 추가한 후 SysOps 관리자는 그룹이 최소 인스턴스 수에 도달하지 못했다는 것을 알게 됩니다. SysOps 관리자는 다음과 같은 오류 메시지를 받습니다.

새 EC2 인스턴스를 시작합니다. 상태 이유: 할당량에 따라 실행 중인 인스턴스가 0개 더 허용됩니다.
최소 1개를 요청했습니다. EC2 인스턴스 시작이 실패했습니다.

어떤 조치로 이 문제를 해결할 수 있습니까?

1. AWS Billing and Cost Management 콘솔에서 Amazon EC2에 대한 계정 지출 한도를 조정합니다.
2. EC2 콘솔의 EC2 설정 섹션에서 해당 AWS 지역의 EC2 할당량을 수정합니다.
3. AWS Management Console에서 Service Quotas를 사용하여 인스턴스 유형 패밀리에 대한 할당량 증가를 요청합니다.
4. AWS Management Console의 자동 크기 조정 그룹에서 재균형 조정 작업을 사용합니다.

정답: **3. AWS Management Console에서 Service Quotas를 사용하여 인스턴스 유형 패밀리에 대한 할당량 증가를 요청합니다.**

### 이유:
AWS 계정은 인스턴스 수에 대한 기본 할당량이 설정되어 있으며, 이 할당량을 초과하여 인스턴스를 시작할 수 없습니다. 오류 메시지에서 "할당량에 따라 실행 중인 인스턴스가 0개 더 허용됩니다."라고 언급된 것은 현재 계정에서 해당 유형의 인스턴스를 시작할 수 있는 최대 수를 초과했음을 의미합니다. 

이 문제를 해결하기 위해서는 **Service Quotas**를 사용하여 인스턴스 유형 패밀리에 대한 할당량 증가를 요청해야 합니다. 이렇게 하면 새로운 EC2 인스턴스를 시작할 수 있는 허용량을 확보할 수 있습니다.

### 다른 옵션들:
1. **AWS Billing and Cost Management 콘솔에서 Amazon EC2에 대한 계정 지출 한도를 조정**: 이는 비용 관리와 관련된 설정이지만, 인스턴스 수에 대한 할당량에는 영향을 미치지 않습니다.
   
2. **EC2 콘솔의 EC2 설정 섹션에서 해당 AWS 지역의 EC2 할당량 수정**: EC2 설정에서 직접 할당량을 수정할 수 없으므로 이 방법은 올바르지 않습니다.
   
4. **AWS Management Console의 자동 크기 조정 그룹에서 재균형 조정 작업을 사용**: 이는 Auto Scaling 그룹의 인스턴스를 조정하는 방법이지만, 현재 할당량 문제를 해결하는 데는 도움이 되지 않습니다.


## 질문: 129
SysOps 관리자가 두 개의 AWS CloudFormation 템플릿을 만들고 있습니다. 

첫 번째 템플릿은 서브넷, 경로 테이블, 인터넷 게이트웨이와 같은 연관된 리소스가 있는 VPC를 만듭니다. 두 번째 템플릿은 첫 번째 템플릿에서 만든 VPC 내에 애플리케이션 리소스를 배포합니다. 두 번째 템플릿은 첫 번째 템플릿에서 만든 리소스를 참조해야 합니다.

이를 최소한의 관리 노력으로 어떻게 달성할 수 있을까요?

1. 첫 번째 템플릿의 출력에 내보내기 필드를 추가하고 두 번째 템플릿에 있는 값을 가져옵니다.
2. 첫 번째 템플릿에서 생성된 스택을 쿼리하고 필요한 값을 검색하는 사용자 지정 리소스를 만듭니다.
3. 두 번째 템플릿에서 참조되는 첫 번째 템플릿에서 매핑을 만듭니다.
4. 첫 번째 템플릿에 리소스 이름을 입력하고 두 번째 템플릿에서 해당 이름을 매개변수로 참조합니다

정답: **1. 첫 번째 템플릿의 출력에 내보내기 필드를 추가하고 두 번째 템플릿에 있는 값을 가져옵니다.**

### 이유:
AWS CloudFormation에서는 여러 템플릿 간에 리소스를 참조할 수 있도록 하기 위해 출력(Output) 섹션을 사용합니다. 첫 번째 템플릿에서 필요한 리소스의 정보를 출력으로 내보내고, 두 번째 템플릿에서는 이 출력을 가져와서 사용할 수 있습니다. 

이 접근 방식은 **최소한의 관리 노력**으로 구현할 수 있으며, 다음과 같은 단계로 진행됩니다:

1. **첫 번째 템플릿에서 리소스의 출력을 정의합니다.**
   - 예를 들어, VPC ID와 같은 리소스 정보를 출력으로 내보냅니다.
   ```yaml
   Outputs:
     VPCId:
       Value: !Ref MyVPC
       Export:
         Name: MyVPCId
   ```

2. **두 번째 템플릿에서 첫 번째 템플릿의 출력을 가져옵니다.**
   - `Fn::ImportValue` 함수를 사용하여 첫 번째 템플릿에서 내보낸 값을 참조합니다.
   ```yaml
   Resources:
     MyApplication:
       Type: AWS::SomeResource
       Properties:
         VpcId: !ImportValue MyVPCId
   ```

### 다른 옵션들:
2. **첫 번째 템플릿에서 생성된 스택을 쿼리하고 필요한 값을 검색하는 사용자 지정 리소스를 만듭니다.**
   - 이 방법은 복잡하고 관리 오버헤드가 더 큽니다. 또한, 직접적인 리소스 참조 대신 API 호출이 필요해 비효율적입니다.

3. **두 번째 템플릿에서 참조되는 첫 번째 템플릿에서 매핑을 만듭니다.**
   - 매핑은 정적 값을 사용하여 리소스를 참조하는 데 적합하지만, 동적으로 생성된 리소스를 참조하는 데는 적합하지 않습니다.

4. **첫 번째 템플릿에 리소스 이름을 입력하고 두 번째 템플릿에서 해당 이름을 매개변수로 참조합니다.**
   - 이 방법은 두 템플릿 간의 직접적인 연결을 생성하지 않으며, 첫 번째 템플릿의 리소스 이름이 변경될 경우 두 번째 템플릿도 수정해야 합니다.
   - 

## 질문: 130
한 회사가 Application Load Balancer(ALB) 뒤의 세 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다. 


어떤 솔루션이 이러한 요구 사항을 충족합니까?

1. 원하는 임계값에 도달하면 각 EC2 인스턴스의 크기를 늘리고 애플리케이션 지연 시간을 모니터링하기 위해 Amazon CloudWatch 알람을 생성합니다.
2. 애플리케이션 지연 시간을 모니터링하고 원하는 임계값에 도달하면 ALB에 EC2 인스턴스를 추가하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.
3. 대상 추적 스케일링 정책이 있는 EC2 인스턴스의 자동 스케일링 그룹에 애플리케이션을 배포합니다. ALB를 자동 스케일링 그룹에 연결합니다.
4. 예약된 스케일링 정책이 있는 EC2 인스턴스의 자동 스케일링 그룹에 애플리케이션을 배포합니다. ALB를 자동 스케일링 그룹에 연결합니다.

정답: **3. 대상 추적 스케일링 정책이 있는 EC2 인스턴스의 자동 스케일링 그룹에 애플리케이션을 배포합니다. ALB를 자동 스케일링 그룹에 연결합니다.**

### 이유:
대상 추적 스케일링 정책은 EC2 인스턴스의 자동 스케일링 그룹에서 애플리케이션의 성능을 최적화하는 데 매우 효과적입니다. 이 정책을 사용하면 다음과 같은 장점이 있습니다:

1. **자동화된 확장**: 대상 추적 스케일링 정책은 지정된 메트릭(예: CPU 사용량, 애플리케이션 지연 시간 등)을 기반으로 인스턴스 수를 자동으로 조정합니다. 이로 인해 트래픽이 증가할 때 자동으로 더 많은 인스턴스가 시작됩니다.

2. **ALB와의 통합**: ALB(Application Load Balancer)를 자동 스케일링 그룹에 연결함으로써 인스턴스가 추가되거나 제거될 때 로드 밸런서가 트래픽을 자동으로 분산시킵니다. 이로 인해 애플리케이션의 가용성과 성능이 향상됩니다.

### 다른 옵션들:
1. **각 EC2 인스턴스의 크기를 늘리고 CloudWatch 알람을 생성**: 이는 수동적인 접근 방식으로, 트래픽의 변동에 즉시 대응할 수 없습니다. EC2 인스턴스를 단순히 늘리는 것은 비용이 증가할 수 있으며, 최적의 성능을 보장하지 못할 수 있습니다.

2. **ALB에 EC2 인스턴스를 추가하는 EventBridge 규칙 생성**: 이 방법은 인스턴스를 수동으로 추가해야 하며, 트래픽 급증에 즉시 대응하지 못할 수 있습니다. 자동 스케일링 그룹을 사용하는 것보다 효과적이지 않습니다.

4. **예약된 스케일링 정책**: 이 방법은 특정 시간에만 인스턴스를 추가하는 방식으로, 예상치 못한 트래픽 급증에 즉각적으로 대응할 수 없습니다. 이는 고정된 스케일링이 필요할 때 유용할 수 있지만, 동적인 트래픽에 최적화된 방법이 아닙니다.

## 질문: 131
어떤 회사에 고성능 Windows 워크로드가 있습니다. 

이 워크로드에는 10,000 IOPS의 일관된 성능을 제공하는 스토리지 볼륨이 필요합니다. 이 회사는 이 성능을 달성하기 위해 불필요한 추가 용량에 비용을 지불하고 싶어하지 않습니다.

어떤 솔루션이 가장 적은 비용으로 이러한 요구 사항을 충족할까요?

1. 10,000개의 프로비저닝 IOPS로 구성된 프로비저닝된 IOPS SSD(io1) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.
2. 10,000개의 프로비저닝 IOPS로 구성된 범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.
3. 최대 I/O 모드에서 Amazon Elastic File System(Amazon EFS) 파일 시스템을 사용합니다.
4. 10,000 IOPS로 구성된 Amazon FSx for Windows File Server 파일 시스템을 사용합니다.


정답: **2. 10,000개의 프로비저닝 IOPS로 구성된 범용 SSD(gp3) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용합니다.**

### 이유:
Amazon EBS의 범용 SSD(gp3) 볼륨은 다음과 같은 이유로 이 요구 사항을 충족하는 가장 비용 효율적인 솔루션입니다:

1. **비용 효율성**: gp3 볼륨은 사용자가 원하는 성능(IOPS 및 처리량)을 기준으로 용량을 설정할 수 있습니다. 기본적으로 gp3는 3,000 IOPS를 제공하지만, 최대 16,000 IOPS까지 확장할 수 있습니다. 따라서 10,000 IOPS를 위해 필요한 용량이 적으며, io1보다 비용이 낮습니다.

2. **최소 용량 요구 사항**: gp3 볼륨은 더 적은 저장 용량으로도 높은 IOPS를 제공할 수 있으며, 불필요한 추가 용량을 피할 수 있습니다. io1 볼륨은 10,000 IOPS를 제공하기 위해 최소 1,000 GiB의 용량이 필요하지만, gp3는 적은 용량으로도 같은 성능을 달성할 수 있습니다.

3. **성능 일관성**: gp3 볼륨은 일관된 성능을 제공하므로, 고성능 워크로드에 적합합니다.

### 다른 옵션들:
1. **io1 볼륨**: 10,000개의 프로비저닝 IOPS로 구성된 io1 볼륨은 고성능이지만, 비용이 더 비쌉니다. 불필요한 용량을 지불해야 할 수 있습니다.

3. **Amazon EFS 파일 시스템**: EFS는 파일 시스템으로 IOPS를 보장하지 않으며, 성능이 가변적일 수 있습니다. 또한, IOPS에 따라 비용이 발생할 수 있습니다.

4. **Amazon FSx for Windows File Server**: 이 서비스는 Windows 기반 파일 스토리지에 최적화되어 있지만, 추가 비용이 발생할 수 있으며, 단일 워크로드에 대한 IOPS 성능을 최적화하기 위해 더 비쌀 수 있습니다. 

따라서, 범용 SSD(gp3) 볼륨이 가장 비용 효율적이고 성능 요구 사항을 충족하는 솔루션입니다.

## 질문: 132
SysOps 관리자는 60분 이상 평균 CPU 사용률이 10% 미만인 모든 Amazon EC2 인스턴스를 자동으로 종료하는 솔루션을 만들어야 합니다.

어떤 솔루션이 가장 운영적으로 효율적인 방식으로 이 요구 사항을 충족할까요?

1. 각 EC2 인스턴스에 60분마다 한 번씩 실행되도록 cron 작업을 구현하고 현재 CPU 사용률을 계산합니다. CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
2. 각 EC2 인스턴스에 대해 Amazon CloudWatch 알람을 구현하여 평균 CPU 사용률을 모니터링합니다. 기간을 1시간으로 설정하고 임계값을 10%로 설정합니다. 알람에서 인스턴스를 중지하기 위한 EC2 작업을 구성합니다.
3. 각 EC2 인스턴스에 통합 Amazon CloudWatch 에이전트를 설치하고 기본 수준 사전 정의된 메트릭 세트를 활성화합니다. 60분마다 CPU 사용률을 기록하고 CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
4. AWS Systems Manager Run Command를 사용하여 60분마다 각 EC2 인스턴스의 CPU 사용률을 가져옵니다. CPU 사용률이 10% 미만이면 인스턴스 종료를 시작합니다.
 


정답: **2. 각 EC2 인스턴스에 대해 Amazon CloudWatch 알람을 구현하여 평균 CPU 사용률을 모니터링합니다. 기간을 1시간으로 설정하고 임계값을 10%로 설정합니다. 알람에서 인스턴스를 중지하기 위한 EC2 작업을 구성합니다.**

### 이유:
1. **운영 효율성**: CloudWatch 알람을 사용하면 EC2 인스턴스의 CPU 사용률을 자동으로 모니터링하고, 특정 조건이 충족될 때 인스턴스를 자동으로 중지할 수 있습니다. 이렇게 하면 수동으로 모니터링하거나 스크립트를 실행할 필요가 없으므로 운영 비용과 노력을 줄일 수 있습니다.

2. **자동화**: CloudWatch 알람은 CPU 사용률이 10% 미만인 상태가 60분 이상 지속될 때 자동으로 알림을 트리거하고 인스턴스를 중지하는 작업을 수행할 수 있도록 설정할 수 있습니다. 이는 작업의 자동화를 통해 관리 부담을 최소화합니다.

3. **정확한 모니터링**: CloudWatch는 AWS 리소스에 대한 신뢰할 수 있는 모니터링 솔루션이며, CPU 사용률과 같은 메트릭을 정확하게 수집할 수 있습니다. 

### 다른 옵션들:
1. **cron 작업**: 각 인스턴스에 대해 cron 작업을 설정하는 것은 비효율적이며, 각 인스턴스에서 스크립트를 실행해야 하므로 관리 및 유지보수가 어렵습니다.

3. **CloudWatch 에이전트**: 에이전트를 설치하고 설정하는 데 추가적인 작업이 필요합니다. 또한, 이 방법도 각 인스턴스에서 수동으로 작업을 처리해야 하므로 효율적이지 않습니다.

4. **AWS Systems Manager Run Command**: 이 방법도 EC2 인스턴스에 대해 주기적으로 명령을 실행해야 하며, CloudWatch 알람을 사용하는 것보다 복잡하고 관리가 더 어려울 수 있습니다.

따라서, Amazon CloudWatch 알람을 활용하는 것이 가장 효율적이고 간단한 해결책입니다.

## 질문: 133
SysOps 관리자가 AWS 서비스에 대한 AWS CLI 호출을 인증할 수 없습니다.
다음 중 이 문제의 원인은 무엇입니까?

1. IAM 비밀번호가 올바르지 않습니다.
2. 서버 인증서가 없습니다.
3. SSH 키 쌍이 올바르지 않습니다.
4. 접근 키가 없습니다.


정답: **4. 접근 키가 없습니다.**

### 이유:
AWS CLI를 사용하여 AWS 서비스에 호출을 인증하려면 IAM 사용자에게 할당된 **액세스 키 ID**와 **비밀 액세스 키**가 필요합니다. 이러한 키가 없거나 올바르게 구성되지 않으면 AWS 서비스에 대한 인증이 실패하게 됩니다. 

### 다른 옵션들:
1. **IAM 비밀번호가 올바르지 않습니다**: AWS CLI는 IAM 사용자 비밀번호를 사용하지 않으므로, 비밀번호가 올바르지 않아도 CLI 호출은 영향을 받지 않습니다.

2. **서버 인증서가 없습니다**: AWS CLI 호출은 서버 인증서에 의존하지 않습니다. 이 문제는 주로 HTTPS 통신에서 SSL/TLS 인증서와 관련이 있지만, AWS CLI 인증과는 관련이 없습니다.

3. **SSH 키 쌍이 올바르지 않습니다**: SSH 키 쌍은 EC2 인스턴스에 SSH로 연결할 때 사용되는 것이며, AWS CLI 호출의 인증과는 관련이 없습니다.

따라서, AWS CLI 호출을 인증할 수 없는 주된 원인은 접근 키가 없거나 잘못 구성된 경우입니다.


## 질문: 134
회사에서는 90일 이상 사용되지 않은 모든 IAM 사용자 계정의 액세스 키와 비밀번호를 즉시 비활성화해야 합니다. 

SysOps 관리자는 가장 운영 효율적인 방법을 사용하여 사용되지 않는 키를 비활성화하는 프로세스를 자동화해야 합니다.

SysOps 관리자는 이 솔루션을 어떻게 구현해야 합니까?

1. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Step Functions 워크플로를 만듭니다. 예약된 Amazon EventBridge(Amazon CloudWatch Events) 규칙이 호출되면 AWS Lambda 함수를 실행하여 이러한 IAM 사용자의 AWS 액세스 키와 비밀번호를 자동으로 제거합니다.
2. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Config 규칙을 구성합니다. Amazon EC2 인스턴스에서 자동 주간 일괄 처리 프로세스를 설정하여 이러한 IAM 사용자의 AWS 액세스 키와 비밀번호를 비활성화합니다.
3. Amazon EC2 인스턴스에서 Python 스크립트를 개발하고 실행하여 90일 동안 활성화되지 않은 IAM 사용자를 프로그래밍 방식으로 식별합니다. 이러한 IAM 사용자를 자동으로 삭제합니다.
4. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Config 관리 규칙을 설정합니다. 이러한 IAM 사용자에 대한 AWS 액세스 키를 비활성화하기 위해 AWS Systems Manager 자동화 런북을 설정합니다.

정답: **1. 90일 동안 활성화되지 않은 IAM 사용자를 식별하기 위해 AWS Step Functions 워크플로를 만듭니다. 예약된 Amazon EventBridge(Amazon CloudWatch Events) 규칙이 호출되면 AWS Lambda 함수를 실행하여 이러한 IAM 사용자의 AWS 액세스 키와 비밀번호를 자동으로 제거합니다.**

### 이유:
이 솔루션은 자동화되고 운영 효율성이 높습니다. 구체적인 이점은 다음과 같습니다:

- **자동화**: AWS Lambda를 사용하여 IAM 사용자의 액세스 키와 비밀번호를 비활성화하는 작업을 자동화함으로써 수동 개입을 줄일 수 있습니다.
  
- **정기적인 실행**: Amazon EventBridge를 사용하여 주기적으로 Lambda 함수를 호출하면, 90일 이상 사용되지 않은 IAM 사용자를 자동으로 식별하고 비활성화할 수 있습니다.

- **확장성**: AWS Step Functions를 사용하면 작업의 흐름을 시각화하고 관리할 수 있으며, 다양한 AWS 서비스를 조합하여 복잡한 워크플로를 구현할 수 있습니다.

### 다른 옵션들:
2. **AWS Config 규칙을 구성**: AWS Config는 IAM 사용자 계정에 대한 변경 사항을 모니터링할 수 있지만, 자동으로 액세스 키와 비밀번호를 비활성화하는 데에는 추가적인 작업이 필요할 수 있습니다.

3. **EC2 인스턴스에서 Python 스크립트 실행**: 이 방법은 관리 효율성이 떨어집니다. EC2 인스턴스를 운영해야 하며, 스크립트를 지속적으로 실행하고 모니터링해야 하므로 운영 비용이 증가할 수 있습니다.

4. **AWS Config 관리 규칙과 Systems Manager 자동화**: 이 접근 방식은 가능하지만, AWS Config 규칙이 IAM 사용자를 식별하고 비활성화하는 과정을 직접 수행하기 어렵습니다. 시스템 구성이나 런북을 관리하는 데 추가적인 복잡성이 있을 수 있습니다.

따라서, 선택지 1이 가장 운영 효율적인 솔루션입니다.


## 질문: 135
한 회사가 AWS CloudFormation 템플릿에서 새로운 Amazon EC2 인스턴스를 시작하여 사용자 지정 AMI 이미지를 만듭니다. 

AWS OpsWorks를 통해 필요한 소프트웨어를 설치하고 구성하고 각 EC2 인스턴스의 이미지를 가져옵니다. 소프트웨어를 설치하고 구성하는 프로세스는 2~3시간이 걸릴 수 있지만, 때때로 설치 오류로 인해 프로세스가 중단됩니다.

SysOps 관리자는 CloudFormation 템플릿을 수정해야 하므로 프로세스가 중단되면 전체 스택이 실패하고 롤백됩니다.

이러한 요구 사항에 따라 템플릿에 무엇을 추가해야 합니까?

1. 시간 초과가 4시간으로 설정된 조건.
2. CreationPolicy의 시간 제한이 4시간으로 설정되었습니다.
3. DependsOn의 시간제한은 4시간으로 설정되어 있습니다.
4. 시간 제한이 4시간으로 설정된 메타데이터입니다.

정답: **2. CreationPolicy의 시간 제한이 4시간으로 설정되었습니다.**

### 이유:
`CreationPolicy`는 AWS CloudFormation 템플릿에서 리소스의 생성 상태를 제어할 수 있는 기능입니다. `CreationPolicy`를 사용하면 리소스가 성공적으로 생성되기까지의 시간을 지정할 수 있으며, 이 시간을 초과하면 CloudFormation 스택 생성이 실패하고 롤백됩니다. 이 기능은 소프트웨어 설치와 같은 장기 프로세스를 다룰 때 유용합니다.

- **시간 제한 설정**: 4시간의 시간 제한을 설정함으로써, 2~3시간의 소프트웨어 설치 프로세스가 종료되지 않거나 오류가 발생할 경우 CloudFormation이 스택 생성 프로세스를 실패시키고 롤백하도록 할 수 있습니다.

### 다른 옵션들:
1. **시간 초과가 4시간으로 설정된 조건**: 조건은 리소스 생성에 대한 결정적인 논리를 제공하지만, 특정 리소스 생성의 시간을 제어하지 않습니다.

3. **DependsOn의 시간제한은 4시간으로 설정되어 있습니다**: `DependsOn`은 특정 리소스가 다른 리소스의 생성을 완료해야 한다는 것을 지정하는 데 사용되지만, 시간 제한을 설정하는 기능은 없습니다.

4. **시간 제한이 4시간으로 설정된 메타데이터입니다**: 메타데이터는 리소스의 추가 정보를 제공하지만, 시간 제한이나 생성 실패 시의 롤백을 제어하는 데는 사용되지 않습니다.

따라서 `CreationPolicy`를 사용하여 소프트웨어 설치와 구성 프로세스가 중단될 경우 CloudFormation 스택이 실패하고 롤백되도록 설정하는 것이 가장 적합한 방법입니다.


## 질문: 136
한 회사가 AWS 계정에서 eu-west-1 지역의 90개 Amazon EC2 인스턴스에서 워크로드를 실행합니다. 

2개월 후에 회사는 eu-west-1에서 eu-west-3 지역으로 워크로드를 마이그레이션합니다.

회사는 EC2 인스턴스 비용을 줄여야 합니다. 회사는 다음 주에 시작되는 1년 약정을 할 의향이 있습니다. 회사는 1년 기간 동안 지역에 관계없이 90개 EC2 인스턴스에 대한 할인을 제공하는 EC2 인스턴스 구매 옵션을 선택해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. EC2 Standard 예약 인스턴스를 구매하세요.
2. EC2 인스턴스 할인 플랜을 구매하세요.
3. EC2 변환 가능 예약 인스턴스를 구매하세요.
4. 컴퓨팅 절감 플랜을 구매하세요.

정답: **3. EC2 변환 가능 예약 인스턴스를 구매하세요.**

### 이유:
EC2 변환 가능 예약 인스턴스는 특정 지역에 종속되지 않고, 약정 기간 동안 EC2 인스턴스의 유연성을 제공합니다. 이는 사용자가 인스턴스를 다른 지역으로 이동할 수 있는 옵션을 제공하여, 마이그레이션 후에도 같은 약정 혜택을 받을 수 있게 합니다. 

1. **EC2 Standard 예약 인스턴스**: 이 옵션은 특정 지역과 인스턴스 유형에 묶여 있어, 마이그레이션 시 이점을 제공하지 않습니다.

2. **EC2 인스턴스 할인 플랜**: 이 플랜은 인스턴스에 대한 일관된 할인 혜택을 제공하지만, 예약 인스턴스와 같은 약정 기간을 요구하지 않으며, 변환 가능성이나 지역 이동이 포함되지 않습니다.

4. **컴퓨팅 절감 플랜**: 이 옵션은 온디맨드 인스턴스 사용에 대해 할인을 제공하지만, 예약 인스턴스와 같은 장기 약정 기반의 할인은 아닙니다.

따라서, EC2 변환 가능 예약 인스턴스는 마이그레이션을 계획하고 있는 회사의 요구 사항을 충족하는 가장 적합한 옵션입니다.

## 질문: 137
SysOps 관리자가 퍼블릭 서브넷과 프라이빗 서브넷을 포함하는 VPC를 생성했습니다. 

프라이빗 서브넷에서 시작된 Amazon EC2 인스턴스는 인터넷에 액세스할 수 없습니다. 기본 네트워크 ACL은 VPC의 모든 서브넷에서 활성화되어 있으며 모든 보안 그룹은 모든 아웃바운드 트래픽을 허용합니다.

어떤 솔루션이 프라이빗 서브넷의 EC2 인스턴스에 인터넷에 액세스할 수 있게 할까요?

1. 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
2. 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. 퍼블릭 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
3. 프라이빗 서브넷에 NAT 게이트웨이를 만듭니다. 퍼블릭 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.
4. 프라이빗 서브넷에 NAT 게이트웨이를 만듭니다. 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.

정답: **1. 퍼블릭 서브넷에 NAT 게이트웨이를 만듭니다. 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만듭니다.**

### 이유:
프라이빗 서브넷의 EC2 인스턴스가 인터넷에 액세스할 수 있도록 하려면 NAT(NAT Gateway 또는 NAT Instance) 장치를 사용해야 합니다. NAT 게이트웨이는 퍼블릭 서브넷에 배치되고, 이를 통해 프라이빗 서브넷의 인스턴스가 아웃바운드 트래픽을 인터넷으로 전송할 수 있게 됩니다. 

1. **퍼블릭 서브넷에 NAT 게이트웨이를 만든 후, 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 생성하면** EC2 인스턴스가 NAT 게이트웨이를 통해 인터넷에 액세스할 수 있습니다.

2. **퍼블릭 서브넷에서 NAT 게이트웨이로 가는 경로를 만드는 것은 필요하지 않습니다.** NAT 게이트웨이는 퍼블릭 서브넷에 위치하고, 인터넷에 액세스할 수 있는 IP 주소를 가져야 합니다.

3. **프라이빗 서브넷에 NAT 게이트웨이를 만드는 것은** 올바른 방법이 아닙니다. NAT 게이트웨이는 퍼블릭 서브넷에 있어야 인터넷과 연결될 수 있습니다.

4. **프라이빗 서브넷에 NAT 게이트웨이를 만들고 프라이빗 서브넷에서 NAT 게이트웨이로 가는 경로를 만드는 것은** 이론적으로 맞지 않습니다. NAT 게이트웨이는 퍼블릭 서브넷에 있어야 합니다.

따라서, 프라이빗 서브넷의 EC2 인스턴스가 인터넷에 액세스할 수 있도록 하려면 퍼블릭 서브넷에 NAT 게이트웨이를 생성하고 해당 서브넷에서 적절한 경로를 설정하는 것이 필요합니다.


## 질문: 138
한 회사가 Elastic Load Balancer(ELB) 뒤의 Amazon EC2 인스턴스에서 퍼블릭 웹 애플리케이션을 실행하려고 합니다. 

회사의 보안 팀은 AWS Certificate Manager(ACM) 인증서를 사용하여 웹사이트를 보호하려고 합니다. ELB는 모든 HTTP 요청을 HTTPS로 자동으로 리디렉션해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 포트 80에 HTTPS 리스너가 하나인 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 80에 SSL/TLS 인증서를 연결합니다. HTTP에서 HTTPS로 요청을 리디렉션하는 규칙을 만듭니다.
2. 포트 80에 HTTP 리스너 하나, 포트 443에 HTTPS 프로토콜 리스너 하나가 있는 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.
3. 포트 80과 포트 443에 두 개의 TCP 리스너가 있는 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.
4. 포트 80과 포트 443에 두 개의 TCP 리스너가 있는 네트워크 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.

정답: **2. 포트 80에 HTTP 리스너 하나, 포트 443에 HTTPS 프로토콜 리스너 하나가 있는 애플리케이션 로드 밸런서를 만듭니다. 리스너 포트 443에 SSL/TLS 인증서를 연결합니다. 포트 80에서 포트 443으로 요청을 리디렉션하는 규칙을 만듭니다.**

### 이유:
이 솔루션은 보안 팀의 요구 사항과 HTTP 요청을 HTTPS로 리디렉션하는 방법에 적합합니다.

1. **포트 80에 HTTP 리스너**: HTTP 요청을 수신하고, 이후 HTTPS로 리디렉션하는 역할을 합니다.

2. **포트 443에 HTTPS 프로토콜 리스너**: SSL/TLS 인증서를 연결하여 암호화된 연결을 처리합니다.

3. **리디렉션 규칙**: 포트 80에서 수신된 HTTP 요청을 포트 443으로 리디렉션하여 모든 트래픽이 HTTPS로 안전하게 전달되도록 합니다.

### 다른 옵션 분석:
1. **옵션 1**은 포트 80에 HTTPS 리스너를 설정하고 있습니다. HTTPS 요청은 보안 연결이 필요하므로 이 접근법은 부적절합니다.

3. **옵션 3**에서는 TCP 리스너를 사용하고 있으며, HTTP 리디렉션을 설정하기에는 적합하지 않습니다. TCP 리스너는 프로토콜을 명시적으로 처리하지 않기 때문에 리디렉션 규칙을 적용할 수 없습니다.

4. **옵션 4**에서 사용된 네트워크 로드 밸런서는 일반적으로 HTTP/HTTPS 수준에서의 리디렉션을 지원하지 않습니다. 

따라서, **옵션 2**가 요구 사항을 충족하는 가장 적절한 솔루션입니다.


## 질문: 139
한 회사가 AWS Organizations의 조직에 속한 모든 멤버 계정에서 AWS 비용을 추적하려고 합니다. 

멤버 계정 관리자는 매월 예상 비용이 미리 정해진 금액을 초과할 때 알림을 받고 싶어합니다. 관리자는 청구 알람을 구성할 수 없습니다. 모든 사용자의 IAM 권한이 올바릅니다.

이 문제의 원인은 무엇일까요?

1. 관리/지불자 계정에는 청구 알림이 켜져 있지 않습니다.
2. 회사에서는 회원 계정과 관리/지불자 계정 간에 결제 정보를 공유하도록 AWS Resource Access Manager(AWS RAM)를 구성하지 않았습니다.
3. 모든 계정에 대해 Amazon GuardDuty가 켜져 있습니다.
4. 회사에서는 청구를 모니터링하기 위한 AWS Config 규칙을 구성하지 않았습니다.


정답: **1. 관리/지불자 계정에는 청구 알림이 켜져 있지 않습니다.**

### 이유:
AWS Organizations에서는 청구 알림을 설정할 때 관리/지불자 계정에서 알림을 구성해야 합니다. 각 멤버 계정이 독립적으로 청구 알림을 설정할 수는 없으며, 모든 비용은 관리 계정으로 집계되기 때문에 관리 계정에서 청구 알림을 설정해야 합니다.

### 다른 옵션 분석:
2. **AWS Resource Access Manager(AWS RAM)**: 이 옵션은 결제 정보를 공유하는 것과 관련이 있지만, 실제로 청구 알림을 설정하는 데 직접적인 영향을 주지는 않습니다. 청구 알림은 관리 계정에서만 설정해야 합니다.

3. **Amazon GuardDuty**: GuardDuty는 보안 서비스로, 청구 알림과는 관련이 없습니다. 이 서비스의 활성화 여부가 알림 기능에 영향을 주지 않습니다.

4. **AWS Config 규칙**: Config는 리소스 구성을 모니터링하고 규정을 준수하는 데 사용되며, 청구 알림과는 직접적인 연관이 없습니다.

결론적으로, 멤버 계정 관리자가 청구 알림을 받을 수 없는 주된 원인은 **관리/지불자 계정에서 청구 알림이 활성화되지 않았기 때문**입니다.



## 질문: 140
한 회사가 Amazon EC2 인스턴스에서 컨테이너화된 애플리케이션을 실행하기 위해 Amazon Elastic Container Service(Amazon ECS)를 사용하고 있습니다. SysOps 관리자는 ECS 작업 간의 트래픽 흐름만 모니터링하면 됩니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. 각 작업의 탄력적 네트워크 인터페이스에 Amazon CloudWatch Logs를 구성합니다.
2. 각 작업의 탄력적 네트워크 인터페이스에서 VPC 흐름 로그를 구성합니다.
3. 작업 정의에서 awsvpc 네트워크 모드를 지정하세요.
4. 작업 정의에서 브리지 네트워크 모드를 지정하세요.
5. 작업 정의에서 호스트 네트워크 모드를 지정하세요.

SysOps 관리자가 ECS 작업 간의 트래픽 흐름만 모니터링하기 위해 선택해야 하는 두 가지 단계는 다음과 같습니다:

1. **각 작업의 탄력적 네트워크 인터페이스에서 VPC 흐름 로그를 구성합니다.**  
   - VPC 흐름 로그를 사용하면 VPC 내에서의 트래픽 흐름을 모니터링할 수 있습니다. 이를 통해 ECS 작업 간의 트래픽을 분석하고, 특정 IP 주소 또는 포트에 대한 데이터 전송을 기록할 수 있습니다.

2. **작업 정의에서 awsvpc 네트워크 모드를 지정하세요.**  
   - `awsvpc` 네트워크 모드를 사용하면 각 ECS 작업이 자체 탄력적 네트워크 인터페이스를 갖게 됩니다. 이를 통해 작업 간의 트래픽을 개별적으로 모니터링하고, VPC 흐름 로그와 결합하여 트래픽 흐름을 보다 정밀하게 분석할 수 있습니다.

### 선택하지 않아야 하는 옵션:
- **각 작업의 탄력적 네트워크 인터페이스에 Amazon CloudWatch Logs를 구성합니다.**: CloudWatch Logs는 로그 데이터를 수집하는 데 사용되지만, 트래픽 흐름을 모니터링하는 데는 적합하지 않습니다.

- **작업 정의에서 브리지 네트워크 모드를 지정하세요.**: 브리지 네트워크 모드는 호스트의 Docker 브리지 네트워크를 사용하는 방식으로, 각 작업의 트래픽 흐름을 개별적으로 모니터링하기 어렵습니다.

- **작업 정의에서 호스트 네트워크 모드를 지정하세요.**: 호스트 모드는 각 작업이 호스트의 네트워크 스택을 공유하게 하여, IP 주소가 호스트와 동일해집니다. 이 경우에도 트래픽 흐름을 개별적으로 모니터링하기 어렵습니다.

따라서, **VPC 흐름 로그를 구성**하고 **`awsvpc` 네트워크 모드를 지정**하는 것이 최선의 접근 방식입니다.


## 질문: 141
한 회사가 AWS Organizations를 사용하여 여러 AWS 계정을 관리합니다. 

회사의 SysOps 팀은 수동 프로세스를 사용하여 IAM 역할을 만들고 관리해 왔습니다. 이 팀은 여러 AWS 계정에 필요한 IAM 역할을 만들고 관리하기 위한 자동화된 솔루션이 필요합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. AWS CloudFormation 템플릿을 만듭니다. 템플릿을 재사용하여 각 AWS 계정에서 필요한 IAM 역할을 만듭니다.
2. AWS Directory Service를 AWS Organizations와 함께 사용하면 필요한 IAM 역할을 Microsoft Active Directory 사용자와 자동으로 연결할 수 있습니다.
3. AWS Organizations와 함께 AWS Resource Access Manager를 사용하면 AWS 계정 간에 공유 리소스를 배포하고 관리할 수 있습니다.
4. AWS CloudFormation StackSets를 AWS Organizations와 함께 사용하여 AWS 계정에 대한 IAM 역할을 배포하고 관리합니다.

가장 운영 효율적인 솔루션은 다음과 같습니다:

**4. AWS CloudFormation StackSets를 AWS Organizations와 함께 사용하여 AWS 계정에 대한 IAM 역할을 배포하고 관리합니다.**

### 이유:
- **자동화 및 일관성**: AWS CloudFormation StackSets를 사용하면 하나의 CloudFormation 템플릿을 여러 AWS 계정과 리전에 걸쳐 배포할 수 있습니다. 이를 통해 IAM 역할을 일관되게 생성하고 관리할 수 있습니다.
- **편리한 업데이트**: StackSets를 사용하면 템플릿을 업데이트할 때 모든 관련 계정에서 변경 사항을 쉽게 적용할 수 있습니다.
- **조직 관리**: AWS Organizations와 통합되어, 여러 계정을 효율적으로 관리하고 자동화된 방식으로 IAM 역할을 배포할 수 있습니다.

### 선택하지 않아야 하는 옵션:
1. **AWS CloudFormation 템플릿을 만듭니다. 템플릿을 재사용하여 각 AWS 계정에서 필요한 IAM 역할을 만듭니다.**  
   - 이 방법은 수동으로 각 계정에 템플릿을 배포해야 하므로 자동화된 솔루션이 아닙니다.

2. **AWS Directory Service를 AWS Organizations와 함께 사용하면 필요한 IAM 역할을 Microsoft Active Directory 사용자와 자동으로 연결할 수 있습니다.**  
   - 이 방법은 IAM 역할을 관리하기 위한 것이 아니라 Active Directory와의 통합에 중점을 두고 있습니다.

3. **AWS Organizations와 함께 AWS Resource Access Manager를 사용하면 AWS 계정 간에 공유 리소스를 배포하고 관리할 수 있습니다.**  
   - Resource Access Manager는 리소스를 공유하는 데 사용되며 IAM 역할의 생성 및 관리를 위한 솔루션은 아닙니다.

따라서, **AWS CloudFormation StackSets**를 사용하는 것이 요구 사항을 충족하고 운영 효율성을 극대화하는 가장 적합한 방법입니다.


## 질문: 142
SysOps 관리자는 Amazon RDS 데이터베이스 자격 증명에 대한 자동 로테이션을 구성해야 합니다. 

자격 증명은 30일마다 로테이션해야 합니다. 솔루션은 Amazon RDS와 통합되어야 합니다.

어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할까요?

1. 자격 증명을 AWS Systems Manager Parameter Store에 보안 문자열로 저장합니다. 30일의 로테이션 간격으로 자동 로테이션을 구성합니다.
2. AWS Secrets Manager에 자격 증명을 저장합니다. 30일의 로테이션 간격으로 자동 로테이션을 구성합니다.
3. 자격 증명을 Amazon S3 버킷의 파일에 저장합니다. AWS Lambda 함수를 배포하여 30일마다 자격 증명을 자동으로 회전합니다.
4. AWS Secrets Manager에 자격 증명을 저장합니다. AWS Lambda 함수를 배포하여 30일마다 자격 증명을 자동으로 회전합니다.

가장 적은 운영 오버헤드로 Amazon RDS 데이터베이스 자격 증명을 자동 로테이션하는 솔루션은 다음과 같습니다:

**2. AWS Secrets Manager에 자격 증명을 저장합니다. 30일의 로테이션 간격으로 자동 로테이션을 구성합니다.**

이 옵션은 AWS Secrets Manager가 제공하는 내장된 자동 로테이션 기능을 활용하며, RDS와의 통합이 원활하여 운영 관리를 최소화할 수 있습니다. 

다른 옵션에 비해 추가적인 Lambda 함수를 배포하거나 다른 스토리지 솔루션을 설정할 필요가 없기 때문에 가장 운영적으로 효율적입니다.

## 질문: 143
회사의 SysOps 관리자가 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 복원하려고 시도합니다. 

그러나 다른 시스템 관리자가 실수로 스냅샷을 삭제했기 때문에 스냅샷이 없습니다. 회사는 스냅샷이 삭제된 후 지정된 기간 동안 스냅샷을 복구할 수 있는 기능이 필요합니다.

어떤 솔루션이 이 기능을 제공할까요?

1. 보관해야 하는 개별 EBS 스냅샷에 대해 삭제 보호를 켜세요.
2. 스냅샷 연령에 대한 조건문을 사용하여 EBS 스냅샷 삭제를 거부하는 IAM 정책을 만듭니다. 모든 사용자에게 정책을 적용합니다.
3. 원하는 보관 기간 동안 EBS 스냅샷에 대한 휴지통 보관 규칙을 만듭니다.
4. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 예약하여 EBS 스냅샷을 Amazon S3 Glacier로 복사합니다.
 
스냅샷이 삭제된 후 지정된 기간 동안 복구할 수 있는 기능을 제공하는 가장 적합한 솔루션은 다음과 같습니다:

**3. 원하는 보관 기간 동안 EBS 스냅샷에 대한 휴지통 보관 규칙을 만듭니다.**

이 옵션은 AWS Backup의 기능을 활용하여 삭제된 EBS 스냅샷을 자동으로 보관하고 복구할 수 있게 합니다. 휴지통 보관 규칙을 설정하면 지정된 기간 동안 스냅샷을 복구할 수 있는 기능이 제공됩니다. 

기타 옵션은 스냅샷 보호 또는 삭제 방지와 관련이 있지만, 실제로 삭제된 스냅샷을 복구할 수 있는 기능을 제공하지는 않습니다.



## 질문: 144
SysOps 관리자가 최근 S3 버킷에서 Amazon S3 Cross-Region Replication을 구성했습니다.

이 기능은 기본적으로 대상 S3 버킷에 다음 중 어느 것을 복제합니까?

1. 버킷 소유자에게 권한이 없는 소스 S3 버킷의 개체
2. S3 Glacier에 저장된 객체
3. 복제가 구성되기 전에 존재했던 개체
4. 객체 메타데이터


Amazon S3 Cross-Region Replication (CRR)은 S3 버킷에서 객체를 자동으로 다른 AWS 리전의 S3 버킷으로 복제하는 기능입니다. CRR을 사용할 때, 기본적으로 대상 S3 버킷에 복제되는 것은 다음과 같습니다:

**4. 객체 메타데이터**

CRR은 객체와 해당 메타데이터(예: 태그 및 ACL)를 복제하지만, 복제가 설정되기 전에 존재했던 객체는 복제되지 않으며, Glacier에 저장된 객체는 복제되지 않습니다. 또한, 버킷 소유자에게 권한이 없는 소스 S3 버킷의 개체도 복제되지 않습니다.


## 질문: 145
회사에 Amazon CloudWatch Logs로 로그 데이터를 보내는 작업 부하가 있습니다. 

필드 중 하나에 애플리케이션 지연 시간 측정이 포함됩니다. SysOps 관리자는 시간 경과에 따라 이 필드의 p90 통계를 모니터링해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. 로그 데이터에 대한 Amazon CloudWatch Contributor Insights 규칙을 만듭니다.
2. 로그 데이터에 대한 메트릭 필터를 만듭니다.
3. 로그 데이터에 대한 구독 필터를 만듭니다.
4. 워크로드에 대한 Amazon CloudWatch Application Insights 규칙을 만듭니다.

SysOps 관리자가 애플리케이션 지연 시간 측정에 대한 p90 통계를 모니터링해야 하는 경우 가장 적합한 방법은 **2. 로그 데이터에 대한 메트릭 필터를 만듭니다.**입니다.

### 이유:
- **메트릭 필터**는 CloudWatch Logs에서 특정 패턴을 찾아내어 메트릭을 생성할 수 있는 방법입니다. 이를 통해 애플리케이션의 지연 시간 측정값을 추출하고, p90 같은 통계를 CloudWatch에서 직접 모니터링할 수 있습니다.
- 메트릭 필터를 설정하면 해당 지연 시간 데이터가 CloudWatch에서 메트릭으로 집계되어 그래프화하거나 알림을 설정하는 데 사용할 수 있습니다.

### 다른 옵션들에 대한 설명:
1. **Amazon CloudWatch Contributor Insights 규칙**: 주로 로그의 기여도를 분석하는 데 사용되며, 특정 메트릭(p90 등)을 직접적으로 모니터링하기 위한 것은 아닙니다.
2. **구독 필터**: 로그 데이터를 다른 AWS 서비스로 전송하는 데 사용되며, 메트릭을 수집하거나 통계를 직접적으로 생성하는 데는 적합하지 않습니다.
3. **Amazon CloudWatch Application Insights 규칙**: 애플리케이션 성능 모니터링 및 문제 감지에 유용하지만, 특정 로그 데이터에 대한 메트릭 필터링은 아닙니다.

결론적으로, p90 통계를 효과적으로 모니터링하기 위해서는 **로그 데이터에 대한 메트릭 필터를 만드는 것이 가장 효율적입니다.**



## 질문: 146
어떤 회사가 Amazon S3 Glacier에 민감한 데이터를 보관하려고 합니다. 

회사의 규제 및 규정 준수 요구 사항은 어떤 계정에서도 데이터를 수정하는 것을 허용하지 않습니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

1. 보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 후에 볼트 잠금 정책을 검증합니다.
2. 보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 이내에 볼트 잠금 정책을 검증합니다.
3. 거버넌스 모드에서 S3 객체 잠금을 구성합니다. 24시간 후에 모든 파일을 업로드합니다.
4. 거버넌스 모드에서 S3 객체 잠금을 구성합니다. 모든 파일을 24시간 이내에 업로드합니다.

회사가 Amazon S3 Glacier에 민감한 데이터를 보관하면서 수정하는 것을 허용하지 않으려면, 가장 적합한 솔루션은 **2. 보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 이내에 볼트 잠금 정책을 검증합니다.**입니다.

### 이유:
- **S3 Glacier 볼트 잠금**은 규제 준수 요구 사항을 충족하기 위해 볼트의 데이터가 변경되거나 삭제되지 않도록 보호하는 기능입니다. 볼트 잠금 정책을 설정하면 볼트를 수정할 수 없게 되며, 이로 인해 데이터 무결성을 유지할 수 있습니다.
- **잠금 ID를 사용하여 24시간 이내에 볼트 잠금 정책을 검증**하는 것은 데이터에 대한 변경이 불가능하도록 보장하며, 즉시 적용될 수 있습니다.

### 다른 옵션들에 대한 설명:
1. **보관된 데이터가 포함된 S3 Glacier 볼트에 볼트 잠금 정책을 연결합니다. 잠금 ID를 사용하여 24시간 후에 볼트 잠금 정책을 검증합니다.**
   - 이 옵션은 잠금 정책이 적용되기까지의 시간이 지연되므로, 데이터 수정이 허용되는 시간이 생깁니다.

3. **거버넌스 모드에서 S3 객체 잠금을 구성합니다. 24시간 후에 모든 파일을 업로드합니다.**
   - 거버넌스 모드는 특정 사용자에게 객체를 삭제할 수 있는 권한을 부여하는데, 이 옵션은 수정이 허용되는 시점을 만들 수 있습니다.

4. **거버넌스 모드에서 S3 객체 잠금을 구성합니다. 모든 파일을 24시간 이내에 업로드합니다.**
   - 이 옵션도 마찬가지로 수정이 허용되는 시점을 만들 수 있습니다.

결론적으로, S3 Glacier의 **볼트 잠금을 설정하고 24시간 이내에 검증하는** 것이 회사의 규제 및 규정 준수 요구 사항을 가장 효과적으로 충족하는 방법입니다.


## 질문: 147
한 회사가 두 개의 다른 가용성 영역에 걸쳐 분산된 두 개의 초대형 노드가 있는 Amazon ElastiCache for Redis를 사용하는 애플리케이션을 관리합니다. 

회사의 IT 팀은 ElastiCache for Redis 클러스터에 75%의 사용 가능한 메모리가 있다는 것을 발견했습니다. 애플리케이션은 높은 가용성을 유지해야 합니다.

클러스터 크기를 조정하는 가장 비용 효율적인 방법은 무엇입니까?

1. Redis 클러스터용 ElastiCache의 노드 수를 2개에서 1개로 줄입니다.
2. 대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 새 클러스터로 데이터를 마이그레이션합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.
3. 대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 백업을 가져오고 새 클러스터에서 백업을 복원합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.
4. ElastiCache for Redis 클러스터에 대한 온라인 크기 조정을 수행합니다. 노드 유형을 초대형 노드에서 대형 노드로 변경합니다.

Amazon ElastiCache for Redis의 클러스터 크기를 조정하여 비용 효율성을 유지하면서 높은 가용성을 보장하려면 **4. ElastiCache for Redis 클러스터에 대한 온라인 크기 조정을 수행합니다. 노드 유형을 초대형 노드에서 대형 노드로 변경합니다.**라는 옵션이 가장 적합합니다.

### 이유:
- **온라인 크기 조정**을 통해 애플리케이션의 가용성을 유지하면서 즉시 리소스를 조정할 수 있습니다. 이 과정에서 클러스터가 중단되지 않으므로 애플리케이션이 지속적으로 사용할 수 있습니다.
- **비용 효율성**: 초대형 노드에서 대형 노드로 변경함으로써 메모리 비용을 절감할 수 있습니다. 이는 불필요한 리소스를 줄이는 데 도움이 됩니다.

### 다른 옵션들에 대한 설명:
1. **Redis 클러스터용 ElastiCache의 노드 수를 2개에서 1개로 줄입니다.**
   - 이 옵션은 높은 가용성을 떨어뜨리며, 장애 발생 시 클러스터의 가용성이 크게 저하됩니다.

2. **대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 새 클러스터로 데이터를 마이그레이션합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.**
   - 데이터 마이그레이션은 시간이 걸리며, 이 기간 동안 애플리케이션의 가용성이 영향을 받을 수 있습니다. 이 과정도 비용이 추가될 수 있습니다.

3. **대규모 노드 유형을 사용하는 새로운 ElastiCache for Redis 클러스터를 배포합니다. 원래 클러스터에서 백업을 가져오고 새 클러스터에서 백업을 복원합니다. 프로세스가 완료되면 원래 클러스터를 종료합니다.**
   - 이 방법 역시 가용성에 영향을 미칠 수 있으며, 전체적인 프로세스가 복잡하고 시간이 소요될 수 있습니다.

결론적으로, **온라인 크기 조정을 통해 리소스를 조정하는 것이** 높은 가용성을 유지하면서 비용 효율적으로 클러스터를 조정하는 최선의 방법입니다.




## 질문: 148
회사는 애플리케이션을 AWS로 마이그레이션해야 합니다. 

이 회사는 구성 관리를 위해 Chef 레시피를 사용하고 있습니다. 이 회사는 애플리케이션을 AWS로 마이그레이션한 후에도 기존 Chef 레시피를 계속 사용하고 싶어합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. AWS CloudFormation을 사용하여 Amazon EC2 인스턴스를 생성하고, Chef 서버를 설치하고, Chef 레시피를 추가합니다.
2. AWS CloudFormation을 사용하여 스택을 만들고 Chef 레시피에 대한 계층을 추가합니다.
3. Docker 플랫폼과 함께 AWS Elastic Beanstalk를 사용하여 Chef 레시피를 업로드합니다.
4. AWS OpsWorks를 사용하여 스택을 만들고 Chef 레시피로 레이어를 추가합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 **4. AWS OpsWorks를 사용하여 스택을 만들고 Chef 레시피로 레이어를 추가합니다.** 입니다. 

AWS OpsWorks는 Chef를 지원하며, Chef 레시피를 사용하여 애플리케이션과 인프라를 관리하는 데 최적화되어 있습니다. 이 솔루션은 기존 Chef 레시피를 쉽게 통합하고 관리할 수 있게 해주어 마이그레이션 후에도 효율적으로 구성 관리를 수행할 수 있습니다.



## 질문: 149
한 회사가 AWS Organizations를 사용하여 AWS 계정을 관리합니다. 

SysOps 관리자는 회사의 모든 AWS 계정에서 모든 Amazon EC2 인스턴스에 대한 백업 전략을 만들어야 합니다.

어떤 솔루션이 가장 운영 효율적인 방식으로 이러한 요구 사항을 충족할까요?

1. 각 계정에 AWS Lambda 함수를 배포하여 예약된 기준으로 EC2 인스턴스 스냅샷을 실행합니다.
2. 관리 계정에 AWS CloudFormation 스택 세트를 생성하여 모든 EC2 인스턴스에 AutoBackup=True 태그를 추가합니다.
3. 관리 계정에서 AWS Backup을 사용하여 모든 계정과 리소스에 대한 정책을 배포합니다.
4. SCP(서비스 제어 정책)를 사용하여 각 계정에서 예약된 기준으로 EC2 인스턴스 스냅샷을 실행합니다.

가장 운영 효율적인 방식으로 모든 AWS 계정에서 Amazon EC2 인스턴스에 대한 백업 전략을 만드는 솔루션은 **3. 관리 계정에서 AWS Backup을 사용하여 모든 계정과 리소스에 대한 정책을 배포합니다.**입니다.

AWS Backup은 여러 AWS 계정과 리전에서 백업 정책을 중앙 집중식으로 관리하고 자동화할 수 있는 기능을 제공합니다. 이를 통해 SysOps 관리자는 효율적으로 모든 EC2 인스턴스의 백업을 관리하고, 일관된 정책을 적용하며, 운영 오버헤드를 최소화할 수 있습니다.



## 질문: 150
SysOps 관리자가 VPC의 연결 문제를 해결하기 위해 VPC Flow Logs를 검토하고 있습니다. 

SysOps 관리자는 로그를 검토하는 동안 거부된 트래픽이 나열되지 않은 것을 알아차렸습니다.

SysOps 관리자는 모든 트래픽이 기록되도록 하기 위해 무엇을 해야 합니까?

1. 모든 트래픽을 캡처하기 위한 필터 설정이 있는 새로운 흐름 로그를 만듭니다.
2. 새 흐름 로그를 만듭니다. 로그 레코드 형식을 사용자 지정 형식으로 설정합니다. 로그에 포함할 적절한 필드를 선택합니다.
3. 기존 흐름 로그를 편집합니다. 모든 트래픽을 캡처하도록 필터 설정을 변경합니다.
4. 기존 흐름 로그를 편집합니다. 로그 레코드 형식을 사용자 지정 형식으로 설정합니다. 로그에 포함할 적절한 필드를 선택합니다.

SysOps 관리자가 VPC Flow Logs에서 모든 트래픽(수락 및 거부된 트래픽)을 기록하도록 하려면 **3. 기존 흐름 로그를 편집합니다. 모든 트래픽을 캡처하도록 필터 설정을 변경합니다.**를 선택해야 합니다.

이 방법을 통해 기존 흐름 로그의 필터를 수정하여 거부된 트래픽을 포함한 모든 트래픽을 기록할 수 있습니다. 새로운 흐름 로그를 만들 필요 없이 효율적으로 문제를 해결할 수 있는 방법입니다.


## 질문: 151
한 회사가 포트폴리오 전반에 걸쳐 AWS 서비스 사용을 확대하고 있습니다. 

이 회사는 보안, 규정 준수 및 청구를 위한 비즈니스 프로세스의 분리를 보장하기 위해 각 팀에 AWS 계정을 프로비저닝하려고 합니다. 계정 생성 및 부트스트래핑은 확장 가능하고 효율적인 방식으로 완료되어야 하며, 정의된 기준선과 거버넌스 가드레일이 있는 새 계정이 생성되어야 합니다. SysOps 관리자는 시간과 리소스를 절약하는 프로비저닝 프로세스를 설계해야 합니다.

이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1. AWS Elastic Beanstalk를 사용하여 AWS 계정을 프로비저닝하고, 인프라를 설정하고, AWS Organizations와 통합하는 작업을 자동화합니다.
2. AWS OpsWorks에서 부트스트래핑 스크립트를 만들고 이를 AWS CloudFormation 템플릿과 결합하여 계정과 인프라를 프로비저닝합니다.
3. AWS Config를 사용하면 AWS Service Catalog를 통해 계정을 프로비저닝하고 인스턴스를 배포할 수 있습니다.
4. AWS Control Tower를 사용하여 Account Factory에서 템플릿을 만들고 해당 템플릿을 사용하여 새로운 계정을 프로비저닝합니다.


정답은 **4. AWS Control Tower를 사용하여 Account Factory에서 템플릿을 만들고 해당 템플릿을 사용하여 새로운 계정을 프로비저닝합니다.**입니다.

### 이유:
AWS Control Tower는 다중 AWS 계정을 중앙에서 관리할 수 있는 솔루션으로, 다음과 같은 이점이 있습니다:

1. **자동화된 계정 프로비저닝**: Control Tower는 Account Factory 기능을 통해 표준화된 방식으로 새로운 계정을 쉽게 생성할 수 있습니다. 각 계정은 미리 정의된 템플릿을 기반으로 생성되어 보안과 규정 준수 요구 사항을 충족합니다.

2. **거버넌스 가드레일**: Control Tower는 조직의 규정 준수 및 보안 요구 사항을 만족시키기 위한 정책을 자동으로 적용합니다. 이를 통해 새로 생성된 계정이 정의된 기준선에 따라 운영되도록 보장할 수 있습니다.

3. **확장성**: 새로운 팀이나 부서가 필요할 때마다 기존 프로세스를 반복할 필요 없이, 미리 설정된 템플릿을 사용하여 손쉽게 계정을 추가할 수 있습니다.

### 다른 옵션에 대한 설명:

1. **AWS Elastic Beanstalk**:
   - **설명**: Beanstalk는 애플리케이션을 배포하고 관리하기 위한 서비스로, AWS 계정 생성이나 관리 기능은 없습니다.
   - **적합성**: 계정 프로비저닝에는 적합하지 않습니다.

2. **AWS OpsWorks**:
   - **설명**: OpsWorks는 Chef 또는 Puppet을 사용하여 인프라를 관리하지만, 계정 프로비저닝을 위한 기능이 없습니다.
   - **적합성**: 이 솔루션은 계정 생성과 관련된 요구 사항을 충족하지 못합니다.

3. **AWS Config 및 AWS Service Catalog**:
   - **설명**: Config는 리소스의 상태를 추적하고, Service Catalog는 IT 서비스를 관리하는 데 사용되지만, 직접적인 계정 프로비저닝 기능이 없습니다.
   - **적합성**: 계정 생성을 위한 효율적인 방법이 아닙니다.

### 결론:
AWS Control Tower는 요구 사항을 충족하는 가장 적합하고 효율적인 솔루션으로, 보안 및 규정 준수를 유지하면서도 확장 가능한 계정 프로비저닝 프로세스를 지원합니다.




## 질문: 152
SysOps 관리자가 Amazon CloudFront 배포판의 캐시 적중률이 10% 미만임을 알아챘습니다.

어떤 구성 변경 모음이 배포판의 캐시 적중률을 증가시킬까요? (두 가지를 선택하세요.)

1. 캐시 동작 설정에서 필요한 쿠키, 쿼리 문자열, 헤더만 전달되는지 확인하세요.
2. HTTPS만 사용하도록 뷰어 프로토콜 정책을 변경합니다.
3. 사전 서명된 쿠키와 URL을 사용하여 배포판에 대한 액세스를 제한하도록 배포판을 구성합니다.
4. 캐시 동작 설정에서 객체의 자동 압축을 활성화합니다.
5. 캐시 동작 설정에서 CloudFront TTL(수명) 설정을 늘립니다.

캐시 적중률을 증가시키기 위해 선택할 수 있는 두 가지 구성 변경은 다음과 같습니다:

1. **캐시 동작 설정에서 필요한 쿠키, 쿼리 문자열, 헤더만 전달되는지 확인하세요.**
   - **이유**: CloudFront는 기본적으로 모든 요청의 모든 쿠키, 쿼리 문자열, 헤더를 전달하면 캐시가 더 많은 변형을 생성합니다. 필요한 것만 전달하도록 설정하면, 더 많은 요청이 캐시된 객체를 반환하게 되어 캐시 적중률이 증가합니다.

5. **캐시 동작 설정에서 CloudFront TTL(수명) 설정을 늘립니다.**
   - **이유**: TTL(시간 제한)은 캐시된 객체가 얼마나 오래 유효한지를 결정합니다. TTL을 늘리면 캐시된 객체가 더 오랫동안 유지되어, 더 많은 요청이 캐시에서 처리되므로 캐시 적중률이 높아질 수 있습니다.

### 다른 옵션들에 대한 설명:

2. **HTTPS만 사용하도록 뷰어 프로토콜 정책을 변경합니다.**
   - **설명**: HTTPS를 사용하는 것은 보안과 관련된 설정이며, 캐시 적중률에는 큰 영향을 미치지 않습니다.

3. **사전 서명된 쿠키와 URL을 사용하여 배포판에 대한 액세스를 제한하도록 배포판을 구성합니다.**
   - **설명**: 사전 서명된 쿠키와 URL은 접근 제어와 관련된 설정으로, 캐시 적중률과는 직접적인 관련이 없습니다.

4. **캐시 동작 설정에서 객체의 자동 압축을 활성화합니다.**
   - **설명**: 자동 압축은 전송 성능을 개선할 수 있지만, 캐시 적중률에 직접적인 영향을 미치지는 않습니다. 오히려 데이터 크기를 줄여 전송 속도를 높이는 데 도움이 됩니다.

결론적으로, 캐시 동작 설정에서 쿠키, 쿼리 문자열, 헤더를 최소한으로 전달하고 TTL을 늘리는 것이 캐시 적중률을 높이는 데 가장 효과적입니다.

## 질문: 153
SysOps 관리자가 인터넷에서 개인 서브넷의 인스턴스로 패치를 다운로드하려고 합니다.

VPC에 대한 인터넷 게이트웨이가 있고 NAT 게이트웨이가 공개 서브넷에 배포되었지만 인스턴스에 인터넷 연결이 없습니다.개인 서브넷에 배포된 리소스는 공개 인터넷에서 직접 액세스할 수 없어야 합니다.

공개 서브넷(10.0.1.0/24) 경로 테이블
대상
10.0.0.0/16 로컬
0.0.0.0/0 IGW

개인 서브넷(10.0.2.0/24) 경로 테이블
대상
10.0.0.0/16 로컬

제공된 정보를 고려할 때, 이 문제를 해결하기 위해 개인 서브넷의 경로 테이블에 무엇을 추가해야 합니까?

1. 0.0.0.0/0 IGW
2. 0.0.0.0/0 NAT
3. 10.0.1.0/24 IGW
4. 10.0.1.0/24 NAT

개인 서브넷의 인스턴스가 인터넷에서 패치를 다운로드할 수 있도록 하려면 NAT 게이트웨이를 통해 인터넷에 액세스할 수 있도록 개인 서브넷의 경로 테이블에 경로를 추가해야 합니다.

### 추가해야 할 경로:

- **대상:** `0.0.0.0/0`
- **대상:** NAT 게이트웨이의 ID (예: `nat-xxxxxxxx`)

### 설명:

1. **0.0.0.0/0 경로**: 이 경로는 모든 외부 IP 주소에 대한 트래픽을 처리하도록 지정합니다. 
2. **NAT 게이트웨이**: 이 경로는 인터넷으로 나가는 트래픽이 NAT 게이트웨이를 통해 처리되도록 합니다. NAT 게이트웨이는 개인 서브넷에서 발생하는 요청을 인터넷으로 라우팅하고, 그 응답을 다시 개인 서브넷으로 전달할 수 있게 합니다.

### 최종적으로 개인 서브넷의 경로 테이블은 다음과 같아야 합니다:

| 대상        | 대상                     |
|------------|------------------------|
| 10.0.0.0/16 | 로컬                   |
| 0.0.0.0/0   | NAT 게이트웨이 ID (nat-xxxxxxxx) |

이렇게 설정하면 개인 서브넷의 인스턴스가 NAT 게이트웨이를 통해 인터넷에 패치를 다운로드할 수 있게 됩니다.



## 질문: 154
한 회사가 AWS에서 전적으로 실행되는 시스템에 대한 외부 감사를 받고 있습니다. 

SysOps 관리자는 AWS에서 관리하는 인프라에 대한 PCI DSS(Payment Card Industry Data Security Standard) 준수에 대한 문서를 제공해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1. AWS Artifact 포털에서 해당 보고서를 다운로드하여 감사자에게 제공합니다.
2. AWS CloudTrail 로그 파일의 전체 사본을 다운로드하여 감사자에게 제공합니다.
3. AWS CloudWatch 로그의 전체 사본을 다운로드하여 감사자에게 제공합니다.
4. 감사자에게 프로덕션 AWS 계정에 대한 관리 액세스 권한을 제공하여 감사자가 규정 준수 여부를 확인할 수 있도록 합니다. 


SysOps 관리자가 PCI DSS 준수에 대한 문서를 제공하기 위해 가장 적절한 조치는 **1. AWS Artifact 포털에서 해당 보고서를 다운로드하여 감사자에게 제공합니다.**입니다.

### 이유:

1. **AWS Artifact**는 AWS가 특정 보안 및 규정 준수 표준에 대한 준수 보고서 및 인증서를 제공하는 서비스입니다. PCI DSS 보고서와 같은 공식 보고서를 다운로드하여 감사자에게 제공함으로써, AWS에서 관리하는 인프라가 PCI DSS 요구 사항을 충족한다는 것을 입증할 수 있습니다.

2. **기타 옵션들**:
   - **2. AWS CloudTrail 로그 파일의 전체 사본을 다운로드하여 감사자에게 제공합니다.**: CloudTrail 로그는 모든 API 호출을 기록하지만, PCI DSS 준수 여부를 직접적으로 입증하는 데 필요한 문서가 아닙니다.
   - **3. AWS CloudWatch 로그의 전체 사본을 다운로드하여 감사자에게 제공합니다.**: CloudWatch 로그는 모니터링 및 운영 데이터를 포함하지만, PCI DSS 준수를 직접적으로 나타내는 문서가 아닙니다.
   - **4. 감사자에게 프로덕션 AWS 계정에 대한 관리 액세스 권한을 제공하여 감사자가 규정 준수 여부를 확인할 수 있도록 합니다.**: 이는 보안 및 규정 준수 요구 사항을 위험에 빠뜨릴 수 있으며, 감사자에게 직접적인 액세스를 부여하는 것은 일반적으로 권장되지 않습니다.

따라서, AWS Artifact 포털에서 PCI DSS 관련 보고서를 다운로드하여 제공하는 것이 가장 안전하고 적절한 접근 방식입니다.




## 질문: 155
한 회사가 Amazon EC2 및 AWS Lambda와 관련된 비용을 줄이기 위한 이니셔티브를 가지고 있습니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1. Amazon Athena를 사용하여 AWS 비용 및 사용 보고서를 분석하여 비용 절감 방안을 파악합니다.
2. 계정 지출이 예산의 80%에 도달하면 알림을 보내는 AWS Budgets 알림을 만듭니다.
3. Amazon EC2 콘솔을 통해 예약 인스턴스를 구매하세요.
4. AWS Compute Optimizer를 사용하여 제공된 권장 사항에 따라 조치를 취하세요.

SysOps 관리자가 Amazon EC2 및 AWS Lambda와 관련된 비용을 줄이기 위한 가장 적절한 조치는 **4. AWS Compute Optimizer를 사용하여 제공된 권장 사항에 따라 조치를 취하세요.**입니다.

### 이유:

1. **AWS Compute Optimizer**는 현재 사용 중인 리소스의 사용 패턴을 분석하고, 보다 비용 효율적인 인스턴스 유형이나 크기로의 변경을 권장하여 비용 절감을 도와줍니다. EC2 인스턴스와 Lambda 함수의 사용 패턴을 기반으로 최적의 리소스를 추천받을 수 있습니다.

2. **기타 옵션들**:
   - **1. Amazon Athena를 사용하여 AWS 비용 및 사용 보고서를 분석하여 비용 절감 방안을 파악합니다.**: Athena를 사용하여 데이터를 분석하는 것은 유용하지만, 비용 절감을 위한 직접적인 조치를 제공하지는 않습니다.
   - **2. 계정 지출이 예산의 80%에 도달하면 알림을 보내는 AWS Budgets 알림을 만듭니다.**: 예산 알림은 비용을 모니터링하는 데 유용하지만, 비용 절감 조치를 자동으로 제공하지는 않습니다.
   - **3. Amazon EC2 콘솔을 통해 예약 인스턴스를 구매하세요.**: 예약 인스턴스는 장기적으로 비용 절감을 제공하지만, 사용량을 최적화하는 데 필요한 분석을 제공하지 않으므로, 단기적으로는 더 좋은 선택이 아닐 수 있습니다.

따라서, **AWS Compute Optimizer**를 활용하는 것이 EC2 및 Lambda의 비용을 효과적으로 줄이는 가장 직접적이고 실행 가능한 방법입니다.




## 질문: 156
어떤 회사는 모든 Amazon EC2 인스턴스에 IPv6만 사용하고 싶어합니다.

EC2 인스턴스는 인터넷에서 액세스할 수 없어야 하지만, EC2 인스턴스는 인터넷에 액세스할 수 있어야 합니다. 이 회사는 듀얼 스택 VPC와 IPv6 전용 서브넷을 만듭니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 VPC를 어떻게 구성해야 합니까?

1. NAT 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 NAT 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
2. 인터넷 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 인터넷 게이트웨이로 가리키는 엔트리를 포함하는 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
3. 이탈 전용 인터넷 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 이탈 전용 인터넷 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
4. 인터넷 게이트웨이와 NAT 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 인터넷 게이트웨이로, 모든 IPv4 트래픽을 NAT 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.
 


이 회사의 요구 사항을 충족하기 위해 VPC를 구성하는 가장 적절한 방법은 **1. NAT 게이트웨이를 만들고 연결합니다. 모든 IPv6 트래픽을 NAT 게이트웨이로 가리키는 항목이 포함된 사용자 지정 경로 테이블을 만듭니다. 사용자 지정 경로 테이블을 IPv6 전용 서브넷에 연결합니다.**입니다.

### 이유:

1. **IPv6 전용 서브넷**: EC2 인스턴스가 IPv6만 사용하도록 구성된 경우, 이 인스턴스들은 공용 인터넷에 직접 노출되지 않아야 합니다. 따라서 인터넷 게이트웨이를 사용하는 것이 아니라 NAT 게이트웨이를 사용해야 합니다.

2. **NAT 게이트웨이의 역할**: NAT 게이트웨이는 내부 네트워크에서 인터넷으로의 아웃바운드 트래픽을 가능하게 해줍니다. 따라서 EC2 인스턴스가 인터넷에 액세스할 수 있지만 외부에서 직접 접근할 수 없는 구조를 유지할 수 있습니다.

3. **사용자 지정 경로 테이블**: 사용자 지정 경로 테이블을 사용하여 모든 IPv6 트래픽을 NAT 게이트웨이로 향하도록 설정하면, EC2 인스턴스가 인터넷에 연결할 수 있습니다.

### 기타 옵션들에 대한 설명:

- **2. 인터넷 게이트웨이를 만들고 연결합니다**: 이 경우 인스턴스가 인터넷에서 직접 접근 가능하게 되므로 요구 사항을 충족하지 않습니다.
  
- **3. 이탈 전용 인터넷 게이트웨이를 만들고 연결합니다**: "이탈 전용 인터넷 게이트웨이"는 존재하지 않는 개념입니다. 이 옵션은 잘못된 선택입니다.
  
- **4. 인터넷 게이트웨이와 NAT 게이트웨이를 만들고 연결합니다**: 이 경우, 인터넷 게이트웨이가 추가되어 EC2 인스턴스가 외부에서 접근 가능해져 요구 사항을 충족하지 않습니다.

결론적으로, **NAT 게이트웨이를 사용하는 것이 가장 안전하고 요구 사항에 부합하는 방법**입니다.



## 질문: 157
한 회사에는 두 개의 가용성 영역에 걸쳐 애플리케이션 로드 밸런서(ALB) 뒤에 있는 두 개의 Amazon EC2 인스턴스에서 실행되는 기존 웹 애플리케이션이 있습니다. 

이 애플리케이션은 Amazon RDS Multi-AZ DB 인스턴스를 사용합니다. Amazon Route 53 레코드 세트는 동적 콘텐츠에 대한 요청을 로드 밸런서로 라우팅하고 정적 콘텐츠에 대한 요청을 Amazon S3 버킷으로 라우팅합니다. 사이트 방문자는 로딩 시간이 매우 길다고 보고합니다.

웹사이트 성능을 개선하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하세요.)

1. 정적 콘텐츠에 대한 Amazon CloudFront 캐싱을 추가합니다.
2. 로드 밸런서 리스너를 HTTPS에서 TCP로 변경합니다.
3. Amazon Route 53 지연 기반 라우팅을 활성화합니다.
4. 웹 서버에 Amazon EC2 자동 확장을 구현합니다.
5. 정적 콘텐츠를 Amazon S3에서 웹 서버로 옮깁니다.

웹사이트 성능을 개선하기 위해 선택할 수 있는 두 가지 조치는 다음과 같습니다:

1. **정적 콘텐츠에 대한 Amazon CloudFront 캐싱을 추가합니다.**
   - Amazon CloudFront는 콘텐츠 전송 네트워크(CDN)로, 정적 콘텐츠를 Edge 위치에서 캐싱하여 사용자에게 더 가까운 위치에서 제공할 수 있습니다. 이를 통해 정적 콘텐츠의 로딩 시간을 단축하고 전체 웹사이트 성능을 향상시킬 수 있습니다.

4. **웹 서버에 Amazon EC2 자동 확장을 구현합니다.**
   - EC2 자동 확장은 트래픽 증가에 따라 EC2 인스턴스를 자동으로 추가하거나 제거하여 웹 서버의 용량을 조정할 수 있습니다. 이를 통해 사용자 요청을 보다 효율적으로 처리하고 로딩 시간을 개선할 수 있습니다.

### 기타 옵션들에 대한 설명:

2. **로드 밸런서 리스너를 HTTPS에서 TCP로 변경합니다.**
   - HTTPS를 TCP로 변경하면 보안 연결이 제거되며, 이는 사용자 데이터의 안전성을 저하시킬 수 있습니다. HTTPS를 유지하면서 성능을 개선하는 것이 더 적절합니다.

3. **Amazon Route 53 지연 기반 라우팅을 활성화합니다.**
   - 지연 기반 라우팅은 사용자와 가장 가까운 리전의 리소스를 사용하도록 하지만, 이미 ALB와 RDS를 사용하고 있으므로 이 옵션이 웹사이트의 성능을 크게 개선할 것이라고 보장할 수는 없습니다.

5. **정적 콘텐츠를 Amazon S3에서 웹 서버로 옮깁니다.**
   - 이는 정적 콘텐츠를 S3의 장점을 활용하지 못하게 하며, 오히려 성능을 저하시킬 수 있습니다. S3는 정적 콘텐츠 제공에 최적화되어 있으므로 S3에 두는 것이 더 좋습니다.

결론적으로, **CloudFront를 사용하여 정적 콘텐츠를 캐싱하고, EC2 자동 확장을 통해 트래픽을 처리하는** 것이 웹사이트 성능을 개선하는 가장 효과적인 방법입니다.



## 질문: 158
한 회사가 온프레미스에서 애플리케이션을 실행하고 있으며 데이터 백업에 AWS를 사용하려고 합니다. 

모든 데이터는 로컬에서 사용할 수 있어야 합니다. 백업 애플리케이션은 POSIX(Portable Operating System Interface)와 호환되는 블록 기반 스토리지에만 쓸 수 있습니다.

어떤 백업 솔루션이 이러한 요구 사항을 충족할까요?

1. 데이터 백업의 대상으로 Amazon S3를 사용하도록 백업 소프트웨어를 구성합니다.
2. 데이터 백업의 대상으로 Amazon S3 Glacier를 사용하도록 백업 소프트웨어를 구성합니다.
3. AWS Storage Gateway를 사용하고 게이트웨이 캐시 볼륨을 사용하도록 구성합니다.
4. AWS Storage Gateway를 사용하고 게이트웨이에 저장된 볼륨을 사용하도록 구성합니다.

이 회사의 요구 사항을 충족하기 위한 적합한 백업 솔루션은 **3. AWS Storage Gateway를 사용하고 게이트웨이 캐시 볼륨을 사용하도록 구성합니다.**입니다.

### 이유:
- **AWS Storage Gateway**는 온프레미스 애플리케이션과 AWS 클라우드 간의 매개체 역할을 합니다. 특히 **캐시 볼륨** 모드는 온프레미스에 데이터 캐시를 유지하면서 AWS에 데이터를 백업할 수 있도록 도와줍니다. 이를 통해 데이터는 로컬에서 사용할 수 있고, POSIX 호환 블록 기반 스토리지에 쓸 수 있는 형식으로 제공됩니다.

### 기타 옵션들에 대한 설명:
1. **Amazon S3를 사용하도록 백업 소프트웨어를 구성합니다.**
   - Amazon S3는 객체 스토리지이며 POSIX 호환 블록 기반 스토리지가 아닙니다. 따라서 이 옵션은 요구 사항을 충족하지 않습니다.

2. **Amazon S3 Glacier를 사용하도록 백업 소프트웨어를 구성합니다.**
   - S3 Glacier는 장기 보관 용도로 설계된 스토리지로, 데이터 접근 속도가 느립니다. 또한, POSIX 호환이 아니므로 이 옵션도 요구 사항을 충족하지 않습니다.

4. **AWS Storage Gateway를 사용하고 게이트웨이에 저장된 볼륨을 사용하도록 구성합니다.**
   - 게이트웨이에 저장된 볼륨은 온프레미스에서만 사용할 수 있으며, POSIX 호환 스토리지가 아닌 블록 스토리지로는 사용하기 어렵습니다. 그러나 이 옵션은 원활한 접근성을 보장하지 않기 때문에 적합하지 않습니다.

결론적으로, AWS Storage Gateway의 **캐시 볼륨**을 사용하는 것이 온프레미스 데이터 백업을 AWS에 안전하게 저장하면서도 로컬에서 즉시 접근할 수 있는 최적의 솔루션입니다.




## 질문: 159
글로벌 기업이 내부 웹 포털을 통해 대량의 개인 식별 정보(PII)를 처리합니다. 

이 회사의 애플리케이션은 AWS Direct Connect 연결을 통해 AWS에 연결된 기업 데이터 센터에서 실행됩니다. 이 애플리케이션은 PII를 Amazon S3에 저장합니다. 규정 준수 요구 사항에 따라 웹 포털에서 Amazon S3로의 트래픽은 인터넷을 통과해서는 안 됩니다.

SysOps 관리자는 규정 준수 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. Amazon S3에 대한 인터페이스 VPC 엔드포인트를 프로비저닝합니다. 인터페이스 엔드포인트를 사용하도록 애플리케이션을 수정합니다.
2. AWS 네트워크 방화벽을 구성하여 트래픽을 내부 S3 주소로 리디렉션합니다.
3. S3 경로 스타일 엔드포인트를 사용하도록 애플리케이션을 수정합니다.
4. 트래픽을 내부 S3 주소로 리디렉션하기 위해 다양한 VPC 네트워크 ACL을 설정합니다.

이 회사의 요구 사항을 충족하기 위해 SysOps 관리자가 해야 할 조치는 **1. Amazon S3에 대한 인터페이스 VPC 엔드포인트를 프로비저닝합니다. 인터페이스 엔드포인트를 사용하도록 애플리케이션을 수정합니다.**입니다.

### 이유:
- **Amazon S3에 대한 인터페이스 VPC 엔드포인트**를 사용하면 AWS의 S3 서비스와 안전하게 통신할 수 있으며, 이 트래픽은 인터넷을 통과하지 않고 AWS 네트워크 내에서만 전송됩니다. 이는 PII와 같은 민감한 데이터를 처리하는 애플리케이션에 적합한 방법입니다. 
- 애플리케이션을 수정하여 이 엔드포인트를 사용하면 규정 준수 요구 사항을 완전히 충족하면서 보안이 강화됩니다.

### 기타 옵션들에 대한 설명:
2. **AWS 네트워크 방화벽을 구성하여 트래픽을 내부 S3 주소로 리디렉션합니다.**
   - AWS 네트워크 방화벽은 보안 및 필터링 기능을 제공하지만, 트래픽이 인터넷을 지나가지 않도록 하는 직접적인 해결책이 아닙니다. 이 방법은 요구 사항을 충족하지 못할 수 있습니다.

3. **S3 경로 스타일 엔드포인트를 사용하도록 애플리케이션을 수정합니다.**
   - 경로 스타일 엔드포인트는 S3 버킷에 접근하는 방법을 변경하는 것일 뿐, 인터넷을 통한 트래픽을 차단하는 데는 영향을 주지 않습니다.

4. **트래픽을 내부 S3 주소로 리디렉션하기 위해 다양한 VPC 네트워크 ACL을 설정합니다.**
   - 네트워크 ACL을 설정하는 것은 보안과 관련이 있지만, 이는 복잡하고 관리하기 어렵고, 여전히 인터넷을 통한 트래픽이 발생할 수 있습니다.

결론적으로, **Amazon S3에 대한 인터페이스 VPC 엔드포인트**를 프로비저닝하는 것이 PII를 안전하게 처리하고 인터넷을 통과하지 않도록 하는 가장 효과적인 방법입니다.



## 질문: 160
SysOps 관리자가 Amazon EC2 Auto Scaling 그룹의 확장 이벤트를 알아차렸습니다. 

Amazon CloudWatch는 연관된 Application Load Balancer의 RequestCount 메트릭에서 급증을 보여줍니다. 관리자는 요청 소스의 IP 주소를 알고 싶어합니다.

관리자는 이 정보를 어디에서 찾을 수 있습니까?

1. 자동 크기 조정 로그
2. AWS CloudTrail 로그
3. EC2 인스턴스 로그
4. Elastic Load Balancer 액세스 로그

관리자가 요청 소스의 IP 주소를 찾기 위해 확인해야 할 것은 **4. Elastic Load Balancer 액세스 로그**입니다.

### 이유:
- **Elastic Load Balancer (ELB) 액세스 로그**는 ALB 또는 NLB를 통해 처리된 모든 요청의 상세 정보를 기록하며, 각 요청에 대한 원본 IP 주소를 포함합니다. 이 로그를 통해 특정 시간대의 요청 소스를 분석하고, 어떤 IP 주소가 요청을 발생시켰는지를 확인할 수 있습니다.

### 기타 옵션들에 대한 설명:
1. **자동 크기 조정 로그**:
   - Auto Scaling 이벤트에 대한 정보는 기록하지만, 요청 소스의 IP 주소와 관련된 정보는 포함되지 않습니다.

2. **AWS CloudTrail 로그**:
   - CloudTrail은 AWS API 호출에 대한 기록을 제공합니다. 이 로그는 EC2 인스턴스의 생성, 종료, 수정과 같은 API 이벤트를 기록하지만, 요청의 원본 IP 주소와는 관련이 없습니다.

3. **EC2 인스턴스 로그**:
   - EC2 인스턴스의 로그는 해당 인스턴스에서 실행 중인 애플리케이션의 로깅에 대한 정보일 수 있지만, ALB에서의 요청 소스 IP 주소를 포함하지 않을 수 있습니다.

결론적으로, 요청 소스의 IP 주소를 확인하기 위해서는 **Elastic Load Balancer 액세스 로그**를 확인하는 것이 가장 적절한 방법입니다.

## 질문: 161
회사의 SysOps 관리자가 회사 웹 애플리케이션 앞에 퍼블릭 네트워크 로드 밸런서(NLB)를 배포합니다. 

웹 애플리케이션은 어떠한 Elastic IP 주소도 사용하지 않습니다. 사용자는 회사의 도메인 이름을 사용하여 웹 애플리케이션에 액세스해야 합니다. SysOps 관리자는 트래픽을 NLB로 라우팅하도록 Amazon Route 53을 구성해야 합니다.

어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할까요?

1. NLB에 대한 Route 53 AAAA 레코드를 생성합니다.
2. NL에 대한 Route 53 별칭 레코드를 만듭니다.
3. NLB에 대한 Route 53 CAA 레코드를 생성합니다.
4. NLB에 대한 Route 53 CNAME 레코드를 만듭니다.

SysOps 관리자가 웹 애플리케이션 앞에 퍼블릭 네트워크 로드 밸런서(NLB)를 배포하고, 사용자가 회사의 도메인 이름을 사용하여 해당 애플리케이션에 접근할 수 있도록 트래픽을 NLB로 라우팅하기 위해서는 **2. NLB에 대한 Route 53 별칭 레코드를 만듭니다**가 가장 비용 효율적이고 적절한 솔루션입니다.

### 이유:
- **Route 53 별칭 레코드**는 NLB와 같은 AWS 리소스에 직접적으로 연결할 수 있으며, 특정한 IP 주소를 요구하지 않습니다. 별칭 레코드는 NLB가 제공하는 DNS 이름을 사용하여, 웹 애플리케이션에 대한 도메인 이름으로 직접 라우팅할 수 있습니다. 
- 별칭 레코드는 **DNS 쿼리 비용이 없고**, Route 53의 내부 DNS 구조에서 최적화된 방식으로 작동하여 트래픽을 더 효율적으로 처리합니다.
- 또한, 별칭 레코드는 **루트 도메인**(예: example.com)에도 사용할 수 있는 반면, CNAME 레코드는 루트 도메인에서 사용할 수 없습니다.

### 다른 옵션들에 대한 설명:
1. **NLB에 대한 Route 53 AAAA 레코드를 생성합니다**:
   - AAAA 레코드는 IPv6 주소를 지정하는 레코드로, NLB에 IPv6 지원을 추가하는 것과는 관련이 없습니다.

3. **NLB에 대한 Route 53 CAA 레코드를 생성합니다**:
   - CAA 레코드는 SSL/TLS 인증서 발급을 허용하는 도메인에 대한 제어를 제공하지만, NLB 트래픽 라우팅에는 직접적인 관련이 없습니다.

4. **NLB에 대한 Route 53 CNAME 레코드를 만듭니다**:
   - CNAME 레코드는 다른 도메인 이름으로 리디렉션하지만, **루트 도메인에서는 사용할 수 없**으며, 별칭 레코드보다는 일반적으로 비효율적입니다.

결론적으로, NLB와 도메인 간의 트래픽 라우팅을 설정하기 위해 Route 53의 별칭 레코드를 사용하는 것이 가장 비용 효율적이고 실용적인 방법입니다.



## 질문: 162
한 회사가 암호화된 Amazon RDS for Oracle DB 인스턴스를 실행합니다. 

이 회사는 다른 AWS 지역에서 정기 백업을 제공하고자 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. DB 인스턴스를 수정합니다. 지역 간 자동 백업을 활성화합니다.
2. 다른 지역에서 RDS 읽기 복제본을 만듭니다. 읽기 복제본의 스냅샷을 만듭니다.
3. AWS Database Migration Service(AWS DMS)를 사용하여 다른 지역의 DB 인스턴스로 데이터를 복사합니다.
4. DB 인스턴스에서 암호화를 일시적으로 해제합니다. 스냅샷을 찍습니다. 스냅샷을 다른 Region에 복사합니다.

암호화된 Amazon RDS for Oracle DB 인스턴스를 다른 AWS 지역으로 정기 백업하기 위한 가장 운영 효율적인 솔루션은 **2. 다른 지역에서 RDS 읽기 복제본을 만듭니다. 읽기 복제본의 스냅샷을 만듭니다.**입니다.

### 이유:
- **읽기 복제본 생성**: RDS의 읽기 복제본을 만들면 원본 DB 인스턴스의 데이터가 다른 지역에 실시간으로 복제됩니다. 이는 변경 사항이 발생할 때마다 데이터를 자동으로 업데이트하므로 운영 효율성을 높입니다.
- **스냅샷 생성**: 읽기 복제본의 스냅샷을 만들면 다른 지역에서 데이터의 정기 백업을 생성할 수 있습니다. 이 스냅샷은 백업 및 복구를 위한 안정적인 수단을 제공하며, 필요 시 복원할 수 있습니다.
- **운영 효율성**: 이 방법은 자동화 및 관리가 용이하며, RDS 서비스가 관리하는 인프라로 인해 유지 보수에 대한 부담이 줄어듭니다. 또한, 이 방법은 암호화된 상태를 유지할 수 있습니다.

### 다른 옵션들에 대한 설명:
1. **DB 인스턴스를 수정합니다. 지역 간 자동 백업을 활성화합니다.**: 
   - RDS는 지역 간 자동 백업을 지원하지 않으므로 이 옵션은 유효하지 않습니다.

3. **AWS Database Migration Service(AWS DMS)를 사용하여 다른 지역의 DB 인스턴스로 데이터를 복사합니다.**:
   - DMS를 사용하는 방법은 가능하지만, 설정이 복잡하고 관리 오버헤드가 크며, 지속적인 동기화나 정기적인 백업 솔루션으로는 비효율적일 수 있습니다.

4. **DB 인스턴스에서 암호화를 일시적으로 해제합니다. 스냅샷을 찍습니다. 스냅샷을 다른 Region에 복사합니다.**:
   - 이 방법은 암호화된 DB 인스턴스의 암호화를 해제해야 하므로 보안 위험을 초래할 수 있습니다. 또한, 일시적으로 암호화를 해제하는 것은 비효율적이며 운영 상의 불편함을 초래할 수 있습니다.

결론적으로, 읽기 복제본을 생성하고 그 스냅샷을 사용하는 방법이 암호화를 유지하면서도 정기적으로 데이터를 백업하는 가장 효율적이고 안전한 방법입니다.



## 질문: 163
한 회사가 웹사이트의 새 버전을 출시하고 있습니다. 

경영진은 회사 고객의 20%에 한정된 출시로 새 웹사이트를 배포하려고 합니다. 이 회사는 웹사이트의 DNS 솔루션에 Amazon Route 53을 사용합니다.

어떤 구성이 이러한 요구 사항을 충족할까요?

1. 장애 조치 라우팅 정책을 만듭니다. 정책 내에서 웹사이트 트래픽의 80%를 원래 리소스로 보내도록 구성합니다. 나머지 20%의 트래픽을 새 리소스를 가리키는 장애 조치 레코드로 구성합니다.
2. 다중값 답변 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스의 이름과 IP 주소로 4개의 레코드를 만듭니다. 새 리소스의 이름과 IP 주소로 1개의 레코드를 구성합니다.
3. 지연 기반 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스를 가리키는 레코드를 80의 가중치로 구성합니다. 새 리소스를 가리키는 레코드를 20의 가중치로 구성합니다.
4. 가중치가 적용된 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스를 가리키는 레코드에 대해 가중치 80을 구성합니다. 새 리소스를 가리키는 레코드에 대해 가중치 20을 구성합니다.

경영진이 웹사이트의 새 버전을 고객의 20%에 한정하여 출시하기 위해 필요한 구성은 **4. 가중치가 적용된 라우팅 정책을 만듭니다. 정책 내에서 원래 리소스를 가리키는 레코드에 대해 가중치 80을 구성합니다. 새 리소스를 가리키는 레코드에 대해 가중치 20을 구성합니다.**입니다.

### 이유:
- **가중치 기반 라우팅**: 이 방법은 DNS 쿼리에 대한 응답으로 특정 비율의 트래픽을 두 개의 리소스 간에 분배하는 데 가장 적합합니다. 원래 웹사이트에 대해 80%의 가중치를 설정하고, 새 웹사이트에 대해 20%의 가중치를 설정하면 요청을 비율에 따라 적절히 분배할 수 있습니다.
- **비율 기반 제어**: 이 구성을 통해 웹사이트의 새 버전이 실행되는 동안 원래 리소스의 비율이 높게 유지되며, 고객의 20%만이 새 버전을 사용하도록 할 수 있습니다. 이는 새 버전의 안정성과 성능을 확인하는 데 도움을 줍니다.

### 다른 옵션들에 대한 설명:
1. **장애 조치 라우팅 정책**: 이 정책은 주로 한 리소스가 실패했을 때 다른 리소스로 트래픽을 전환하는 데 사용됩니다. 20%의 트래픽을 새 리소스에 보내기 위한 구성에는 적합하지 않습니다.

2. **다중값 답변 라우팅 정책**: 이 정책은 DNS 응답에 여러 IP 주소를 반환하는 데 사용되지만, 트래픽을 80%와 20%로 세밀하게 조절할 수는 없습니다.

3. **지연 기반 라우팅 정책**: 이 정책은 가장 낮은 지연 시간을 가진 리소스를 선택하는 데 중점을 두므로, 고객의 특정 비율에 대한 트래픽 분배를 지원하지 않습니다.

결론적으로, **가중치가 적용된 라우팅 정책**이 필요에 가장 적합한 해결책입니다.

## 질문: 164
SysOps 관리자가 Amazon EC2 인스턴스, Elastic Load Balancer(ELB) 및 Amazon RDS DB 인스턴스를 프로비저닝하는 AWS CloudFormation 템플릿을 만들었습니다. 

스택 생성 중에 EC2 인스턴스 생성과 ELB 생성이 성공했습니다. 그러나 DB 인스턴스 생성은 실패했습니다.

이 시나리오에서 CloudFormation의 기본 동작은 무엇입니까?

1. CloudFormation은 스택을 롤백하고 삭제합니다.
2. CloudFormation은 스택을 롤백하지만 스택을 삭제하지는 않습니다.
3. CloudFormation은 사용자에게 스택을 롤백할지 아니면 계속할지 묻습니다.
4. CloudFormation은 스택을 성공적으로 완료하지만 DB 인스턴스에 대해 실패 상태를 보고합니다.

CloudFormation에서 스택 생성 중에 리소스 생성이 실패하면 기본 동작은 **1. CloudFormation은 스택을 롤백하고 삭제합니다.**입니다.

### 이유:
- **스택 롤백**: CloudFormation은 리소스 생성 중 오류가 발생하면 자동으로 이전 상태로 되돌리기 위해 스택을 롤백합니다. 이는 생성된 리소스가 중간 상태에 있을 때, 나중에 발생할 수 있는 문제를 방지하는데 도움을 줍니다.
- **리소스 상태**: EC2 인스턴스와 ELB가 성공적으로 생성된 경우에도 DB 인스턴스의 생성이 실패하면, 전체 스택 생성 프로세스는 실패로 간주되며, 생성된 리소스는 모두 삭제됩니다.

이러한 동작은 AWS CloudFormation의 기본 동작으로, 스택을 안전하게 유지하고 일관성을 보장하기 위해 설계되었습니다.


## 질문: 165
SysOps 관리자는 AWS Lambda 함수의 호출을 자동화해야 합니다. 

Lambda 함수는 Amazon S3 버킷에 저장된 데이터에 대한 보고서를 생성하기 위해 매일 마지막에 실행되어야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. Amazon S3와 Lambda 함수를 대상으로 하는 이벤트 패턴이 있는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
2. 일정과 Lambda 함수를 대상으로 하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.
3. S3 버킷에서 객체가 변경될 때마다 Lambda 함수를 호출하는 S3 이벤트 알림을 만듭니다.
4. Cron 작업으로 Amazon EC2 인스턴스를 배포하여 Lambda 함수를 호출합니다.

AWS Lambda 함수를 매일 실행하여 Amazon S3 버킷에 저장된 데이터에 대한 보고서를 생성해야 하는 경우, 가장 운영 효율적인 솔루션은 **2. 일정과 Lambda 함수를 대상으로 하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성합니다.**입니다.

### 이유:
- **스케줄링**: Amazon EventBridge (구 Amazon CloudWatch Events)는 일정에 따라 Lambda 함수를 호출할 수 있는 기능을 제공합니다. 매일 특정 시간에 Lambda 함수를 실행하도록 설정할 수 있어, 자동화된 스케줄링이 가능해집니다.
- **운영 효율성**: Lambda를 직접 호출하기 때문에 추가적인 서버나 관리 리소스가 필요 없으며, AWS 관리 콘솔이나 AWS CLI를 통해 쉽게 설정하고 관리할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
1. **S3와 Lambda 이벤트 패턴**: S3 이벤트는 객체가 생성되거나 수정될 때 호출되므로 매일 특정 시간에 실행하는 데 적합하지 않습니다.
3. **S3 이벤트 알림**: 이 옵션은 S3 버킷의 변경에 따라 Lambda 함수를 호출하지만, 매일 특정 시간에 실행할 수 있는 기능이 없습니다.
4. **EC2 Cron 작업**: EC2 인스턴스를 배포하고 유지 관리하는 것은 운영 효율성에 좋지 않으며, Lambda의 서버리스 특성을 활용하지 못하는 방식입니다. 

따라서 **Amazon EventBridge 규칙을 사용하는 것이 가장 효율적이고 운영적으로 적합한 솔루션**입니다.

## 질문: 166
한 회사가 Amazon S3에 호스팅된 새로운 정적 웹사이트를 출시합니다. 

정적 웹사이트 호스팅 기능이 버킷에서 활성화되었고 콘텐츠가 업로드되었습니다. 하지만 사이트로 이동하면 다음과 같은 오류 메시지가 표시됩니다.

403 Forbidden - Access Denied

이 오류를 해결하려면 어떤 변경을 해야 합니까?

1. 모든 사용자에게 버킷에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가합니다.
2. 모든 사용자에게 버킷 객체에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가합니다.
3. 버킷에 대한 읽기 액세스를 거부하는 기본 버킷 정책을 제거합니다.
4. 버킷에서 CORS(교차 출처 리소스 공유)를 구성합니다.

"403 Forbidden - Access Denied" 오류 메시지가 표시되는 경우, Amazon S3에서 호스팅된 정적 웹사이트에 접근할 수 없다는 것을 의미합니다. 이 문제를 해결하기 위해 가장 적합한 변경 사항은 **2. 모든 사용자에게 버킷 객체에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가합니다.**입니다.

### 이유:
- **객체 접근 권한**: 정적 웹사이트의 콘텐츠(HTML, CSS, JavaScript 파일 등)는 S3 버킷의 객체로 저장됩니다. 모든 사용자에게 이 객체들에 대한 읽기 액세스를 부여해야만 웹사이트 방문자가 이 콘텐츠를 접근할 수 있습니다.
- **버킷 정책**: 버킷 정책을 사용하여 특정 조건(예: 모든 사용자에 대한 읽기 권한)을 지정하여 S3 객체에 대한 접근을 제어할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 적합하지 않습니다:
1. **버킷에 대한 읽기 액세스 권한**: 버킷 자체에 대한 권한이 아닌 객체에 대한 권한이 필요합니다. 따라서 "버킷" 자체가 아니라 "버킷 객체"에 대한 읽기 권한을 부여해야 합니다.
3. **기본 버킷 정책 제거**: 기본적으로 S3 버킷은 비공개로 설정되며, 특정 권한을 부여하지 않으면 접근이 차단됩니다. 하지만 기본 정책을 제거하기보다는 필요한 권한을 추가하는 것이 더 좋습니다.
4. **CORS 구성**: CORS는 웹 브라우저의 보안 정책으로, 서로 다른 출처 간의 요청을 허용하는 데 사용됩니다. 하지만 CORS 설정은 이 오류 메시지와는 관련이 없습니다.

결론적으로, **모든 사용자에게 버킷 객체에 대한 읽기 액세스 권한을 부여하는 버킷 정책을 추가하는 것이 올바른 접근 방법입니다.**


## 질문: 167
한 회사가 AWS Organizations를 사용합니다. 

SysOps 관리자가 관리 계정에서 AWS Compute Optimizer와 AWS 태그 정책을 사용하여 청구 패밀리의 모든 멤버 계정을 관리하려고 합니다. SysOps 관리자가 AWS Organizations 콘솔로 이동하지만 관리 계정을 통해 태그 정책을 활성화할 수 없습니다.

이 문제의 원인은 무엇일까요?

1. 조직에서 모든 기능이 활성화되지 않았습니다.
2. 통합 결제가 활성화되지 않았습니다.
3. 회원 계정에는 비용 할당을 위한 태그가 활성화되어 있지 않습니다.
4.  멤버 계정에서 Compute Optimizer에 대한 신뢰할 수 있는 액세스를 수동으로 활성화하지 않았습니다.
 

SysOps 관리자가 AWS Organizations 콘솔에서 태그 정책을 활성화할 수 없는 원인은 **1. 조직에서 모든 기능이 활성화되지 않았습니다.**입니다.

### 이유:
- **AWS Organizations의 모든 기능 활성화**: 태그 정책과 같은 고급 기능을 사용하려면 조직이 모든 기능 모드로 활성화되어 있어야 합니다. 기본 모드에서는 이러한 기능을 사용할 수 없습니다. 모든 기능 모드로 전환하면 태그 정책, 서비스 제어 정책(SCP) 및 기타 기능을 활용할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 문제가 아닙니다:
2. **통합 결제가 활성화되지 않았습니다**: 통합 결제는 여러 계정의 청구를 하나의 관리 계정으로 통합하는 기능이며, 태그 정책과는 직접적인 연관이 없습니다.
3. **회원 계정에는 비용 할당을 위한 태그가 활성화되어 있지 않습니다**: 비용 할당 태그는 태그 정책이 활성화된 이후에 적용되는 것이므로, 태그 정책을 활성화할 수 없다면 이 문제가 발생하지 않습니다.
4. **회원 계정에서 Compute Optimizer에 대한 신뢰할 수 있는 액세스를 수동으로 활성화하지 않았습니다**: Compute Optimizer의 신뢰할 수 있는 액세스는 태그 정책과는 별개의 설정으로, 태그 정책을 활성화하지 못하는 원인과는 관련이 없습니다.

결론적으로, **조직에서 모든 기능이 활성화되지 않아서 태그 정책을 활성화할 수 없는 것이 문제의 원인입니다.**



## 질문: 168
한 회사가 Amazon S3 버킷에 미디어 콘텐츠를 저장하고 Amazon CloudFront를 사용하여 사용자에게 콘텐츠를 배포합니다. 

라이선스 조건으로 인해 회사는 일부 국가에서 콘텐츠를 배포할 권한이 없습니다. SysOps 관리자는 특정 국가에 대한 액세스를 제한해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. S3:LocationConstraint 조건에 따라 GetObject 작업을 거부하도록 S3 버킷 정책을 구성합니다.
2. 2차 오리진 액세스 ID(OAI)를 만듭니다. S3 버킷 정책을 구성하여 허가되지 않은 국가의 액세스를 방지합니다.
3. CloudFront 배포에서 지역 제한 기능을 활성화하여 허가되지 않은 국가의 액세스를 차단합니다.
4. 승인된 국가의 IP 주소에 대해서만 서명된 CloudFront URL을 생성하도록 애플리케이션을 업데이트합니다.

회사가 Amazon S3 버킷에 저장된 미디어 콘텐츠의 배포를 특정 국가에 대해 제한해야 할 때, 가장 운영 효율적인 솔루션은 **3. CloudFront 배포에서 지역 제한 기능을 활성화하여 허가되지 않은 국가의 액세스를 차단합니다.**입니다.

### 이유:
- **CloudFront의 지역 제한 기능**: 이 기능을 사용하면 CloudFront 배포에 대한 요청을 특정 국가에서만 허용할 수 있습니다. 이는 간단하고 효율적인 방법으로, 회사가 라이선스 조건을 준수할 수 있도록 보장합니다. CloudFront는 요청의 IP 주소를 기반으로 국가를 식별하고, 허가되지 않은 국가에서의 액세스를 차단할 수 있습니다.

다른 옵션들은 다음과 같은 이유로 덜 효율적입니다:
1. **S3:LocationConstraint 조건**: S3 버킷 정책을 사용하여 객체 접근을 거부하는 것은 특정 국가에 대한 액세스를 제어하는 데 적합하지 않으며, 이 경우에는 CloudFront를 통한 요청을 차단할 수 없습니다.
2. **2차 오리진 액세스 ID(OAI)**: OAI는 S3 버킷에 대한 액세스를 제어하는 방법이지만, 특정 국가의 요청을 차단하는 데는 적합하지 않습니다.
4. **서명된 CloudFront URL 생성**: 서명된 URL을 생성하는 방법도 허가된 국가의 요청을 관리하는 데 도움이 될 수 있지만, 이 방법은 구현이 복잡하고 관리해야 할 추가적인 로직이 필요합니다. 지역 제한 기능을 사용하는 것이 더 간단하고 관리하기 쉽습니다.

결론적으로, **CloudFront의 지역 제한 기능을 활성화하는 것이 가장 운영 효율적인 해결책입니다.**


## 질문: 169
SysOps 관리자가 인터넷에 액세스해야 하는 IPv6 CIDR 블록이 있는 Amazon VPC를 만들었습니다. 

그러나 인터넷에서 VPC로의 액세스는 금지되어 있습니다. VPC에 필요한 구성 요소를 추가하고 구성한 후 관리자는 인터넷에 있는 도메인에 연결할 수 없습니다.

관리자는 경로 테이블에 어떤 추가 경로 대상 규칙을 추가해야 합니까?

1. Route ::/0 트래픽을 NAT 게이트웨이로
2. Route ::/0 인터넷 게이트웨이로의 트래픽
3. 0.0.0.0/0 트래픽을 출구 전용 인터넷 게이트웨이로 경로 지정
4. Route ::/0 트래픽을 이탈 전용 인터넷 게이트웨이로 전송

IPv6 CIDR 블록을 가진 Amazon VPC가 인터넷에 액세스하도록 설정하려면, **2. Route `::/0` 인터넷 게이트웨이로의 트래픽**을 추가해야 합니다.

### 이유:
- **인터넷 게이트웨이**: 인터넷과 VPC 간의 트래픽을 허용하는 역할을 하며, IPv4 및 IPv6 트래픽 모두를 지원합니다. `::/0` 경로를 추가하면 VPC 내의 모든 IPv6 트래픽이 인터넷으로 라우팅되도록 설정됩니다.
- 이 경로를 통해 VPC 내부에서 인터넷으로 나가는 IPv6 트래픽이 올바르게 전달될 수 있습니다.

### 다른 옵션에 대한 설명:
1. **Route `::/0` 트래픽을 NAT 게이트웨이로**: NAT 게이트웨이는 IPv4 트래픽을 인터넷으로 전달하는 데 사용됩니다. IPv6 트래픽에 대해선 NAT 게이트웨이를 사용할 수 없으므로 이 옵션은 적합하지 않습니다.
3. **0.0.0.0/0 트래픽을 출구 전용 인터넷 게이트웨이로 경로 지정**: 0.0.0.0/0는 IPv4 주소에 해당하며, IPv6 주소와는 관련이 없습니다.
4. **Route `::/0` 트래픽을 이탈 전용 인터넷 게이트웨이로 전송**: 이탈 전용 인터넷 게이트웨이는 AWS에서 제공하는 IPv4 전용 옵션으로 IPv6 트래픽에는 적용되지 않습니다.

따라서, 올바른 구성은 **Route `::/0` 인터넷 게이트웨이로의 트래픽**입니다.

## 질문: 170
한 회사가 여러 쓰기 집약적 애플리케이션을 호스팅합니다. 

이러한 애플리케이션은 단일 Amazon EC2 인스턴스에서 실행되는 MySQL 데이터베이스를 사용합니다. 이 회사는 SysOps 관리자에게 멀티 테넌트 워크로드에 이상적인 고가용성 데이터베이스 솔루션을 구현해 달라고 요청합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 구현해야 합니까?

1. MySQL에 대한 두 번째 EC2 인스턴스를 만듭니다. 두 번째 인스턴스를 읽기 복제본으로 구성합니다.
2. 데이터베이스를 Amazon Aurora DB 클러스터로 마이그레이션합니다. Aurora Replica를 추가합니다.
3. 데이터베이스를 Amazon Aurora 다중 마스터 DB 클러스터로 마이그레이션합니다.
4. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다

멀티 테넌트 워크로드에 이상적인 고가용성 데이터베이스 솔루션을 구현하기 위해 SysOps 관리자가 선택해야 할 솔루션은 **3. 데이터베이스를 Amazon Aurora 다중 마스터 DB 클러스터로 마이그레이션합니다.**입니다.

### 이유:
- **Amazon Aurora 다중 마스터 DB 클러스터**는 고가용성과 쓰기 집약적인 워크로드에 최적화된 솔루션입니다. 이 구성은 여러 리전에서 동시에 읽기 및 쓰기가 가능하므로, 멀티 테넌트 환경에서의 성능과 가용성을 극대화할 수 있습니다.
- Aurora는 자동 스케일링, 고가용성, 복구 기능을 제공하며, 읽기 및 쓰기 분산이 가능하여 성능 저하를 방지합니다.

### 다른 옵션에 대한 설명:
1. **MySQL에 대한 두 번째 EC2 인스턴스를 만듭니다. 두 번째 인스턴스를 읽기 복제본으로 구성합니다.**: 이 방법은 읽기 전용 복제본을 추가하지만, 쓰기 집약적인 애플리케이션에 대한 고가용성을 제공하지 않습니다.
   
2. **데이터베이스를 Amazon Aurora DB 클러스터로 마이그레이션합니다. Aurora Replica를 추가합니다.**: Aurora 클러스터는 읽기 복제본을 추가할 수 있지만, 쓰기 성능을 고려할 때 다중 마스터 구성이 더 적합합니다.

4. **데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다.**: RDS for MySQL은 관리형 서비스로서 고가용성을 제공하지만, 쓰기 집약적 멀티 테넌트 애플리케이션에 대한 최적의 솔루션은 아닙니다.

결론적으로, **Amazon Aurora 다중 마스터 DB 클러스터**로의 마이그레이션이 가장 적합한 솔루션입니다.


## 질문: 171
한 회사에는 Elastic Load Balancer(ELB) 뒤의 Amazon EC2 인스턴스 플릿에서 실행되는 메모리 집약적 애플리케이션이 있습니다. 

인스턴스는 Auto Scaling 그룹에서 실행됩니다. SysOps 관리자는 애플리케이션에 연결하는 사용자 수에 따라 애플리케이션이 확장될 수 있도록 해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. ELB에서 생성된 ActiveConnectionCount Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.
2. EL에서 생성된 mem_used Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.
3. 추가 연결을 지원하기 위해 자동 크기 조정 그룹의 EC2 인스턴스 수를 늘리려면 예약된 크기 조정 정책을 만듭니다.
4. ELB에 스크립트를 생성하고 배포하여 연결된 사용자 수를 사용자 정의 Amazon CloudWatch 메트릭으로 노출합니다. 메트릭을 사용하는 스케일링 정책을 만듭니다.
 
메모리 집약적 애플리케이션의 사용자 수에 따라 애플리케이션을 자동으로 확장할 수 있도록 하기 위해 SysOps 관리자가 선택해야 할 솔루션은 **1. ELB에서 생성된 ActiveConnectionCount Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.**입니다.

### 이유:
- **ActiveConnectionCount 메트릭**은 ELB가 현재 유지하고 있는 활성 연결 수를 추적합니다. 이는 애플리케이션의 사용량을 직접적으로 나타내며, 사용자 수가 증가함에 따라 연결 수가 늘어나는 것을 반영합니다. 
- 이 메트릭을 기반으로 확장 정책을 설정하면 사용자가 많아질 때 EC2 인스턴스를 자동으로 추가하여 애플리케이션이 원활하게 작동하도록 할 수 있습니다.

### 다른 옵션에 대한 설명:
2. **ELB에서 생성된 mem_used Amazon CloudWatch 메트릭을 기반으로 애플리케이션을 확장하는 확장 정책을 만듭니다.**: 이 메트릭은 메모리 사용량을 나타내지만, 사용자 수와 직접적인 연관성이 낮아 원하는 목표를 달성하기 어려울 수 있습니다.

3. **추가 연결을 지원하기 위해 자동 크기 조정 그룹의 EC2 인스턴스 수를 늘리려면 예약된 크기 조정 정책을 만듭니다.**: 예약된 크기 조정 정책은 특정 시간에 인스턴스 수를 늘리거나 줄이는 데 유용하지만, 실시간 사용자 수 변화에 적응하지 못합니다.

4. **ELB에 스크립트를 생성하고 배포하여 연결된 사용자 수를 사용자 정의 Amazon CloudWatch 메트릭으로 노출합니다. 메트릭을 사용하는 스케일링 정책을 만듭니다.**: 이 접근 방식은 복잡성과 유지 보수 비용이 증가할 수 있으며, 기본 제공 메트릭을 사용하는 것이 더 효율적입니다.

결론적으로, **ActiveConnectionCount**를 사용하는 것이 자동 확장 솔루션으로 가장 효과적입니다.



## 질문: 172
SysOps 관리자가 퍼블릭 서브넷과 프라이빗 서브넷을 포함하는 새 VPC를 만듭니다. 

SysOps 관리자가 프라이빗 서브넷에서 11개의 Amazon EC2 인스턴스를 성공적으로 시작합니다. SysOps 관리자가 동일한 서브넷에서 EC2 인스턴스를 하나 더 시작하려고 시도합니다. 그러나 SysOps 관리자는 사용 가능한 IP 주소가 충분하지 않다는 오류 메시지를 받습니다.

SysOps 관리자가 더 많은 EC2 인스턴스를 배포하려면 무엇을 해야 합니까?

1. CIDR 블록을 /27로 변경하려면 개인 서브넷을 편집합니다.
2. 두 번째 가용성 영역으로 확장하도록 개인 서브넷을 편집합니다.
3. 개인 서브넷에 추가적인 Elastic IP 주소를 할당합니다.
4. 필요한 EC2 인스턴스를 보관할 새로운 개인 서브넷을 만듭니다.

SysOps 관리자가 프라이빗 서브넷에서 더 많은 Amazon EC2 인스턴스를 배포하려면 **4. 필요한 EC2 인스턴스를 보관할 새로운 개인 서브넷을 만듭니다.**를 선택하는 것이 가장 적합합니다.

### 이유:
- **IP 주소 부족 문제**: 현재 프라이빗 서브넷에 할당된 CIDR 블록이 충분한 IP 주소를 제공하지 않는 경우, 기존 서브넷에서 추가 인스턴스를 시작할 수 없습니다. EC2 인스턴스를 시작할 수 있는 IP 주소의 수는 서브넷의 CIDR 블록에 따라 제한됩니다. 
- **새 서브넷 생성**: 새로운 프라이빗 서브넷을 생성하면 추가 IP 주소를 할당받을 수 있어 더 많은 EC2 인스턴스를 배포할 수 있습니다. 

### 다른 옵션에 대한 설명:
1. **CIDR 블록을 /27로 변경하려면 개인 서브넷을 편집합니다.**: 서브넷의 CIDR 블록을 변경하면 현재 서브넷에 할당된 인스턴스가 영향을 받을 수 있으며, 이미 사용 중인 IP 주소를 해제해야 하므로 직접적으로 해결책이 아닙니다.

2. **두 번째 가용성 영역으로 확장하도록 개인 서브넷을 편집합니다.**: 단순히 가용성 영역을 변경한다고 해서 IP 주소의 수가 늘어나는 것은 아닙니다. 가용성 영역은 리소스를 배포하는 위치를 지정할 뿐입니다.

3. **개인 서브넷에 추가적인 Elastic IP 주소를 할당합니다.**: Elastic IP 주소는 퍼블릭 IP 주소이며, 프라이빗 서브넷 내의 인스턴스에 적용되지 않습니다. 프라이빗 서브넷의 인스턴스는 기본적으로 프라이빗 IP 주소를 사용합니다.

결론적으로, 새로운 개인 서브넷을 만드는 것이 더 많은 EC2 인스턴스를 배포하는 데 효과적인 해결책입니다.


## 질문: 173
회사는 여러 지리적 위치에서 잠재적인 무단 AWS Management Console 로그인에 대해 AWS 계정을 자동으로 모니터링해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

1. Amazon Cognito를 구성하여 손상된 IAM 자격 증명을 감지합니다.
2. Amazon Inspector를 설정합니다. 승인되지 않은 로그인에 대한 리소스를 스캔하고 모니터링합니다.
3. AWS Config를 설정합니다. 계정에 iam-policy-blacklisted-check 관리 규칙을 추가합니다.
4. Amazon GuardDuty를 구성하여 UnauthorizedAccess:IAMUser/ConsoleLoginSuccess.B 발견 사항을 모니터링합니다.

회사가 여러 지리적 위치에서 잠재적인 무단 AWS Management Console 로그인에 대해 AWS 계정을 자동으로 모니터링해야 하는 경우, **4. Amazon GuardDuty를 구성하여 UnauthorizedAccess:IAMUser/ConsoleLoginSuccess.B 발견 사항을 모니터링합니다.**가 가장 적합한 솔루션입니다.

### 이유:
- **Amazon GuardDuty**는 AWS 계정 및 리소스의 보안 위협을 자동으로 모니터링하고 탐지하는 서비스입니다. 
- **UnauthorizedAccess:IAMUser/ConsoleLoginSuccess.B**는 AWS Management Console에 대한 성공적인 로그인 시도를 탐지하는 GuardDuty의 발견 항목으로, 여러 지리적 위치에서의 의심스러운 로그인을 식별하는 데 유용합니다.
- GuardDuty는 지속적으로 로그를 분석하여 이상 징후를 감지하고, 잠재적인 무단 액세스 시도를 알림으로써 보안성을 높일 수 있습니다.

### 다른 옵션에 대한 설명:
1. **Amazon Cognito를 구성하여 손상된 IAM 자격 증명을 감지합니다.**: Amazon Cognito는 주로 인증 및 사용자 관리를 위한 서비스이며, IAM 자격 증명의 손상 여부를 직접적으로 모니터링하지 않습니다.

2. **Amazon Inspector를 설정합니다. 승인되지 않은 로그인에 대한 리소스를 스캔하고 모니터링합니다.**: Amazon Inspector는 애플리케이션 보안 및 취약점 평가 도구로, 로그인 시도를 모니터링하는 데 적합하지 않습니다.

3. **AWS Config를 설정합니다. 계정에 iam-policy-blacklisted-check 관리 규칙을 추가합니다.**: AWS Config는 리소스 구성을 모니터링하지만, 로그인 시도를 모니터링하는 데는 적합하지 않습니다. IAM 정책의 적합성을 평가하는 데는 유용할 수 있으나 로그인 시도 감지에는 한계가 있습니다.

따라서, Amazon GuardDuty를 사용하는 것이 가장 효과적이고 효율적인 방법입니다.

## 질문: 174
한 회사에 Amazon RDS DB 인스턴스가 있습니다. 

이 회사는 고가용성을 유지하면서 캐싱 서비스를 구현하고자 합니다.

어떤 작업 조합이 이러한 요구 사항을 충족할까요? (두 가지를 선택하세요.)

1. 데이터 저장소에 자동 검색을 추가합니다.
2. Memcached용 Amazon ElastiCache 데이터 저장소를 만듭니다.
3. Redis용 Amazon ElastiCache 데이터 저장소를 만듭니다.
4. 데이터 저장소에 대해 다중 AZ를 활성화합니다.
5. 데이터 저장소에 대해 멀티스레딩을 활성화합니다.

고가용성을 유지하면서 캐싱 서비스를 구현하기 위해 선택할 수 있는 두 가지 작업 조합은 다음과 같습니다:

### 선택 1: 캐싱 솔루션 구축
1. **Memcached용 Amazon ElastiCache 데이터 저장소를 만듭니다.**: Memcached는 고속 캐싱을 제공하여 데이터베이스에 대한 요청을 줄이고 성능을 향상시킬 수 있습니다. ElastiCache를 사용하면 관리의 복잡성을 줄이고 고가용성을 유지하는 데 도움을 줄 수 있습니다.

### 선택 2: 고가용성 구현
4. **데이터 저장소에 대해 다중 AZ를 활성화합니다.**: RDS 인스턴스를 다중 AZ로 구성하면 데이터베이스의 고가용성을 보장할 수 있습니다. 이는 장애 조치(failover) 시 자동으로 다른 가용성 영역(AZ)으로 전환되어 지속적인 가용성을 유지합니다.

### 결론
- **Memcached용 Amazon ElastiCache 데이터 저장소를 만들고, 데이터 저장소에 대해 다중 AZ를 활성화**하면 고가용성을 유지하면서 캐싱 서비스를 효과적으로 구현할 수 있습니다.

### 추가 선택지
- **Redis용 Amazon ElastiCache 데이터 저장소를 만듭니다.**: Redis는 메모리 캐싱 솔루션으로, 추가적인 기능(예: 영속성 및 데이터 구조 지원)을 제공합니다. 이 옵션도 고려할 수 있습니다. 
- **자동 검색 추가**는 캐싱 성능 향상에 도움을 줄 수 있지만, 기존의 캐시 솔루션과 병행하여 사용할 수 있습니다. 

고가용성 및 캐싱 요구 사항을 충족하기 위해서는 **Memcached 또는 Redis와 다중 AZ**의 조합이 최선의 선택입니다.

## 질문: 175
한 회사가 AWS CloudTrail을 사용하여 계정 활동을 모니터링하고 있으며, 로그가 계정의 Amazon S3 버킷에 전달된 후 일부 로그 파일이 변조되는 것을 우려하고 있습니다.

앞으로 SysOps 관리자는 로그 파일이 S3 버킷에 전달된 후 수정되지 않았는지 어떻게 확인할 수 있습니까?

1. CloudTrail 로그를 Amazon CloudWatch Logs로 스트리밍하여 보조 위치에 로그를 저장합니다.
2. 로그 파일 무결성 검증을 활성화하고 다이제스트 파일을 사용하여 로그 파일의 해시 값을 확인합니다.
3. 여러 지역 간에 S3 로그 버킷을 복제하고 S3 관리 키로 로그 파일을 암호화합니다.
4. 보안 감사를 위해 로그 버킷에 대한 요청을 추적하려면 S3 서버 액세스 로깅을 활성화합니다.

로그 파일이 Amazon S3 버킷에 전달된 후 수정되지 않았는지 확인하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### 정답
2. **로그 파일 무결성 검증을 활성화하고 다이제스트 파일을 사용하여 로그 파일의 해시 값을 확인합니다.**

### 이유
- **로그 파일 무결성 검증**: 로그 파일이 S3 버킷에 저장된 후, 해당 파일이 수정되지 않았음을 확인할 수 있는 가장 확실한 방법은 로그 파일의 해시 값을 계산하고 이를 다이제스트 파일과 비교하는 것입니다. 이 방법은 원본 로그와 수신된 로그의 무결성을 검증할 수 있도록 해주며, 변조가 발생했는지 쉽게 감지할 수 있습니다.

### 다른 선택지 설명
1. **CloudTrail 로그를 Amazon CloudWatch Logs로 스트리밍**: 이 방법은 로그를 모니터링할 수 있지만, 로그 파일의 무결성을 검증하는 기능은 제공하지 않습니다.
   
3. **S3 로그 버킷을 여러 지역 간에 복제하고 S3 관리 키로 로그 파일을 암호화**: 이 방법은 로그 파일의 보안을 강화하지만, 로그 파일이 수정되지 않았는지를 확인하는 데는 직접적인 도움이 되지 않습니다.
   
4. **S3 서버 액세스 로깅을 활성화**: 이 방법은 S3 버킷에 대한 요청을 추적할 수 있지만, 로그 파일의 무결성을 검증하는 데는 직접적인 방법이 아닙니다. 서버 액세스 로그는 액세스 로그를 기록하는 것이며, 로그 파일 자체의 변경 여부를 알 수는 없습니다.

따라서 **로그 파일 무결성 검증을 활성화하고 해시 값을 확인하는 것이** 로그의 변조 여부를 확인하는 데 가장 효과적인 방법입니다.



## 질문: 176
SysOps 관리자가 AWS Trusted Advisor 경고를 검토하고 오픈 액세스 권한이 있는 S3 버킷 정책에 대한 경고를 발견했습니다. 

버킷 소유자와 문제를 논의하는 동안 관리자는 S3 버킷이 Amazon CloudFront 웹 배포의 출처임을 깨달았습니다.

사용자가 CloudFront URL만 사용하여 Amazon S3의 객체에 액세스하도록 하려면 관리자가 어떤 조치를 취해야 합니까?

1. Amazon S3 관리 키(SSE-S3)를 사용한 서버 측 암호화로 S3 버킷 콘텐츠를 암호화합니다.
2. 원본 액세스 ID를 생성하고 S3 버킷의 객체를 읽을 수 있는 권한을 부여합니다.
3. CloudFront 배포에 IAM 사용자를 할당하고 S3 버킷 정책에서 사용자 권한을 부여합니다.
4. CloudFront 배포에 IAM 역할을 할당하고 S3 버킷 정책에서 역할 권한을 부여합니다.

사용자가 CloudFront URL만 사용하여 Amazon S3의 객체에 액세스하도록 하려면 관리자가 취해야 할 조치는 다음과 같습니다:

### 정답
2. **원본 액세스 ID를 생성하고 S3 버킷의 객체를 읽을 수 있는 권한을 부여합니다.**

### 이유
- **원본 액세스 ID (OAI)**: CloudFront는 S3 버킷의 콘텐츠에 액세스할 수 있도록 특정한 ID를 사용합니다. 원본 액세스 ID를 사용하면 CloudFront에서만 S3 버킷의 객체에 대한 액세스가 허용되고, 직접 S3 URL을 통해 접근하는 것을 차단할 수 있습니다. 이를 통해 CloudFront URL을 통해서만 객체에 접근할 수 있도록 보안성을 강화할 수 있습니다.

### 다른 선택지 설명
1. **Amazon S3 관리 키(SSE-S3)를 사용한 서버 측 암호화**: 이 방법은 데이터를 암호화하는 것이지만, S3 버킷에 대한 액세스를 제한하는 데는 직접적인 도움이 되지 않습니다.
   
3. **CloudFront 배포에 IAM 사용자를 할당하고 S3 버킷 정책에서 사용자 권한을 부여**: IAM 사용자를 사용하여 CloudFront와 S3 간의 권한을 관리하는 것은 비효율적이며, OAI를 사용하는 것이 더 간편하고 안전합니다.
   
4. **CloudFront 배포에 IAM 역할을 할당하고 S3 버킷 정책에서 역할 권한을 부여**: IAM 역할을 사용하는 것도 가능하지만, CloudFront와 S3 간의 권한 관리를 더 쉽게 하고 보안을 강화하기 위해 원본 액세스 ID(OAI)를 사용하는 것이 더 적절합니다.

결론적으로, **원본 액세스 ID를 생성하고 S3 버킷의 객체를 읽을 수 있는 권한을 부여하는 것이** 사용자에게 CloudFront URL을 통해서만 객체에 접근할 수 있도록 설정하는 가장 적절한 방법입니다.


## 질문: 177
SysOps 관리자가 AWS Trusted Advisor 권장 사항을 검토하고 있습니다. 

SysOps 관리자는 재무 애플리케이션의 모든 애플리케이션 서버가 Low Utilization Amazon EC2 Instances 검사에 나열되어 있음을 알아차렸습니다. 애플리케이션은 3개의 가용성 영역에 걸쳐 3개의 인스턴스에서 실행됩니다. SysOps 관리자는 애플리케이션의 가용성이나 디자인에 영향을 미치지 않으면서 애플리케이션 실행 비용을 줄여야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 애플리케이션 서버의 수를 줄이세요.
2. AWS Cost Explorer에서 적절한 크기 조정 권장 사항을 적용하여 인스턴스 크기를 줄입니다.
3. 인스턴스 앞에 애플리케이션 로드 밸런서를 프로비저닝합니다.
4. 애플리케이션 서버의 인스턴스 크기를 확장합니다

**2. AWS Cost Explorer에서 적절한 크기 조정 권장 사항을 적용하여 인스턴스 크기를 줄입니다.**

### 이유:
AWS Trusted Advisor의 Low Utilization Amazon EC2 Instances 경고는 인스턴스가 과도한 리소스를 사용하고 있지 않다는 것을 나타냅니다. **Cost Explorer**는 해당 인스턴스의 리소스 사용률을 분석하여 적절한 크기로 자동 조정 권장 사항을 제공합니다. 이 방법을 사용하면 애플리케이션의 가용성이나 디자인에 영향을 주지 않으면서 비용을 절감할 수 있습니다.

### 다른 선택지 설명:
1. **애플리케이션 서버의 수를 줄이세요**: 서버 수를 줄이는 것은 애플리케이션의 가용성과 확장성에 영향을 줄 수 있기 때문에 권장되지 않습니다.
   
3. **인스턴스 앞에 애플리케이션 로드 밸런서를 프로비저닝합니다**: 로드 밸런서는 트래픽 분산을 담당하지만, EC2 인스턴스 비용을 줄이는 직접적인 방법이 아닙니다.

4. **애플리케이션 서버의 인스턴스 크기를 확장합니다**: 확장은 비용을 줄이는 것이 아니라 인프라를 확장하는 방법이므로 이 요구 사항에 적합하지 않습니다.

따라서 인스턴스 크기를 줄이는 것이 최적의 솔루션입니다.

## 질문: 178
한 회사가 us-east-1 지역에 웹사이트를 호스팅합니다. 

이 회사는 eu-central-1 지역에 웹사이트를 배포할 준비를 하고 있습니다. 유럽에 있는 웹사이트 방문자는 eu-central-1에 호스팅된 웹사이트에 액세스해야 합니다. 다른 모든 방문자는 us-east-1에 호스팅된 웹사이트에 액세스합니다. 이 회사는 Amazon Route 53을 사용하여 웹사이트의 DNS 레코드를 관리합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 Route 53 레코드 세트에 어떤 라우팅 정책을 적용해야 합니까?

1. 지리적 위치 라우팅 정책
2. 지근거리 라우팅 정책
3. 지연 라우팅 정책
4. 다중값 답변 라우팅 정책

회사의 요구 사항을 충족하기 위해 적용해야 할 Amazon Route 53 라우팅 정책은 **1. 지리적 위치 라우팅 정책**입니다.

### 이유:
- **지리적 위치 라우팅 정책**을 사용하면 사용자 위치(대륙, 국가, 또는 주)에 따라 DNS 요청을 특정 리전으로 라우팅할 수 있습니다. 이 경우 유럽에 있는 방문자를 **eu-central-1** 리전에 호스팅된 웹사이트로 라우팅하고, 그 외 지역 방문자는 **us-east-1**에 있는 웹사이트로 라우팅할 수 있습니다. 이는 정확하게 요구 사항에 부합합니다.

### 다른 선택지 설명:
2. **지근거리 라우팅 정책**: 이 정책은 사용자의 물리적 위치와 여러 AWS 리전 간의 네트워크 지연을 기반으로 트래픽을 라우팅합니다. 특정 리전으로의 직접 라우팅을 보장하지 않기 때문에 요구 사항에 적합하지 않습니다.
   
3. **지연 라우팅 정책**: 이 정책은 트래픽을 가장 낮은 네트워크 지연 시간을 기준으로 선택된 리전으로 라우팅합니다. 특정 지역(유럽)에 대한 트래픽 제어를 요구하는 경우보다는 응답 시간에 따라 결정되므로, 요구 사항에 적합하지 않습니다.
   
4. **다중값 답변 라우팅 정책**: 이 정책은 다중 IP 주소를 반환하여 가용성을 높이지만, 특정 위치 기반 라우팅을 제공하지 않기 때문에 요구 사항에 맞지 않습니다.

따라서 **지리적 위치 라우팅 정책**이 유럽 사용자와 나머지 사용자에게 각각 다른 리전으로 트래픽을 라우팅할 수 있는 가장 적절한 방법입니다.

## 질문: 179
대규모 IT 부서가 있는 조직에서 AWS로 마이그레이션하기로 결정했습니다.
IT 부서의 직무 기능이 다르기 때문에 모든 사용자에게 모든 AWS 리소스에 대한 액세스 권한을 부여하는 것은 바람직하지 않습니다. 현재 조직은 LDAP 그룹 멤버십을 통해 액세스를 처리합니다.

현재 LDAP 자격 증명을 사용하여 액세스를 허용하는 가장 좋은 방법은 무엇입니까?

1. AWS Directory Service Simple AD를 만듭니다. 온프레미스 LDAP 디렉토리를 Simple AD로 복제합니다.
2. LDAP 그룹을 읽고 IAM 사용자 생성을 자동화하는 Lambda 함수를 만듭니다.
3. AWS CloudFormation을 사용하여 IAM 역할을 만듭니다. Direct Connect를 배포하여 온프레미스 LDAP 서버에 대한 액세스를 허용합니다.
4. SAML을 사용하여 LDAP 디렉토리를 IAM과 페더레이션합니다. 다른 LDAP 그룹에 대응하도록 다른 IAM 역할을 만들어 권한을 제한합니다.


**4. SAML을 사용하여 LDAP 디렉토리를 IAM과 페더레이션합니다. 다른 LDAP 그룹에 대응하도록 다른 IAM 역할을 만들어 권한을 제한합니다.**

### 이유:
LDAP 자격 증명을 활용하여 AWS 리소스에 대한 액세스를 관리하려면 **SAML 기반 SSO(단일 로그인)**을 사용하는 것이 가장 효과적인 방법입니다. 이를 통해 온프레미스 LDAP 디렉토리를 AWS Identity and Access Management(IAM)와 페더레이션하여 LDAP 그룹과 AWS IAM 역할을 연동할 수 있습니다. 각 LDAP 그룹에 맞게 IAM 역할을 설정하여 필요한 리소스에 대한 제한적인 액세스 권한을 부여할 수 있습니다.

### 다른 선택지 설명:
1. **AWS Directory Service Simple AD를 만듭니다. 온프레미스 LDAP 디렉토리를 Simple AD로 복제합니다**: Simple AD는 제한된 기능을 제공하며, 복제 및 동기화 작업을 수행하는 데 어려움이 있을 수 있어 LDAP와의 연동을 처리하기에는 적합하지 않습니다.

2. **LDAP 그룹을 읽고 IAM 사용자 생성을 자동화하는 Lambda 함수를 만듭니다**: 이는 수동으로 IAM 사용자를 생성하는 비효율적인 방법이며, 페더레이션과 비교했을 때 확장성이 떨어집니다.

3. **AWS CloudFormation을 사용하여 IAM 역할을 만듭니다. Direct Connect를 배포하여 온프레미스 LDAP 서버에 대한 액세스를 허용합니다**: Direct Connect는 네트워크 연결을 위한 솔루션으로, SSO와 IAM 페더레이션을 처리하기에는 적합하지 않습니다.

따라서, LDAP 디렉토리와 SAML을 사용한 IAM 페더레이션은 확장성과 관리 효율성을 모두 고려한 최적의 솔루션입니다.

## 질문: 180
SysOps 관리자가 us-east-1 지역에서 AWS CloudFormation 템플릿을 사용하여 Amazon EC2 인스턴스를 생성했습니다. 

관리자는 이 템플릿이 us-west-2 지역에서 EC2 인스턴스를 생성하지 못했다는 것을 알게 되었습니다.

이 실패의 원인 중 하나는 무엇입니까?

1. CloudFormation 템플릿에 정의된 리소스 태그는 us-east-1 지역에만 적용됩니다.
2. CloudFormation 템플릿에서 참조된 Amazon Machine Image(AMI) ID를 us-west-2 지역에서 찾을 수 없습니다.
3. cfn-init 스크립트는 us-west-2 지역에서 리소스 프로비저닝 중에 실행되지 않았습니다.
4. 지정된 지역에 IAM 사용자가 생성되지 않았습니다.

**2. CloudFormation 템플릿에서 참조된 Amazon Machine Image(AMI) ID를 us-west-2 지역에서 찾을 수 없습니다.**

### 이유:
각 AWS 지역은 고유한 Amazon Machine Image(AMI) ID를 가지고 있습니다. CloudFormation 템플릿이 특정 지역에서 AMI ID를 참조할 때, 그 AMI가 해당 지역에 존재하지 않으면 EC2 인스턴스 생성이 실패할 수 있습니다. 이 문제는 동일한 템플릿을 다른 지역에서 사용할 때 발생할 수 있습니다. AMI ID는 지역 간에 다르기 때문에, 템플릿에서 해당 지역의 AMI를 정확하게 참조해야 합니다.

### 다른 선택지 설명:
1. **CloudFormation 템플릿에 정의된 리소스 태그는 us-east-1 지역에만 적용됩니다**: 리소스 태그는 지역에 의존적이지 않으며, 리소스 태그 때문에 EC2 인스턴스 생성이 실패하지는 않습니다.

3. **cfn-init 스크립트는 us-west-2 지역에서 리소스 프로비저닝 중에 실행되지 않았습니다**: `cfn-init` 스크립트가 실행되지 않더라도 EC2 인스턴스가 생성되지만, 인스턴스 내부 설정이 완료되지 않을 수 있습니다. 그러나 인스턴스 생성 실패의 직접적인 원인은 아닙니다.

4. **지정된 지역에 IAM 사용자가 생성되지 않았습니다**: IAM 사용자는 글로벌 서비스로, 특정 지역에 종속되지 않으며 EC2 인스턴스 생성 실패의 원인이 아닙니다.

따라서, 템플릿에서 참조된 AMI ID의 지역 불일치가 실패의 가장 가능성 있는 원인입니다.

## 질문: 181
글로벌 게임 회사가 AWS에서 새로운 게임을 출시할 준비를 하고 있습니다. 

이 게임은 Amazon EC2 인스턴스의 여러 AWS 지역에서 실행됩니다. 인스턴스는 각 지역의 Application Load Balancer(ALB) 뒤에 있는 Auto Scaling 그룹에 있습니다. 이 회사는 DNS 서비스에 Amazon Route 53을 사용할 계획입니다. DNS 구성은 사용자를 가장 가까운 지역으로 안내해야 하며 자동화된 장애 조치를 제공해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Route 53을 구성하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. 각 지역의 ALB 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.
2. 각 지역의 EC2 인스턴스 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.
3. 각 지역의 EC2 인스턴스의 개인 IP 주소를 모니터링하는 상태 검사를 사용하여 Route 53 DNS 장애 조치를 구성합니다.
4. Route 53 지리적 근접 라우팅을 구성합니다. 인프라에 사용되는 지역을 지정합니다.
5. Route 53 단순 라우팅을 구성합니다. 인프라에 사용되는 대륙, 국가, 주 또는 지방을 지정합니다.


**정답:**

1. **각 지역의 ALB 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.**
   - **이유**: ALB는 Auto Scaling 그룹과 연결된 EC2 인스턴스를 대상으로 트래픽을 라우팅합니다. Route 53에서 상태 확인을 사용하여 ALB의 상태를 모니터링하면 특정 지역의 ALB에 장애가 발생할 경우 자동으로 장애 조치를 수행할 수 있습니다.

4. **Route 53 지리적 근접 라우팅을 구성합니다. 인프라에 사용되는 지역을 지정합니다.**
   - **이유**: Route 53의 **지리적 근접 라우팅**은 사용자를 물리적으로 가장 가까운 AWS 지역으로 안내하는 기능을 제공합니다. 게임 플레이어가 자신에게 가장 가까운 서버로 연결되도록 하려면 이 라우팅 정책이 적합합니다. 이는 글로벌 게임에서 지연 시간을 최소화하는 데 중요한 역할을 합니다.

### 선택지 분석:

2. **각 지역의 EC2 인스턴스 상태를 모니터링하는 Amazon CloudWatch 알람을 만듭니다. 알람을 모니터링하는 상태 확인을 사용하여 Route 53 DNS 장애 조치를 구성합니다.**
   - ALB 뒤에 있는 EC2 인스턴스는 ALB에서 이미 상태를 모니터링하고 있으므로, ALB 상태를 모니터링하는 것이 더 적합합니다. EC2 인스턴스 자체의 상태를 모니터링하는 대신, ALB 상태 확인을 사용하는 것이 더 효율적입니다.

3. **각 지역의 EC2 인스턴스의 개인 IP 주소를 모니터링하는 상태 검사를 사용하여 Route 53 DNS 장애 조치를 구성합니다.**
   - EC2 인스턴스의 개인 IP 주소는 직접적으로 Route 53 상태 검사에서 모니터링할 필요가 없습니다. 대신 ALB 뒤에 있는 EC2 인스턴스의 상태를 ALB가 모니터링하고 있으므로, ALB 상태를 모니터링하는 것이 더 적합합니다.

5. **Route 53 단순 라우팅을 구성합니다. 인프라에 사용되는 대륙, 국가, 주 또는 지방을 지정합니다.**
   - **단순 라우팅**은 사용자 요청을 고정된 단일 리소스로만 라우팅합니다. 이 게임의 경우 글로벌 사용자에게 근접한 지역으로 트래픽을 라우팅해야 하므로 적합하지 않습니다.
 - 

## 질문: 182
SysOps 관리자가 회사의 웹 애플리케이션의 성능 문제를 조사하고 있습니다. 

이 애플리케이션은 Auto Scaling 그룹에 있는 Amazon EC2 인스턴스에서 실행됩니다. 이 애플리케이션은 하루 종일 무작위로 많은 트래픽이 증가합니다. 트래픽이 빠르게 증가하는 기간 동안 Auto Scaling 그룹은 용량을 충분히 빠르게 추가하지 않습니다. 그 결과 사용자는 성능이 저하됩니다.

이 회사는 웹 트래픽이 빠르게 급증할 때 사용자 경험에 부정적인 영향을 미치지 않으면서 비용을 최소화하고자 합니다. 이 회사는 작은 트래픽 증가보다 큰 트래픽 증가에 대해 Auto Scaling 그룹에 더 많은 용량을 추가하는 솔루션이 필요합니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Auto Scaling 그룹을 어떻게 구성해야 합니까?

1. 시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 간단한 확장 정책을 만듭니다.
2. 시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 단계별 확장 정책을 만듭니다.
3. 시스템에 과부하가 걸릴 때 용량을 더 크게 조정할 수 있는 설정을 사용하여 대상 추적 확장 정책을 만듭니다.
4. Amazon EC2 Auto Scaling 라이프사이클 후크를 사용합니다. 모든 스케일링 이벤트 후 Auto Scaling 그룹의 최대 인스턴스 수를 조정합니다.

SysOps 관리자가 웹 애플리케이션의 급격한 트래픽 증가에 대응하기 위해 가장 적합한 설정은 **2. 단계별 확장 정책**을 사용하는 것입니다. 단계별 확장 정책은 트래픽 급증에 맞춰 더 많은 용량을 한 번에 추가할 수 있어 작은 트래픽 변화보다 큰 트래픽 변화에 대해 더 효과적입니다. 이 방법은 Auto Scaling 그룹이 빠르게 증가하는 트래픽에 더 빠르게 대응하고, 사용자 경험이 성능 저하로 인해 영향을 받지 않도록 합니다. 

이 방법은 비용을 최적화하면서도 큰 트래픽 급증 시 성능을 보장하는 데 유리합니다.


## 질문: 183
어떤 회사에는 보안 그룹이 SSH 포트를 모든 IP 주소에 개방할 수 없다는 규정 준수 요구 사항이 있습니다. 

SysOps 관리자는 보안 그룹 규칙이 이 요구 사항을 위반할 때 회사의 SysOps 팀에 알리는 솔루션을 구현해야 합니다. 이 솔루션은 또한 보안 그룹 규칙을 자동으로 수정해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 보안 그룹이 변경될 때 AWS Lambda 함수를 호출하는 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 보안 그룹의 규정 준수 여부를 평가하고, 모든 포트에서 모든 인바운드 보안 그룹 규칙을 제거하고, 보안 그룹이 규정을 준수하지 않는 경우 SysOps 팀에 알립니다.

2. 보안 그룹 변경 사항에 대한 AWS CloudTrail 메트릭 필터를 만듭니다. 메트릭이 0보다 클 때 Amazon Simple Notification Service(Amazon SNS) 토픽을 통해 SysOps 팀에 알리는 Amazon CloudWatch 알람을 만듭니다. AWS Lambda 함수를 SNS 토픽에 구독하여 규칙을 제거하여 보안 그룹 규칙을 수정합니다.

3. AWS Config restricted-ssh 관리 규칙을 활성화합니다. AWS Systems Manager Automation AWS-DisablePublicAccessForSecurityGroup 런북을 사용하여 AWS Config 규칙에 자동 수정을 추가합니다. 규칙이 규정을 준수하지 않을 때 SysOps 팀에 알리기 위해 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다.

4. 보안 그룹 변경에 대한 AWS CloudTrail 메트릭 필터를 만듭니다. 메트릭이 0보다 큰 경우 Amazon CloudWatch 알람을 만듭니다. 알람이 ALARM 상태일 때 Systems Manager Automation AWS-DisablePublicAccessForSecurityGroup 런북을 사용하여 보안 그룹을 일시 중단하기 위해 CloudWatch 알람에 AWS Systems Manager 작업을 추가합니다. SysOps 팀에 알리기 위해 두 번째 대상으로 Amazon Simple Notification Service(Amazon SNS) 토픽을 추가합니다.

정답은 **3. AWS Config restricted-ssh 관리 규칙을 활성화하고 AWS Systems Manager Automation AWS-DisablePublicAccessForSecurityGroup 런북을 사용하여 자동 수정을 추가하는 솔루션**입니다.

이 솔루션이 적합한 이유는 다음과 같습니다:
- **AWS Config**의 restricted-ssh 규칙은 보안 그룹에서 SSH(포트 22)를 모든 IP 주소에 개방하는 규정을 위반하는지 자동으로 평가합니다.
- **AWS Systems Manager Automation**과 함께 사용하여 규정을 위반한 보안 그룹을 자동으로 수정할 수 있습니다. AWS-DisablePublicAccessForSecurityGroup 런북을 실행하여 해당 규칙을 위반한 인바운드 규칙을 자동으로 제거합니다.
- **Amazon EventBridge**(CloudWatch Events)를 사용하여 위반 사항이 발생할 때 SysOps 팀에 알림을 보냄으로써 규정 준수를 보장할 수 있습니다.

이 솔루션은 규정 위반을 자동으로 감지하고 즉시 수정하며, SysOps 팀에 알림을 제공하는 완전한 자동화된 방식입니다.



## 질문: 184
한 회사에는 Amazon EC2 Spot Instances에서만 실행되는 애플리케이션이 있습니다. 

인스턴스는 예약된 스케일링 작업이 있는 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 그러나 용량은 항상 예약된 시간에 늘어나지 않으며 인스턴스는 하루에 여러 번 종료됩니다. SysOps 관리자는 인스턴스가 정시에 시작되고 중단이 적도록 해야 합니다.

어떤 작업이 이러한 요구 사항을 충족할까요?

1. Spot Instances에 대한 용량 최적화 할당 전략을 지정합니다. Auto Scaling 그룹에 더 많은 인스턴스 유형을 추가합니다.
2. Spot Instances에 대한 용량 최적화 할당 전략을 지정합니다. Auto Scaling 그룹의 인스턴스 크기를 늘립니다.
3. Spot Instances에 대한 최저 가격 할당 전략을 지정합니다. Auto Scaling 그룹에 더 많은 인스턴스 유형을 추가합니다.
4. Spot Instances에 대한 최저 가격 할당 전략을 지정합니다. Auto Scaling 그룹의 인스턴스 크기를 늘립니다.

정답은 **1. Spot Instances에 대한 용량 최적화 할당 전략을 지정하고 Auto Scaling 그룹에 더 많은 인스턴스 유형을 추가합니다**입니다.

이 선택이 적합한 이유는 다음과 같습니다:

- **용량 최적화 할당 전략**: 이 전략은 Amazon EC2 Spot Instances를 사용하여 인스턴스를 최대한 활용할 수 있는 용량이 높은 인스턴스를 선택합니다. 이로 인해 인스턴스가 종료되는 것을 최소화하고, 정시에 시작될 가능성을 높입니다.
  
- **더 많은 인스턴스 유형 추가**: 다양한 인스턴스 유형을 추가하면 Spot Instances에 대한 가용성을 높이고, 특정 시간에 필요한 용량을 더 잘 충족할 수 있습니다. 다양한 인스턴스 유형을 활용하면 용량이 부족할 때 대체 인스턴스 유형이 자동으로 시작될 수 있습니다.

이 조합은 인스턴스가 정시에 시작되도록 하고 중단을 최소화하는 데 도움이 됩니다.



## 질문: 185
한 회사가 Amazon Aurora MySQL DB 클러스터에 데이터베이스를 배포할 계획입니다. 

데이터베이스는 데모 환경을 위한 데이터를 저장합니다. 데이터는 매일 재설정해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. 데이터가 채워진 후 DB 클러스터의 수동 스냅샷을 만듭니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 스냅샷을 복원한 다음 이전 DB 클러스터를 삭제하도록 함수를 구성합니다.

2. DB 클러스터 생성 중에 Backtrack 기능을 활성화합니다. 48시간의 대상 백트랙 창을 지정합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 백트랙 작업을 수행하도록 함수를 구성합니다.

3. 데이터가 채워진 후 DB 클러스터의 수동 스냅샷을 Amazon S3 버킷으로 내보냅니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. Amazon S3에서 스냅샷을 복원하도록 함수를 구성합니다.

4. DB 클러스터 백업 보존 기간을 2일로 설정합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 함수를 구성하여 DB 클러스터를 특정 시점으로 복원한 다음 이전 DB 클러스터를 삭제합니다.

정답은 **4. DB 클러스터 백업 보존 기간을 2일로 설정합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만들어 매일 AWS Lambda 함수를 호출합니다. 함수를 구성하여 DB 클러스터를 특정 시점으로 복원한 다음 이전 DB 클러스터를 삭제합니다.**입니다.

### 이유:
- **자동화 및 운영 효율성**: DB 클러스터 백업 보존 기간을 2일로 설정하면 시스템이 자동으로 최신 백업을 유지하며, 필요 없는 오래된 백업을 삭제하여 스토리지 비용을 절감할 수 있습니다. 매일 Lambda 함수를 호출하여 특정 시점으로 복원하는 프로세스를 자동화하면 수동 개입이 필요 없고 효율적으로 운영할 수 있습니다.

- **신속한 데이터 재설정**: 특정 시점으로 복원하는 기능을 사용하면 매일 데이터를 쉽게 재설정할 수 있어, 데모 환경을 빠르고 쉽게 업데이트할 수 있습니다.

### 대안 검토:
1. **수동 스냅샷 후 복원 (옵션 1)**:
   - 수동으로 스냅샷을 만들고 이를 복원하는 과정은 시간이 많이 걸리고 자동화가 부족하여 운영 효율성이 떨어집니다.
   - 매일 스냅샷을 복원하고 삭제하는 작업은 관리자의 개입을 필요로 하여 오류의 가능성이 있습니다.

2. **Backtrack 기능 사용 (옵션 2)**:
   - Backtrack 기능은 이전 상태로의 복원이 가능하지만, 이 기능은 Aurora의 인스턴스가 계속 실행 중일 때만 작동합니다. 인스턴스가 정지되면 Backtrack을 사용할 수 없습니다.
   - 백트랙은 비용 효율적이지 않을 수 있으며, 48시간 동안의 창만 제공하기 때문에 완전한 유연성을 보장하지 않습니다.

3. **S3로 수동 스냅샷 내보내기 (옵션 3)**:
   - 수동 스냅샷을 S3로 내보내는 과정은 추가적인 스토리지 관리 및 복원 과정을 필요로 하여 복잡성을 증가시킵니다.
   - 매일 Lambda 함수를 통해 복원해야 하며, 이 또한 수동 개입이 필요할 수 있습니다.

### 결론:
옵션 4는 운영 효율성을 높이면서 자동화된 재설정 과정을 통해 최소한의 관리로 요구 사항을 충족할 수 있는 최적의 선택입니다.


## 질문: 186
SysOps 관리자가 기본 하드웨어 장애 발생 시 Amazon EC2 인스턴스를 복구하기 위한 자동화된 프로세스를 설정하고 있습니다. 

복구된 인스턴스는 원래 인스턴스와 동일한 개인 IP 주소와 동일한 Elastic IP 주소를 가져야 합니다. SysOps 팀은 복구 프로세스가 시작될 때 이메일 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만들고 StatusCheckFailed_Instance 메트릭을 지정합니다. 인스턴스를 복구하기 위한 EC2 작업을 알람에 추가합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하기 위한 알람 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.

2. EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만들고 StatusCheckFailed_System 메트릭을 지정합니다. 인스턴스를 복구하기 위한 EC2 작업을 알람에 추가합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하기 위한 알람 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.

3. 최소, 최대 및 원하는 크기가 1인 동일한 가용성 영역의 세 개의 서로 다른 서브넷에 걸쳐 자동 확장 그룹을 만듭니다. 개인 IP 주소와 탄력적 IP 주소를 지정하는 시작 템플릿을 사용하도록 자동 확장 그룹을 구성합니다. Amazon Simple Email Service(Amazon SES)를 통해 SysOps 팀에 이메일 메시지를 보내도록 자동 확장 그룹에 대한 활동 알림을 추가합니다.

4. 최소, 최대, 원하는 크기가 1인 3개의 가용 영역에 걸쳐 자동 확장 그룹을 만듭니다. 개인 IP 주소와 탄력적 IP 주소를 지정하는 시작 템플릿을 사용하도록 자동 확장 그룹을 구성합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 자동 확장 그룹에 대한 활동 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.
 

정답은 **1. EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만들고 StatusCheckFailed_Instance 메트릭을 지정합니다. 인스턴스를 복구하기 위한 EC2 작업을 알람에 추가합니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하기 위한 알람 알림을 추가합니다. SysOps 팀 이메일 주소를 SNS 토픽에 구독합니다.**입니다.

### 이유:
- **StatusCheckFailed_Instance 메트릭**: 이 메트릭은 인스턴스의 상태가 실패할 때 발생하며, 이는 하드웨어 장애와 관련된 경우에 해당합니다. 이 경우 인스턴스를 복구하기 위한 EC2 작업을 자동으로 트리거할 수 있습니다.
  
- **이메일 알림**: SNS 토픽을 사용하여 알림을 설정하면 SysOps 팀이 장애 발생 시 이메일로 즉시 통보받을 수 있습니다. SNS는 설정과 관리가 용이하여 팀에 신속하게 정보를 전달할 수 있습니다.

### 대안 검토:
2. **StatusCheckFailed_System 메트릭 (옵션 2)**:
   - 이 메트릭은 시스템 수준의 문제(예: 하드웨어 장애가 아니라 AWS 인프라 문제)를 나타냅니다. 주어진 시나리오에서는 인스턴스의 하드웨어 장애를 직접적으로 반영하지 않으므로 적합하지 않습니다.

3. **자동 확장 그룹 (옵션 3)**:
   - 이 방법은 기본적으로 인스턴스를 자동으로 복구할 수 있지만, 세 개의 서로 다른 서브넷에 걸쳐 인스턴스를 배포하는 것은 불필요한 복잡성을 추가할 수 있습니다. 또한, 이 방법은 하드웨어 장애 발생 시에 즉시 복구를 보장하지 않으며, 초기 IP 주소와 Elastic IP 주소를 자동으로 복구하는 데 어려움이 있을 수 있습니다.

4. **자동 확장 그룹 (옵션 4)**:
   - 이 방법은 3번 옵션과 유사하며, 기본적으로 복구 메커니즘을 제공하지만, 기본 EC2 인스턴스의 원래 IP 주소와 Elastic IP 주소를 유지하는 데 필요한 추가 설정이 요구될 수 있습니다. 이 옵션은 간단한 인스턴스 복구 요구 사항을 충족하지 못합니다.

### 결론:
옵션 1은 하드웨어 장애 발생 시 원활하게 인스턴스를 복구하고, SysOps 팀에게 이메일 알림을 통해 통지를 제공하여 요구 사항을 충족하는 가장 효율적인 솔루션입니다.


## 질문: 187
한 회사에 최근에 문제가 발생한 공개 웹사이트가 있습니다. 

일부 링크는 누락된 웹페이지로 이어졌고, 다른 링크는 잘못된 웹페이지로 이어졌습니다. 애플리케이션 인프라는 제대로 실행 중이었고, 제공된 모든 리소스는 정상이었습니다. 애플리케이션 로그와 대시보드에는 오류가 표시되지 않았고 모니터링 알람도 발생하지 않았습니다. 시스템 관리자는 최종 사용자가 문제를 보고할 때까지 문제를 알지 못했습니다.

회사는 앞으로 이러한 문제에 대해 웹사이트를 사전에 모니터링해야 하며 가능한 한 빨리 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요?

1. 문제가 발생하면 애플리케이션 로그에 사용자 지정 오류를 표시하도록 애플리케이션을 다시 작성합니다. 오류에 대한 로그를 자동으로 구문 분석합니다. 문제가 감지되면 알림을 제공하는 Amazon CloudWatch 알람을 만듭니다.
2. 웹사이트를 테스트하기 위한 AWS Lambda 함수를 만듭니다. 오류가 감지되면 Amazon CloudWatch 사용자 지정 메트릭을 내보내도록 Lambda 함수를 구성합니다. 문제가 감지되면 알림을 제공하도록 CloudWatch 알람을 구성합니다.
3. Amazon CloudWatch Synthetics 카나리아를 만듭니다. CloudWatch Synthetics Recorder 플러그인을 사용하여 카나리아 실행을 위한 스크립트를 생성합니다. 요구 사항에 따라 카나리아를 구성합니다. 문제가 감지되면 알림을 제공하는 알람을 만듭니다.
4. Amazon CloudWatch 콘솔에서 Application Insights를 켭니다. 문제가 감지되면 알림을 제공하기 위해 CloudWatch 알람을 만듭니다.

정답은 **3. Amazon CloudWatch Synthetics 카나리아를 만듭니다. CloudWatch Synthetics Recorder 플러그인을 사용하여 카나리아 실행을 위한 스크립트를 생성합니다. 요구 사항에 따라 카나리아를 구성합니다. 문제가 감지되면 알림을 제공하는 알람을 만듭니다.**입니다.

### 이유:
- **자동화된 웹사이트 모니터링**: Amazon CloudWatch Synthetics는 웹 애플리케이션을 자동으로 테스트하고 모니터링하는 기능을 제공합니다. 카나리아 스크립트를 사용하면 웹 페이지의 정상적인 동작을 주기적으로 검사할 수 있습니다. 만약 특정 링크가 누락되거나 잘못된 경우, 이를 즉시 감지하여 알림을 보낼 수 있습니다.

- **최소 운영 오버헤드**: 이 솔루션은 애플리케이션 코드를 변경할 필요 없이 기존 웹사이트를 모니터링할 수 있으며, 다른 옵션보다 관리와 유지가 간편합니다. 카나리아가 웹사이트를 테스트하므로 수동으로 모니터링할 필요가 줄어듭니다.

### 대안 검토:
1. **애플리케이션 로그에 사용자 지정 오류 표시 (옵션 1)**:
   - 애플리케이션을 다시 작성해야 하며, 이는 추가적인 개발 및 유지 관리 오버헤드를 초래합니다. 사용자가 문제를 보고하기 전에 자동으로 오류를 감지하지 않기 때문에 사전 예방적이지 않습니다.

2. **AWS Lambda 함수를 사용한 웹사이트 테스트 (옵션 2)**:
   - Lambda 함수를 사용하여 웹사이트를 테스트할 수 있지만, 이 방법은 설정 및 관리가 더 복잡할 수 있습니다. 또한, Lambda 함수가 정상 동작을 정의하기 위해 추가적인 로직을 요구할 수 있습니다.

4. **Application Insights 사용 (옵션 4)**:
   - Application Insights는 애플리케이션의 성능을 모니터링하는 데 유용하지만, 특정 웹 링크의 누락이나 잘못된 동작을 감지하는 데는 한계가 있을 수 있습니다. 이 옵션은 특정 웹 페이지의 상태를 확인하는 데 적합하지 않습니다.

### 결론:
옵션 3은 자동화된 웹사이트 모니터링을 제공하며, 카나리아 스크립트를 통해 실시간으로 웹사이트의 정상 작동 여부를 확인하여 문제를 조기에 감지할 수 있는 가장 효율적인 솔루션입니다.


## 질문: 188
SysOps 관리자는 회사의 보안 그룹을 담당합니다. 

회사는 보안 그룹에 대한 모든 변경 사항을 문서화하여 보관하고자 합니다. SysOps 관리자는 보안 그룹이 변경될 때마다 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. Amazon Detective를 설정하여 보안 그룹 변경 사항을 기록합니다. 구성 기록 로그를 저장할 Amazon CloudWatch Logs 로그 그룹을 지정합니다. 구성 변경에 대한 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 만듭니다. SysOps 관리자의 이메일 주소를 SQS 대기열에 구독합니다.

2. 보안 그룹 변경 사항을 기록하도록 AWS Systems Manager Change Manager를 설정합니다. 구성 기록 로그를 저장할 Amazon CloudWatch Logs 로그 그룹을 지정합니다. 구성 변경 사항에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.

3. 보안 그룹 변경 사항을 기록하도록 AWS Config를 설정합니다. 구성 스냅샷 및 기록 파일의 위치로 Amazon S3 버킷을 지정합니다. 구성 변경 사항에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.

4. Amazon Detective를 설정하여 보안 그룹 변경 사항을 기록합니다. 구성 스냅샷 및 기록 파일의 위치로 Amazon S3 버킷을 지정합니다. 구성 변경에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.
 
정답은 **3. 보안 그룹 변경 사항을 기록하도록 AWS Config를 설정합니다. 구성 스냅샷 및 기록 파일의 위치로 Amazon S3 버킷을 지정합니다. 구성 변경 사항에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 만듭니다. SysOps 관리자의 이메일 주소를 SNS 토픽에 구독합니다.**입니다.

### 이유:
- **AWS Config**: AWS Config는 AWS 리소스의 구성 변경 사항을 지속적으로 모니터링하고 기록하는 서비스입니다. 보안 그룹을 포함하여 모든 AWS 리소스의 상태를 추적할 수 있습니다. 변경 사항이 있을 때마다 이를 기록하고 S3에 저장할 수 있습니다.

- **구성 변경 알림**: AWS Config는 구성 변경 사항을 감지하여 SNS 토픽에 알림을 보낼 수 있습니다. SysOps 관리자는 해당 SNS 토픽을 구독하여 이메일로 즉시 알림을 받을 수 있습니다.

- **운영 효율성**: AWS Config는 변경 사항에 대한 상세한 이력을 제공하므로, 문서화와 보관의 요구 사항을 충족하는 데 유리합니다. 또한 설정이 비교적 간단하여 운영 오버헤드를 최소화할 수 있습니다.

### 대안 검토:
1. **Amazon Detective 사용 (옵션 1 & 4)**:
   - Amazon Detective는 보안 및 규정 준수를 위한 분석 서비스로, 보안 그룹 변경 사항 기록에 적합하지 않습니다. 변경 사항을 문서화하는 기능이 기본적으로 제공되지 않습니다.

2. **AWS Systems Manager Change Manager 사용 (옵션 2)**:
   - Change Manager는 변경 관리에 유용하지만, AWS Config보다 더 많은 설정과 관리가 필요합니다. 보안 그룹 변경 사항에 대한 직접적인 추적 및 알림 기능은 AWS Config에 비해 제한적입니다.

### 결론:
옵션 3은 AWS 리소스의 변경 사항을 효과적으로 모니터링하고 문서화할 수 있는 가장 적합한 솔루션입니다. AWS Config를 활용하면 보안 그룹의 변경 사항을 기록하고, 변경 시 즉각적인 알림을 받을 수 있어 운영 효율성을 높일 수 있습니다.



## 질문: 189
전자상거래 회사가 Amazon Aurora DB 클러스터를 사용하는 웹 애플리케이션을 구축했습니다. 

DB 클러스터에는 작성자 노드와 판독자 노드가 모두 있는 메모리 최적화 인스턴스 유형이 포함됩니다. 트래픽 볼륨은 하루 종일 변합니다. 트래픽이 갑자기 급증하는 동안 DB 클러스터에 대한 Amazon CloudWatch 메트릭은 높은 RAM 소비와 선택 대기 시간 증가를 나타냅니다.

SysOps 관리자는 DB 클러스터의 성능을 개선하기 위해 구성 변경을 구현해야 합니다. 변경은 다운타임을 최소화해야 하며 데이터 손실로 이어져서는 안 됩니다.

어떤 변경이 이러한 요구 사항을 충족할까요?

1. DB 클러스터에 Aurora Replica를 추가합니다.
2. DB 클러스터를 수정하여 DB 클러스터를 멀티 마스터 DB 클러스터로 변환합니다.
3. DB 클러스터의 스냅샷을 찍습니다. 해당 스냅샷에서 더 큰 메모리 최적화 인스턴스를 가진 새 DB 클러스터를 만듭니다.
4. DB 클러스터의 디스크 저장 용량을 기존 디스크 용량의 두 배로 늘립니다.

정답은 **1. DB 클러스터에 Aurora Replica를 추가합니다.**입니다.

### 이유:
1. **Aurora Replica 추가**: Aurora Replica를 추가하면 읽기 성능을 향상시킬 수 있습니다. 높은 트래픽이 발생할 때 읽기 작업을 여러 인스턴스에 분산할 수 있으므로 선택 대기 시간과 RAM 소비를 줄이는 데 효과적입니다. 이는 다운타임 없이 추가할 수 있으며, 데이터 손실을 초래하지 않습니다.

2. **구성 변경의 영향**: Aurora Replica는 기본 작성자 노드의 데이터에 실시간으로 복제되므로 데이터 손실 없이 성능을 개선하는 안전한 방법입니다. 이 방법은 트래픽이 급증할 때 응답성을 유지하는 데 매우 유용합니다.

### 대안 검토:
2. **DB 클러스터를 멀티 마스터로 변환**:
   - 멀티 마스터 DB 클러스터는 쓰기 작업에 대해 더 나은 성능을 제공할 수 있지만, 이는 복잡한 구성 변경을 요구하며, 다운타임이나 데이터 손실의 위험이 있습니다. 또한 멀티 마스터 환경에서는 충돌 관리가 필요할 수 있습니다.

3. **스냅샷에서 새 DB 클러스터 생성**:
   - 이 방법은 더 큰 인스턴스를 사용할 수 있도록 하지만, 스냅샷을 찍고 새 클러스터를 만드는 동안 상당한 다운타임이 발생할 수 있으며, 데이터 손실 위험이 존재합니다. 이는 애플리케이션의 지속적인 가용성을 보장하지 않습니다.

4. **디스크 저장 용량을 두 배로 늘리기**:
   - 디스크 용량을 늘리는 것은 성능 향상에 기여하지 않으며, RAM 소비와 선택 대기 시간을 해결하는 데 도움이 되지 않습니다. 추가 디스크 용량은 읽기 성능 향상과는 관련이 없습니다.

### 결론:
DB 클러스터에 Aurora Replica를 추가하는 것은 성능을 개선하고, 다운타임과 데이터 손실 없이 높은 트래픽을 처리하는 효과적인 솔루션입니다. 이 방법은 읽기 작업을 분산시켜 시스템의 전반적인 성능을 향상시킬 수 있습니다.


## 질문: 190
한 회사에는 eu-west-2 지역의 Elastic Load Balancer 뒤에 있는 일련의 Amazon EC2 인스턴스에서 실행되는 간단한 웹 애플리케이션이 있습니다. 

Amazon Route 53은 간단한 라우팅 정책으로 애플리케이션에 대한 DNS 레코드를 보관합니다. 전 세계의 사용자가 웹 브라우저를 통해 애플리케이션에 액세스합니다.

이 회사는 us-east-1 지역과 ap-south-1 지역에 애플리케이션의 추가 사본을 만들어야 합니다. 이 회사는 사용자가 애플리케이션을 로드할 때 가장 빠른 응답 시간을 제공하는 지역으로 사용자를 안내해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. 각각의 새로운 지역에서 새로운 Elastic Load Balancer와 새로운 EC2 인스턴스 세트를 만들어 애플리케이션 사본을 실행합니다. 지리적 위치 라우팅 정책으로 전환합니다.
2. 각 새 지역에서 새 EC2 인스턴스에 애플리케이션 사본을 만듭니다. 이 새 EC2 인스턴스를 eu-west-2의 Elastic Load Balancer에 추가합니다. 대기 시간 라우팅 정책으로 전환합니다.
3. 각 새 지역에서 새 EC2 인스턴스에 애플리케이션 사본을 만듭니다. 이 새 EC2 인스턴스를 eu-west-2의 Elastic Load Balancer에 추가합니다. 다중값 라우팅 정책으로 전환합니다.
4.  각각의 새로운 지역에서 새로운 Elastic Load Balancer와 새로운 EC2 인스턴스 세트를 만들어 애플리케이션 사본을 실행합니다. 대기 시간 라우팅 정책으로 전환합니다.

정답은 **4. 각각의 새로운 지역에서 새로운 Elastic Load Balancer와 새로운 EC2 인스턴스 세트를 만들어 애플리케이션 사본을 실행합니다. 대기 시간 라우팅 정책으로 전환합니다.**입니다.

### 이유:
1. **Elastic Load Balancer 및 EC2 인스턴스 세트 생성**: us-east-1과 ap-south-1 지역에 각각의 새로운 Elastic Load Balancer와 EC2 인스턴스 세트를 만드는 것은 애플리케이션의 추가 사본을 실행하기 위한 필수 단계입니다. 이렇게 하면 각 지역에서 로드 밸런싱 및 가용성을 관리할 수 있습니다.

2. **대기 시간 라우팅 정책**: 대기 시간 라우팅 정책을 사용하면 Route 53이 사용자의 DNS 요청을 처리할 때 가장 짧은 응답 시간을 가진 리전으로 요청을 라우팅할 수 있습니다. 이는 전 세계의 사용자에게 최적의 응답 시간을 제공하는 데 효과적입니다.

### 대안 검토:
1. **지리적 위치 라우팅 정책으로 전환**:
   - 지리적 위치 라우팅 정책은 사용자의 IP 주소에 따라 요청을 특정 리전으로 라우팅합니다. 이는 사용자에게 가장 가까운 리전으로 연결할 수 있지만, 사용자의 대기 시간을 고려하지는 않으므로 응답 시간을 최적화하는 데 적합하지 않을 수 있습니다.

2. **기존 Elastic Load Balancer에 추가**:
   - eu-west-2의 Elastic Load Balancer에 새 EC2 인스턴스를 추가하는 것은 비효율적입니다. 여러 지역에서 실행되는 애플리케이션의 경우, 각 지역에 해당 지역에 맞는 로드 밸런서를 사용하는 것이 더 효과적입니다.

3. **다중값 라우팅 정책으로 전환**:
   - 다중값 라우팅 정책은 여러 리소스를 반환할 수 있지만, 최적의 응답 시간을 보장하지 않습니다. 이는 로드 밸런서가 여러 리소스를 반환하도록 하여 로드 분산을 가능하게 하지만, 대기 시간이 가장 짧은 리전으로 라우팅되지 않을 수 있습니다.

### 결론:
각각의 새로운 지역에서 새로운 Elastic Load Balancer와 EC2 인스턴스 세트를 생성하고, 대기 시간 라우팅 정책으로 전환함으로써 전 세계 사용자에게 최적의 응답 시간을 제공할 수 있는 효율적인 솔루션이 됩니다.


## 질문: 191
회사가 AWS Organizations를 사용하여 새 멤버 계정을 만듭니다. 

SysOps 관리자는 새 계정에 AWS Business Support를 추가해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

1. IAM 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다.
2. 루트 사용자 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다.
3. AWS Support API를 사용하여 지원 플랜을 변경하세요.
4. 루트 사용자 계정의 비밀번호를 재설정합니다.
5. 새 계정에서 관리자 권한이 있는 IAM 사용자를 만듭니다.

AWS Organizations를 사용하여 새 멤버 계정을 만들고 AWS Business Support를 추가하기 위해 SysOps 관리자가 취해야 할 단계 조합은 다음과 같습니다:

### 정답
1. **IAM 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다.**
2. **AWS Support API를 사용하여 지원 플랜을 변경하세요.**

### 이유
1. **IAM 자격 증명을 사용하여 새 계정에 로그인**: 새 계정에 대한 IAM 사용자를 설정하고, 해당 사용자로 로그인하여 지원 계획을 변경하는 것이 가능하다면, 이 방법이 일반적으로 더 안전하고 권장됩니다. 루트 사용자 대신 IAM 사용자를 사용하는 것은 보안 모범 사례입니다.

2. **AWS Support API를 사용하여 지원 플랜을 변경**: AWS Support API를 통해 프로그래매틱하게 지원 계획을 변경할 수 있습니다. 이를 통해 자동화된 스크립트나 애플리케이션에서 지원 계획을 쉽게 조정할 수 있습니다.

### 선택하지 않은 옵션 검토
- **루트 사용자 자격 증명을 사용하여 새 계정에 로그인합니다. 지원 계획을 변경합니다**: 루트 사용자 자격 증명으로 로그인하여 지원 계획을 변경할 수 있지만, 이는 보안 모범 사례에 맞지 않습니다. 루트 사용자 계정은 중요한 작업에만 사용해야 하며, 가능한 한 사용을 피하는 것이 좋습니다.

- **루트 사용자 계정의 비밀번호를 재설정합니다**: 이 단계는 지원 계획을 변경하는 것과 직접적인 관련이 없습니다. 비밀번호 재설정은 특정 필요에 따라 수행할 수 있지만, 이 요구 사항에 대해서는 필요하지 않습니다.

- **새 계정에서 관리자 권한이 있는 IAM 사용자를 만듭니다**: 관리자 권한이 있는 IAM 사용자를 만드는 것은 유용할 수 있지만, 기존의 IAM 사용자로 로그인하여 지원 계획을 변경할 수 있기 때문에 꼭 필요한 단계는 아닙니다.

### 결론
따라서, 새 계정에 로그인하여 지원 계획을 변경하고, AWS Support API를 사용하여 지원 플랜을 조정하는 것이 최선의 접근 방식입니다.


## 질문: 192
SysOps 관리자가 회사의 AWS 계정에 두 개의 VPC(VPC1 및 VPC2)를 만듭니다. 

SysOps 관리자가 VPC1에 Linux Amazon EC2 인스턴스를 배포하고 VPC2에 Amazon RDS for MySQL DB 인스턴스를 배포합니다. DB 인스턴스는 프라이빗 서브넷에 배포됩니다. EC2 인스턴스에서 실행되는 애플리케이션은 데이터베이스에 연결해야 합니다.

SysOps 관리자는 EC2 인스턴스가 데이터베이스에 연결할 수 있도록 하기 위해 무엇을 해야 합니까?

1. DB 인스턴스 연결 문자열을 VPC1 경로 테이블에 입력합니다.
2. 두 VPC 간에 VPC 피어링을 구성합니다.
3. 두 VPC에 동일한 IPv4 CIDR 범위를 추가합니다.
4. DB 인스턴스의 공용 IP 주소를 사용하여 DB 인스턴스에 연결합니다.

SysOps 관리자가 EC2 인스턴스가 VPC2에 있는 Amazon RDS for MySQL DB 인스턴스에 연결할 수 있도록 하기 위해 필요한 조치는 다음과 같습니다:

### 정답
**2. 두 VPC 간에 VPC 피어링을 구성합니다.**

### 이유
- **VPC 피어링**: VPC 피어링을 설정하면 두 VPC 간에 직접 통신할 수 있는 연결이 생성됩니다. 이를 통해 VPC1의 EC2 인스턴스가 VPC2에 있는 RDS 인스턴스에 직접 연결할 수 있게 됩니다. VPC 피어링은 프라이빗 IP 주소를 사용하여 통신하므로, 보안과 성능 측면에서도 최선의 선택입니다.

### 선택하지 않은 옵션 검토
1. **DB 인스턴스 연결 문자열을 VPC1 경로 테이블에 입력합니다**: 경로 테이블에 연결 문자열을 입력하는 것은 잘못된 접근 방식입니다. 연결 문자열은 애플리케이션에서 데이터베이스에 접근하는 방법을 나타내지만, VPC 간의 연결을 설정하는 데는 도움이 되지 않습니다.

2. **두 VPC에 동일한 IPv4 CIDR 범위를 추가합니다**: 서로 다른 VPC 간에 동일한 CIDR 범위를 사용하는 것은 불가능합니다. 두 VPC는 서로 다른 CIDR 범위를 가져야 합니다.

3. **DB 인스턴스의 공용 IP 주소를 사용하여 DB 인스턴스에 연결합니다**: RDS 인스턴스가 프라이빗 서브넷에 배포된 경우, 공용 IP 주소를 사용하여 연결할 수 없습니다. EC2 인스턴스는 VPC2의 RDS 인스턴스에 접근하기 위해 VPC 피어링이나 다른 연결 방법이 필요합니다.

### 결론
따라서, **두 VPC 간에 VPC 피어링을 구성하는 것이 EC2 인스턴스가 RDS 데이터베이스에 연결할 수 있도록 하는 올바른 방법입니다.**


## 질문: 193
한 회사가 Amazon S3 버킷을 사용하여 데이터 파일을 저장합니다. 

S3 버킷에는 수백 개의 객체가 들어 있습니다. 이 회사는 S3 버킷의 모든 객체에 있는 태그를 다른 태그로 교체해야 합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

1. S3 배치 작업을 사용합니다. 모든 객체 태그를 대체할 작업을 지정합니다.
2. AWS CLI를 사용하여 각 객체의 태그를 가져옵니다. 태그를 목록에 저장합니다. S3 Batch Operations를 사용합니다. 모든 객체 태그를 삭제하는 작업을 지정합니다. AWS CLI와 목록을 사용하여 객체에 태그를 다시 지정합니다.
3. AWS CLI를 사용하여 각 객체의 태그를 가져옵니다. 태그를 목록에 저장합니다. AWS CLI와 목록을 사용하여 객체 태그를 제거합니다. AWS CLI와 목록을 사용하여 객체에 태그를 다시 지정합니다.
4. AWS CLI를 사용하여 객체를 다른 S3 버킷으로 복사합니다. 복사된 객체에 새 태그를 추가합니다. 원래 객체를 삭제합니다.


회사가 Amazon S3 버킷의 모든 객체에 있는 태그를 다른 태그로 교체해야 할 때 가장 운영 효율적인 방법은 다음과 같습니다:

### 정답
**1. S3 배치 작업을 사용합니다. 모든 객체 태그를 대체할 작업을 지정합니다.**

### 이유
- **S3 배치 작업**: S3 배치 작업을 사용하면 여러 객체에 대한 태그 작업을 동시에 수행할 수 있습니다. 이를 통해 태그를 효율적으로 관리할 수 있으며, 특히 수백 개의 객체가 있을 때 매우 유용합니다. 이 방법은 API 호출 수를 줄이고 작업을 자동화하여 운영 효율성을 높입니다.

### 선택하지 않은 옵션 검토
2. **AWS CLI를 사용하여 각 객체의 태그를 가져옵니다. 태그를 목록에 저장합니다. S3 Batch Operations를 사용합니다. 모든 객체 태그를 삭제하는 작업을 지정합니다. AWS CLI와 목록을 사용하여 객체에 태그를 다시 지정합니다**:
   - 이 방법은 비효율적입니다. 모든 객체의 태그를 삭제한 후 다시 추가하는 과정을 거쳐야 하므로, 작업이 더 복잡하고 시간이 많이 소요됩니다.

3. **AWS CLI를 사용하여 각 객체의 태그를 가져옵니다. 태그를 목록에 저장합니다. AWS CLI와 목록을 사용하여 객체 태그를 제거합니다. AWS CLI와 목록을 사용하여 객체에 태그를 다시 지정합니다**:
   - 이 방법도 비효율적입니다. 각 객체에 대해 여러 번의 API 호출을 수행해야 하므로 운영 오버헤드가 증가합니다.

4. **AWS CLI를 사용하여 객체를 다른 S3 버킷으로 복사합니다. 복사된 객체에 새 태그를 추가합니다. 원래 객체를 삭제합니다**:
   - 이 방법은 필요 없는 객체 복사를 포함하여 리소스를 낭비할 수 있습니다. 또한 데이터 손실의 위험이 있으며, 작업이 복잡해질 수 있습니다.

### 결론
따라서, **S3 배치 작업을 사용하여 모든 객체 태그를 대체하는 것이 가장 운영 효율적인 방법입니다.**


## 질문: 194
회사에서 여러 Amazon EC2 인스턴스에서 실행 중인 애플리케이션의 인벤토리를 작성해야 합니다. 


회사에서는 AWS Systems Manager에 대한 적절한 권한이 있는 사용자와 역할을 구성했습니다. Systems Manager Agent의 업데이트된 버전이 설치되어 모든 인스턴스에서 실행 중입니다. 인벤토리 컬렉션을 구성하는 동안 SysOps 관리자는 단일 서브넷의 모든 인스턴스가 Systems Manager에서 관리되지 않는다는 사실을 발견했습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1. 모든 EC2 인스턴스에 Systems Manager 액세스에 대한 올바른 태그가 있는지 확인하세요.
2. AWS Identity and Access Management Access Analyzer를 구성하여 문제를 파악하고 자동으로 해결합니다.
3. 모든 EC2 인스턴스에 Systems Manager 액세스 권한이 있는 인스턴스 프로필이 있는지 확인하세요.
4. Systems Manager를 구성하여 인터페이스 VPC 엔드포인트를 사용합니다.

SysOps 관리자가 여러 Amazon EC2 인스턴스에서 실행 중인 애플리케이션의 인벤토리를 작성하려고 할 때, 단일 서브넷의 모든 인스턴스가 AWS Systems Manager에서 관리되지 않는 문제를 해결하기 위해 가장 적절한 조치는 다음과 같습니다:

### 정답
**3. 모든 EC2 인스턴스에 Systems Manager 액세스 권한이 있는 인스턴스 프로필이 있는지 확인하세요.**

### 이유
- **인스턴스 프로필**: Systems Manager 에이전트가 EC2 인스턴스와 통신할 수 있도록 하려면 해당 인스턴스에 적절한 IAM 역할(인스턴스 프로필)을 할당해야 합니다. 이 역할에는 Systems Manager와 관련된 API 호출을 허용하는 정책이 포함되어야 합니다. 따라서 모든 EC2 인스턴스에 Systems Manager 액세스 권한이 있는 인스턴스 프로필이 있는지 확인하는 것이 중요합니다.

### 선택하지 않은 옵션 검토
1. **모든 EC2 인스턴스에 Systems Manager 액세스에 대한 올바른 태그가 있는지 확인하세요**:
   - 태그는 인스턴스에 대한 관리 및 검색을 도와주지만, Systems Manager 에이전트의 작동과는 직접적인 관련이 없습니다. 따라서 태그 확인만으로는 문제를 해결할 수 없습니다.

2. **AWS Identity and Access Management Access Analyzer를 구성하여 문제를 파악하고 자동으로 해결합니다**:
   - Access Analyzer는 리소스에 대한 액세스 권한을 분석하는 도구입니다. 하지만 인스턴스가 Systems Manager에서 관리되지 않는 이유를 해결하는 데는 직접적인 도움이 되지 않습니다.

4. **Systems Manager를 구성하여 인터페이스 VPC 엔드포인트를 사용합니다**:
   - 인터페이스 VPC 엔드포인트를 사용하는 것은 네트워크 연결의 안정성을 높일 수 있지만, 인스턴스에 적절한 IAM 역할이 없으면 여전히 문제가 발생할 수 있습니다. 따라서 이 조치는 문제를 해결하기 위한 근본적인 접근이 아닙니다.

### 결론
따라서, **모든 EC2 인스턴스에 Systems Manager 액세스 권한이 있는 인스턴스 프로필이 있는지 확인하는 것이 가장 효과적인 해결책입니다.**


## 질문: 195
한 회사가 Amazon S3 버킷에 민감한 데이터를 저장합니다. 

회사는 S3 버킷에 대한 모든 액세스 시도를 기록해야 합니다. 회사의 위험 팀은 모든 삭제 이벤트에 대한 즉각적인 알림을 받아야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 감사 로그에 대한 S3 서버 액세스 로깅을 활성화합니다. S3 버킷에 대한 Amazon Simple Notification Service(Amazon SNS) 알림을 설정합니다. 알림 시스템의 이벤트 유형에 대해 DeleteObject를 선택합니다.

2. 감사 로그에 대한 S3 서버 액세스 로깅을 활성화합니다. 알림 시스템에 대한 Amazon EC2 인스턴스를 시작합니다. EC2 인스턴스에서 cron 작업을 실행하여 매일 액세스 로그를 다운로드하고 DeleteObject 이벤트를 스캔합니다.

3. 감사 로그에는 Amazon CloudWatch Logs를 사용합니다. 알림 시스템에는 Amazon Simple Notification Service(Amazon SNS) 알림과 함께 Amazon CloudWatch 알람을 사용합니다.

4. 감사 로그에는 Amazon CloudWatch Logs를 사용합니다. 알림 시스템에 Amazon EC2 인스턴스를 시작합니다. 매일 EC2 인스턴스에서 cron 작업을 실행하여 항목 목록을 전날 목록과 비교합니다. 항목이 누락된 경우 알림을 보내도록 cron 작업을 구성합니다.

회사가 Amazon S3 버킷에 민감한 데이터를 저장하고 모든 액세스 시도를 기록하며 삭제 이벤트에 대한 즉각적인 알림을 필요로 할 때, 가장 적절한 솔루션은 다음과 같습니다:

### 정답
**1. 감사 로그에 대한 S3 서버 액세스 로깅을 활성화합니다. S3 버킷에 대한 Amazon Simple Notification Service(Amazon SNS) 알림을 설정합니다. 알림 시스템의 이벤트 유형에 대해 DeleteObject를 선택합니다.**

### 이유
- **S3 서버 액세스 로깅**: 이 기능을 활성화하면 S3 버킷에 대한 모든 요청이 로그로 기록됩니다. 이를 통해 민감한 데이터에 대한 모든 액세스를 추적할 수 있습니다.
- **SNS 알림**: Amazon SNS를 사용하여 삭제 이벤트(즉, `DeleteObject`)에 대한 알림을 설정하면 위험 팀이 즉각적으로 삭제 이벤트를 인지할 수 있습니다. 이는 자동화된 경고 시스템으로, 비즈니스 요구 사항에 잘 부합합니다.

### 선택하지 않은 옵션 검토
2. **S3 서버 액세스 로깅을 활성화하고 EC2 인스턴스를 사용하여 cron 작업을 설정**:
   - 이 방법은 수동적인 접근 방식이며, 삭제 이벤트를 즉각적으로 알리는 대신 매일 다운로드하여 스캔하는 방식으로, 실시간 모니터링을 제공하지 않습니다.

3. **Amazon CloudWatch Logs를 사용하고 SNS 알림과 CloudWatch 알람을 설정**:
   - CloudWatch Logs는 훌륭한 로그 수집 및 분석 도구이지만, S3 서버 액세스 로깅과 SNS를 직접적으로 연결하는 방식은 아닙니다. S3의 액세스를 실시간으로 모니터링하기 위해서는 S3의 내장 기능을 활용하는 것이 더 효과적입니다.

4. **CloudWatch Logs를 사용하고 EC2 인스턴스에서 cron 작업을 실행**:
   - 이 방법은 역시 수동적인 접근이며, 누락된 항목을 비교하는 방법으로 즉각적인 알림을 제공하지 않습니다. 시스템에 추가적인 부하를 주고, 복잡성을 증가시킵니다.

### 결론
따라서, **S3 서버 액세스 로깅을 활성화하고 SNS를 통해 삭제 이벤트에 대한 즉각적인 알림을 설정하는 것이 가장 효율적이고 효과적인 솔루션입니다.**


## 질문: 196
SysOps 관리자가 Amazon GuardDuty로부터 Amazon EC2 인스턴스에서 의심스러운 네트워크 활동에 대한 알림을 받습니다. 

GuardDuty 발견 사항은 트래픽 대상으로 새 외부 IP 주소를 나열합니다. SysOps 관리자는 외부 IP 주소를 인식하지 못합니다. SysOps 관리자는 GuardDuty가 식별한 외부 IP 주소로의 트래픽을 차단해야 합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

1. 외부 IP 주소로의 트래픽을 차단하기 위해 새 보안 그룹을 만듭니다. 새 보안 그룹을 EC2 인스턴스에 할당합니다.
2. Amazon Athena에서 VPC 흐름 로그를 사용하여 외부 IP 주소로의 트래픽을 차단합니다.
3. 네트워크 ACL을 만듭니다. 외부 IP 주소로의 트래픽에 대한 아웃바운드 거부 규칙을 추가합니다.
4. 외부 IP 주소로의 트래픽을 차단하기 위해 새 보안 그룹을 만듭니다. 새 보안 그룹을 전체 VPC에 할당합니다.
 
SysOps 관리자가 Amazon GuardDuty에서 의심스러운 네트워크 활동에 대한 알림을 받고 외부 IP 주소로의 트래픽을 차단해야 할 경우, 가장 적절한 솔루션은 다음과 같습니다:

### 정답
**3. 네트워크 ACL을 만듭니다. 외부 IP 주소로의 트래픽에 대한 아웃바운드 거부 규칙을 추가합니다.**

### 이유
- **네트워크 ACL (Access Control List)**: VPC에서 서브넷 수준에서 트래픽을 제어하는 방법입니다. ACL은 아웃바운드 및 인바운드 트래픽에 대해 규칙을 설정할 수 있으며, 특정 외부 IP 주소로의 트래픽을 차단하는 데 효과적입니다. 이는 모든 EC2 인스턴스에 적용되므로, 네트워크 레벨에서 추가적인 보안을 제공합니다.

### 선택하지 않은 옵션 검토
1. **새 보안 그룹을 만들고 EC2 인스턴스에 할당**:
   - 보안 그룹은 인스턴스 수준에서 작동하며, 아웃바운드 트래픽에 대한 기본 허용 규칙이 있기 때문에 이 방법은 이미 설정된 규칙을 변경하지 않는 한, 외부 IP 주소로의 트래픽을 차단하는 데 적합하지 않습니다.

2. **Amazon Athena에서 VPC 흐름 로그를 사용**:
   - Athena는 데이터 쿼리 및 분석 도구이며, VPC 흐름 로그를 조회하는 데 사용할 수 있지만, 직접적으로 트래픽을 차단하는 방법이 아닙니다. 로그를 분석하는 것은 중요하지만, 실시간 차단을 제공하지 않습니다.

4. **새 보안 그룹을 만들고 전체 VPC에 할당**:
   - 보안 그룹은 특정 인스턴스에만 적용할 수 있으며, 전체 VPC에 보안 그룹을 할당할 수 없습니다. 또한, 보안 그룹은 기본적으로 모든 아웃바운드 트래픽을 허용하므로, 이 방법으로는 외부 IP 주소로의 트래픽을 차단할 수 없습니다.

### 결론
따라서, **네트워크 ACL을 사용하여 외부 IP 주소로의 아웃바운드 트래픽을 차단하는 것이 가장 효율적이고 효과적인 솔루션입니다.**



## 질문: 197
15분이 걸리던 회사의 보고 작업이 이제 1시간이 걸립니다. 애플리케이션이 보고서를 생성합니다. 


이 애플리케이션은 Amazon EC2 인스턴스에서 실행되고 Amazon RDS for MySQL 데이터베이스에서 데이터를 추출합니다.

SysOps 관리자가 RDS 인스턴스의 Amazon CloudWatch 대시보드를 확인하고 보고서가 실행되지 않을 때에도 Read IOPS 메트릭이 높다는 것을 알아챘습니다. SysOps 관리자는 RDS 인스턴스의 성능과 가용성을 개선해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. RDS 인스턴스 앞에 Amazon ElastiCache 클러스터를 구성합니다. ElastiCache 클러스터를 쿼리하도록 보고 작업을 업데이트합니다.
2. RDS 읽기 복제본을 배포합니다. 보고 작업을 업데이트하여 리더 엔드포인트를 쿼리합니다.
3. Amazon CloudFront 배포를 만듭니다. RDS 인스턴스를 원본으로 설정합니다. CloudFront 배포를 쿼리하도록 보고 작업을 업데이트합니다.
4. RDS 인스턴스의 크기를 늘립니다.
 

보고 작업이 15분에서 1시간으로 늘어났고, Amazon RDS for MySQL의 Read IOPS 메트릭이 높다는 것은 데이터베이스의 성능 문제를 나타냅니다. SysOps 관리자는 RDS 인스턴스의 성능과 가용성을 개선하기 위해 다음과 같은 솔루션을 고려할 수 있습니다.

### 정답
**2. RDS 읽기 복제본을 배포합니다. 보고 작업을 업데이트하여 리더 엔드포인트를 쿼리합니다.**

### 이유
- **읽기 복제본 사용**: RDS 읽기 복제본은 데이터베이스의 읽기 전용 복사본을 생성하여 읽기 작업의 부하를 분산시킬 수 있습니다. 보고 작업이 RDS 인스턴스에서 데이터를 읽는 경우, 읽기 복제본을 사용하면 원본 RDS 인스턴스의 부하를 줄이고 성능을 개선할 수 있습니다. 따라서 RDS 인스턴스가 더 나은 성능을 제공할 수 있도록 할 수 있습니다.

### 선택하지 않은 옵션 검토
1. **RDS 인스턴스 앞에 Amazon ElastiCache 클러스터를 구성**:
   - ElastiCache는 캐시 계층을 추가하여 데이터베이스 쿼리의 일부를 캐시할 수 있도록 도와주지만, 보고서 작업이 데이터베이스에 대해 읽기 작업을 많이 수행한다면, 읽기 복제본이 더 효과적일 수 있습니다. ElastiCache는 캐싱을 활용하여 성능을 향상시킬 수 있으나, 데이터베이스의 전체 부하를 완화하는 데는 한계가 있습니다.

3. **Amazon CloudFront 배포를 만듭니다**:
   - CloudFront는 콘텐츠 전송 네트워크(CDN)로, 주로 정적 자산을 캐시하고 전송하는 데 사용됩니다. 데이터베이스 쿼리를 위해 CloudFront를 사용하는 것은 적합하지 않습니다.

4. **RDS 인스턴스의 크기를 늘리기**:
   - 인스턴스의 크기를 늘리는 것은 성능을 개선할 수 있지만, 이는 비용이 더 많이 들고 다운타임이 발생할 수 있습니다. 또한, 이미 높은 Read IOPS를 사용하고 있다면 단순히 인스턴스를 늘리는 것만으로는 문제를 근본적으로 해결하지 못할 수 있습니다.

### 결론
따라서 **RDS 읽기 복제본을 배포하고 보고 작업을 업데이트하여 리더 엔드포인트를 쿼리하는 것이 가장 효과적인 솔루션입니다.** 이를 통해 데이터베이스의 부하를 줄이고 보고서 생성 성능을 향상시킬 수 있습니다.


## 질문: 198
회사의 SysOps 관리자는 회사의 각 계정에서 AWS Personal Health Dashboard를 정기적으로 확인합니다. 

계정은 AWS Organizations의 조직에 속합니다. 회사는 최근 조직에 10개의 계정을 추가했습니다. SysOps 관리자는 각 계정의 Personal Health Dashboard에서 알림을 통합해야 합니다.

어떤 솔루션이 최소한의 노력으로 이 요구 사항을 충족할까요?

1. AWS Health에서 조직 보기를 활성화합니다.
2. 각 계정의 개인 건강 대시보드를 구성하여 이벤트를 중앙 AWS CloudTrail 로그로 전달합니다.
3. AWS Health API를 쿼리하고 모든 이벤트를 Amazon DynamoDB 테이블에 기록하는 AWS Lambda 함수를 생성합니다.
4. AWS Health API를 사용하여 Amazon DynamoDB 테이블에 이벤트를 기록합니다.

AWS Personal Health Dashboard의 알림을 통합하기 위해 SysOps 관리자가 선택할 수 있는 최적의 솔루션은 다음과 같습니다.

### 정답
**1. AWS Health에서 조직 보기를 활성화합니다.**

### 이유
- **조직 보기를 활성화하면**: AWS Organizations의 모든 계정에서 발생하는 개인 건강 이벤트를 중앙에서 모니터링할 수 있습니다. 이를 통해 각 계정에서 별도로 Personal Health Dashboard를 확인할 필요 없이 한 곳에서 모든 알림을 통합하여 쉽게 관리할 수 있습니다.

### 선택하지 않은 옵션 검토
2. **각 계정의 개인 건강 대시보드를 구성하여 이벤트를 중앙 AWS CloudTrail 로그로 전달**:
   - CloudTrail은 AWS API 호출을 기록하지만, 개인 건강 대시보드의 이벤트를 직접적으로 CloudTrail로 전달하는 기능은 없습니다. 이는 실질적으로 알림을 통합하는 데 적합하지 않습니다.

3. **AWS Health API를 쿼리하고 모든 이벤트를 Amazon DynamoDB 테이블에 기록하는 AWS Lambda 함수를 생성**:
   - 이 솔루션은 비효율적입니다. Lambda 함수와 DynamoDB를 사용하는 것은 알림을 수집하는 데 추가적인 관리 작업과 복잡성을 가져오며, 최소한의 노력 요구 사항을 충족하지 않습니다.

4. **AWS Health API를 사용하여 Amazon DynamoDB 테이블에 이벤트를 기록**:
   - 이 방법 역시 Lambda 함수를 사용하여 이벤트를 DynamoDB에 기록하는 것과 유사하게, 추가적인 복잡성과 관리를 요구하므로 비효율적입니다.

### 결론
따라서 **AWS Health에서 조직 보기를 활성화하는 것이 가장 간단하고 효율적인 방법으로, 최소한의 노력으로 모든 계정의 개인 건강 이벤트를 통합하여 모니터링할 수 있습니다.**



## 질문: 199
한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 

EC2 인스턴스는 자동 확장 그룹에 있으며 애플리케이션 로드 밸런서(ALB) 뒤에서 실행됩니다. 총 요청이 초당 100건을 초과하면 애플리케이션에 오류가 발생합니다. SysOps 관리자는 요청이 이 임계값을 초과한 시점을 확인하기 위해 2주 기간 동안의 총 요청에 대한 정보를 수집해야 합니다.

SysOps 관리자는 이 데이터를 수집하기 위해 무엇을 해야 합니까?

1. ALB의 RequestCount 메트릭을 사용합니다. 2주와 1분의 기간을 구성합니다. 차트를 검토하여 최대 트래픽 시간과 볼륨을 확인합니다.
2. Amazon CloudWatch 메트릭 수학을 사용하여 2주 기간 동안 모든 EC2 인스턴스에 대한 요청 수의 합계를 생성합니다. 1분 간격으로 정렬합니다.
3. EC2 시작 구성 템플릿에서 Amazon CloudWatch 사용자 지정 메트릭을 만들어 모든 EC2 인스턴스에서 집계된 요청 메트릭을 생성합니다.
4. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. EC2 요청을 기반으로 하는 메트릭을 만드는 EC2 이벤트 매칭 패턴을 구성합니다. 그래프에 데이터를 표시합니다.
 
SysOps 관리자가 Amazon EC2 인스턴스에서 실행되는 애플리케이션의 요청 수를 수집하여, 2주 기간 동안 총 요청에 대한 정보를 확인하기 위한 최적의 방법은 다음과 같습니다.

### 정답
**1. ALB의 RequestCount 메트릭을 사용합니다. 2주와 1분의 기간을 구성합니다. 차트를 검토하여 최대 트래픽 시간과 볼륨을 확인합니다.**

### 이유
- **ALB의 RequestCount 메트릭을 활용하면**: ALB가 수신한 총 요청 수를 직접적으로 모니터링할 수 있습니다. 이를 통해 2주 동안의 요청 수를 쉽게 수집하고 분석할 수 있습니다.
- **기간 구성**: 2주와 1분의 기간을 설정함으로써, 요청 수의 변화를 세부적으로 살펴볼 수 있어 피크 시간대와 볼륨을 효과적으로 파악할 수 있습니다.

### 선택하지 않은 옵션 검토
2. **Amazon CloudWatch 메트릭 수학을 사용하여 2주 기간 동안 모든 EC2 인스턴스에 대한 요청 수의 합계를 생성합니다. 1분 간격으로 정렬합니다.**
   - 이 방법은 사용 가능하지만, ALB의 RequestCount 메트릭을 직접 사용하는 것보다 더 복잡한 절차입니다. ALB의 메트릭을 직접적으로 사용하는 것이 더 간단하고 효율적입니다.

3. **EC2 시작 구성 템플릿에서 Amazon CloudWatch 사용자 지정 메트릭을 만들어 모든 EC2 인스턴스에서 집계된 요청 메트릭을 생성합니다.**
   - 이 방법은 사용자 지정 메트릭을 설정하고 관리하는 데 추가적인 오버헤드를 요구합니다. ALB의 메트릭을 활용하는 것이 더 효율적입니다.

4. **Amazon EventBridge(Amazon CloudWatch Events) 규칙을 만듭니다. EC2 요청을 기반으로 하는 메트릭을 만드는 EC2 이벤트 매칭 패턴을 구성합니다. 그래프에 데이터를 표시합니다.**
   - 이 방법은 불필요한 복잡성을 도입하며, ALB에서 제공하는 기본 메트릭을 활용하는 것보다 효율적이지 않습니다.

### 결론
따라서 **ALB의 RequestCount 메트릭을 사용하여 2주 동안의 요청 수를 수집하고 분석하는 것이 가장 효율적이며, 요청이 초과한 시점을 파악하는 데 도움이 됩니다.**




## 질문: 200
한 회사가 최근 AWS의 VPC로 애플리케이션을 마이그레이션했습니다. 

AWS Site-to-Site VPN 연결은 회사의 온프레미스 네트워크를 VPC에 연결합니다. 애플리케이션은 온프레미스에 있는 다른 시스템에서 고객 데이터를 검색합니다. 애플리케이션은 온프레미스 DNS 서버를 사용하여 도메인 레코드를 확인합니다. 마이그레이션 후 애플리케이션은 이름 확인 오류로 인해 고객 데이터에 연결할 수 없습니다.

어떤 솔루션이 애플리케이션에 내부 도메인 이름을 확인할 수 있는 기능을 제공할까요?

1. VPC에서 EC2 인스턴스를 시작합니다. EC2 인스턴스에서 모든 DNS 요청을 온프레미스 DNS 서버로 전달하는 사용자 지정 DNS 포워더를 배포합니다. 이름 서버에 EC2 인스턴스를 사용하는 Amazon Route 53 프라이빗 호스팅 영역을 만듭니다.
2. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 온프레미스 도메인에 대한 DNS 쿼리를 온프레미스 DNS 서버로 전달하도록 아웃바운드 엔드포인트를 구성합니다.
3. AWS 환경과 온프레미스 네트워크 간에 두 개의 AWS Direct Connect 연결을 설정합니다. 두 연결을 포함하는 링크 집계 그룹(LAG)을 설정합니다. 온프레미스 DNS 서버를 가리키도록 VPC 리졸버 주소를 변경합니다.
4. 온프레미스 도메인에 대한 Amazon Route 53 퍼블릭 호스팅 존을 만듭니다. 온프레미스 도메인에 대한 DNS 요청을 Route 53 퍼블릭 호스팅 존으로 전달하도록 네트워크 ACL을 구성합니다.

애플리케이션이 온프레미스 DNS 서버를 사용하여 도메인 레코드를 확인하는 데 문제가 발생하고 있는 상황에서, 내부 도메인 이름을 확인할 수 있는 기능을 제공하는 최적의 솔루션은 다음과 같습니다.

### 정답
**2. Amazon Route 53 Resolver 아웃바운드 엔드포인트를 만듭니다. 온프레미스 도메인에 대한 DNS 쿼리를 온프레미스 DNS 서버로 전달하도록 아웃바운드 엔드포인트를 구성합니다.**

### 이유
- **Route 53 Resolver 아웃바운드 엔드포인트**는 VPC 내에서 DNS 쿼리를 온프레미스 DNS 서버로 전달하는 데 필요한 구성을 제공합니다. 이 방식은 온프레미스 네트워크와의 연결을 간소화하며, 애플리케이션이 온프레미스 DNS 서버에 대한 쿼리를 성공적으로 수행할 수 있도록 합니다.
- **이 솔루션은 마이그레이션 후 발생한 DNS 문제를 해결하는 데 매우 적합**합니다. 이는 VPC와 온프레미스 네트워크 간의 DNS 쿼리 전송을 원활하게 수행합니다.

### 선택하지 않은 옵션 검토
1. **VPC에서 EC2 인스턴스를 시작합니다. EC2 인스턴스에서 모든 DNS 요청을 온프레미스 DNS 서버로 전달하는 사용자 지정 DNS 포워더를 배포합니다. 이름 서버에 EC2 인스턴스를 사용하는 Amazon Route 53 프라이빗 호스팅 영역을 만듭니다.**
   - 이 방법은 추가적인 관리 오버헤드를 수반하며, AWS Route 53 Resolver를 사용하는 것보다 복잡하고 비효율적입니다.

3. **AWS 환경과 온프레미스 네트워크 간에 두 개의 AWS Direct Connect 연결을 설정합니다. 두 연결을 포함하는 링크 집계 그룹(LAG)을 설정합니다. 온프레미스 DNS 서버를 가리키도록 VPC 리졸버 주소를 변경합니다.**
   - Direct Connect는 고정된 데이터 전송을 필요로 하며 DNS 쿼리 문제를 해결하는 데 직접적인 도움이 되지 않습니다. DNS 쿼리 전송은 Route 53 Resolver를 사용하는 것이 더 간단하고 효과적입니다.

4. **온프레미스 도메인에 대한 Amazon Route 53 퍼블릭 호스팅 존을 만듭니다. 온프레미스 도메인에 대한 DNS 요청을 Route 53 퍼블릭 호스팅 존으로 전달하도록 네트워크 ACL을 구성합니다.**
   - 퍼블릭 호스팅 존은 온프레미스 DNS 요청을 처리할 수 없으며, 보안 및 네트워크 구성을 고려할 때 적합하지 않습니다.

### 결론
따라서 **Amazon Route 53 Resolver 아웃바운드 엔드포인트를 구성하여 온프레미스 DNS 서버로의 DNS 쿼리를 성공적으로 전달하는 것이 최선의 선택입니다.**



## 질문: 201
회사의 웹 애플리케이션은 Amazon CloudFront 배포를 통해 사용할 수 있으며 인터넷 연결 Application Load Balancer(ALB)를 통해 직접 사용할 수 있습니다. SysOps 관리자는 CloudFront 배포를 통해서만 애플리케이션에 액세스할 수 있도록 해야 하며 ALB를 통해 직접 액세스할 수 있도록 해서는 안 됩니다. SysOps 관리자는 애플리케이션 코드를 변경하지 않고 이 변경을 해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. ALB 유형을 내부로 수정합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다.
2. Lambda@Edge 함수를 만듭니다. 요청의 사용자 지정 헤더 값을 저장된 비밀번호와 비교하고 일치하는 경우 요청을 원본으로 전달하도록 함수를 구성합니다. 함수를 배포와 연결합니다.
3. ALB를 새 내부 ALB로 교체합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다. 배포의 원점 설정에 사용자 지정 HTTP 헤더를 추가합니다. ALB 리스너에서 일치하는 사용자 지정 헤더와 헤더의 값을 포함하는 요청을 전달하는 규칙을 추가합니다. 고정된 응답 코드 403을 반환하는 기본 규칙을 추가합니다.
4. 배포를 위한 원본 설정에 사용자 지정 HTTP 헤더를 추가합니다. ALB 리스너에서 일치하는 사용자 지정 헤더와 헤더의 값을 포함하는 요청을 전달하는 규칙을 추가합니다. 고정된 응답 코드 403을 반환하는 기본 규칙을 추가합니다.

회사의 웹 애플리케이션에 대한 요구 사항을 충족하기 위해서 **"ALB 유형을 내부로 수정합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다."**가 가장 적합한 솔루션입니다.

### 정답:
**1. ALB 유형을 내부로 수정합니다. 배포의 원점을 내부 ALB 도메인 이름으로 설정합니다.**

#### 이유:
- **직접 액세스 차단**: ALB를 내부로 설정하면 ALB에 대한 외부 액세스가 차단됩니다. 따라서 사용자는 CloudFront 배포를 통해서만 애플리케이션에 액세스할 수 있습니다.
- **애플리케이션 코드 변경 없음**: 이 방법은 애플리케이션 코드나 아키텍처를 변경하지 않고, ALB의 유형만 변경하는 방식이기 때문에 요구 사항을 충족할 수 있습니다.

### 대안 설명:
2. **Lambda@Edge 함수를 만듭니다.**
   - Lambda@Edge를 사용하여 요청의 헤더를 검사하고 조건에 따라 요청을 처리할 수 있지만, 이 방식은 다소 복잡하고 성능에 영향을 미칠 수 있습니다. 또한, 코드의 변경 없이 요구 사항을 충족하기 어렵습니다.

3. **ALB를 새 내부 ALB로 교체합니다.**
   - 이 방법도 효과적일 수 있지만, ALB를 교체하는 것은 불필요한 작업을 추가하고, 내부 ALB를 추가로 설정하는 것보다 기존 ALB를 내부로 변경하는 것이 더 간단합니다.

4. **배포를 위한 원본 설정에 사용자 지정 HTTP 헤더를 추가합니다.**
   - 사용자 지정 HTTP 헤더를 추가하는 것은 요청을 검증하는 데 유용할 수 있지만, ALB에 대한 직접 액세스를 차단하는 데는 효과적이지 않습니다. 요청이 ALB로 직접 전달될 수 있으므로, 이 방법은 요구 사항을 완전히 충족하지 않습니다.

따라서, **ALB 유형을 내부로 수정하고 배포의 원점을 내부 ALB로 설정하는 것이 가장 효율적이며 요구 사항을 충족하는 방법입니다.**

## 질문: 202
한 회사가 AWS에서 여러 워크로드를 실행합니다. 

이 회사는 특정 AWS 지역에서 모니터링할 5개의 AWS Trusted Advisor 서비스 할당량 지표를 식별합니다. 이 회사는 리소스 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 받고 싶어합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. 각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.

2. 각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.

3. AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 지표를 모니터링합니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.

4. AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 메트릭을 모니터링합니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
 

회사가 AWS에서 Trusted Advisor 서비스 할당량 지표를 모니터링하고 이메일 알림을 받고자 할 때 가장 적합한 솔루션은 **"각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다."**입니다.

### 정답:
**1. 각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.**

#### 이유:
- **세부 모니터링**: CloudWatch 알람을 사용하여 각 서비스 할당량 메트릭을 개별적으로 모니터링할 수 있습니다. 이는 특정 리소스의 사용량이 임계값을 초과했을 때 신속하게 대응할 수 있게 해줍니다.
- **알림의 유연성**: Amazon SNS를 사용하면 이메일 알림을 쉽게 설정할 수 있으며, 사용자가 선택한 구독자에게 알림을 보낼 수 있습니다.
- **효율성**: 각 메트릭에 대해 개별적으로 알람을 설정하면, 각 서비스 할당량의 상태를 효과적으로 관리할 수 있습니다.

### 대안 설명:
2. **각 Trusted Advisor 서비스 할당량 메트릭에 대해 하나씩, 총 5개의 Amazon CloudWatch 알람을 만듭니다. 사용량이 서비스 할당량 중 하나의 60%를 초과할 때마다 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.**
   - SQS는 메시지를 큐에 저장하는 데 유용하지만, 이메일 알림을 직접 제공하지 않으므로 SNS가 더 적합합니다.

3. **AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 지표를 모니터링합니다.**
   - Service Health Dashboard는 서비스의 상태를 모니터링하는 데 사용되지만, 특정 리소스 사용량을 측정하거나 알림을 설정하는 데는 적합하지 않습니다.

4. **AWS Service Health Dashboard를 사용하여 각 Trusted Advisor 서비스 할당량 메트릭을 모니터링합니다.**
   - 이 방법은 위와 동일한 이유로 적합하지 않으며, CloudWatch 알람을 설정하는 것이 훨씬 효율적입니다.

따라서, **각 Trusted Advisor 서비스 할당량 메트릭에 대해 Amazon CloudWatch 알람을 만들고, SNS를 통해 이메일 알림을 설정하는 방법이 가장 효과적입니다.**


## 질문: 203
회사에서 온프레미스 사용자를 위한 Windows 파일 공유를 호스팅하기 위해 관리형 파일 시스템을 구현해야 합니다. 

AWS 클라우드의 리소스도 이러한 파일 공유의 데이터에 액세스할 수 있어야 합니다. SysOps 관리자는 온프레미스에서 사용자 파일 공유를 제공하고 최소 지연 시간으로 사용자 파일 공유를 AWS에서 사용할 수 있도록 해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. Amazon S3 파일 게이트웨이를 설정합니다.
2. AWS Direct Connect 연결을 설정합니다.
3. AWS DataSync를 사용하여 기존 파일 서버와 AWS 간의 데이터 전송을 자동화합니다.
4. Amazon FSx 파일 게이트웨이를 설정합니다.

이러한 요구 사항을 충족하기 위해 가장 적합한 솔루션은 **"AWS Direct Connect 연결을 설정합니다."**입니다.

### 정답:
**2. AWS Direct Connect 연결을 설정합니다.**

#### 이유:
- **지연 시간 최소화**: AWS Direct Connect는 온프레미스 데이터 센터와 AWS 간의 전용 네트워크 연결을 제공합니다. 이는 인터넷을 통한 연결보다 더 낮은 지연 시간과 더 안정적인 성능을 제공합니다.
- **온프레미스와 AWS 통합**: 이 연결을 통해 온프레미스 파일 공유와 AWS 리소스 간의 데이터 전송을 원활하게 할 수 있습니다. 사용자는 로컬 네트워크와 유사한 방식으로 AWS 리소스에 액세스할 수 있습니다.
- **안정성 및 보안**: Direct Connect는 데이터가 전송되는 동안 더 높은 보안성과 신뢰성을 제공하므로, 파일 공유에 적합합니다.

### 대안 설명:
1. **Amazon S3 파일 게이트웨이를 설정합니다.**
   - S3 파일 게이트웨이는 온프레미스 애플리케이션이 S3에 파일을 저장하고 가져올 수 있도록 하는 서비스입니다. 그러나 이 옵션은 지연 시간에 영향을 줄 수 있으며, 파일 공유를 위한 완전한 솔루션은 아닙니다.

3. **AWS DataSync를 사용하여 기존 파일 서버와 AWS 간의 데이터 전송을 자동화합니다.**
   - DataSync는 데이터를 자동으로 이동하는 데 유용하지만, 실시간 액세스가 필요한 파일 공유에는 적합하지 않습니다. 이 옵션은 주기적인 데이터 전송에는 유용하지만, 파일 공유에 대한 즉각적인 액세스를 보장하지는 않습니다.

4. **Amazon FSx 파일 게이트웨이를 설정합니다.**
   - FSx 파일 게이트웨이는 Amazon FSx 스토리지를 온프레미스 환경에서 사용할 수 있도록 지원하지만, 최적의 지연 시간을 제공하기 위해서는 Direct Connect와 함께 사용하는 것이 더 좋습니다. FSx는 주로 AWS 내에서 파일 시스템을 제공하는 데 사용됩니다.

결론적으로, **AWS Direct Connect 연결을 설정하여 온프레미스와 AWS 간의 파일 공유를 위한 안정적이고 낮은 지연 시간의 연결을 구현하는 것이 가장 효과적입니다.**

## 질문: 204
한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 이 회사는 Amazon RDS for PostgreSQL DB 인스턴스에서 데이터베이스를 호스팅하고 있습니다. 이 회사는 DB 인스턴스에 대한 모든 연결을 암호화하도록 요구합니다.

이 요구 사항을 충족하기 위해 SysOps 관리자는 무엇을 해야 합니까?

1. 인바운드 보안 그룹 규칙을 사용하여 데이터베이스에 대한 SSL 연결을 허용합니다.
2. AWS Key Management Service(AWS KMS) 암호화 키를 사용하여 데이터베이스를 암호화합니다.
3. 사용자 정의 매개변수 그룹을 사용하여 데이터베이스에 대한 SSL 연결을 적용합니다.
4. 사용자 정의 PostgreSQL 확장 기능을 사용하여 데이터베이스에 SSL/TLS 패치를 적용합니다.

Amazon RDS for PostgreSQL DB 인스턴스에 대한 모든 연결을 암호화하도록 요구하기 위해 SysOps 관리자가 취해야 할 가장 적절한 조치는 **"인바운드 보안 그룹 규칙을 사용하여 데이터베이스에 대한 SSL 연결을 허용합니다."**입니다.

### 정답:
**1. 인바운드 보안 그룹 규칙을 사용하여 데이터베이스에 대한 SSL 연결을 허용합니다.**

#### 이유:
- **SSL/TLS 사용**: PostgreSQL은 SSL/TLS를 통해 연결을 암호화할 수 있습니다. DB 인스턴스에 대한 연결을 암호화하기 위해서는 클라이언트가 SSL을 통해 연결할 수 있도록 해야 합니다.
- **보안 그룹 설정**: 인바운드 보안 그룹 규칙을 통해 SSL 연결이 허용되도록 설정함으로써, 안전하게 암호화된 연결이 가능하게 됩니다.

### 대안 설명:
2. **AWS Key Management Service(AWS KMS) 암호화 키를 사용하여 데이터베이스를 암호화합니다.**
   - AWS KMS는 데이터 저장을 위한 암호화를 제공하지만, DB 인스턴스와의 연결을 암호화하는 것과는 다릅니다. KMS는 데이터베이스 내에서 저장된 데이터를 암호화하는 데 사용됩니다.

3. **사용자 정의 매개변수 그룹을 사용하여 데이터베이스에 대한 SSL 연결을 적용합니다.**
   - 사용자 정의 매개변수 그룹을 사용하여 SSL 연결을 적용할 수 있지만, 인바운드 보안 그룹을 설정하지 않으면 클라이언트가 SSL로 연결할 수 없습니다. 따라서 보안 그룹 규칙이 먼저 적용되어야 합니다.

4. **사용자 정의 PostgreSQL 확장 기능을 사용하여 데이터베이스에 SSL/TLS 패치를 적용합니다.**
   - PostgreSQL 자체의 SSL/TLS 패치를 적용하는 것은 일반적인 요구 사항이 아니며, RDS에서는 관리형 서비스이므로 사용자가 직접 패치를 적용하는 것은 불가능합니다.

결론적으로, DB 인스턴스에 대한 모든 연결을 암호화하기 위해서는 인바운드 보안 그룹 규칙을 사용하여 SSL 연결을 허용하는 것이 가장 효과적입니다.


## 질문: 205
한 회사가 최근에 Savings Plans를 구매했습니다. 이 회사는 회사의 활용도가 특정 날짜에 90% 미만으로 떨어지면 이메일 알림을 받고 싶어합니다.

어떤 솔루션이 이 요구 사항을 충족할까요?

1. AWS Trusted Advisor에서 Savings Plan 체크를 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 특정 날짜에 사용률이 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.
2. CloudWatch의 AWS/SavingsPlans 네임스페이스에서 SavingsPlansUtilization 메트릭을 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다. 특정 날짜에 사용률이 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다.
3. Savings Plans 알림을 만들어 Savings Plans의 일일 사용률을 모니터링합니다. 사용률이 주어진 날의 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
4. AWS Budgets를 사용하여 Savings Plans 예산을 생성하여 Savings Plans의 일일 사용률을 추적합니다. 사용률이 주어진 날의 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.
 

회사가 Savings Plans의 활용도가 특정 날짜에 90% 미만으로 떨어지면 이메일 알림을 받고 싶어하는 요구 사항을 충족하기 위한 가장 적절한 솔루션은 **"AWS Budgets를 사용하여 Savings Plans 예산을 생성하여 Savings Plans의 일일 사용률을 추적합니다."**입니다.

### 정답:
**4. AWS Budgets를 사용하여 Savings Plans 예산을 생성하여 Savings Plans의 일일 사용률을 추적합니다. 사용률이 주어진 날의 90% 미만으로 떨어지면 이메일 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽을 구성합니다.**

#### 이유:
- **예산 관리**: AWS Budgets를 사용하면 리소스의 사용률을 기반으로 예산을 설정할 수 있습니다. Savings Plans 활용도에 대한 예산을 설정하고, 특정 임계값(예: 90% 미만)에 도달할 때 알림을 받을 수 있습니다.
- **이메일 알림**: Budgets를 통해 SNS 토픽에 알림을 설정하여, 활용도가 특정 기준에 미치지 않을 때 이메일로 알림을 받을 수 있습니다.

### 대안 설명:
1. **AWS Trusted Advisor에서 Savings Plan 체크를 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다.**
   - AWS Trusted Advisor는 Savings Plans 활용도에 대한 정보를 제공하지만, 직접적인 알림 기능이 부족하므로 이 방법은 적합하지 않습니다.

2. **CloudWatch의 AWS/SavingsPlans 네임스페이스에서 SavingsPlansUtilization 메트릭을 모니터링하기 위해 Amazon CloudWatch 알람을 만듭니다.**
   - CloudWatch에서 메트릭을 모니터링할 수는 있지만, 알림을 설정하는 데 필요한 정책을 구성하는 데 한계가 있습니다. 또한, Savings Plans 활용도에 대한 알림이 SNS와 결합되지 않으면 실질적인 이메일 알림을 제공하기 어렵습니다.

3. **Savings Plans 알림을 만들어 Savings Plans의 일일 사용률을 모니터링합니다.**
   - Savings Plans 알림은 있지만, AWS Budgets를 사용하는 것이 더 나은 방법입니다. Budgets는 더 유연하게 예산을 관리하고 알림을 설정할 수 있도록 돕기 때문입니다.

따라서, **AWS Budgets를 사용하여 Savings Plans의 일일 사용률을 추적하고 특정 기준에 따라 이메일 알림을 받는 것이 가장 효과적인 솔루션입니다.**


## 질문: 206
한 회사가 애플리케이션에서 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 사용합니다. 애플리케이션은 고유한 메시지 본문이 있는 메시지를 대기열로 보냅니다. 회사는 SQS FIFO 대기열로 전환하기로 결정했습니다.

회사는 SQS FIFO 대기열로 마이그레이션하기 위해 무엇을 해야 합니까?

1. 새 SQS FIFO 대기열을 만듭니다. 새 FIFO 대기열에서 콘텐츠 기반 중복 제거를 켭니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다.
2. 새 SQS FIFO 대기열을 만듭니다. DelaySeconds 매개변수를 메시지에 포함하도록 애플리케이션을 업데이트합니다.
3. 대기열 유형을 SQS 표준에서 SQS FIFO로 수정합니다. 대기열에서 콘텐츠 기반 중복 제거를 끕니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다.
4. SQS 표준에서 SQS FIFO로 큐 유형을 수정합니다. 동일한 메시지 본문으로 메시지를 보내고 메시지에 DelaySeconds 매개변수를 포함하도록 애플리케이션을 업데이트합니다.

회사가 Amazon SQS 표준 대기열에서 FIFO 대기열로 마이그레이션하기 위해 필요한 조치는 **"새 SQS FIFO 대기열을 만듭니다. 새 FIFO 대기열에서 콘텐츠 기반 중복 제거를 켭니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다."**입니다.

### 정답:
**1. 새 SQS FIFO 대기열을 만듭니다. 새 FIFO 대기열에서 콘텐츠 기반 중복 제거를 켭니다. 메시지를 메시지 그룹 ID에 포함하도록 애플리케이션을 업데이트합니다.**

#### 이유:
- **새 대기열 생성**: SQS의 대기열 유형을 변경할 수 없기 때문에 새로운 FIFO 대기열을 만들어야 합니다.
- **메시지 그룹 ID**: FIFO 대기열에서는 메시지가 순서대로 처리되고 중복이 방지되도록 메시지 그룹 ID를 사용해야 합니다. 애플리케이션에서 메시지 그룹 ID를 포함하도록 업데이트해야 합니다.
- **중복 제거**: FIFO 대기열에서는 콘텐츠 기반 중복 제거를 사용할 수 있으며, 이를 통해 동일한 메시지가 중복되어 처리되는 것을 방지할 수 있습니다.

### 대안 설명:
2. **새 SQS FIFO 대기열을 만듭니다. DelaySeconds 매개변수를 메시지에 포함하도록 애플리케이션을 업데이트합니다.**
   - DelaySeconds 매개변수는 메시지의 지연 전송에 관한 것이며 FIFO 대기열로의 전환에는 필요하지 않습니다.

3. **대기열 유형을 SQS 표준에서 SQS FIFO로 수정합니다.**
   - 대기열 유형을 직접 수정하는 것은 불가능합니다. 반드시 새 FIFO 대기열을 생성해야 합니다.

4. **SQS 표준에서 SQS FIFO로 큐 유형을 수정합니다.**
   - 마찬가지로 대기열 유형을 수정하는 것은 불가능하며, 같은 이유로 새로운 FIFO 대기열을 만들어야 합니다.

따라서, **새 SQS FIFO 대기열을 생성하고, 메시지 그룹 ID를 포함하도록 애플리케이션을 업데이트하는 것이 FIFO 대기열로의 마이그레이션을 위한 올바른 접근 방식입니다.**


## 질문: 207
회사의 SysOps 관리자는 AWS 계정에서 시작된 모든 Amazon EC2 Windows 인스턴스에 타사 에이전트가 설치되어 있는지 확인해야 합니다. 

타사 에이전트에는 .msi 패키지가 있습니다. 회사는 패치를 위해 AWS Systems Manager를 사용하고 Windows 인스턴스에 적절한 태그가 지정됩니다. 타사 에이전트는 새 버전이 출시됨에 따라 주기적 업데이트가 필요합니다. SysOps 관리자는 이러한 업데이트를 자동으로 배포해야 합니다.

어떤 단계 조합이 최소한의 운영 노력으로 이러한 요구 사항을 충족할 수 있을까요? (두 가지를 선택하세요.)

1. 타사 에이전트에 대한 Systems Manager Distributor 패키지를 만듭니다.

2. Systems Manager Inventory가 구성되어 있는지 확인하세요. Systems Manager Inventory가 구성되어 있지 않으면 Windows에 적합한 태그 값을 기반으로 인스턴스에 대한 새 인벤토리를 설정하세요.
3. AWS-RunRemoteScript 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.
4. AWS-ConfigureAWSPackage 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.
5. Windows에 대한 태그 값으로 Systems Manager OpsItem을 만듭니다. Systems Manager Distributor 패키지를 OpsItem에 연결합니다. 패키지 배포에 특정한 유지 관리 기간을 만듭니다. 유지 관리 기간을 하루 24시간으로 구성합니다.

SysOps 관리자가 요구 사항을 충족하기 위해 최소한의 운영 노력으로 선택할 수 있는 두 가지 단계는 다음과 같습니다:

1. **타사 에이전트에 대한 Systems Manager Distributor 패키지를 만듭니다.**
   - 이 단계는 타사 에이전트를 자동으로 배포하기 위해 필요한 패키지를 생성하는 것입니다. 이를 통해 향후 업데이트를 쉽게 관리할 수 있습니다.

4. **AWS-ConfigureAWSPackage 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.**
   - 이 단계는 정의된 일정에 따라 타사 에이전트를 자동으로 업데이트하고 설치하는 데 필요한 프로세스를 설정합니다. 태그를 기반으로 인스턴스를 필터링하여 특정 인스턴스에만 업데이트를 적용할 수 있습니다.

### 이유:
- **운영 효율성**: 이 두 가지 조합을 통해 패키지 관리와 인스턴스 업데이트를 자동화하여 운영 부담을 줄일 수 있습니다.
- **자동화된 업데이트**: Systems Manager의 기능을 활용하여 패치 및 업데이트를 정기적으로 자동으로 수행할 수 있습니다.

### 대안 설명:
2. **Systems Manager Inventory가 구성되어 있는지 확인하세요. Systems Manager Inventory가 구성되어 있지 않으면 Windows에 적합한 태그 값을 기반으로 인스턴스에 대한 새 인벤토리를 설정하세요.**
   - 인벤토리 구성은 중요하지만, 타사 에이전트를 업데이트하는 직접적인 방법은 아닙니다.

3. **AWS-RunRemoteScript 문서를 실행하기 위해 Systems Manager State Manager 연결을 만듭니다. 타사 에이전트 패키지의 세부 정보를 채웁니다. 1일 일정으로 Windows에 적합한 태그 값을 기반으로 인스턴스 태그를 지정합니다.**
   - 이 옵션은 스크립트를 실행하는 방법으로 업데이트를 수행할 수 있지만, 패키지 관리가 아닌 원격 스크립트 실행에 의존하므로 좀 더 복잡할 수 있습니다.

5. **Windows에 대한 태그 값으로 Systems Manager OpsItem을 만듭니다. Systems Manager Distributor 패키지를 OpsItem에 연결합니다. 패키지 배포에 특정한 유지 관리 기간을 만듭니다. 유지 관리 기간을 하루 24시간으로 구성합니다.**
   - OpsItem을 설정하는 것은 유용하지만, 타사 에이전트 업데이트 자동화의 핵심 단계는 아닙니다.

따라서, 선택된 두 단계가 가장 적합합니다.



## 질문: 208
한 회사가 단일 AWS 리전에서 수백 개의 Amazon EC2 인스턴스를 실행합니다. 

각 EC2 인스턴스에는 연결된 1GiB General Purpose SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨이 두 개 있습니다. 중요한 워크로드는 EBS 볼륨에서 사용 가능한 모든 IOPS 용량을 사용하는 것입니다.

회사 정책에 따라 회사는 회사의 애플리케이션이 제대로 작동하는지 확인하기 위한 긴 수락 테스트를 완료하지 않고는 인스턴스 유형이나 EBS 볼륨 유형을 변경할 수 없습니다. SysOps 관리자는 가능한 한 빨리 EBS 볼륨의 I/O 성능을 높여야 합니다. SysOps

관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1. 1GiB EBS 볼륨의 크기를 늘립니다.
2. 각 EC2 인스턴스에 두 개의 추가 탄력적 네트워크 인터페이스를 추가합니다.
3. 해당 지역의 EBS 볼륨에서 전송 가속을 켭니다.
4. 모든 EC2 인스턴스를 클러스터 배치 그룹에 추가합니다.

EBS 볼륨의 I/O 성능을 즉시 높이기 위해 SysOps 관리자가 취해야 할 조치는 다음과 같습니다:

### **1. 1GiB EBS 볼륨의 크기를 늘립니다.**

#### 이유:
- **IOPS 성능 증가**: Amazon EBS의 gp2 볼륨은 볼륨 크기에 따라 IOPS 성능이 결정됩니다. 구체적으로, gp2 볼륨은 각 GiB에 대해 3 IOPS를 제공합니다. 따라서 볼륨의 크기를 늘리면 더 많은 IOPS를 제공받을 수 있습니다. 예를 들어, 1GiB에서 100GiB로 늘리면 IOPS는 300으로 증가합니다.
- **빠른 적용**: EBS 볼륨 크기 변경은 최소한의 다운타임으로 수행할 수 있으며, 이미 설정된 정책이나 수락 테스트 없이도 즉시 성능을 향상시킬 수 있는 가장 빠른 방법입니다.

### **대안 설명:**
2. **각 EC2 인스턴스에 두 개의 추가 탄력적 네트워크 인터페이스를 추가합니다.**
   - 이 방법은 네트워크 성능을 향상시킬 수 있지만, EBS 볼륨의 IOPS와는 관련이 없습니다.

3. **해당 지역의 EBS 볼륨에서 전송 가속을 켭니다.**
   - EBS 볼륨에서 전송 가속은 지원되지 않으며, EBS 볼륨의 성능을 직접적으로 향상시키지 않습니다.

4. **모든 EC2 인스턴스를 클러스터 배치 그룹에 추가합니다.**
   - 클러스터 배치 그룹은 네트워크 대역폭 및 지연 시간 측면에서 성능을 향상시킬 수 있지만, EBS 볼륨의 IOPS 성능에는 직접적인 영향을 미치지 않습니다.

결론적으로, **EBS 볼륨의 크기를 늘리는 것이 I/O 성능을 높이는 가장 효과적이고 빠른 방법입니다.**



## 질문: 209
회사에서 AWS에 새로운 워크로드를 배포해야 합니다. 회사는 모든 저장 데이터를 암호화하고 매년 한 번씩 암호화 키를 순환해야 합니다. 워크로드는 데이터 저장을 위해 Amazon RDS for MySQL Multi-AZ 데이터베이스를 사용합니다.

어떤 구성 방식이 이러한 요구 사항을 충족할까요?

1. MySQL 구성 파일에서 Transparent Data Encryption(TDE)을 활성화합니다. 12개월마다 수동으로 키를 회전합니다.
2. Amazon RDS에 대한 AWS 관리 키를 사용하여 데이터베이스 생성 시 RDS 암호화를 활성화합니다.
3. 새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. KMS 키를 사용하여 생성 시 데이터베이스에서 RDS 암호화를 활성화합니다.
4. 새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. RDS DB 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에서 암호화를 활성화합니다.

회사의 요구 사항에 맞게 AWS에서 새로운 워크로드를 배포하기 위한 최적의 구성 방식은 다음과 같습니다:

### **3. 새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. KMS 키를 사용하여 생성 시 데이터베이스에서 RDS 암호화를 활성화합니다.**

#### 이유:
- **데이터 암호화**: AWS KMS를 사용하여 RDS 데이터베이스를 암호화할 수 있으며, 데이터베이스가 생성될 때 KMS 키를 사용하여 데이터를 보호합니다.
- **자동 키 로테이션**: KMS는 고객 관리 키에 대해 자동 키 로테이션을 지원하므로, 매년 키를 수동으로 순환할 필요 없이 1년에 한 번 자동으로 키를 교체할 수 있습니다. 이를 통해 보안성을 높이고 관리의 편의성을 제공합니다.

### **대안 설명:**

1. **MySQL 구성 파일에서 Transparent Data Encryption(TDE)을 활성화합니다. 12개월마다 수동으로 키를 회전합니다.**
   - MySQL TDE는 RDS에서 지원되지 않으며, RDS for MySQL의 경우 AWS KMS를 사용한 암호화가 필요합니다. 수동으로 키를 회전하는 것은 비효율적입니다.

2. **Amazon RDS에 대한 AWS 관리 키를 사용하여 데이터베이스 생성 시 RDS 암호화를 활성화합니다.**
   - AWS 관리 키는 AWS에 의해 관리되지만, 회사가 매년 키를 순환해야 하는 요구 사항을 충족하지 않습니다. 키 관리에 대한 제어력이 떨어집니다.

4. **새로운 AWS Key Management Service(AWS KMS) 고객 관리 키를 만듭니다. 자동 키 로테이션을 활성화합니다. RDS DB 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에서 암호화를 활성화합니다.**
   - EBS 볼륨의 암호화는 RDS의 데이터베이스 자체와는 관계가 없습니다. RDS 데이터베이스의 암호화를 위해서는 KMS 키를 사용하여 RDS에서 직접 암호화를 활성화해야 합니다.

결론적으로, **AWS KMS를 사용하여 고객 관리 키를 생성하고 자동 키 로테이션을 활성화하는 것이 요구 사항을 충족하는 가장 효과적인 방법입니다.**

## 질문: 210
한 회사에 액티브-패시브 구성으로 두 개의 AWS 리전에 배포된 애플리케이션이 있습니다. 이 애플리케이션은 각 리전의 애플리케이션 로드 밸런서(ALB) 뒤에 있는 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 각 리전의 Amazon EC2 자동 확장 그룹에 있습니다. 이 애플리케이션은 DNS에 Amazon Route 53 호스팅 영역을 사용합니다. SysOps 관리자는 보조 리전으로 자동 장애 조치를 구성해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. 각 ALB를 가리키는 Route 53 별칭 레코드를 구성합니다. 장애 조치 라우팅 정책을 선택합니다. Evaluate Target Health를 Yes로 설정합니다.
2. 각 AL을 가리키는 CNAME 레코드 구성 장애 조치 라우팅 정책 선택. 대상 상태 평가를 예로 설정.
3. Auto Scaling 그룹에 대한 Elastic Load Balancing(ELB) 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.
4. 자동 확장 그룹에 대한 EC2 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.

SysOps 관리자가 액티브-패시브 구성으로 두 개의 AWS 리전에 배포된 애플리케이션에 대해 자동 장애 조치를 구성하기 위한 최적의 솔루션은 다음과 같습니다:

### **1. 각 ALB를 가리키는 Route 53 별칭 레코드를 구성합니다. 장애 조치 라우팅 정책을 선택합니다. Evaluate Target Health를 Yes로 설정합니다.**

#### 이유:
- **Route 53 별칭 레코드**: Amazon Route 53의 별칭 레코드를 사용하면 ALB에 대한 직접적인 DNS 레코드를 생성할 수 있습니다. 이 방식은 ELB와 같은 AWS 리소스를 직접적으로 참조할 수 있는 장점이 있습니다.
- **장애 조치 라우팅 정책**: 장애 조치 라우팅 정책을 선택함으로써, 기본 리전의 ALB가 비정상일 경우 Route 53이 보조 리전으로 자동으로 트래픽을 전환할 수 있습니다.
- **Evaluate Target Health**: 이 설정을 `Yes`로 설정하면 Route 53이 ALB의 상태를 모니터링하여, ALB가 비정상일 경우 장애 조치를 수행할 수 있습니다.

### **대안 설명:**

2. **각 ALB를 가리키는 CNAME 레코드 구성 장애 조치 라우팅 정책 선택. 대상 상태 평가를 예로 설정.**
   - CNAME 레코드는 AWS 리소스를 직접 참조할 수 없으며, 별칭 레코드를 사용해야 합니다. 또한, `Evaluate Target Health`가 CNAME 레코드에서는 적용되지 않습니다.

3. **Auto Scaling 그룹에 대한 Elastic Load Balancing(ELB) 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.**
   - 이 방법은 ALB의 상태 검사와 관련이 있지만, Route 53의 DNS 장애 조치 기능을 사용하지 않으므로, 트래픽을 자동으로 전환하는 방식에 대한 해결책이 아닙니다.

4. **자동 확장 그룹에 대한 EC2 상태 검사를 구성합니다. 기본 지역의 ALB에 대상 그룹을 추가합니다. 보조 지역의 EC2 인스턴스를 대상으로 포함합니다.**
   - EC2 상태 검사는 EC2 인스턴스의 상태를 모니터링하지만, Route 53을 통해 DNS 수준에서 자동으로 장애 조치를 수행하는 방법이 아닙니다.

결론적으로, **Route 53 별칭 레코드와 장애 조치 라우팅 정책을 사용하는 것이 이 시나리오에서 자동 장애 조치를 효과적으로 구현하는 방법입니다.**


## 질문: 211
한 회사가 머신 러닝을 기반으로 하는 모니터링 솔루션을 구현하고 있습니다. 

모니터링 솔루션은 Amazon EC2 Auto Scaling에서 생성된 Amazon EventBridge(Amazon CloudWatch Events) 이벤트를 사용합니다. 모니터링 솔루션은 예상치 못한 확장 이벤트와 같은 비정상적인 동작을 감지하며 EventBridge(CloudWatch Events) API 대상으로 구성됩니다.

초기 테스트 중에 회사는 모니터링 솔루션이 이벤트를 수신하지 않는다는 것을 알게 됩니다. 그러나 Amazon CloudWatch는 EventBridge(CloudWatch Events) 규칙이 호출되고 있음을 보여줍니다. SysOps 관리자는 이 문제를 해결하기 위해 클라이언트 오류 세부 정보를 검색하는 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 노력으로 이러한 요구 사항을 충족할까요?

1. 이벤트 패턴에 대한 EventBridge(CloudWatch Events) 아카이브를 만들어 이벤트를 재생합니다. 모니터링 솔루션에서 로깅을 늘립니다. replay를 사용하여 모니터링 솔루션을 호출합니다. 오류 세부 정보를 검토합니다.
2. 대상의 배달 못한 편지 대기열로 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 추가합니다. 배달 못한 편지 대기열의 메시지를 처리하여 오류 세부 정보를 검색합니다.
3. AWS Lambda 함수를 대상으로 동일한 이벤트 패턴에 대한 두 번째 EventBridge(CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 모니터링 솔루션을 호출하고 Amazon CloudWatch Logs에 결과를 기록합니다. 로그에서 오류를 검사합니다.
4. Amazon Simple Notification Service(Amazon SNS) 주제에 오류 메시지를 보내도록 EventBridge(CloudWatch Events) 규칙을 구성합니다.
 
이 문제를 해결하기 위한 최소한의 운영 노력으로 요구 사항을 충족할 수 있는 솔루션은 다음과 같습니다:

### **1. 이벤트 패턴에 대한 EventBridge(CloudWatch Events) 아카이브를 만들어 이벤트를 재생합니다. 모니터링 솔루션에서 로깅을 늘립니다. replay를 사용하여 모니터링 솔루션을 호출합니다. 오류 세부 정보를 검토합니다.**

#### 이유:
- **이벤트 아카이브**: EventBridge에서는 이벤트 아카이브를 생성하여 과거의 이벤트를 저장하고 필요 시 재생할 수 있습니다. 이는 이벤트가 정상적으로 수신되지 않는 이유를 진단하는 데 유용합니다.
- **이벤트 재생**: 아카이브에서 이벤트를 재생하여 모니터링 솔루션이 해당 이벤트를 제대로 처리하는지 확인할 수 있습니다. 이를 통해 모니터링 솔루션에서 오류가 발생하는지 또는 이벤트 처리에 문제가 있는지 검토할 수 있습니다.
- **로깅 증가**: 모니터링 솔루션에서 로깅을 늘리면 발생한 오류의 세부 사항을 더 잘 파악할 수 있어 문제 해결에 도움이 됩니다.

### **대안 설명:**

2. **대상의 배달 못한 편지 대기열로 Amazon Simple Queue Service(Amazon SQS) 표준 대기열을 추가합니다. 배달 못한 편지 대기열의 메시지를 처리하여 오류 세부 정보를 검색합니다.**
   - 이 방법은 추가적인 복잡성을 도입하며, 문제를 진단하기 위한 정보 제공 측면에서 덜 효율적일 수 있습니다. 특히 클라이언트 오류가 발생하는 경우를 완전히 감지하지 못할 수 있습니다.

3. **AWS Lambda 함수를 대상으로 동일한 이벤트 패턴에 대한 두 번째 EventBridge(CloudWatch Events) 규칙을 만듭니다. Lambda 함수를 구성하여 모니터링 솔루션을 호출하고 Amazon CloudWatch Logs에 결과를 기록합니다. 로그에서 오류를 검사합니다.**
   - 이 방법은 효과적일 수 있지만, 추가적인 Lambda 함수를 설정해야 하고 이를 통해 발생할 수 있는 복잡성을 감안하면 초기 테스트의 간단한 문제를 해결하기에는 과한 솔루션입니다.

4. **Amazon Simple Notification Service(Amazon SNS) 주제에 오류 메시지를 보내도록 EventBridge(CloudWatch Events) 규칙을 구성합니다.**
   - SNS를 통한 오류 메시지 전송은 모니터링 솔루션이 실패할 경우 알림을 받을 수 있지만, 세부적인 오류 정보를 수집하는 데는 한계가 있을 수 있습니다. 클라이언트 오류 세부 정보를 얻기 위한 방법으로는 덜 효과적입니다.

결론적으로, **이벤트 아카이브를 사용하고 이벤트를 재생하여 로깅을 통해 오류 세부 정보를 확인하는 방법이 가장 효과적이며 운영 노력도 최소화할 수 있습니다.**



## 질문: 212
한 회사가 Amazon S3 버킷에 백업을 저장하고 있습니다. 백업은 백업이 생성된 후 최소 3개월 동안 삭제되어서는 안 됩니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. 모든 사용자에 대해 s3:DeleteObject 작업을 거부하는 IAM 정책을 구성합니다. 객체가 작성된 후 3개월이 지나면 정책을 제거합니다.
2. 규정 준수 모드에서 새 S3 버킷에 S3 개체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관 기간 3개월로 저장합니다.
3. 기존 S3 버킷에서 S3 버전 관리를 활성화합니다. 백업을 보호하기 위해 S3 라이프사이클 규칙을 구성합니다.
4. 거버넌스 모드에서 새 S3 버킷에 S3 객체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관하고 보관 기간은 3개월입니다.
 

이 요구 사항을 충족하기 위한 가장 적절한 솔루션은 다음과 같습니다:

### **2. 규정 준수 모드에서 새 S3 버킷에 S3 개체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관 기간 3개월로 저장합니다.**

#### 이유:
- **S3 개체 잠금**: S3 개체 잠금을 사용하면 객체가 잠금 상태로 유지되어 지정된 기간 동안 삭제할 수 없게 됩니다. 이 기능은 데이터의 무결성을 보장하고 요구 사항에 맞게 데이터를 보호하는 데 적합합니다.
- **규정 준수 모드**: 규정 준수 모드를 선택하면 모든 객체가 설정된 보관 기간 동안 삭제되지 않도록 보장할 수 있으며, 이 모드에서는 객체의 삭제가 허용되지 않습니다.
- **3개월 보관**: 이 요구 사항은 3개월 동안 객체를 삭제할 수 없도록 하기 때문에 S3 개체 잠금이 가장 적합한 옵션입니다.

### **대안 설명:**

1. **모든 사용자에 대해 s3:DeleteObject 작업을 거부하는 IAM 정책을 구성합니다. 객체가 작성된 후 3개월이 지나면 정책을 제거합니다.**
   - 이 방법은 객체를 보호하는 데 효과적이지 않습니다. IAM 정책을 수동으로 제거해야 하므로 실수나 관리 작업으로 인해 오류가 발생할 수 있습니다.

3. **기존 S3 버킷에서 S3 버전 관리를 활성화합니다. 백업을 보호하기 위해 S3 라이프사이클 규칙을 구성합니다.**
   - S3 버전 관리는 객체의 이전 버전을 보관하는 데 유용하지만, 이 옵션은 특정 기간 동안 객체를 삭제할 수 없도록 보장하지 않으므로 요구 사항을 완전히 충족하지 않습니다.

4. **거버넌스 모드에서 새 S3 버킷에 S3 객체 잠금을 활성화합니다. 모든 백업을 새 S3 버킷에 보관하고 보관 기간은 3개월입니다.**
   - 거버넌스 모드는 삭제 권한이 있는 사용자에게 객체를 삭제할 수 있는 권한을 남겨두지만, 요구 사항에서는 3개월 동안 삭제가 불가능해야 하므로 적절하지 않습니다.

결론적으로, **S3 개체 잠금을 규정 준수 모드로 활성화하여 백업이 3개월 동안 삭제되지 않도록 하는 방법이 가장 효과적이며 요구 사항을 충족하는 방법입니다.**




## 질문: 213
SysOps 관리자는 AWS 리전 간 데이터 전송 비용을 추적해야 합니다. SysOps 관리자는 전송 비용이 특정 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내는 솔루션을 구현해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. AWS 비용 및 사용 보고서를 만듭니다. Amazon Athena에서 결과를 분석합니다. 비용이 임계값의 75%에 도달하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.
2. 비용이 임계값의 75%에 도달하면 감지하도록 Amazon CloudWatch 청구 알람을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.
3. AWS Budgets를 사용하여 데이터 전송 비용에 대한 비용 예산을 만듭니다. 예산 금액의 75%에 알림을 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 예산을 구성합니다.
4. VPC 흐름 로그를 설정합니다. 데이터 전송을 분석하기 위해 AWS Lambda 함수에 구독 필터를 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 Lambda 함수를 구성합니다.

이 요구 사항을 충족하기 위한 가장 적절한 솔루션은 다음과 같습니다:

### **3. AWS Budgets를 사용하여 데이터 전송 비용에 대한 비용 예산을 만듭니다. 예산 금액의 75%에 알림을 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 예산을 구성합니다.**

#### 이유:
- **AWS Budgets**: 이 서비스는 사용자가 설정한 예산 기준에 따라 비용 및 사용량을 추적할 수 있게 해줍니다. 데이터 전송 비용에 대해 특정 임계값을 설정하고, 해당 임계값의 75%에 도달했을 때 알림을 보낼 수 있습니다.
- **이메일 알림**: AWS Budgets에서는 비용이 임계값에 도달했을 때 Amazon Simple Notification Service(Amazon SNS)를 통해 이메일 알림을 보낼 수 있습니다. 이를 통해 필요한 이메일 배포 목록에 직접 알림을 보낼 수 있습니다.

### **대안 설명:**

1. **AWS 비용 및 사용 보고서를 만듭니다. Amazon Athena에서 결과를 분석합니다. 비용이 임계값의 75%에 도달하면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.**
   - 이 방법은 유용하지만 설정과 관리가 복잡합니다. Athena를 사용해 분석해야 하므로 추가적인 작업이 필요합니다.

2. **비용이 임계값의 75%에 도달하면 감지하도록 Amazon CloudWatch 청구 알람을 만듭니다. Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시하도록 알람을 구성합니다. 토픽에 이메일 배포 목록을 구독합니다.**
   - CloudWatch 청구 알람은 특정 비용을 감지하는 데 유용하지만, 예산을 설정하고 관리하는 것보다 덜 유연합니다. AWS Budgets가 더 적합한 선택입니다.

4. **VPC 흐름 로그를 설정합니다. 데이터 전송을 분석하기 위해 AWS Lambda 함수에 구독 필터를 설정합니다. 비용이 임계값의 75%에 도달하면 이메일 배포 목록에 알림을 보내도록 Lambda 함수를 구성합니다.**
   - VPC 흐름 로그 및 Lambda를 사용하여 데이터 전송을 추적하는 것은 가능하지만, 비용 전송과 직접적인 관련이 없고 설정이 복잡하므로 최적의 솔루션이 아닙니다.

결론적으로, **AWS Budgets를 사용하여 데이터 전송 비용에 대한 예산을 설정하고 알림을 구성하는 방법이 가장 효과적이며 요구 사항을 충족하는 방법입니다.**


## 질문: 214
회사는 모든 감사 로그를 10년 동안 보관해야 합니다. 회사는 로그를 향후 편집으로부터 보호해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. AWS Key Management Service(AWS KMS) 암호화를 구성합니다.
2. Amazon S3 Glacier 볼트에 데이터를 저장합니다. WORM(write-once, read-many) 액세스에 대한 볼트 잠금 정책을 구성합니다.
3. Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 서버 측 암호화를 구성합니다.
4. Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 다중 요소 인증(MFA)을 구성합니다.
 
회사가 모든 감사 로그를 10년 동안 보관하고, 로그를 향후 편집으로부터 보호해야 하는 요구 사항을 충족하기 위한 가장 적절한 솔루션은 다음과 같습니다:

### **2. Amazon S3 Glacier 볼트에 데이터를 저장합니다. WORM(write-once, read-many) 액세스에 대한 볼트 잠금 정책을 구성합니다.**

#### 이유:
- **Amazon S3 Glacier**: 이 서비스는 장기 보관 및 저비용 저장에 적합하며, 10년 동안 데이터를 안전하게 보관하는 데 유용합니다.
- **WORM 볼트 잠금 정책**: WORM 정책을 사용하면 데이터가 작성된 후 변경할 수 없도록 보호되며, 이는 로그 데이터의 무결성을 보장하는 데 매우 중요합니다. 볼트 잠금을 통해 데이터는 설정된 기간 동안 삭제되거나 수정될 수 없습니다.

### **대안 설명:**

1. **Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. AWS Key Management Service(AWS KMS) 암호화를 구성합니다.**
   - EBS는 일반적으로 블록 저장소이며, 장기 보관 및 WORM 보호에는 적합하지 않습니다. 로그 데이터의 무결성을 보장하기 어려울 수 있습니다.

3. **Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 서버 측 암호화를 구성합니다.**
   - S3 Standard-IA는 적당한 비용으로 데이터에 액세스할 수 있지만, WORM 보호 기능이 없어 로그의 편집 및 삭제로부터 보호할 수 없습니다.

4. **Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 다중 요소 인증(MFA)을 구성합니다.**
   - MFA는 추가적인 보안 계층을 제공하지만, WORM 보호 기능이 없으므로 로그의 변경을 방지하는 데 적합하지 않습니다.

결론적으로, **Amazon S3 Glacier와 WORM 볼트 잠금 정책을 사용하는 것이 10년 동안 로그를 보관하고 편집으로부터 보호하는 데 가장 효과적인 방법입니다.**



## 질문: 215
회사의 AWS Lambda 함수에서 성능 문제가 발생하고 있습니다. Lambda 함수는 많은 CPU 집약적 작업을 수행합니다. Lambda 함수가 충분히 빠르게 실행되지 않아 시스템에 병목 현상이 발생합니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1. Lambda 함수의 CPU 시작 옵션에서 하이퍼스레딩을 활성화합니다.
2. AWS 관리 암호화를 끕니다.
3. Lambda 함수의 메모리 양을 늘립니다.
4. 필요한 코드를 사용자 정의 레이어에 로드합니다.

AWS Lambda 함수에서 CPU 집약적 작업으로 인해 성능 문제가 발생하는 경우, 이를 해결하기 위해 가장 적절한 조치는 다음과 같습니다:

### **3. Lambda 함수의 메모리 양을 늘립니다.**

#### 이유:
- AWS Lambda는 메모리 할당량에 따라 CPU 성능을 자동으로 조정합니다. 즉, 더 많은 메모리를 할당하면 Lambda 함수에 할당되는 CPU 용량도 증가합니다. 따라서 Lambda 함수의 메모리를 늘리면 CPU 성능이 향상되어 성능 병목 현상이 완화될 수 있습니다.

### **대안 설명:**

1. **Lambda 함수의 CPU 시작 옵션에서 하이퍼스레딩을 활성화합니다.**
   - AWS Lambda에서는 하이퍼스레딩을 수동으로 활성화할 수 없으며, CPU는 메모리와 함께 자동으로 할당됩니다. 따라서 이 옵션은 사용할 수 없습니다.

2. **AWS 관리 암호화를 끕니다.**
   - 암호화는 성능에 큰 영향을 미치지 않으며, 보안과 관련된 중요한 요소이기 때문에 단순히 끄는 것은 권장되지 않습니다.

4. **필요한 코드를 사용자 정의 레이어에 로드합니다.**
   - 사용자 정의 레이어는 코드 재사용 및 관리에 유용하지만, CPU 성능 문제를 직접 해결하지는 않습니다. 성능을 개선하려면 메모리를 늘리는 것이 더 효과적입니다.

결론적으로, Lambda 함수의 성능을 개선하기 위해 **메모리 양을 늘리는 것이 가장 효과적인 방법**입니다.

## 질문: 216
한 회사가 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다.

 웹 서버 로그는 Amazon CloudWatch Logs에 게시됩니다. 로그 이벤트는 동일한 구조를 가지고 있으며 사용자 요청과 관련된 HTTP 응답 코드를 포함합니다. 이 회사는 웹 서버가 HTTP 404 응답을 반환하는 횟수를 모니터링해야 합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1. 웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 메트릭 필터를 만듭니다.
2. 웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 구독 필터를 만듭니다.
3. 지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 AWS Lambda 함수를 만듭니다.
4. 지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 스크립트를 만듭니다.
 
HTTP 404 응답을 모니터링하기 위한 가장 운영 효율적인 솔루션은 다음과 같습니다:

### **1. 웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 메트릭 필터를 만듭니다.**

#### 이유:
- **메트릭 필터**를 사용하면 CloudWatch Logs에서 특정 로그 이벤트(이 경우 HTTP 404 응답)를 자동으로 수집하고 이를 기반으로 메트릭을 생성할 수 있습니다. 이 방법은 실시간으로 모니터링할 수 있으며, 다른 설정이나 추가 작업 없이도 특정 이벤트의 수를 쉽게 추적할 수 있습니다.
- 메트릭 필터를 설정하면 CloudWatch 대시보드에서 이를 시각화하거나 알람을 설정하는 것도 간단합니다.

### **대안 설명:**

2. **웹 서버가 HTTP 404 응답을 반환하는 횟수를 세는 CloudWatch Logs 구독 필터를 만듭니다.**
   - 구독 필터는 실시간 데이터 흐름을 위해 주로 사용됩니다. HTTP 404 응답을 모니터링하는 데 유용할 수 있지만, 메트릭을 수집하고 모니터링하는 효율성 측면에서는 메트릭 필터보다 덜 효율적입니다.

3. **지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 AWS Lambda 함수를 만듭니다.**
   - 이 방법은 수동적이며, Lambda 함수를 호출해야 하므로 운영적으로 덜 효율적입니다. 쿼리를 정기적으로 실행해야 하므로 자동화 측면에서도 추가적인 관리가 필요합니다.

4. **지난 1시간 동안 로그 이벤트에서 404 코드의 수를 계산하는 CloudWatch Logs Insights 쿼리를 실행하는 스크립트를 만듭니다.**
   - 스크립트를 주기적으로 실행해야 하며, 추가적인 유지 관리가 필요하므로 운영 효율성 측면에서는 비효율적입니다.

결론적으로, **CloudWatch Logs 메트릭 필터**를 설정하는 것이 HTTP 404 응답을 모니터링하는 데 있어 가장 운영 효율적인 솔루션입니다.



## 질문: 217
한 회사가 AWS 클라우드에서 비용을 관리하려고 합니다. SysOps 관리자는 청구 보고서에 표시될 리소스에 할당된 특정 회사 정의 태그가 필요합니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1. AWS에서 생성한 비용 할당 태그로 태그를 활성화합니다.
2. 태그를 사용자 정의 비용 배분 태그로 활성화합니다.
3. 새로운 비용 범주를 만듭니다. 계정 청구 차원을 선택합니다.
4. 새로운 AWS 비용 및 사용 보고서를 만듭니다. 리소스 ID를 포함합니다.

AWS에서 비용 관리 요구 사항을 충족하기 위해 SysOps 관리자가 해야 할 조치는 다음과 같습니다:

### **2. 태그를 사용자 정의 비용 배분 태그로 활성화합니다.**

#### 이유:
- **사용자 정의 비용 배분 태그**를 활성화하면 AWS 청구 및 비용 관리 대시보드에서 특정 태그를 사용하여 리소스 비용을 추적하고 보고할 수 있습니다. 이렇게 하면 각 리소스에 대한 비용을 분석하고 회사의 요구에 따라 리소스를 할당할 수 있습니다.
- 이 태그는 청구 보고서에 포함되어 특정 태그가 할당된 리소스의 비용을 정확하게 파악할 수 있도록 도와줍니다.

### **대안 설명:**

1. **AWS에서 생성한 비용 할당 태그로 태그를 활성화합니다.**
   - AWS에서 자동으로 생성한 태그는 일반적으로 기본 제공되는 태그이며, 특정 회사 정의 태그를 포함하지 않을 수 있습니다.

3. **새로운 비용 범주를 만듭니다. 계정 청구 차원을 선택합니다.**
   - 비용 범주는 비용을 그룹화하는 데 사용되지만, 특정 리소스에 대한 태그를 활성화하는 것과는 다릅니다. 특정 태그에 대한 비용을 관리하기 위해서는 비용 배분 태그가 필요합니다.

4. **새로운 AWS 비용 및 사용 보고서를 만듭니다. 리소스 ID를 포함합니다.**
   - 비용 및 사용 보고서는 정보를 집계할 수 있지만, 특정 태그를 활성화하지 않으면 원하는 리소스에 대한 세부 비용을 추적할 수 없습니다.

결론적으로, **사용자 정의 비용 배분 태그를 활성화하는 것**이 회사 정의 태그가 청구 보고서에 표시될 수 있도록 하는 가장 효과적인 방법입니다.


## 질문: 218
한 회사가 전 세계적으로 확장 중이며 Amazon Elastic Block Store(Amazon EBS) 볼륨의 데이터를 다른 AWS 리전으로 백업해야 합니다. 데이터를 저장하는 대부분의 EBS 볼륨은 암호화되어 있지만 일부 EBS 볼륨은 암호화되지 않았습니다. 이 회사는 모든 EBS 볼륨의 백업 데이터를 암호화해야 합니다.

어떤 솔루션이 가장 적은 관리 오버헤드로 이러한 요구 사항을 충족할까요?

1. Amazon Data Lifecycle Manager(Amazon DLM)에서 수명 주기 정책을 구성하여 크로스 리전 백업이 활성화된 EBS 볼륨 스냅샷을 만듭니다. AWS Key Management Service(AWS KMS)를 사용하여 스냅샷 사본을 암호화합니다.
2. EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷 상태가 COMPLETED이면 스냅샷을 다른 Region으로 복사하고 Encrypted 매개변수를 False로 설정합니다.
3. EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷을 서버 측 암호화를 사용하는 Amazon S3 버킷에 복사합니다. S3 버킷에서 S3 Cross-Region Replication을 켭니다.
4.  Python 런타임으로 AWS Lambda 함수를 예약합니다. Lambda 함수를 구성하여 EBS 볼륨 스냅샷을 만들고, 암호화되지 않은 스냅샷을 암호화하고, 스냅샷을 다른 리전으로 복사합니다.

주어진 요구 사항을 충족하는 가장 관리 오버헤드가 적은 솔루션은 다음과 같습니다:

### **1. Amazon Data Lifecycle Manager(Amazon DLM)에서 수명 주기 정책을 구성하여 크로스 리전 백업이 활성화된 EBS 볼륨 스냅샷을 만듭니다. AWS Key Management Service(AWS KMS)를 사용하여 스냅샷 사본을 암호화합니다.**

#### 이유:
- **Amazon Data Lifecycle Manager (DLM)**를 사용하면 EBS 볼륨의 스냅샷을 자동으로 생성하고 관리할 수 있으며, 정책에 따라 주기적으로 실행됩니다. 이로 인해 수동으로 스냅샷을 만들 필요가 없어 관리 오버헤드가 줄어듭니다.
- **크로스 리전 백업**을 활성화하면 스냅샷이 다른 AWS 리전으로 자동으로 복사되므로 추가적인 작업이 필요 없습니다.
- **AWS KMS를 사용한 암호화**는 자동으로 모든 스냅샷에 적용되므로, 암호화되지 않은 볼륨도 안전하게 보호할 수 있습니다.

### **대안 설명:**

2. **EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷 상태가 COMPLETED이면 스냅샷을 다른 Region으로 복사하고 Encrypted 매개변수를 False로 설정합니다.**
   - 이 방법은 수동 작업이 필요하며 관리 오버헤드가 더 많습니다. 각 스냅샷을 수동으로 확인하고 복사해야 하므로 비효율적입니다.

3. **EBS 볼륨의 시점 스냅샷을 만듭니다. 스냅샷을 서버 측 암호화를 사용하는 Amazon S3 버킷에 복사합니다. S3 버킷에서 S3 Cross-Region Replication을 켭니다.**
   - 이 방법은 EBS 스냅샷을 S3에 복사하는 복잡한 절차를 요구하며, EBS 볼륨의 데이터를 S3로 복사하는 것은 일반적으로 권장되지 않습니다.

4. **Python 런타임으로 AWS Lambda 함수를 예약합니다. Lambda 함수를 구성하여 EBS 볼륨 스냅샷을 만들고, 암호화되지 않은 스냅샷을 암호화하고, 스냅샷을 다른 리전으로 복사합니다.**
   - Lambda 함수를 사용하는 방법은 관리 오버헤드가 크고 유지보수해야 할 코드가 필요합니다. 이는 자동화의 이점을 줄입니다.

결론적으로, **Amazon Data Lifecycle Manager를 사용하는 방법**이 가장 효율적이며 관리 오버헤드가 적어 요구 사항을 충족할 수 있습니다.

## 질문: 219
SysOps 관리자가 AWS Fargate를 사용하는 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터를 만듭니다. 클러스터가 성공적으로 배포되었습니다. SysOps 관리자는 kubectl 명령줄 도구를 사용하여 클러스터를 관리해야 합니다.

kubectl이 클러스터 API 서버와 통신할 수 있도록 SysOps 관리자의 머신에서 다음 중 어떤 것을 구성해야 합니까?

1. kubeconfig 파일
2. kube-proxy Amazon EKS 추가 기능
3. Fargate 프로필
4. eks-connector.yaml 파일

SysOps 관리자가 AWS Fargate를 사용하는 Amazon Elastic Kubernetes Service (EKS) 클러스터에서 `kubectl` 명령줄 도구를 사용하여 클러스터를 관리하기 위해 구성해야 하는 것은 다음과 같습니다:

### **1. kubeconfig 파일**

#### 이유:
- **kubeconfig 파일**은 `kubectl`이 Kubernetes API 서버와 통신하기 위해 필요한 클러스터 정보, 사용자 인증 정보 및 네임스페이스 설정을 포함합니다.
- EKS 클러스터를 배포하면 AWS CLI 또는 AWS Management Console을 통해 `kubeconfig` 파일을 생성하고 구성할 수 있습니다. 이 파일을 사용하여 `kubectl` 명령어로 EKS 클러스터에 접근하고 관리할 수 있습니다.

### **다른 옵션 설명:**

2. **kube-proxy Amazon EKS 추가 기능**:
   - `kube-proxy`는 Kubernetes 클러스터 내에서 네트워크 트래픽을 관리하는 구성 요소입니다. 이 기능은 클러스터 내부에서 동작하며 `kubectl`과의 통신을 설정하는 데 필요하지 않습니다.

3. **Fargate 프로필**:
   - Fargate 프로필은 EKS에서 작업을 실행할 Fargate 작업을 정의하는 데 사용되며, `kubectl`의 통신 설정과는 관련이 없습니다.

4. **eks-connector.yaml 파일**:
   - `eks-connector.yaml`은 일반적으로 EKS 클러스터와 AWS 리소스를 연결하는 구성 파일이지만, `kubectl`을 사용하여 클러스터를 관리하는 데는 필요하지 않습니다.

따라서, **kubeconfig 파일**을 설정하는 것이 `kubectl`이 클러스터 API 서버와 통신할 수 있도록 하는 올바른 방법입니다.


## 질문: 220
한 회사가 분석에 사용할 애플리케이션에서 데이터를 수집하려고 합니다. 

처음 90일 동안은 데이터에 자주 액세스하지 않지만 가용성은 높게 유지해야 합니다. 이 기간 동안 회사의 분석 팀은 밀리초 단위로 데이터에 액세스해야 합니다. 그러나 90일 후에는 회사에서 더 낮은 비용으로 장기간 데이터를 보관해야 합니다. 90일 후 검색 시간은 5시간 미만이어야 합니다.

이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

1.처음 90일 동안 S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터를 저장합니다. 90일 후 S3 Glacier Flexible Retrieval로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
2.처음 90일 동안 S3 One Zone-Infrequent Access(S3 One Zone-IA)에 데이터를 저장합니다. 90일 후에 S3 Glacier Deep Archive로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
3.처음 90일 동안 S3 Standard에 데이터를 저장합니다. 90일 후 S3 Glacier Flexible Retrieval로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.
4.처음 90일 동안 S3 Standard에 데이터를 저장합니다. 90일 후 S3 Glacier Deep Archive로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.

이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 다음과 같습니다:

### **3. 처음 90일 동안 S3 Standard에 데이터를 저장합니다. 90일 후 S3 Glacier Flexible Retrieval로 데이터를 이동하기 위한 S3 Lifecycle 규칙을 설정합니다.**

#### 이유:
1. **초기 90일 동안 S3 Standard 사용**:
   - **S3 Standard** 스토리지 클래스는 고가용성을 제공하며, 밀리초 단위로 데이터에 액세스할 수 있는 속도를 지원합니다. 처음 90일 동안 자주 액세스할 데이터에 적합합니다.

2. **90일 후 S3 Glacier Flexible Retrieval로 이동**:
   - **S3 Glacier Flexible Retrieval**는 장기 저장을 위해 비용 효율적이며, 검색 시간은 5시간 이내로 설정할 수 있습니다. 따라서 초기 요구 사항이 완료된 후 데이터를 안전하게 저장할 수 있습니다.

### **다른 옵션 설명:**

1. **S3 Standard-IA**:
   - 처음 90일 동안 사용할 수 있지만, 이 스토리지 클래스는 저비용의 비정기적인 액세스를 위한 것이므로 데이터에 자주 액세스해야 하는 경우 적합하지 않습니다.

2. **S3 One Zone-IA**:
   - 저렴한 비용으로 제공되지만, 데이터 내구성과 가용성이 떨어집니다. 따라서 높은 가용성이 필요한 데이터에는 적합하지 않습니다.

3. **S3 Glacier Deep Archive**:
   - 가장 저렴한 스토리지 옵션이지만, 검색 시간이 12시간 이상 걸리므로 90일 후에도 5시간 이내로 검색해야 하는 요구 사항에 부합하지 않습니다.

따라서, **처음 90일 동안 S3 Standard에 데이터를 저장하고 90일 후에 S3 Glacier Flexible Retrieval로 이동하는 방법이 가장 적합합니다.**

## 질문: 221
회사의 애플리케이션은 현재 모든 AWS 서비스에 대한 모든 액세스를 허용하는 IAM 역할을 사용합니다. 

SysOps 관리자는 회사의 IAM 정책이 애플리케이션에 필요한 권한만 허용하는지 확인해야 합니다.

SysOps 관리자는 이 요구 사항을 충족하는 정책을 어떻게 만들 수 있습니까?

1.AWS CloudTrail을 켭니다. AWS Security Hub를 사용하여 정책을 생성합니다.
2.Amazon EventBridge(Amazon CloudWatch Events)를 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.
3.AWS CLI를 사용하여 AWS Identity and Access Management Access Analyzer에서 get-generated-policy 명령을 실행합니다.
4.AWS CloudTrail을 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.
 

SysOps 관리자가 회사의 IAM 정책이 애플리케이션에 필요한 권한만 허용하는지 확인하기 위해 가장 적합한 방법은 다음과 같습니다:

### **3. AWS CLI를 사용하여 AWS Identity and Access Management Access Analyzer에서 get-generated-policy 명령을 실행합니다.**

#### 이유:
- **AWS IAM Access Analyzer**는 기존 리소스의 액세스 로그를 분석하여 IAM 역할 또는 정책에 필요한 최소 권한을 생성하는 데 도움을 줍니다.
- `get-generated-policy` 명령은 특정 역할에 대한 사용 기록을 기반으로 권한을 자동으로 생성합니다. 이를 통해 현재 IAM 역할이 실제로 사용하는 권한만 포함된 정책을 얻을 수 있습니다.

### **다른 옵션 설명:**

1. **AWS CloudTrail을 켭니다. AWS Security Hub를 사용하여 정책을 생성합니다.**
   - CloudTrail은 API 호출을 기록하지만, Security Hub는 보안 관련 데이터를 집계하는 도구로 IAM 정책을 직접 생성하는 데는 사용되지 않습니다.

2. **Amazon EventBridge(Amazon CloudWatch Events)를 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.**
   - EventBridge는 이벤트 기반 서비스이며, Access Analyzer와 함께 사용할 수 있지만, 정책 생성을 위한 직접적인 방법은 아닙니다.

4. **AWS CloudTrail을 켭니다. AWS Identity and Access Management Access Analyzer를 사용하여 정책을 생성합니다.**
   - CloudTrail을 활성화하는 것은 좋지만, 직접적인 정책 생성 기능은 Access Analyzer의 기능이므로, 이 방법은 완전한 솔루션이 아닙니다.

따라서, **AWS CLI를 사용하여 AWS Identity and Access Management Access Analyzer에서 get-generated-policy 명령을 실행하는 것이 가장 적합한 방법입니다.**




## 질문: 222
한 회사에서 Amazon EC2 Amazon Machine Image(AMI)로 제공되는 타사 단위 테스트 솔루션을 배포하고 있습니다. 

모든 시스템 구성 데이터는 Amazon DynamoDB에 저장됩니다. 테스트 결과는 Amazon S3에 저장됩니다.

제품을 작동하려면 최소 3개의 EC2 인스턴스가 필요합니다. 회사의 테스트 팀은 Spot Instance 가격이 특정 임계값에 도달하면 추가로 3개의 EC2 인스턴스를 사용하려고 합니다. SysOps 관리자는 이 기능을 제공하는 고가용성 솔루션을 구현해야 합니다.

어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구 사항을 충족할까요?

1.시작 구성을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 구성에서 제공된 AMI를 사용합니다. 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성합니다. 시작 구성에서 최대 스팟 인스턴스 가격을 구성합니다.
2.시작 템플릿을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 템플릿에서 제공된 AMI를 사용합니다. 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성합니다. 시작 템플릿에서 최대 스팟 인스턴스 가격을 구성합니다.
3.시작 구성을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 구성에서 제공된 AMI를 사용합니다. 한 자동 확장 그룹에 대해 세 개의 온디맨드 인스턴스를 구성합니다. 다른 자동 확장 그룹에 대해 세 개의 스팟 인스턴스를 구성합니다. 스팟 인스턴스가 있는 자동 확장 그룹에 대해 시작 구성에서 최대 스팟 인스턴스 가격을 구성합니다.
4.시작 템플릿을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 템플릿에서 제공하는 AMI를 사용합니다. 한 자동 확장 그룹에 대해 세 개의 온디맨드 인스턴스를 구성합니다. 다른 자동 확장 그룹에 대해 세 개의 스팟 인스턴스를 구성합니다. 스팟 인스턴스가 있는 자동 확장 그룹에 대해 시작 템플릿에서 최대 스팟 인스턴스 가격을 구성합니다.

고가용성 솔루션을 구현하고, 스팟 인스턴스 가격이 특정 임계값에 도달했을 때 추가로 EC2 인스턴스를 사용하도록 하는 최소한의 운영 오버헤드 솔루션은 다음과 같습니다:

### **2. 시작 템플릿을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다. 시작 템플릿에서 제공된 AMI를 사용합니다. 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성합니다. 시작 템플릿에서 최대 스팟 인스턴스 가격을 구성합니다.**

#### 이유:
- **시작 템플릿**은 시작 구성에 비해 유연성과 기능이 더 많습니다. 예를 들어, 버전 관리와 변경 관리가 용이하며, 태그 및 다른 기능을 더 잘 지원합니다.
- **자동 확장 그룹**을 사용하면 EC2 인스턴스의 수를 동적으로 조정할 수 있습니다. 이는 고가용성을 유지하는 데 중요한 역할을 합니다.
- 3개의 온디맨드 인스턴스와 3개의 스팟 인스턴스를 구성하여, 스팟 인스턴스 가격이 임계값에 도달했을 때 자동으로 인스턴스를 추가할 수 있습니다.

### **다른 옵션 설명:**

1. **시작 구성을 사용하여 Amazon EC2 자동 확장 그룹을 정의합니다.**
   - 시작 구성은 더 이상 권장되지 않으며, 기능이 제한적입니다.

3. **시작 구성을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다.**
   - 이 방법은 관리 오버헤드가 증가할 수 있으며, 시작 구성은 권장되지 않습니다.

4. **시작 템플릿을 사용하여 두 개의 Amazon EC2 자동 확장 그룹을 정의합니다.**
   - 이 방법도 가능하지만, 단일 자동 확장 그룹에서 온디맨드와 스팟 인스턴스를 조합하여 관리하는 것이 더 효율적입니다.

따라서 **시작 템플릿을 사용하여 단일 자동 확장 그룹을 정의하고, 온디맨드와 스팟 인스턴스를 조합하여 구성하는 것이 가장 적합한 방법입니다.**


## 질문: 223
SysOps 관리자는 여러 AWS 리전에 배포할 수 있는 애플리케이션 스택을 정의하기 위해 AWS CloudFormation 템플릿을 만듭니다. 

SysOps 관리자는 또한 AWS Management Console을 사용하여 Amazon CloudWatch 대시보드를 만듭니다. 애플리케이션의 각 배포에는 고유한 CloudWatch 대시보드가 ​​필요합니다.

SysOps 관리자는 애플리케이션이 배포될 때마다 CloudWatch 대시보드 생성을 어떻게 자동화할 수 있습니까?

1.AWS CLI를 사용하여 대시보드 이름으로 aws cloudformation put-dashboard 명령을 실행하기 위해 스크립트를 만듭니다. 새 CloudFormation 스택이 생성될 때마다 명령을 실행합니다.
2.기존 CloudWatch 대시보드를 JSON으로 내보냅니다. CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. 내보낸 JSON을 리소스의 DashboardBody 속성에 포함합니다.
3.CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. Intrinsic Ref 함수를 사용하여 기존 CloudWatch 대시보드의 ID를 참조합니다.
4.CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. DashboardName 속성에 기존 대시보드의 이름을 지정합니다.


AWS CloudFormation 템플릿을 사용하여 애플리케이션 배포 시 Amazon CloudWatch 대시보드 생성을 자동화하기 위한 가장 효율적인 솔루션은 다음과 같습니다:

### **2. 기존 CloudWatch 대시보드를 JSON으로 내보냅니다. CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. 내보낸 JSON을 리소스의 DashboardBody 속성에 포함합니다.**

#### 이유:
- **CloudFormation 리소스 정의**: AWS::CloudWatch::Dashboard 리소스를 정의하면 CloudFormation 스택이 생성될 때 자동으로 대시보드를 생성할 수 있습니다.
- **JSON 내보내기**: 기존 대시보드를 JSON으로 내보내면, 대시보드의 현재 구성과 모니터링할 지표를 그대로 가져올 수 있어 재사용이 가능합니다.
- **자동화**: 새로운 애플리케이션 배포마다 CloudFormation 스택을 실행하면 대시보드도 자동으로 생성되므로 운영 오버헤드가 줄어듭니다.

### **다른 옵션 설명:**

1. **AWS CLI를 사용하여 대시보드 이름으로 aws cloudformation put-dashboard 명령을 실행하기 위해 스크립트를 만듭니다.**
   - 이 방법은 CLI를 통한 수동 작업이 필요하고, CloudFormation과의 통합이 없어 자동화가 부족합니다.

3. **CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. Intrinsic Ref 함수를 사용하여 기존 CloudWatch 대시보드의 ID를 참조합니다.**
   - 기존 대시보드의 ID를 참조하는 것은 새로운 대시보드를 자동으로 생성하는 데 적합하지 않으며, 대시보드가 이미 존재하는 경우에만 유용합니다.

4. **CloudFormation 템플릿을 업데이트하여 AWS::CloudWatch::Dashboard 리소스를 정의합니다. DashboardName 속성에 기존 대시보드의 이름을 지정합니다.**
   - 이 방법도 기존 대시보드를 참조하는 것이며, 새로운 대시보드를 생성하는 데는 적합하지 않습니다.

따라서 **기존 대시보드를 JSON으로 내보내고, CloudFormation 템플릿에 포함하여 대시보드를 자동으로 생성하는 것이 가장 효과적인 방법입니다.**


## 질문: 224
한 회사가 규제된 워크로드에 대한 클라우드 호스팅 준비를 명확히 하기 위해 보안 정책을 업데이트했습니다. 민감한 것으로 식별된 워크로드는 회사 내의 다른 고객이나 다른 AWS 계정과 공유되지 않는 하드웨어에서 실행되어야 합니다.

어떤 솔루션이 이 정책을 준수하도록 보장할까요?

1.전용 호스트에만 워크로드를 배포합니다.
2.전용 인스턴스에만 워크로드를 배포합니다.
3.예약 인스턴스에만 워크로드를 배포합니다.
4.모든 인스턴스를 전용 배치 그룹에 배치합니다.

회사의 보안 정책에 따라 민감한 워크로드가 다른 고객이나 AWS 계정과 공유되지 않는 하드웨어에서 실행되어야 한다면, 가장 적합한 솔루션은 **"전용 호스트에만 워크로드를 배포합니다."**입니다.

### 정답:
**1. 전용 호스트에만 워크로드를 배포합니다.**

#### 이유:
- **물리적 격리**: 전용 호스트는 단일 고객을 위해 물리적으로 전용된 EC2 호스트입니다. 이는 해당 호스트에서 실행되는 모든 인스턴스가 고객의 것만으로 구성되며, 다른 고객과 자원을 공유하지 않습니다. 이러한 방식은 규제된 워크로드에 대해 높은 수준의 보안을 제공합니다.
- **규제 준수**: 전용 호스트를 사용하면 민감한 데이터가 다른 고객과 격리된 환경에서 처리되므로 규제 요구 사항을 준수하는 데 적합합니다.

### 대안 설명:
2. **전용 인스턴스에만 워크로드를 배포합니다.**
   - 전용 인스턴스는 특정 하드웨어에서 실행되지만, 해당 인스턴스는 여전히 다른 AWS 계정과 같은 물리적 호스트를 공유할 수 있습니다. 따라서 완전한 격리를 보장하지는 않습니다.

3. **예약 인스턴스에만 워크로드를 배포합니다.**
   - 예약 인스턴스는 인스턴스에 대한 결제 모델로, 물리적 호스트에 대한 격리를 제공하지 않습니다. 예약 인스턴스는 다른 고객과 호스트를 공유할 수 있습니다.

4. **모든 인스턴스를 전용 배치 그룹에 배치합니다.**
   - 전용 배치 그룹은 인스턴스가 특정 하드웨어에 배치되도록 하지만, 여전히 다른 고객과 같은 물리적 호스트를 공유할 수 있으므로 완전한 격리를 제공하지는 않습니다.

따라서, **전용 호스트에 워크로드를 배포하는 것이 보안 정책을 준수하는 가장 적합한 솔루션입니다.**


## 질문: 225
한 회사가 호주 시드니에서 웹사이트를 운영합니다. 미국과 유럽의 사용자들은 이미지와 비디오가 로드되는 데 시간이 오래 걸린다고 보고하고 있습니다. 그러나 호주에서 실시한 로컬 테스트에서는 성능 문제가 나타나지 않았습니다. 웹사이트에는 Amazon S3에 저장된 이미지와 비디오 형태의 정적 콘텐츠가 대량으로 있습니다.

미국과 유럽 사용자의 사용자 경험을 가장 크게 개선할 수 있는 솔루션은 무엇일까요?

1.Amazon S3에 대한 AWS PrivateLink를 구성합니다.
2.S3 전송 가속을 구성합니다.
3.Amazon CloudFront 배포를 만듭니다. 정적 콘텐츠를 CloudFront 엣지 위치에 배포합니다.
4.각 AWS 리전에서 Amazon API Gateway API를 만듭니다. 로컬에서 콘텐츠를 캐시합니다.

미국과 유럽 사용자들의 이미지와 비디오 로딩 시간을 개선하기 위해 가장 효과적인 솔루션은 **"Amazon CloudFront 배포를 만듭니다. 정적 콘텐츠를 CloudFront 엣지 위치에 배포합니다."**입니다.

### 정답:
**3. Amazon CloudFront 배포를 만듭니다. 정적 콘텐츠를 CloudFront 엣지 위치에 배포합니다.**

#### 이유:
- **전 세계적인 엣지 위치**: Amazon CloudFront는 전 세계에 분산된 엣지 로케이션을 제공하여 사용자의 위치와 가까운 서버에서 콘텐츠를 제공함으로써 지연 시간을 줄입니다. 이는 미국과 유럽 사용자에게 더 빠른 로딩 시간을 제공합니다.
- **정적 콘텐츠 캐싱**: CloudFront는 정적 콘텐츠를 캐싱하여 이후 요청 시 서버에 대한 부하를 줄이고 사용자에게 더 빠르게 데이터를 제공합니다.

### 대안 설명:
1. **Amazon S3에 대한 AWS PrivateLink를 구성합니다.**
   - AWS PrivateLink는 보안 통신을 제공하지만, 사용자 경험을 개선하는 데 도움이 되지 않으며, 특히 정적 콘텐츠의 지연 시간 문제를 해결할 수 없습니다.

2. **S3 전송 가속을 구성합니다.**
   - S3 전송 가속은 업로드 성능을 향상시키지만, 정적 콘텐츠의 배포 속도에는 직접적인 영향을 미치지 않습니다. 이 솔루션은 다운로드 속도를 개선하는 데 제한적입니다.

4. **각 AWS 리전에서 Amazon API Gateway API를 만듭니다. 로컬에서 콘텐츠를 캐시합니다.**
   - API Gateway는 RESTful API를 생성하는 데 유용하지만, 정적 콘텐츠의 전송을 위해 사용하기에는 비효율적이며, CloudFront와 같은 콘텐츠 전송 네트워크(CDN) 솔루션보다 성능 개선 효과가 적습니다.

따라서 **CloudFront를 사용하여 정적 콘텐츠를 전 세계에 효율적으로 배포하는 것이 가장 좋은 해결책입니다.**


## 질문: 226
SysOps 관리자가 Amazon Elastic Block Store(Amazon EBS) 볼륨이 연결된 Amazon EC2 인스턴스 세트에서 사용 가능한 디스크 공간을 모니터링하려고 합니다. SysOps 관리자는 EBS 볼륨의 사용된 디스크 공간이 임계값을 초과할 때 알림을 받고 싶지만 DiskReadOps 메트릭도 임계값을 초과할 때만 알림을 받고 싶어합니다. SysOps 관리자가 Amazon Simple Notification Service(Amazon SNS) 토픽을 설정했습니다. SysOps 관리자

가 두 메트릭이 모두 임계값을 초과할 때만 알림을 받을 수 있는 방법은 무엇입니까?

1.EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
2.EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 각 알람을 구성하여 SNS 토픽에 알림을 게시합니다.
3.EBSByteBalance% 메트릭에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
4.EC2 인스턴스에 대한 자세한 모니터링을 구성합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.
 

SysOps 관리자가 Amazon EBS 볼륨의 사용된 디스크 공간과 DiskReadOps 메트릭이 모두 임계값을 초과할 때만 알림을 받기 위해 가장 적절한 방법은 **"EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만들고, 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다."**입니다.

### 정답:
**1. EC2 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 디스크 공간에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다. 두 개의 메트릭 알람을 포함하는 복합 알람을 만들어 SNS 토픽에 알림을 게시합니다.**

#### 이유:
- **복합 알람 기능**: CloudWatch에서 복합 알람을 사용하면 여러 메트릭이 모두 특정 조건을 만족할 때만 알림을 받을 수 있습니다. 이 기능을 사용하면 두 메트릭이 동시에 임계값을 초과할 때만 SNS 알림을 받을 수 있습니다.
- **CloudWatch 에이전트**: EBS의 디스크 사용량을 모니터링하려면 EC2 인스턴스에 CloudWatch 에이전트를 설치해야 합니다. 이 에이전트는 인스턴스의 디스크 사용량에 대한 세부 메트릭을 수집할 수 있습니다.

### 대안 설명:
2. **각 알람을 구성하여 SNS 토픽에 알림을 게시합니다.**
   - 이 방법은 각 메트릭에 대해 별도의 알람을 설정하므로, 두 메트릭이 모두 임계값을 초과할 때 알림을 받지 않게 됩니다. 각 메트릭의 임계값 초과에 대한 개별 알림이 전송됩니다.

3. **EBSByteBalance% 메트릭에 대한 메트릭 알람과 DiskReadOps 메트릭에 대한 메트릭 알람을 만듭니다.**
   - EBSByteBalance% 메트릭은 EBS 용량의 가용성에 대한 정보를 제공하지만, 사용된 디스크 공간을 모니터링하는 데 필요한 메트릭이 아닙니다. 디스크 공간의 사용량을 정확히 측정하려면 CloudWatch 에이전트를 통해 수집된 메트릭을 사용하는 것이 좋습니다.

4. **자세한 모니터링을 구성합니다.**
   - 자세한 모니터링을 구성하는 것은 유용하지만, 복합 알람을 사용하여 두 개의 메트릭을 결합하지 않으면 여전히 개별 알람이 생성되어 두 메트릭이 모두 임계값을 초과할 때만 알림을 받는 목표를 달성할 수 없습니다.

따라서 **첫 번째 옵션이 가장 적절한 해결책입니다.**


## 질문: 227
회사가 회사 계정의 Amazon S3 버킷에 있는 모든 데이터의 공개 노출을 금지하기 위해 보안 정책을 업데이트했습니다.

SysOps 관리자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1.계정 수준에서 S3 공개 액세스 차단을 켭니다.
2.모든 S3 객체가 비공개로 유지되도록 Amazon Event Bridge(Amazon CloudWatch Events) 규칙을 만듭니다.
3.Amazon Inspector를 사용하여 S3 버킷을 검색하고 공개 S3 버킷이 발견되면 S3 ACL을 자동으로 재설정합니다.
4.S3 객체 람다를 사용하여 S3 ACL을 조사하고 모든 공개 S3 ACL을 비공개로 변경합니다.

회사가 Amazon S3 버킷에 있는 모든 데이터의 공개 노출을 금지하기 위해 가장 적절한 조치는 **"계정 수준에서 S3 공개 액세스 차단을 켭니다."**입니다.

### 정답:
**1. 계정 수준에서 S3 공개 액세스 차단을 켭니다.**

#### 이유:
- **전체적인 보안 강화**: S3 공개 액세스 차단 기능을 활성화하면 모든 S3 버킷 및 객체에 대해 공용 액세스를 기본적으로 차단할 수 있습니다. 이는 의도치 않게 데이터가 공개되는 것을 방지하고, 전체 계정의 보안을 강화하는 데 매우 효과적입니다.
- **정책 적용의 용이성**: S3 공개 액세스 차단은 단일 설정으로 모든 S3 버킷에 적용되므로, 개별 버킷에 대한 추가적인 설정을 필요로 하지 않습니다.

### 대안 설명:
2. **모든 S3 객체가 비공개로 유지되도록 Amazon Event Bridge(Amazon CloudWatch Events) 규칙을 만듭니다.**
   - 이 방법은 비공식적인 방법으로, S3 객체의 상태를 모니터링하고 자동으로 조치를 취하는 데는 유용하지만, 모든 버킷과 객체에 대한 보안을 보장하는 것에는 한계가 있습니다.

3. **Amazon Inspector를 사용하여 S3 버킷을 검색하고 공개 S3 버킷이 발견되면 S3 ACL을 자동으로 재설정합니다.**
   - Amazon Inspector는 보안 취약점을 분석하는 도구이지만, S3 ACL을 자동으로 조정하는 기능은 제공하지 않습니다. 이 접근 방식은 주기적인 검사를 통해 문제를 발견할 수는 있지만, 실시간으로 문제를 해결하는 데는 한계가 있습니다.

4. **S3 객체 람다를 사용하여 S3 ACL을 조사하고 모든 공개 S3 ACL을 비공개로 변경합니다.**
   - 이 방법은 리소스를 검사하고 변경하는 데 사용할 수 있지만, S3 공개 액세스 차단 기능을 통해 사전 예방적으로 모든 공개 액세스를 차단하는 것이 더 효과적입니다. 추가적인 유지 관리 작업이 필요하며, 모든 상황에 적합하지 않을 수 있습니다.

따라서, **계정 수준에서 S3 공개 액세스 차단을 활성화하는 것이 가장 안전하고 효과적인 방법입니다.**


## 질문: 228
회사의 SysOps 관리자가 회사의 AWS 계정 중 하나에 대한 AWS 지원 플랜을 변경해야 합니다. 계정에는 다중 요소 인증(MFA)이 활성화되어 있고 MFA 장치가 분실되었습니다.

SysOps 관리자는 로그인하기 위해 무엇을 해야 합니까?

1.이메일 및 전화 인증을 사용하여 루트 사용자로 로그인합니다. 새 MFA 장치를 설정합니다. 루트 사용자 비밀번호를 변경합니다.
2.관리자 권한이 있는 IAM 사용자로 로그인합니다. IAM 콘솔을 사용하여 MFA 토큰을 다시 동기화합니다.
3.관리자 권한이 있는 IAM 사용자로 로그인합니다. 새 장치를 추가하여 루트 사용자에 대한 MFA 장치를 재설정합니다.
4.비밀번호 분실 절차를 사용하여 이메일 주소를 확인하세요. 새 비밀번호와 MFA 장치를 설정하세요.

MFA 장치가 분실된 경우 SysOps 관리자가 AWS 계정에 로그인하기 위한 적절한 접근 방식은 **"관리자 권한이 있는 IAM 사용자로 로그인합니다. IAM 콘솔을 사용하여 MFA 토큰을 다시 동기화합니다."**입니다.

### 정답:
**2. 관리자 권한이 있는 IAM 사용자로 로그인합니다. IAM 콘솔을 사용하여 MFA 토큰을 다시 동기화합니다.**

#### 이유:
- **IAM 사용자 접근**: 관리자가 IAM 사용자 계정을 가지고 있다면, 해당 계정으로 로그인하여 MFA 토큰을 다시 동기화하거나, 새로운 MFA 장치를 추가할 수 있습니다. 
- **MFA 재동기화**: AWS에서는 MFA 장치가 분실된 경우, IAM 콘솔을 통해 MFA 장치를 재동기화하는 옵션이 제공됩니다. 이를 통해 계정에 대한 접근 권한을 복구할 수 있습니다.

### 대안 설명:
1. **이메일 및 전화 인증을 사용하여 루트 사용자로 로그인합니다. 새 MFA 장치를 설정합니다. 루트 사용자 비밀번호를 변경합니다.**
   - 이 방법은 MFA 장치를 잃어버린 상태에서는 사용할 수 없습니다. 루트 사용자 계정에 대한 MFA를 우회할 수 있는 방법이 없기 때문입니다.

3. **관리자 권한이 있는 IAM 사용자로 로그인합니다. 새 장치를 추가하여 루트 사용자에 대한 MFA 장치를 재설정합니다.**
   - IAM 사용자는 루트 사용자 계정의 MFA를 직접 재설정할 수 없습니다. 루트 사용자의 MFA는 루트 사용자 계정에 속해 있으며, IAM 사용자는 이 작업을 수행할 권한이 없습니다.

4. **비밀번호 분실 절차를 사용하여 이메일 주소를 확인하세요. 새 비밀번호와 MFA 장치를 설정하세요.**
   - 비밀번호 분실 절차는 일반적으로 루트 사용자 계정에 대한 접근을 위한 방법으로, MFA 장치가 활성화된 경우에는 접근할 수 없습니다.

따라서, **관리자 권한이 있는 IAM 사용자로 로그인하여 MFA 토큰을 다시 동기화하는 것이 가장 적절한 접근 방법입니다.**

## 질문: 229
회사에서 새로운 다중 계정 아키텍처를 만들고 있습니다. SysOps 관리자는 모든 AWS 계정에서 사용자 액세스 및 권한을 중앙에서 관리하는 로그인 솔루션을 구현해야 합니다. 이 솔루션은 AWS Organizations와 통합되어야 하며 타사 Security Assertion Markup Language(SAML) 2.0 ID 공급자(IdP)에 연결되어야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

1.Amazon Cognito 사용자 풀을 구성합니다. 사용자 풀을 타사 IdP와 통합합니다.
2.타사 IdP로 AWS Single Sign-On을 활성화하고 구성합니다.
3.조직의 각 AWS 계정에 대해 타사 IdP를 AWS Identity and Access Management(IAM)와 연합합니다.
4.타사 IdP를 AWS Organizations와 직접 통합합니다.

이러한 요구 사항을 충족하기 위해 가장 적합한 솔루션은 **"타사 IdP로 AWS Single Sign-On을 활성화하고 구성합니다."**입니다.

### 정답:
**2. 타사 IdP로 AWS Single Sign-On을 활성화하고 구성합니다.**

#### 이유:
- **중앙 관리**: AWS Single Sign-On(SSO)을 사용하면 모든 AWS 계정에 대한 사용자 액세스를 중앙에서 관리할 수 있습니다. 이를 통해 사용자는 단일 자격 증명으로 여러 AWS 계정에 안전하게 액세스할 수 있습니다.
- **SAML 2.0 지원**: AWS SSO는 SAML 2.0을 지원하므로, 타사 IdP와 통합하여 사용자 인증을 처리할 수 있습니다. 이 통합을 통해 기업은 기존의 IdP를 활용하여 AWS 계정에 대한 액세스를 관리할 수 있습니다.
- **AWS Organizations와 통합**: AWS SSO는 AWS Organizations와 잘 통합되어 있어 여러 계정에서 일관된 사용자 권한 관리를 쉽게 구현할 수 있습니다.

### 대안 설명:
1. **Amazon Cognito 사용자 풀을 구성합니다. 사용자 풀을 타사 IdP와 통합합니다.**
   - Amazon Cognito는 주로 모바일 및 웹 애플리케이션에서 사용자 인증을 처리하는 데 사용됩니다. 이는 여러 AWS 계정에 대한 중앙 관리 솔루션으로는 적합하지 않습니다.

3. **조직의 각 AWS 계정에 대해 타사 IdP를 AWS Identity and Access Management(IAM)와 연합합니다.**
   - IAM을 통해 각 계정에 대해 연합을 설정할 수 있지만, 이는 중앙에서 관리하는 접근 방식을 제공하지 않으며, 각 계정에서 별도로 설정해야 하므로 비효율적입니다.

4. **타사 IdP를 AWS Organizations와 직접 통합합니다.**
   - AWS Organizations는 타사 IdP와 직접 통합되는 기능을 제공하지 않습니다. 대신 AWS SSO를 통해 IdP와 통합해야 하며, SSO는 여러 계정의 관리에 더 적합합니다.

따라서, **타사 IdP로 AWS Single Sign-On을 활성화하고 구성하는 것이 가장 적합한 솔루션입니다.**



## 질문: 230
한 회사가 AWS Organizations에서 단일 조직을 사용하여 여러 계정을 관리하고 있습니다. 조직은 모든 ​​기능을 활성화했습니다. 회사는 조직의 모든 계정과 모든 AWS 지역에서 AWS Config를 켜고 싶어합니다.

SysOps 관리자는 이러한 요구 사항을 가장 운영적으로 효율적인 방식으로 충족하기 위해 무엇을 해야 합니까?

1.AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 켜는 스택 인스턴스를 배포할 수 있습니다.
2.AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 활성화하는 스택 정책을 배포할 수 있습니다.
3.SCP(서비스 제어 정책)를 사용하여 모든 계정과 모든 지역에서 AWS Config를 구성합니다.
4.조직의 모든 계정에서 AWS Config를 켜기 위해 AWS CLI를 사용하는 스크립트를 만듭니다. 조직의 관리 계정에서 스크립트를 실행합니다.

AWS Organizations에서 여러 계정을 효율적으로 관리하고 AWS Config를 모든 계정과 모든 리전에서 활성화하기 위한 가장 적합한 방법은 **"AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 켜는 스택 인스턴스를 배포할 수 있습니다."**입니다.

### 정답:
**1. AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 켜는 스택 인스턴스를 배포할 수 있습니다.**

#### 이유:
- **운영 효율성:** AWS CloudFormation Stack Sets를 사용하면 관리 계정에서 단일 스택 템플릿을 정의하여 여러 계정과 리전에서 AWS Config를 활성화할 수 있습니다. 이는 반복적인 작업을 줄이고, 모든 계정에서 일관된 구성을 보장하는 데 효과적입니다.
- **자동화:** Stack Sets는 AWS Config를 활성화하는 데 필요한 리소스를 자동으로 생성하고 관리하여 관리 작업의 수고를 덜어줍니다.

### 대안 설명:
2. **AWS CloudFormation Stack Sets를 사용하면 모든 계정과 모든 지역에서 AWS Config를 활성화하는 스택 정책을 배포할 수 있습니다.**
   - 스택 정책은 스택 인스턴스에 대한 권한을 설정하는 것이며, AWS Config를 활성화하는 데 직접적으로 사용되지 않습니다. 따라서 이 방법은 요구 사항을 충족하지 못합니다.

3. **SCP(서비스 제어 정책)를 사용하여 모든 계정과 모든 지역에서 AWS Config를 구성합니다.**
   - SCP는 특정 서비스에 대한 액세스를 제어하는 데 사용되며, AWS Config를 활성화하는 데 필요한 작업이 아닙니다. SCP는 AWS Config의 활성화와는 관련이 없습니다.

4. **조직의 모든 계정에서 AWS Config를 켜기 위해 AWS CLI를 사용하는 스크립트를 만듭니다. 조직의 관리 계정에서 스크립트를 실행합니다.**
   - 이 방법은 수동 작업을 포함하며, 수많은 계정과 리전에서 AWS Config를 활성화하는 데 비효율적입니다. Stack Sets를 사용하면 자동화되고 일관된 방식으로 작업을 수행할 수 있습니다.

따라서, **AWS CloudFormation Stack Sets를 사용하여 모든 계정과 모든 리전에서 AWS Config를 활성화하는 것이 가장 운영 효율적인 방법입니다.**


## 질문: 231
SysOps 관리자가 더 이상 사용하지 않는 AWS CloudFormation 스택을 삭제해야 합니다. 

CloudFormation 스택이 DELETE_FAILED 상태입니다. SysOps 관리자가 CloudFormation 스택을 삭제하는 데 필요한 권한을 검증했습니다.

다음 중 DELETE_FAILED 상태의 가능한 원인은 무엇입니까? (두 가지를 선택하십시오.)

1.스택을 삭제하기 위해 구성된 시간 제한이 너무 짧아 삭제 작업을 완료할 수 없습니다.
2.스택에는 중첩된 스택이 포함되어 있으므로 이를 먼저 수동으로 삭제해야 합니다.
3.스택은 --disable-rollback 옵션으로 배포되었습니다.
4.스택의 보안 그룹과 연관된 추가 리소스가 있습니다.
5.스택에 객체가 여전히 들어 있는 Amazon S3 버킷이 있습니다.
 

DELETE_FAILED 상태의 AWS CloudFormation 스택이 발생하는 가능한 원인으로는 다음 두 가지를 선택할 수 있습니다:

### 정답:
1. **스택을 삭제하기 위해 구성된 시간 제한이 너무 짧아 삭제 작업을 완료할 수 없습니다.**
   - 스택 삭제 시 리소스를 정리하는 데 필요한 시간보다 짧은 시간 제한이 설정된 경우, 작업이 완료되지 않아 DELETE_FAILED 상태로 전환될 수 있습니다.

2. **스택에는 중첩된 스택이 포함되어 있으므로 이를 먼저 수동으로 삭제해야 합니다.**
   - 중첩된 스택이 존재할 경우, 외부에서 이 스택을 삭제하기 전에 먼저 중첩된 스택을 수동으로 삭제해야 합니다. 이 과정이 누락되면 DELETE_FAILED 상태가 발생할 수 있습니다.

### 대안 설명:
3. **스택은 --disable-rollback 옵션으로 배포되었습니다.**
   - --disable-rollback 옵션은 스택 생성을 실패할 경우 롤백을 비활성화하는 옵션으로, 삭제와는 관련이 없습니다. 이 옵션은 스택이 실패했을 때 삭제 작업에는 영향을 미치지 않습니다.

4. **스택의 보안 그룹과 연관된 추가 리소스가 있습니다.**
   - 일반적으로 보안 그룹은 삭제가 완료되지 않으면 리소스가 있더라도 삭제될 수 있습니다. 이 경우에는 DELETE_FAILED 상태가 발생하지 않습니다.

5. **스택에 객체가 여전히 들어 있는 Amazon S3 버킷이 있습니다.**
   - CloudFormation 스택의 삭제는 S3 버킷 내의 객체와는 관련이 없습니다. 버킷 자체가 스택의 일부가 아닌 한, 객체가 남아 있다고 해서 DELETE_FAILED 상태가 발생하지 않습니다.

따라서, **시간 제한 문제와 중첩 스택의 존재가 DELETE_FAILED 상태의 원인이 될 수 있습니다.**


## 질문: 232
SysOps 관리자는 Amazon CloudFront를 통해 승인된 사용자 집합에 디지털 콘텐츠를 제공하는 솔루션을 구성해야 합니다. 승인되지 않은 사용자는 액세스가 제한되어야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

1.퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. 서명된 URL을 사용하여 CloudFront를 통해 S3 버킷에 액세스합니다.
2.퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(원본 액세스 ID)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. CloudFront에서 서명된 URL로 S3 버킷 액세스를 제한합니다.
3.퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(Origin Access Identity)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. 필드 수준 암호화를 활성화합니다.
4.디지털 콘텐츠를 퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 저장합니다. CloudFront를 통한 콘텐츠의 제한된 전달을 위해 서명된 쿠키를 사용합니다.

Amazon CloudFront를 통해 승인된 사용자 집합에 디지털 콘텐츠를 제공하고, 승인되지 않은 사용자는 액세스가 제한되도록 하는 최적의 솔루션은 **"퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(원본 액세스 ID)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. CloudFront에서 서명된 URL로 S3 버킷 액세스를 제한합니다."**입니다.

### 정답:
**2. 퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(원본 액세스 ID)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. CloudFront에서 서명된 URL로 S3 버킷 액세스를 제한합니다.**

#### 이유:
- **퍼블릭 액세스 차단:** Amazon S3 버킷의 퍼블릭 액세스를 차단하면 승인되지 않은 사용자가 직접 S3 버킷에 접근할 수 없습니다.
- **OAI 사용:** CloudFront의 원본 액세스 ID(OAI)를 사용하면 CloudFront가 S3 버킷의 콘텐츠에 접근할 수 있게 하면서, 직접적인 S3 URL 접근을 차단할 수 있습니다. 이렇게 하면 CloudFront를 통해서만 콘텐츠를 안전하게 제공할 수 있습니다.
- **서명된 URL 사용:** 서명된 URL을 사용하면 특정 사용자에게만 콘텐츠에 대한 액세스를 허용할 수 있습니다. URL에 만료 시간을 설정하여 일정 기간 동안만 액세스할 수 있도록 하여 보안을 강화합니다.

### 대안 설명:
1. **퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. 서명된 URL을 사용하여 CloudFront를 통해 S3 버킷에 액세스합니다.**
   - 퍼블릭 액세스가 차단되지 않은 경우, 승인되지 않은 사용자가 콘텐츠에 직접 접근할 수 있으므로 요구 사항을 충족하지 않습니다.

3. **퍼블릭 액세스가 차단된 Amazon S3 버킷에 디지털 콘텐츠를 저장합니다. OAI(Origin Access Identity)를 사용하여 CloudFront를 통해 콘텐츠를 제공합니다. 필드 수준 암호화를 활성화합니다.**
   - 필드 수준 암호화는 보안에 도움이 되지만, 주된 요구 사항인 승인된 사용자 집합에 대한 액세스 제한을 직접 해결하지 않습니다.

4. **디지털 콘텐츠를 퍼블릭 액세스가 차단되지 않은 Amazon S3 버킷에 저장합니다. CloudFront를 통한 콘텐츠의 제한된 전달을 위해 서명된 쿠키를 사용합니다.**
   - 퍼블릭 액세스가 차단되지 않은 경우, 승인되지 않은 사용자가 S3 버킷에 접근할 수 있는 문제가 발생하므로 요구 사항을 충족하지 않습니다. 서명된 쿠키는 추가적인 보안을 제공하지만, 여전히 S3 버킷의 퍼블릭 액세스 문제가 해결되지 않습니다.

따라서, **퍼블릭 액세스가 차단된 S3 버킷과 OAI를 사용하여 CloudFront를 통한 안전한 콘텐츠 제공이 가장 적절한 해결책입니다.**

## 질문: 233
SysOps 관리자는 회사의 Amazon EC2 인스턴스가 예상대로 자동 확장되도록 해야 합니다. 

SysOps 관리자는 Amazon EC2 자동 확장 수명 주기 후크를 구성하여 Amazon EventBridge(Amazon CloudWatch Events)로 이벤트를 전송한 다음 AWS Lambda 함수를 호출하여 EC2 인스턴스를 구성합니다. 구성이 완료되면 Lambda 함수가 complete-lifecycle-action 이벤트를 호출하여 EC2 인스턴스를 서비스에 넣습니다. 테스트에서 SysOps 관리자는 EC2 인스턴스가 자동 확장될 때 Lambda 함수가 호출되지 않는다는 것을 발견했습니다.

SysOps 관리자는 이 문제를 해결하기 위해 무엇을 해야 합니까?

1.Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 합니다.
2.라이프사이클 후크에 오류나 시간 초과가 발생하는 경우 라이프사이클 후크 작업을 CONTINUE로 변경합니다.
3.EventBridge(CloudWatch Events) 규칙에서 재시도 정책을 구성하여 실패 시 Lambda 함수 호출을 다시 시도합니다.
4.Lambda 함수 실행 역할을 업데이트하여 complete-lifecycle-action 이벤트를 호출할 수 있는 권한을 부여합니다.
 

SysOps 관리자가 Amazon EC2 인스턴스의 자동 확장이 예상대로 작동하도록 하기 위해 Lambda 함수가 호출되지 않는 문제를 해결하려면 **"Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 합니다."**가 올바른 선택입니다.

### 정답:
**1. Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 합니다.**

#### 이유:
- Lambda 함수가 EventBridge (이전의 CloudWatch Events)에서 호출되기 위해서는 해당 이벤트 소스가 Lambda 함수를 호출할 수 있는 권한이 필요합니다. 이 권한은 IAM 역할 정책을 통해 설정해야 합니다. 권한이 없으면 Lambda 함수가 호출되지 않으므로, 이 문제를 해결하기 위해 Lambda 함수에 EventBridge에서 호출할 수 있도록 필요한 권한을 추가해야 합니다.

### 대안 설명:
2. **라이프사이클 후크에 오류나 시간 초과가 발생하는 경우 라이프사이클 후크 작업을 CONTINUE로 변경합니다.**
   - 이 설정은 후크가 실패했을 때의 동작을 변경하는 것이지만, Lambda 함수가 호출되지 않는 근본 원인을 해결하지 않습니다.

3. **EventBridge(CloudWatch Events) 규칙에서 재시도 정책을 구성하여 실패 시 Lambda 함수 호출을 다시 시도합니다.**
   - 재시도 정책을 설정하는 것은 유용할 수 있지만, Lambda 함수가 호출되지 않는 문제를 해결하지 않습니다. 권한이 부족한 경우에는 재시도해도 호출되지 않습니다.

4. **Lambda 함수 실행 역할을 업데이트하여 complete-lifecycle-action 이벤트를 호출할 수 있는 권한을 부여합니다.**
   - 이는 Lambda 함수가 EC2 인스턴스의 상태를 업데이트할 수 있도록 하는 것이며, Lambda 함수가 호출되지 않는 문제와는 관련이 없습니다. 이 작업은 Lambda 함수가 호출된 후에 필요한 조치입니다.

따라서, **Lambda 함수에 권한을 추가하여 EventBridge(CloudWatch Events) 규칙에서 호출할 수 있도록 하는 것이 이 문제를 해결하는 올바른 방법입니다.**


## 질문: 234
한 회사에서는 모든 IAM 사용자에게 다중 인증(MFA)을 사용하도록 의무화했으며, 사용자는 CLI를 사용하여 모든 API 호출을 해야 합니다. 

그러나 사용자는 MFA 토큰을 입력하라는 메시지를 받지 않으며, MFA 없이도 CLI 명령을 실행할 수 있습니다. 이 회사는 MFA를 시행하기 위해 MFA로 인증되지 않은 API 호출을 거부하는 IAM 정책을 모든 사용자에게 첨부했습니다.

API 호출이 MFA를 사용하여 인증되도록 하려면 어떤 추가 단계를 거쳐야 합니까?

1.IAM 역할에서 MFA를 활성화하고 IAM 사용자에게 역할 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.
2.CLI를 사용하여 API 호출을 하기 전에 IAM 사용자에게 MFA를 사용하여 AWS 관리 콘솔에 로그인하도록 요청합니다.
3.MFA는 CLI 사용에 지원되지 않으므로 IAM 사용자는 콘솔 사용으로 제한합니다.
4.사용자에게 get-session token 명령에서 임시 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.

이 시나리오에서 모든 IAM 사용자가 다중 인증(MFA)을 사용하여 AWS CLI에서 API 호출을 해야 하는 상황에서, 추가적인 단계로 **"사용자에게 get-session-token 명령에서 임시 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다."**가 올바른 선택입니다.

### 정답:
**4. 사용자에게 get-session-token 명령에서 임시 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.**

#### 이유:
- MFA를 사용하여 AWS CLI에서 API 호출을 수행하려면, 사용자가 먼저 `get-session-token` 명령을 통해 임시 자격 증명을 요청해야 합니다. 이 명령은 MFA 토큰을 입력하도록 요구하며, 인증이 완료되면 임시 자격 증명(Access Key, Secret Access Key, Session Token)을 제공합니다. 사용자는 이 임시 자격 증명을 사용하여 CLI에서 API 호출을 수행할 수 있습니다. 

### 대안 설명:
1. **IAM 역할에서 MFA를 활성화하고 IAM 사용자에게 역할 자격 증명을 사용하여 API 호출에 서명하도록 요구합니다.**
   - IAM 역할을 사용하여 MFA를 활성화할 수 있지만, 이 접근 방식은 사용자가 CLI에서 API 호출을 하도록 요구하는 것과는 관련이 없습니다. 사용자는 여전히 임시 자격 증명을 얻어야 합니다.

2. **CLI를 사용하여 API 호출을 하기 전에 IAM 사용자에게 MFA를 사용하여 AWS 관리 콘솔에 로그인하도록 요청합니다.**
   - 관리 콘솔에서 MFA를 사용하여 로그인하는 것은 유용하지만, CLI에서 API 호출을 하려면 임시 자격 증명을 필요로 하므로 이 방법은 요구 사항을 충족하지 않습니다.

3. **MFA는 CLI 사용에 지원되지 않으므로 IAM 사용자는 콘솔 사용으로 제한합니다.**
   - 이는 잘못된 정보입니다. MFA는 CLI 사용에도 지원되며, 이를 사용하여 API 호출을 수행할 수 있습니다. 사용자를 콘솔 사용으로 제한하는 것은 최선의 해결책이 아닙니다.

따라서, **사용자가 `get-session-token` 명령을 통해 MFA를 활용하여 임시 자격 증명을 얻고 이를 사용하여 API 호출을 수행하는 것이 MFA를 적용하는 올바른 방법입니다.**


## 질문: 235
SysOps 관리자가 모든 회사 Amazon S3 버킷에 대한 퍼블릭 액세스를 차단했습니다. 

SysOps 관리자는 S3 버킷이 미래에 공개적으로 읽을 수 있게 되면 알림을 받고 싶어합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 방법은 무엇입니까?

1.각 S3 버킷의 퍼블릭 액세스 설정을 주기적으로 확인하는 AWS Lambda 함수를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.
2.S3 API를 사용하여 각 S3 버킷의 퍼블릭 액세스 설정을 확인하는 cron 스크립트를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.
3.각 S3 버킷에 대해 S3 이벤트 알림을 활성화합니다. Amazon Simple Notification Service(Amazon SNS) 주제에 S3 이벤트 알림을 구독합니다.
4.AWS Config에서 s3-bucket-public-read-prohibited 관리형 규칙을 활성화합니다. AWS Config 규칙을 Amazon Simple Notification Service(Amazon SNS) 토픽에 구독합니다.
 

SysOps 관리자가 모든 Amazon S3 버킷에 대한 퍼블릭 액세스를 차단하고, 미래에 S3 버킷이 공개적으로 읽을 수 있게 될 경우 알림을 받으려면 **"AWS Config에서 s3-bucket-public-read-prohibited 관리형 규칙을 활성화합니다. AWS Config 규칙을 Amazon Simple Notification Service(Amazon SNS) 토픽에 구독합니다."**가 가장 운영 효율적인 방법입니다.

### 정답:
**4. AWS Config에서 s3-bucket-public-read-prohibited 관리형 규칙을 활성화합니다. AWS Config 규칙을 Amazon Simple Notification Service(Amazon SNS) 토픽에 구독합니다.**

#### 이유:
- **AWS Config**는 AWS 리소스의 구성 및 변경 사항을 추적하는 서비스로, S3 버킷의 퍼블릭 액세스 설정과 같은 규정을 모니터링하는 데 매우 유용합니다. `s3-bucket-public-read-prohibited` 관리형 규칙은 S3 버킷이 퍼블릭 읽기 권한을 갖고 있는지를 자동으로 검사하고, 위반 시 AWS Config에서 이벤트를 생성합니다.
- 이를 Amazon SNS와 통합하면, 규칙 위반 시 자동으로 알림을 받을 수 있어 운영 효율성이 높아집니다. 관리형 규칙을 사용하면 매번 Lambda 함수를 설정하거나 스크립트를 실행할 필요가 없어 관리가 간편합니다.

### 대안 설명:
1. **각 S3 버킷의 퍼블릭 액세스 설정을 주기적으로 확인하는 AWS Lambda 함수를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.**
   - Lambda 함수를 사용하여 버킷 설정을 주기적으로 확인하는 것은 가능하지만, AWS Config를 사용하는 것보다 관리가 더 복잡하고 지속적인 유지 보수가 필요합니다.

2. **S3 API를 사용하여 각 S3 버킷의 퍼블릭 액세스 설정을 확인하는 cron 스크립트를 만듭니다. 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS)를 설정합니다.**
   - cron 스크립트는 관리와 유지 보수가 필요하며, AWS 환경 내에서 S3 버킷의 상태를 실시간으로 모니터링하기에는 비효율적입니다.

3. **각 S3 버킷에 대해 S3 이벤트 알림을 활성화합니다. Amazon Simple Notification Service(Amazon SNS) 주제에 S3 이벤트 알림을 구독합니다.**
   - S3 이벤트 알림은 객체 생성, 삭제 등의 이벤트에 대한 알림을 제공하지만, 퍼블릭 액세스 설정의 변경 사항에 대한 알림을 제공하지 않으므로 이 요구 사항에 부합하지 않습니다.

따라서, **AWS Config에서 관리형 규칙을 활성화하고 SNS와 통합하는 것이 S3 버킷의 퍼블릭 액세스 설정 변경을 효과적으로 모니터링하는 가장 효율적인 방법입니다.**



## 질문: 236
한 회사가 Amazon S3를 사용하여 도메인 example.com과 하위 도메인 www.example.com에서 정적 웹사이트를 출시할 계획입니다.

SysOps 관리자는 이 요구 사항을 어떻게 충족해야 합니까?

1. 도메인과 하위 도메인 모두에 대해 example.com이라는 이름의 S3 버킷을 하나 만듭니다.
2. 도메인과 하위 도메인 모두에 *.example.com이라는 와일드카드를 사용하여 하나의 S3 버킷을 생성합니다.
3. example.com과 www.example.com이라는 이름의 두 개의 S3 버킷을 만듭니다. 하위 도메인 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.
4. http://example.com과 http://*.example.com이라는 이름의 두 개의 S3 버킷을 만듭니다. 와일드카드(*) 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.
 

정적 웹사이트를 Amazon S3에서 호스팅하려면 SysOps 관리자는 다음과 같은 방법으로 요구 사항을 충족할 수 있습니다:

**3. `example.com`과 `www.example.com`이라는 이름의 두 개의 S3 버킷을 만듭니다. 하위 도메인 버킷을 구성하여 요청을 도메인 버킷으로 리디렉션합니다.**

이유:
- **S3 버킷 네이밍 규칙**: Amazon S3에서 정적 웹사이트 호스팅 시 버킷 이름은 DNS 호환 도메인 이름이어야 합니다. 따라서 `example.com`과 `www.example.com`이라는 두 개의 S3 버킷이 필요합니다.
- **리디렉션 설정**: 일반적으로 `www.example.com`으로 들어오는 트래픽을 `example.com`으로 리디렉션합니다. 이를 위해 `www.example.com` S3 버킷을 리디렉션 버킷으로 설정하고, 실제 웹 콘텐츠는 `example.com` 버킷에서 호스팅합니다.
- **와일드카드 버킷 지원 없음**: Amazon S3는 와일드카드(*) 버킷을 지원하지 않으므로, 옵션 2나 4는 불가능합니다.

이 방법으로 도메인과 하위 도메인 모두에서 정적 웹사이트를 성공적으로 호스팅할 수 있습니다.

## 질문: 237
SysOps 관리자가 AWS Client VPN을 구성하여 기업 네트워크의 사용자를 VPC에서 실행 중인 AWS 리소스에 연결하고 있습니다. 

규정 준수 요구 사항에 따라 VPC로 향하는 트래픽만 VPN 터널을 통과할 수 있습니다.

SysOps 관리자는 이러한 요구 사항을 충족하도록 Client VPN을 어떻게 구성해야 합니까?

1.NAT 게이트웨이를 통한 인터넷 경로가 있는 개인 서브넷과 클라이언트 VPN 엔드포인트를 연결합니다.
2.클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켭니다.
3.클라이언트 VPN 엔드포인트에서 DNS 서버 IP 주소를 지정합니다.
4.VPN 클라이언트의 신원 인증서로 사용할 개인 인증서를 선택하세요.

AWS Client VPN을 구성하여 규정 준수 요구 사항에 따라 VPC로 향하는 트래픽만 VPN 터널을 통과할 수 있도록 하려면 **"클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켭니다."**가 올바른 선택입니다.

### 정답: 
**2. 클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켭니다.**

#### 이유:
- **분할 터널**은 클라이언트 VPN 엔드포인트에서 설정할 수 있는 옵션으로, 이를 활성화하면 VPN을 통해 특정 트래픽만 VPC로 전송되고 나머지 트래픽(예: 인터넷으로 향하는 트래픽)은 로컬 네트워크를 통해 직접 전송됩니다. 따라서 VPC로 향하는 트래픽만 터널을 통해 전송되어 규정 준수 요구 사항을 충족할 수 있습니다.

### 대안 설명:
1. **NAT 게이트웨이를 통한 인터넷 경로가 있는 개인 서브넷과 클라이언트 VPN 엔드포인트를 연결합니다.**
   - NAT 게이트웨이는 인터넷으로의 아웃바운드 트래픽을 지원하지만, 이 설정은 분할 터널링과는 직접적인 관련이 없습니다. NAT 게이트웨이를 사용하는 것은 일반적으로 VPC 내에서 인터넷에 접근하기 위한 것이며, 규정 준수 요구 사항에 맞지 않습니다.

3. **클라이언트 VPN 엔드포인트에서 DNS 서버 IP 주소를 지정합니다.**
   - DNS 서버 IP 주소를 지정하는 것은 클라이언트가 도메인 이름을 해결하는 데 필요할 수 있지만, 규정 준수 요구 사항을 충족하는 데는 직접적인 관련이 없습니다.

4. **VPN 클라이언트의 신원 인증서로 사용할 개인 인증서를 선택하세요.**
   - 개인 인증서를 선택하는 것은 클라이언트의 인증을 설정하는 것이며, 이는 보안 설정과 관련이 있지만 VPN 트래픽의 흐름을 규제하는 데는 도움이 되지 않습니다.

따라서, **클라이언트 VPN 엔드포인트에서 분할 터널 옵션을 켜는 것이 VPC로 향하는 트래픽만 VPN 터널을 통과하도록 설정하는 올바른 방법입니다.**



## 질문: 238
SysOps 관리자가 5개의 Amazon EC2 인스턴스에 호스팅된 애플리케이션을 테스트하고 있습니다. 

인스턴스는 Application Load Balancer(ALB) 뒤의 Auto Scaling 그룹에서 실행됩니다. 부하 테스트 중 CPU 사용률이 높아 Auto Scaling 그룹이 확장되고 있습니다. SysOps 관리자는 Auto Scaling 그룹이 확장되기 전에 CPU 사용률이 높은 근본 원인을 찾기 위해 문제를 해결해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?

1.인스턴스 확장 보호를 활성화합니다.
2.인스턴스를 대기 상태로 전환합니다.
3.ALB에서 리스너를 제거합니다.
4.실행 및 종료 프로세스 유형을 일시 중단합니다


이 시나리오에서 SysOps 관리자가 Auto Scaling 그룹의 확장을 방지하고 CPU 사용률이 높은 근본 원인을 조사하기 위해 취해야 할 적절한 조치는 **"인스턴스 확장 보호를 활성화합니다."**입니다.

### 정답: 
**1. 인스턴스 확장 보호를 활성화합니다.**

#### 이유:
- 인스턴스 확장 보호를 활성화하면 Auto Scaling 그룹이 CPU 사용률이 높아질 때 인스턴스를 자동으로 종료하거나 축소하지 않도록 보호할 수 있습니다. 이로 인해 관리자는 인스턴스가 계속 실행되고 있는 동안 문제를 진단하고 해결할 수 있습니다.

### 대안 설명:
2. **인스턴스를 대기 상태로 전환합니다.**
   - 대기 상태로 전환하면 인스턴스가 요청을 처리하지 않지만, Auto Scaling 그룹의 확장을 방지하는 데는 도움이 되지 않습니다. 오히려 사용자의 요청이 해당 인스턴스로 라우팅되지 않게 되므로 문제가 악화될 수 있습니다.

3. **ALB에서 리스너를 제거합니다.**
   - ALB에서 리스너를 제거하면 인스턴스에 대한 모든 트래픽이 차단됩니다. 이는 테스트 중에 의도한 대로 트래픽을 차단할 수 있지만, CPU 사용률이 높은 원인을 조사하는 데 도움이 되지 않습니다.

4. **실행 및 종료 프로세스 유형을 일시 중단합니다.**
   - 실행 및 종료 프로세스를 일시 중단하면 Auto Scaling 그룹의 활동을 중단하지만, CPU 사용률이 높은 근본 원인을 찾는 데 실질적인 도움이 되지 않습니다. 이는 기본적으로 Auto Scaling의 기능을 중단하는 것이므로 긴급한 경우가 아닌 이상 권장되지 않습니다.

따라서, **인스턴스 확장 보호를 활성화하는 것이 CPU 사용률 문제를 조사하는 가장 적절한 접근법입니다.**


## 질문: 239
웹 애플리케이션은 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 

인스턴스는 여러 가용성 영역에 걸쳐 Auto Scaling 그룹에서 실행됩니다. SysOps 관리자는 이러한 EC2 인스턴스 중 일부가 Auto Scaling 그룹에서는 정상으로 표시되지만 ALB 대상 그룹에서는 비정상으로 표시된다는 것을 알아챘습니다.

이 문제의 가능한 이유는 무엇입니까?

1.보안 그룹은 ALB와 오류가 발생한 EC2 인스턴스 간의 트래픽을 허용하지 않습니다.
2.자동 크기 조정 그룹 상태 검사는 EC2 상태 검사를 위해 구성되었습니다.
3.EC2 인스턴스를 시작할 수 없고 EC2 상태 확인에도 실패합니다.
4.대상 그룹 상태 검사가 잘못된 포트 또는 경로로 구성되었습니다.

EC2 인스턴스가 Auto Scaling 그룹에서는 정상으로 표시되지만, ALB 대상 그룹에서는 비정상으로 표시되는 이유 중 가장 가능성이 높은 것은 **4. 대상 그룹 상태 검사가 잘못된 포트 또는 경로로 구성되었습니다.**

### 이유:
- ALB는 대상 그룹의 EC2 인스턴스에 대해 **상태 검사(health check)**를 수행하며, 특정 경로 또는 포트를 통해 상태를 확인합니다. 만약 상태 검사 경로 또는 포트가 잘못 설정되어 있거나, 애플리케이션이 그 경로에서 정상적으로 응답하지 않는 경우, ALB는 인스턴스를 **비정상**으로 판단할 수 있습니다.
- 반면, Auto Scaling 그룹은 **EC2 인스턴스의 상태**(예: 인스턴스 자체가 실행 중인지)를 기준으로 하므로, 인스턴스가 정상으로 표시될 수 있습니다.

### 선택하지 않은 다른 옵션 검토:
1. **보안 그룹은 ALB와 오류가 발생한 EC2 인스턴스 간의 트래픽을 허용하지 않습니다.**
   - 만약 보안 그룹이 트래픽을 허용하지 않는다면, EC2 인스턴스에 대한 연결 자체가 이루어지지 않기 때문에, 비정상으로 표시될 가능성이 있지만, 이 경우 트래픽 문제는 상태 검사 경로 설정보다는 연결 문제에서 발생합니다.

2. **자동 크기 조정 그룹 상태 검사는 EC2 상태 검사를 위해 구성되었습니다.**
   - Auto Scaling 그룹은 EC2 인스턴스의 **시스템 및 네트워크 상태**에 따라 상태를 결정하며, 상태가 "정상"으로 표시되지만, 이는 ALB 상태 검사와는 다르기 때문에 ALB의 상태 검사와 직접적인 연관이 없습니다.

3. **EC2 인스턴스를 시작할 수 없고 EC2 상태 확인에도 실패합니다.**
   - 만약 EC2 인스턴스 자체가 실패했다면, Auto Scaling 그룹에서 해당 인스턴스는 **정상으로 표시되지** 않으며, 문제가 더 광범위할 것입니다.

따라서 가장 가능성이 높은 원인은 **대상 그룹의 상태 검사 설정 오류(경로 또는 포트 설정 오류)**입니다.



## 질문: 240
SysOps 관리자가 Amazon EC2 Auto Scaling 그룹의 확장 이벤트를 알아차렸습니다. Amazon CloudWatch는 연관된 Application Load Balancer의 RequestCount 메트릭에서 급증을 보여줍니다. 관리자는 요청 소스의 IP 주소를 알고 싶어합니다.

관리자는 이 정보를 어디에서 찾을 수 있습니까?

1.자동 크기 조정 로그
2.AWS CloudTrail 로그
3.EC2 인스턴스 로그
4.Elastic Load Balancer 액세스 로그

관리자가 요청 소스의 IP 주소를 확인하려면 다음 옵션이 가장 적절합니다.

### 정답:
**4. Elastic Load Balancer 액세스 로그**

### 이유:
- **Elastic Load Balancer 액세스 로그**는 Application Load Balancer(ALB)에 도달하는 모든 요청에 대한 세부 정보를 제공합니다. 여기에는 **요청을 보낸 클라이언트의 IP 주소**를 비롯한 여러 중요한 정보가 포함됩니다. 액세스 로그는 S3 버킷에 저장되며, 이를 통해 특정 시간대의 요청 소스 IP를 확인할 수 있습니다.
  
### 선택하지 않은 옵션 검토:
1. **자동 크기 조정 로그**
   - 자동 크기 조정 로그에는 인스턴스의 크기 조정과 관련된 이벤트가 기록되지만, 클라이언트의 IP 주소와 같은 세부 요청 정보를 제공하지 않습니다.

2. **AWS CloudTrail 로그**
   - AWS CloudTrail은 AWS API 호출을 기록하며, ELB와 관련된 호출을 추적할 수 있지만, 개별 요청에 대한 IP 주소 정보는 제공하지 않습니다.

3. **EC2 인스턴스 로그**
   - EC2 인스턴스 로그는 해당 인스턴스에서 실행되는 애플리케이션의 로그일 수 있으나, ELB를 경유한 모든 클라이언트 IP 주소 정보를 제공하는 데는 적합하지 않습니다.

### 결론:
**Elastic Load Balancer 액세스 로그**는 요청의 IP 주소를 파악하는 데 가장 신뢰할 수 있는 소스입니다.


## 질문: 241
한 회사가 여러 개의 고성능 컴퓨팅(HPC) 가상 머신(VM)을 AWS의 Amazon EC2 인스턴스로 마이그레이션할 계획입니다. 

SysOps 관리자는 이 배포를 위한 배치 그룹을 식별해야 합니다. 이 전략은 네트워크 지연을 최소화하고 HPC VM 간의 네트워크 처리량을 최대화해야 합니다.

SysOps 관리자는 이러한 요구 사항을 충족하기 위해 어떤 전략을 선택해야 합니까?

1.하나의 가용성 영역에 있는 클러스터 배치 그룹에 인스턴스를 배포합니다.
2.두 개의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.
3.하나의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.
4.2개의 가용성 영역에 분산된 배치 그룹에 인스턴스를 배포합니다.

SysOps 관리자가 네트워크 지연을 최소화하고 HPC(고성능 컴퓨팅) VM 간의 네트워크 처리량을 최대화하기 위해 선택해야 할 전략은 **1. 하나의 가용성 영역에 있는 클러스터 배치 그룹에 인스턴스를 배포합니다.**입니다.

### 이유:
- **클러스터 배치 그룹**은 동일한 가용성 영역(AZ) 내에서 EC2 인스턴스가 물리적으로 가까운 하드웨어에 배치되도록 보장합니다. 이 방식은 높은 네트워크 처리량과 낮은 지연 시간을 요구하는 HPC 작업에 매우 적합합니다.
- **네트워크 지연을 최소화하고 처리량을 최대화**하기 위한 최고의 선택입니다.

### 선택하지 않은 옵션 검토:
2. **두 개의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.**
   - 두 개의 AZ에 분산하면 네트워크 지연이 증가할 수 있으며, HPC의 성능 요구사항에 적합하지 않습니다.

3. **하나의 가용성 영역에 있는 파티션 배치 그룹에 인스턴스를 배포합니다.**
   - 파티션 배치 그룹은 인스턴스가 서로 다른 하드웨어에 분리되어 배치되도록 보장하여 장애 도메인 격리를 제공합니다. 이는 내결함성에 좋지만, 지연 시간과 처리량 최적화에는 클러스터 배치 그룹이 더 유리합니다.

4. **2개의 가용성 영역에 분산된 배치 그룹에 인스턴스를 배포합니다.**
   - 가용성 영역 간의 통신은 높은 네트워크 지연 시간을 발생시킬 수 있으므로, HPC 워크로드에는 적합하지 않습니다.

따라서 네트워크 성능을 극대화하기 위해 **클러스터 배치 그룹**을 사용하는 것이 가장 적합한 전략입니다.


## 질문: 242
오류 프로세스는 전체 프로세서를 사용하고 100%로 실행되는 것으로 알려져 있습니다. 

SysOps 관리자는 문제가 2분 이상 발생할 때 Amazon EC2 인스턴스를 자동으로 다시 시작하려고 합니다.

어떻게 이를 달성할 수 있을까요?

1.기본 모니터링을 사용하여 EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만듭니다. 인스턴스를 다시 시작하는 작업을 추가합니다.
2.EC2 인스턴스에 대한 Amazon CloudWatch 알람을 자세한 모니터링과 함께 생성합니다. 인스턴스를 다시 시작하는 작업을 추가합니다.
3.2분마다 예약된 시간에 호출되는 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.
4.EC2 상태 확인을 통해 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.
 
이 요구 사항을 가장 효율적으로 달성하려면 **2. EC2 인스턴스에 대한 Amazon CloudWatch 알람을 자세한 모니터링과 함께 생성합니다. 인스턴스를 다시 시작하는 작업을 추가합니다.**가 가장 적합한 솔루션입니다.

### 이유:
- **자세한 모니터링(Enhanced Monitoring)**은 1분 간격의 더 정밀한 모니터링을 제공합니다. 이를 통해 CPU 사용량이 100%에 도달했을 때 신속하게 알람을 설정할 수 있습니다.
- CloudWatch 알람을 생성하여 CPU 사용량이 2분 동안 100% 이상일 때 트리거되도록 설정하고, 그에 따라 인스턴스를 자동으로 다시 시작하는 작업을 추가할 수 있습니다.
  
### 선택하지 않은 옵션 검토:
1. **기본 모니터링을 사용하여 EC2 인스턴스에 대한 Amazon CloudWatch 알람을 만듭니다.**
   - 기본 모니터링은 5분 간격으로 데이터를 수집하므로, 2분 이상 100% CPU 사용 시 문제를 확인하기에는 적합하지 않습니다.

3. **2분마다 예약된 시간에 호출되는 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.**
   - 이는 너무 자주 호출되어 불필요하게 인스턴스를 다시 시작할 수 있으며, CPU 사용량과 같은 성능 지표에 기반한 조건을 설정할 수 없습니다.

4. **EC2 상태 확인을 통해 EC2 인스턴스를 다시 시작하는 AWS Lambda 함수를 생성합니다.**
   - EC2 상태 확인은 주로 인스턴스의 하드웨어 문제를 감지합니다. CPU 사용량 100%와 같은 문제를 해결하는 데는 적합하지 않습니다.

따라서 **자세한 모니터링과 CloudWatch 알람을 사용하는 방법**이 문제를 해결하는 데 가장 적합한 솔루션입니다. 


## 질문: 243
한 회사가 Amazon S3 버킷에 많은 양의 민감한 데이터를 보관합니다.

회사의 보안팀은 SysOps 관리자에게 S3 버킷의 모든 현재 객체가 암호화되었는지 확인하도록 요청합니다.

이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

1.S3 버킷에 대해 실행되고 각 객체의 상태를 출력하는 스크립트를 만듭니다.
2.S3 버킷에서 S3 인벤토리 구성을 만듭니다. 적절한 상태 필드를 포함합니다.
3.보안 팀에 S3 버킷에 대한 읽기 액세스 권한이 있는 IAM 사용자를 제공합니다.
4.AWS CLI를 사용하여 S3 버킷에 있는 모든 객체 목록을 출력합니다.

이 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 **2. S3 버킷에서 S3 인벤토리 구성을 만듭니다. 적절한 상태 필드를 포함합니다.**

### 이유:
- **S3 인벤토리**는 S3 버킷 내의 모든 객체에 대한 메타데이터를 자동으로 제공하는 서비스입니다. 인벤토리 보고서는 암호화 상태, 크기, 태그 등 다양한 객체 속성을 포함할 수 있으며, 대규모 데이터 집합에서도 효율적으로 사용됩니다.
- 이를 통해 관리자는 객체 암호화 상태를 확인하고, 필요한 조치를 쉽게 취할 수 있습니다. 또한 인벤토리 보고서는 정기적으로 생성되어 자동으로 최신 정보를 제공하므로 수동 작업을 줄일 수 있습니다.

### 선택하지 않은 옵션 검토:
1. **S3 버킷에 대해 실행되고 각 객체의 상태를 출력하는 스크립트를 만듭니다.**
   - 스크립트를 만드는 방법은 가능하지만, 수동 관리가 필요하고 큰 S3 버킷의 경우 시간이 오래 걸리며 비효율적입니다.

3. **보안 팀에 S3 버킷에 대한 읽기 액세스 권한이 있는 IAM 사용자를 제공합니다.**
   - 보안 팀이 객체의 암호화 상태를 직접 확인할 수 있게 하지만, 암호화 상태를 수동으로 검토해야 하므로 비효율적입니다.

4. **AWS CLI를 사용하여 S3 버킷에 있는 모든 객체 목록을 출력합니다.**
   - AWS CLI를 통해 객체 목록을 출력할 수는 있지만, 객체 암호화 상태를 직접적으로 출력하지 않으므로 추가적인 작업이 필요합니다.

따라서 **S3 인벤토리**를 설정하여 자동으로 객체의 암호화 상태를 추적하는 것이 가장 효율적인 솔루션입니다.

## 질문: 244
사용자는 관계형 데이터베이스에서 주기적으로 느린 응답 시간을 경험하고 있습니다. 

데이터베이스는 350GB General Purpose SSD(gp2) Amazon Elastic Block Store(Amazon EBS) 볼륨이 있는 버스트 가능한 Amazon EC2 인스턴스에서 실행됩니다. SysOps 관리자는 Amazon CloudWatch에서 EC2 인스턴스를 모니터링하고 느린 응답 기간 동안 VolumeReadOps 메트릭이 최고 값의 10% 미만으로 떨어지는 것을 관찰합니다.

SysOps 관리자는 지속적으로 높은 성능을 보장하기 위해 무엇을 해야 합니까?

1.gp2 볼륨을 일반 용도 SSD(gp3) EBS 볼륨으로 변환합니다.
2.gp2 볼륨을 Cold HDD(sc1) EBS 볼륨으로 변환합니다.
3.EC2 인스턴스를 메모리 최적화된 인스턴스 유형으로 변환합니다.
4.EC2 인스턴스에서 무제한 모드를 활성화합니다.

지속적으로 높은 성능을 보장하기 위한 최선의 선택은 **1. gp2 볼륨을 일반 용도 SSD(gp3) EBS 볼륨으로 변환합니다.**

### 이유:
- **gp2 볼륨**은 용량에 따라 IOPS 성능이 결정되며, 일정 기간에 걸쳐 IOPS 버스트가 가능하지만, 버스트 크레딧이 소진되면 성능이 저하됩니다. VolumeReadOps 메트릭이 낮다는 것은 IOPS 제한에 도달했음을 나타낼 수 있습니다.
- **gp3 볼륨**은 용량과 성능이 분리되어 있으며, 기본적으로 더 높은 IOPS를 제공하고 필요에 따라 성능을 조정할 수 있어 일관된 성능을 보장합니다. 따라서 **gp3 볼륨**으로 전환하면 더 안정적인 IOPS를 제공할 수 있습니다.

### 선택하지 않은 옵션 검토:
2. **gp2 볼륨을 Cold HDD(sc1) EBS 볼륨으로 변환합니다.**
   - **sc1 볼륨**은 주로 대용량, 저성능 워크로드에 적합하며, 랜덤 읽기 및 쓰기 성능이 낮기 때문에 관계형 데이터베이스 성능을 개선하지 못합니다.

3. **EC2 인스턴스를 메모리 최적화된 인스턴스 유형으로 변환합니다.**
   - 메모리 최적화된 인스턴스는 메모리 집약적인 워크로드에 적합하지만, 문제의 원인은 EBS IOPS와 관련이 있으므로 이 옵션이 적합하지 않습니다.

4. **EC2 인스턴스에서 무제한 모드를 활성화합니다.**
   - 무제한 모드는 CPU 크레딧과 관련이 있으며, 현재 문제는 CPU 성능과 관련이 없으므로 이 옵션이 적절하지 않습니다.

따라서 **gp3 볼륨**으로 변환하는 것이 성능 문제를 해결하는 가장 적절한 솔루션입니다.
## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



## 



