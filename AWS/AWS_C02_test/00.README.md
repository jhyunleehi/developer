## AWS ElastiCache에서 Memcached와 Redis 차이점 
AWS ElastiCache에서 Memcached와 Redis는 둘 다 인메모리 데이터 저장소로 사용되지만, 각기 다른 특성과 사용 사례가 있습니다. 다음은 두 가지의 주요 차이점입니다:

### 1. 데이터 구조

- **Memcached**:
  - 단순한 키-값 저장소로, 문자열 형태의 데이터만 저장할 수 있습니다.
  - 복잡한 데이터 구조나 기능이 필요하지 않은 간단한 캐싱에 적합합니다.

- **Redis**:
  - 키-값 저장소이지만, 다양한 데이터 구조(리스트, 셋, 해시, 정렬된 셋 등)를 지원합니다.
  - 복잡한 데이터 구조와 추가 기능(예: Pub/Sub, 트랜잭션 등)을 필요로 하는 애플리케이션에 적합합니다.

### 2. 지속성

- **Memcached**:
  - 메모리에만 데이터를 저장하며, 서버가 재시작되면 모든 데이터가 사라집니다.
  - 주로 휘발성 데이터 캐싱에 사용됩니다.

- **Redis**:
  - 데이터를 메모리에 저장하면서도 디스크에 스냅샷을 저장하거나 로그를 기록하여 지속성을 지원합니다.
  - 재시작 후에도 데이터 복구가 가능합니다.

### 3. 성능

- **Memcached**:
  - 단순한 구조로 인해 속도가 빠르고, 큰 캐시 스토리지에 유리합니다.
  - 메모리에서 데이터를 빠르게 읽고 쓸 수 있습니다.

- **Redis**:
  - 다양한 기능을 제공하지만, 그로 인해 약간의 성능 오버헤드가 있을 수 있습니다.
  - 그러나 높은 성능을 유지하며, 데이터 구조에 최적화된 다양한 성능 튜닝 옵션이 있습니다.

### 4. 사용 사례

- **Memcached**:
  - 웹 페이지 캐싱, 세션 저장, 간단한 데이터 캐싱 등 단순한 캐싱 요구에 적합합니다.

- **Redis**:
  - 실시간 분석, 소셜 미디어 기능(예: 팔로워 수 카운트), 게임 리더보드, 세션 스토리지, Pub/Sub 시스템 등 다양한 사용 사례에 적합합니다.

### 5. 클러스터링

- **Memcached**:
  - 수평 확장 가능하지만, 클러스터링이 복잡합니다. 일반적으로 캐시 클러스터를 수동으로 관리해야 합니다.

- **Redis**:
  - 클러스터링과 샤딩을 지원하여 자동으로 데이터를 분산할 수 있습니다.
  - Redis Sentinel을 사용해 고가용성을 제공할 수 있습니다.

이러한 차이점들을 고려하여, 필요에 맞는 캐시 솔루션을 선택하는 것이 중요합니다.

## AWS Elastic Beanstalk
AWS Elastic Beanstalk를 사용하는 방법에 대한 구체적인 예시를 제공할게요. 여기서는 Python Flask 애플리케이션을 배포하는 예를 들어볼게요.

### 1. 애플리케이션 준비

먼저, Flask 애플리케이션을 간단하게 만들어보세요. 예를 들어, `application.py`라는 파일을 만들어서 아래와 같이 작성합니다:

```python
from flask import Flask

app = Flask(__name__)

@app.route('/')
def hello():
    return 'Hello, World!'

if __name__ == '__main__':
    app.run()
```

### 2. 필요 라이브러리 설치

Flask와 AWS Elastic Beanstalk CLI를 사용하려면 `requirements.txt` 파일도 만들어야 합니다. 이 파일에는 필요한 라이브러리를 명시합니다:

```
Flask==2.0.1
```

### 3. AWS Elastic Beanstalk CLI 설치

AWS Elastic Beanstalk CLI를 설치합니다. Python과 pip가 설치되어 있어야 하며, 다음 명령어를 사용합니다:

```bash
pip install awsebcli
```

### 4. AWS CLI 설정

AWS CLI를 설정합니다. 다음 명령어를 실행하여 AWS 자격 증명을 설정합니다:

```bash
aws configure
```

여기서 Access Key ID, Secret Access Key, 지역, 출력 형식을 입력합니다.

### 5. Elastic Beanstalk 애플리케이션 생성

애플리케이션을 생성하려면 아래 명령어를 사용합니다:

```bash
eb init -p python-3.8 my-flask-app
```

이 명령어에서 `my-flask-app`은 애플리케이션 이름이며, 사용할 Python 버전을 지정합니다.

### 6. 환경 생성

다음으로 Elastic Beanstalk 환경을 생성합니다:

```bash
eb create my-flask-env
```

`my-flask-env`는 환경 이름입니다.

### 7. 애플리케이션 배포

이제 애플리케이션을 배포합니다:

```bash
eb deploy
```

### 8. 웹 애플리케이션 열기

배포가 완료되면, 웹 애플리케이션을 열어보세요:

```bash
eb open
```

### 9. 로그 확인

문제가 생길 경우, 로그를 확인할 수 있습니다:

```bash
eb logs
```

### 10. 환경 종료

애플리케이션을 더 이상 사용하지 않을 경우, 환경을 종료할 수 있습니다:

```bash
eb terminate my-flask-env
```

이러한 단계들을 통해 AWS Elastic Beanstalk에서 Flask 애플리케이션을 배포할 수 있습니다. 필요에 따라 추가 설정이나 리소스를 구성할 수 있습니다!


## AWS SNS SQS Lambda 구성 모범 사례

AWS Lambda, SQS (Simple Queue Service), SNS (Simple Notification Service)를 연동하여 효율적이고 확장 가능한 아키텍처를 구성하는 것은 매우 유용합니다. 이러한 구성의 모범 사례는 다음과 같습니다:

### **구성 아키텍처**

1. **SNS**: 이벤트나 알림을 생성하는 역할을 합니다. 여러 구독자를 가질 수 있으며, 다양한 프로토콜(예: HTTP/HTTPS, SQS, Lambda 등)로 메시지를 전송할 수 있습니다.
2. **SQS**: 메시지를 큐에 저장하여 비동기적으로 처리할 수 있게 합니다. Lambda 함수는 SQS에서 메시지를 수신하여 처리합니다.
3. **Lambda**: SQS에서 메시지를 읽고, 필요한 처리를 수행하며, 후속 작업을 진행합니다.

### **모범 사례**

1. **SNS와 SQS 통합**
   - SNS 주제를 생성하고, 이를 SQS 대기열과 연결하여 이벤트가 발생할 때마다 SQS 대기열에 메시지를 푸시합니다.
   - **구성 방법**:
     - SNS 콘솔에서 새로운 주제를 생성합니다.
     - SQS 대기열을 생성합니다.
     - SNS 주제의 구독으로 SQS 대기열을 추가합니다.

2. **Lambda와 SQS 통합**
   - Lambda 함수를 생성하여 SQS 대기열의 메시지를 처리하도록 설정합니다.
   - **구성 방법**:
     - Lambda 콘솔에서 새 함수를 생성합니다.
     - 함수의 트리거로 SQS 대기열을 추가합니다.
     - Lambda 함수는 SQS에서 메시지를 폴링하여 처리합니다.

3. **지속적인 에러 처리 및 재처리**
   - Lambda가 메시지 처리를 실패하면 SQS는 기본적으로 메시지를 다시 큐에 넣습니다. 이를 통해 재처리를 가능하게 합니다.
   - **DLQ(Dead Letter Queue)**를 설정하여, 일정 횟수 이상 실패한 메시지를 별도의 SQS 대기열로 보내어 수동으로 조사하거나 재처리할 수 있도록 합니다.

4. **모니터링 및 로깅**
   - AWS CloudWatch를 사용하여 Lambda 함수의 메트릭(예: 호출 수, 오류 수 등)을 모니터링합니다.
   - Lambda 함수에서 발생하는 로그는 CloudWatch Logs에 기록되므로, 이를 통해 문제를 진단할 수 있습니다.

5. **적절한 배치 처리**
   - Lambda 함수에서 SQS 메시지를 처리할 때, **배치 크기**를 설정하여 한 번에 여러 메시지를 처리할 수 있도록 합니다. 이 설정은 처리 효율성을 높이는 데 도움이 됩니다.
   - 예를 들어, `MaxBatchSize`를 10으로 설정하면, Lambda는 SQS에서 한 번에 최대 10개의 메시지를 가져와 처리합니다.

6. **비동기 처리 설계**
   - SNS에서 발행된 이벤트가 SQS로 전달되고, Lambda가 이 메시지를 비동기적으로 처리함으로써 시스템의 응답성을 높이고, 트래픽 급증에 대처할 수 있습니다.

### **구성 예시**

```json
{
  "SNS": {
    "TopicName": "MyTopic",
    "Subscriptions": [
      {
        "Protocol": "sqs",
        "Endpoint": "arn:aws:sqs:us-east-1:123456789012:MyQueue"
      }
    ]
  },
  "SQS": {
    "QueueName": "MyQueue",
    "VisibilityTimeout": 30,
    "DeadLetterQueue": {
      "MaxReceiveCount": 5,
      "DLQQueueName": "MyDLQ"
    }
  },
  "Lambda": {
    "FunctionName": "MyLambdaFunction",
    "SQS": {
      "BatchSize": 10
    }
  }
}
```

### **정리**

이러한 구성은 AWS Lambda와 SQS, SNS를 효과적으로 연동하여, 높은 확장성과 비동기 처리, 에러 핸들링을 지원합니다. 각 구성 요소의 역할과 모범 사례를 이해하고 구현하는 것이 중요합니다. 이 아키텍처를 통해 시스템의 안정성과 성능을 향상시킬 수 있습니다! 🚀


## cloudTrail 
**AWS CloudWatch**와 **AWS CloudTrail**은 모두 AWS에서 제공하는 모니터링 및 로깅 서비스이지만, 사용 목적과 기능이 다릅니다. 주요 차이점을 다음과 같이 비교할 수 있습니다:

### 1. **목적**
   - **CloudWatch**: AWS 리소스의 성능 모니터링 및 로그 관리를 담당합니다. 리소스 사용량, 애플리케이션 성능 및 운영 상태를 실시간으로 추적할 수 있습니다.
   - **CloudTrail**: AWS 계정에서 발생하는 API 호출과 관련된 활동을 기록하고 추적합니다. 누가, 언제, 어떤 작업을 수행했는지에 대한 로그를 남깁니다.

### 2. **기능**
   - **CloudWatch**:
     - EC2, RDS, Lambda 등 다양한 AWS 서비스의 **지표(metric)**를 수집하고 모니터링합니다.
     - **경보(Alarm)** 설정을 통해 리소스의 상태가 특정 임계치를 초과하거나 미달할 때 알림을 제공합니다.
     - **로그(Log) 관리**: 애플리케이션 로그, 시스템 로그 등을 중앙에서 수집하고 검색, 분석이 가능합니다.
   - **CloudTrail**:
     - AWS 리소스와 관련된 **API 활동 기록**을 저장합니다. 예를 들어, 어떤 사용자가 S3 버킷에서 데이터를 삭제했는지 기록합니다.
     - **보안 및 규정 준수**에 중점을 두며, 의심스러운 활동이나 비정상적인 행동을 추적할 수 있습니다.
     - 로그는 감사, 법적 요구 사항, 보안 분석에 주로 사용됩니다.

### 3. **로그**
   - **CloudWatch**: 시스템 및 애플리케이션 로그를 다룹니다. 예를 들어, EC2의 운영 체제 로그나, Lambda의 실행 로그를 수집합니다.
   - **CloudTrail**: 관리 작업 및 API 호출 기록 로그를 다룹니다. AWS 콘솔, CLI, SDK 등을 통한 작업이 모두 기록됩니다.

### 4. **사용 사례**
   - **CloudWatch**:
     - 애플리케이션 성능 모니터링 및 오류 분석
     - 시스템 리소스 사용량 추적
     - 특정 지표가 임계치를 넘을 때 경보 설정
   - **CloudTrail**:
     - AWS 계정에서 수행된 모든 활동을 감사 및 추적
     - 보안 문제 발생 시, 누가 어떤 작업을 수행했는지 확인
     - 규정 준수를 위한 API 활동 기록 저장

### 5. **요약**
   - **CloudWatch**는 **리소스 모니터링 및 성능 관리** 도구이고,
   - **CloudTrail**은 **보안 및 API 활동 추적**을 위한 도구입니다.

----

## AWS Amplify

AWS Amplify는 풀스택 애플리케이션을 쉽게 개발, 배포할 수 있게 해주는 서비스로, 특히 프론트엔드와 백엔드가 모두 포함된 애플리케이션을 자동으로 배포할 때 매우 유용합니다. AWS Amplify는 여러 리소스를 자동으로 구성해주며, 이를 CloudFormation을 통해 관리할 수도 있습니다.

아래는 AWS Amplify를 이용해 자동으로 풀스택 애플리케이션을 배포하는 CloudFormation 템플릿의 예시입니다.

### AWS Amplify 배포 예시 (CloudFormation 템플릿)
```yaml
Resources:
  AmplifyApp:
    Type: AWS::Amplify::App
    Properties:
      Name: "MyAmplifyApp"
      Repository: "https://github.com/your-repository/my-app" # GitHub 저장소 주소
      OauthToken: !Sub "${GitHubToken}"  # GitHub OAuth Token
      BuildSpec: |  # 선택 사항: 커스텀 빌드 사양 (buildspec.yml에서 설정 가능)
        version: 1
        applications:
          - frontend:
              phases:
                build:
                  commands:
                    - npm install
                    - npm run build
              artifacts:
                baseDirectory: public
                files:
                  - '**/*'
      EnvironmentVariables:
        - Name: "ENVIRONMENT"
          Value: "dev"

  AmplifyBranch:
    Type: AWS::Amplify::Branch
    Properties:
      AppId: !Ref AmplifyApp
      BranchName: "main"  # 배포할 브랜치 이름
      EnableAutoBuild: true  # 코드 푸시 시 자동 빌드 및 배포

  AmplifyBackendEnv:
    Type: AWS::Amplify::BackendEnvironment
    Properties:
      AppId: !Ref AmplifyApp
      EnvironmentName: "dev"
```

### 설명
1. **AmplifyApp**: Amplify 애플리케이션을 정의하는 리소스입니다. 이 부분에서 앱의 이름, 연결할 Git 저장소, 그리고 빌드 사양 등을 설정합니다. 저장소는 GitHub, GitLab, Bitbucket 등 다양한 소스를 지원합니다.
2. **AmplifyBranch**: Amplify 앱에 연결된 특정 브랜치를 정의하는 리소스입니다. 주로 `main` 또는 `master` 브랜치를 자동으로 빌드하고 배포하도록 설정할 수 있습니다.
3. **AmplifyBackendEnv**: Amplify 백엔드 환경을 설정하는 리소스입니다. 백엔드 서비스 (예: GraphQL API, Auth, Storage 등)를 배포할 환경을 설정할 수 있습니다.

### GitHub와 연동된 Amplify CI/CD
Amplify의 핵심 기능 중 하나는 GitHub와 같은 Git 기반 소스 컨트롤과 연동해 CI/CD 파이프라인을 자동으로 구축하는 것입니다. CloudFormation 템플릿에서 `Repository` 및 `BranchName`을 설정하여 코드가 해당 브랜치에 푸시될 때마다 자동으로 빌드와 배포가 이루어집니다.

### 전체 흐름
1. 사용자는 GitHub 리포지토리에서 코드를 업데이트하거나 커밋합니다.
2. Amplify가 해당 리포지토리와 브랜치의 변화를 감지하여 CI/CD 파이프라인을 통해 빌드 및 배포를 자동으로 처리합니다.
3. Amplify는 배포가 완료되면 사용자가 설정한 도메인 또는 기본 제공된 도메인을 통해 웹 애플리케이션을 접근할 수 있게 합니다.

### 빌드 사양 (buildspec.yml)
필요시 커스텀 빌드 사양을 템플릿에 정의할 수 있으며, `buildspec.yml` 파일을 통해 설정할 수도 있습니다. 예를 들어, 리액트(React) 앱이라면 아래와 같은 `buildspec.yml` 파일을 사용할 수 있습니다.

```yaml
version: 1
applications:
  - frontend:
      phases:
        install:
          commands:
            - npm install
        build:
          commands:
            - npm run build
      artifacts:
        baseDirectory: build
        files:
          - '**/*'
```

이러한 설정을 통해 Amplify는 풀스택 애플리케이션을 자동으로 관리하고 배포할 수 있으며, 특히 프론트엔드와 백엔드 리소스를 한 번에 통합 관리하는데 강력한 도구입니다.

## CloudFormation 

**AWS CloudFormation**은 AWS 리소스들을 코드로 정의하고 관리할 수 있게 해주는 서비스입니다. 하나의 **템플릿** 파일을 사용하여 다양한 AWS 리소스를 선언적으로 프로비저닝할 수 있습니다. 이 템플릿 파일은 JSON 또는 YAML 형식으로 작성되며, AWS 리소스들을 선언하고 관계를 정의합니다.

다음은 간단한 CloudFormation 템플릿 예시입니다. 이 템플릿은 **S3 버킷**과 **EC2 인스턴스**를 생성하는 내용을 포함하고 있습니다.

### 1. S3 버킷과 EC2 인스턴스를 만드는 CloudFormation 템플릿 예시 (YAML)

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: Simple CloudFormation example to create an S3 bucket and an EC2 instance.

Resources:
  MyS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: my-sample-bucket-12345

  MyEC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: t2.micro
      ImageId: ami-0c55b159cbfafe1f0 # Amazon Linux 2 AMI ID
      KeyName: my-key-pair  # Replace with your key pair name
      Tags:
        - Key: Name
          Value: MySampleEC2
```

### 설명:
1. **AWSTemplateFormatVersion**: CloudFormation 템플릿의 버전을 나타냅니다.
2. **Description**: 템플릿에 대한 간단한 설명입니다.
3. **Resources**: 실제로 생성할 AWS 리소스들을 정의합니다.

   - **MyS3Bucket**: S3 버킷을 생성합니다. `BucketName`은 버킷의 이름을 정의하며, 이 예시에서는 `my-sample-bucket-12345`로 설정됩니다.
   - **MyEC2Instance**: EC2 인스턴스를 생성합니다. `InstanceType`은 `t2.micro`로 설정되었으며, Amazon Linux 2 AMI ID를 사용하여 인스턴스를 시작합니다. `KeyName` 필드에 EC2에 연결하기 위한 키 페어 이름을 지정해야 합니다.

### 2. CloudFormation 스택을 생성하는 방법

이 템플릿을 사용하여 AWS CLI를 통해 **CloudFormation 스택**을 생성할 수 있습니다. 스택은 CloudFormation에서 생성된 AWS 리소스 집합을 의미합니다.

#### 1. 템플릿 파일 저장
위 템플릿을 **`template.yaml`**이라는 파일로 저장합니다.

#### 2. AWS CLI를 통해 CloudFormation 스택 생성

```bash
aws cloudformation create-stack \
    --stack-name my-sample-stack \
    --template-body file://template.yaml \
    --parameters ParameterKey=KeyName,ParameterValue=my-key-pair \
    --capabilities CAPABILITY_IAM
```

- **--stack-name**: CloudFormation 스택의 이름입니다. 이 예시에서는 `my-sample-stack`으로 지정되었습니다.
- **--template-body**: 템플릿 파일의 경로입니다. 로컬 파일을 사용할 경우 `file://` 접두사를 붙입니다.
- **--parameters**: EC2 인스턴스에서 사용할 **KeyPair**를 지정해야 합니다.
- **--capabilities**: IAM 리소스를 생성할 때는 `CAPABILITY_IAM` 또는 `CAPABILITY_NAMED_IAM`을 지정해야 합니다.

#### 3. 생성된 리소스 확인

스택이 성공적으로 생성되면, AWS 콘솔의 **CloudFormation** 서비스에서 스택 상태와 리소스를 확인할 수 있습니다. **S3 버킷**과 **EC2 인스턴스**가 생성된 것을 확인할 수 있습니다.

### 3. 스택 삭제

생성된 스택과 모든 리소스를 삭제하려면 AWS CLI에서 다음 명령을 실행합니다.

```bash
aws cloudformation delete-stack --stack-name my-sample-stack
```

이 명령을 실행하면 스택 내의 모든 AWS 리소스가 삭제됩니다.

### 결론

CloudFormation을 사용하면 하나의 템플릿 파일로 여러 AWS 리소스를 정의하고 관리할 수 있습니다. 이 예시에서 S3 버킷과 EC2 인스턴스를 선언적으로 정의하고 생성했으며, 템플릿과 AWS CLI를 통해 쉽게 관리할 수 있습니다.

---
---

## CloudFormation Stack 

AWS CloudFormation에서 "스택(Stack)"은 인프라 리소스들의 논리적 그룹을 의미합니다. CloudFormation 템플릿을 사용하여 여러 AWS 리소스를 정의하고 배포하는데, 이 템플릿이 실행되면 그 결과로 생성된 리소스들이 스택을 구성하게 됩니다.

예를 들어, 하나의 애플리케이션을 배포하기 위해 EC2 인스턴스, S3 버킷, RDS 데이터베이스 등을 필요로 할 수 있습니다. 이를 CloudFormation 템플릿으로 정의하고 배포하면 해당 리소스들이 하나의 스택으로 묶입니다. 스택을 통해 이 리소스들을 일괄적으로 관리하거나 삭제할 수 있습니다.

### 예시: 웹 애플리케이션 스택
AWS에서 간단한 웹 애플리케이션을 배포한다고 가정해 보겠습니다. CloudFormation 템플릿을 통해 아래와 같은 리소스들을 정의합니다:

1. **EC2 인스턴스** (웹 서버 역할)
2. **S3 버킷** (정적 콘텐츠 호스팅)
3. **RDS 데이터베이스** (데이터 저장소)
4. **Security Group** (네트워크 보안)

이 CloudFormation 템플릿을 실행하면 위의 리소스들이 생성되고, 하나의 스택으로 관리됩니다. 예를 들어, "WebAppStack"이라는 스택을 만들면, 이 스택에는 위의 리소스들이 포함되어 있습니다.

이를 통해 모든 리소스를 일관되게 관리하고, 스택을 삭제할 경우 포함된 리소스들도 함께 삭제됩니다.

### CloudFormation 템플릿 예시 (YAML)
```yaml
Resources:
  MyEC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: t2.micro
      ImageId: ami-0abcdef1234567890
  MyS3Bucket:
    Type: AWS::S3::Bucket
  MyRDSDatabase:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceClass: db.t2.micro
      Engine: MySQL
      AllocatedStorage: 20
```

이 템플릿을 사용하여 스택을 배포하면 EC2 인스턴스, S3 버킷, RDS 인스턴스가 포함된 하나의 스택이 생성됩니다.

---
## CloudFormation과 Amplify 차이점

AWS Amplify와 AWS CloudFormation은 둘 다 인프라를 코드로 관리하고 배포하는 데 사용되지만, 주된 목적과 사용 방법은 다릅니다. Amplify는 주로 풀스택 애플리케이션 개발을 지원하며 프런트엔드와 백엔드를 쉽게 설정하고 관리할 수 있게 해주고, CloudFormation은 AWS 리소스들을 정의하고 프로비저닝하는 데 집중합니다. 예시를 통해 차이점을 설명해 보겠습니다.

### 1. **AWS Amplify**

**주요 역할**: AWS Amplify는 풀스택 애플리케이션(모바일, 웹)을 쉽게 배포하고 관리할 수 있도록 지원합니다. 프런트엔드 개발자가 쉽게 백엔드 리소스를 설정할 수 있게 해주는 개발 프레임워크이자 배포 플랫폼입니다. Amplify는 API, 인증, 스토리지 등의 백엔드 리소스를 손쉽게 설정할 수 있도록 간단한 CLI 명령어와 서비스 연동을 제공합니다.

- **사용 예시**:  
  한 개발자가 **React**로 웹 애플리케이션을 개발하는 중, 사용자를 위한 인증 기능이 필요합니다. Amplify CLI를 사용해 몇 가지 명령어를 통해 **AWS Cognito**를 설정하고 애플리케이션에 통합합니다. 이어서 **GraphQL API (AppSync)**와 **S3 스토리지**를 추가하여 애플리케이션의 데이터 저장과 이미지 업로드 기능을 손쉽게 구현합니다. Amplify Console을 통해 프런트엔드를 호스팅하고 자동으로 CI/CD를 설정하여 애플리케이션을 관리합니다.

  Amplify는 인프라 관리를 사용자가 직접 하지 않고, 필요한 리소스를 자동으로 프로비저닝해 주기 때문에 개발자가 복잡한 인프라 구성을 신경 쓰지 않고도 애플리케이션 개발에 집중할 수 있습니다.

### 2. **AWS CloudFormation**

**주요 역할**: AWS CloudFormation은 AWS 리소스를 코드로 정의하고 관리할 수 있게 해주는 **인프라 자동화 도구**입니다. JSON 또는 YAML 형식의 템플릿을 사용하여 AWS 리소스를 선언적으로 정의하며, 이를 통해 AWS의 거의 모든 리소스를 프로비저닝하고 관리할 수 있습니다. Amplify와 달리 백엔드뿐만 아니라 네트워킹, 보안, 데이터베이스, 로드 밸런서 같은 광범위한 인프라 리소스를 모두 다룰 수 있습니다.

- **사용 예시**:  
  한 엔터프라이즈 팀이 **웹 애플리케이션**을 위한 복잡한 AWS 인프라를 구축하고자 합니다. **VPC, 서브넷, 보안 그룹, RDS 데이터베이스, EC2 인스턴스, API Gateway, Lambda** 등을 포함하는 인프라 아키텍처가 필요합니다. 이를 CloudFormation 템플릿으로 정의하여 모든 리소스를 자동으로 생성하고, 나중에 쉽게 업데이트할 수 있도록 관리합니다. 만약 인프라를 수정해야 할 경우 템플릿을 업데이트하고 재배포할 수 있습니다. 

  CloudFormation은 모든 AWS 리소스를 세밀하게 관리할 수 있으며, 복잡한 상호 의존성을 가진 리소스들을 효율적으로 프로비저닝하고 관리할 수 있게 합니다.

### **Amplify와 CloudFormation 비교 예시**:

#### **예시: 풀스택 애플리케이션 개발**
**Amplify 사용**: 
- 한 스타트업이 간단한 모바일 앱을 개발하고 있습니다. 이 앱은 사용자 인증(Cognito), 파일 저장(S3), 그리고 간단한 API 통신(GraphQL API)을 필요로 합니다.
- Amplify CLI를 통해 몇 가지 명령어만으로 Cognito, S3, AppSync(API)를 설정하고 자동으로 백엔드를 프로비저닝합니다.
- Amplify Console을 통해 프런트엔드 앱을 호스팅하고, Git과 연동하여 자동 배포 파이프라인(CI/CD)을 설정합니다.

**CloudFormation 사용**: 
- 한 대기업이 여러 서비스가 연결된 복잡한 웹 애플리케이션을 개발하고 있습니다. 이는 여러 AWS 계정 및 리전에 걸쳐있는 복잡한 네트워크 구성, 여러 데이터베이스, 로드 밸런서, 및 다양한 Lambda 함수 등을 필요로 합니다.
- CloudFormation 템플릿을 사용하여 이 모든 리소스를 코드로 관리하고, 팀 간에 일관된 인프라 설정을 유지할 수 있습니다.
- 템플릿을 통해 VPC, 서브넷, EC2 인스턴스, RDS 데이터베이스, API Gateway, Lambda, IAM 역할 등 다양한 리소스를 정의하여 AWS 인프라를 자동으로 프로비저닝하고, 필요 시 쉽게 수정합니다.

### **Amplify와 CloudFormation의 주요 차이점**:
1. **사용 용도**:
   - **Amplify**: 풀스택 애플리케이션 개발자, 특히 프런트엔드 개발자를 위한 툴로, 백엔드 서비스(API, 인증, 스토리지)와 프런트엔드를 쉽게 연동.
   - **CloudFormation**: AWS 리소스 전체를 코드로 관리하는 고급 인프라 자동화 도구. 주로 백엔드 및 네트워크 구성 같은 복잡한 인프라 관리에 적합.

2. **관리 리소스**:
   - **Amplify**: 인증, 스토리지, API 같은 특정 백엔드 서비스 및 프런트엔드 호스팅에 집중.
   - **CloudFormation**: 모든 AWS 리소스를 다룰 수 있으며, 네트워크, 보안, 데이터베이스, 컴퓨팅 리소스 등 매우 광범위한 인프라를 정의 가능.

3. **개발자 경험**:
   - **Amplify**: 명령어 몇 개로 손쉽게 설정이 가능하며, 프런트엔드와 백엔드를 간편하게 연동할 수 있어, 개발 초기 단계나 빠른 프로토타입 작업에 적합.
   - **CloudFormation**: YAML 또는 JSON 템플릿 작성이 필요하며, 더 복잡한 인프라 관리와 다수의 AWS 리소스에 대한 세밀한 제어가 가능.


## CloudFromation 이용한 Lambda 배포 예시

AWS CloudFormation을 이용하여 Lambda 함수를 배포하는 예시를 보여드리겠습니다. 이 템플릿은 Lambda 함수와 API Gateway, 그리고 CloudWatch 로그 그룹을 포함하여 간단한 서버리스 애플리케이션을 배포하는 예시입니다.

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Resources:
  # Lambda 함수 생성
  MyLambdaFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      FunctionName: MyLambdaFunction
      Handler: index.handler
      Runtime: nodejs14.x
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        S3Bucket: !Ref CodeS3Bucket
        S3Key: !Ref CodeS3Key
      MemorySize: 128
      Timeout: 30
      Environment:
        Variables:
          STAGE: prod

  # Lambda 실행을 위한 IAM 역할
  LambdaExecutionRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: LambdaExecutionPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: arn:aws:logs:*:*:*

  # API Gateway 생성
  ApiGateway:
    Type: 'AWS::ApiGateway::RestApi'
    Properties:
      Name: LambdaApiGateway
      Description: API Gateway for Lambda

  # API Gateway 리소스
  ApiResource:
    Type: 'AWS::ApiGateway::Resource'
    Properties:
      ParentId: !GetAtt ApiGateway.RootResourceId
      RestApiId: !Ref ApiGateway
      PathPart: myresource

  # API Gateway 메서드
  ApiMethod:
    Type: 'AWS::ApiGateway::Method'
    Properties:
      AuthorizationType: NONE
      HttpMethod: GET
      ResourceId: !Ref ApiResource
      RestApiId: !Ref ApiGateway
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        Uri: !Sub arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${MyLambdaFunction.Arn}/invocations

  # Lambda 권한 설정 (API Gateway에서 호출 가능하게 허용)
  LambdaInvokePermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      FunctionName: !Ref MyLambdaFunction
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com
      SourceArn: !Sub arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${ApiGateway}/*/GET/myresource

Outputs:
  ApiEndpoint:
    Value: !Sub https://${ApiGateway}.execute-api.${AWS::Region}.amazonaws.com/prod/myresource
    Description: "API Gateway endpoint URL for Prod stage"
```


---
## AWS CDK CLI

AWS Cloud Development Kit(AWS CDK)는 프로그래밍 언어를 사용해 AWS 리소스를 정의하고 프로비저닝할 수 있게 해주는 오픈 소스 프레임워크입니다. 개발자가 TypeScript, Python, Java, C#, Go 등의 언어로 AWS 인프라를 코드로 작성할 수 있으며, 이를 CloudFormation 템플릿으로 변환해 배포합니다.

### **AWS CDK 간단한 사용 예시** (TypeScript)

예시로 S3 버킷을 생성하고, 해당 버킷에 버전 관리를 활성화하는 CDK 스택을 작성해보겠습니다.

#### 1. **사전 준비**
- Node.js가 설치되어 있어야 합니다.
- AWS CLI가 설정되어 있어야 합니다.

#### 2. **CDK 프로젝트 생성**

```bash
# CDK 프로젝트를 생성
mkdir my-cdk-app
cd my-cdk-app

# CDK 초기화 (언어 선택은 TypeScript)
cdk init app --language typescript
```

이 명령어는 기본 프로젝트 구조와 `cdk.json`, `package.json` 파일들을 생성합니다.

#### 3. **CDK로 S3 버킷 생성**

이제 `lib/my-cdk-app-stack.ts` 파일을 수정하여 S3 버킷을 생성하는 코드를 추가합니다.

```typescript
import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';
import * as s3 from 'aws-cdk-lib/aws-s3';

export class MyCdkAppStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    // S3 버킷 생성
    new s3.Bucket(this, 'MyFirstBucket', {
      versioned: true,  // 버전 관리 활성화
      removalPolicy: cdk.RemovalPolicy.DESTROY,  // 스택 삭제 시 버킷도 삭제
      autoDeleteObjects: true,  // 스택 삭제 시 버킷 내 객체도 삭제
    });
  }
}
```

이 코드는 `MyCdkAppStack` 클래스 내에서 S3 버킷을 생성하고, 해당 버킷에 버전 관리 기능을 활성화하며, 스택이 삭제될 때 버킷과 객체도 함께 삭제되도록 설정합니다.

#### 4. **CDK 애플리케이션 배포**

프로젝트의 디펜던시를 설치하고, 스택을 AWS에 배포합니다.

```bash
# 필요한 패키지 설치
npm install

# CDK 구문 확인 및 CloudFormation 템플릿 생성
cdk synth

# 스택 배포
cdk deploy
```

`cdk deploy` 명령어는 CloudFormation 템플릿을 생성한 후, AWS에 스택을 배포합니다. 배포가 완료되면 AWS S3 콘솔에서 새로 생성된 버킷을 확인할 수 있습니다.

#### 5. **CDK 스택 제거**

스택과 모든 리소스를 제거하려면 다음 명령어를 사용합니다.

```bash
cdk destroy
```

`cdk destroy` 명령어는 생성한 S3 버킷과 해당 버킷에 포함된 모든 객체를 삭제하고 스택을 제거합니다.


### **정리**:
이 예시는 AWS CDK를 사용하여 S3 버킷을 생성하는 간단한 예제입니다. CDK는 CloudFormation과 달리 코드 기반으로 인프라를 정의하므로, 개발자가 익숙한 프로그래밍 언어로 AWS 리소스를 쉽게 관리할 수 있습니다.


## AWS CDK Bootstrap

**AWS CDK Bootstrap**은 CDK 애플리케이션을 AWS 계정에 배포할 수 있도록 사전에 필요한 리소스들을 설정하는 과정입니다. 기본적으로 AWS CDK는 **CloudFormation** 스택을 통해 AWS 리소스를 프로비저닝하지만, 이 과정에서 일부 CDK 리소스(예: S3 버킷, 역할 등)가 필요합니다. 이러한 리소스들을 **CDK Bootstrap**을 통해 사전에 준비합니다.

### **AWS CDK Bootstrap의 주요 목적**
CDK는 애플리케이션을 배포할 때 다음과 같은 리소스를 필요로 할 수 있습니다:
1. **S3 버킷**: 애플리케이션의 자산(예: Lambda 함수의 코드 패키지, Docker 이미지)을 저장하는 용도.
2. **IAM 역할 및 권한**: CDK가 리소스를 생성하고 관리하기 위한 권한을 설정하는 역할.
3. **ECR 레지스트리**: Docker 이미지를 관리할 때 사용.

**CDK Bootstrap**은 이러한 리소스를 자동으로 설정하여 CDK가 정상적으로 리소스를 배포할 수 있도록 합니다.

### **Bootstrap이 필요한 이유**
CDK 애플리케이션을 AWS에 배포할 때, 일부 리소스들은 자체적으로 CloudFormation 템플릿에 포함되지 않습니다. 특히, Lambda 함수의 코드나 자산 파일들을 S3 버킷에 업로드해야 하거나, Docker 이미지를 ECR에 저장해야 할 때, 미리 설정된 리소스가 없으면 CDK는 애플리케이션을 배포할 수 없습니다. 그래서 배포를 시작하기 전에 필요한 리소스를 설정하는 과정이 필요합니다. 이것이 바로 CDK **bootstrap**입니다.

### **CDK Bootstrap 사용 방법**

**1. CDK Bootstrap 명령 실행**
```bash
cdk bootstrap
```

이 명령어는 현재 CDK 프로젝트가 배포될 AWS 계정과 리전에 부트스트랩 스택을 설정합니다. `cdk bootstrap` 명령을 실행하면, AWS에 `CDKToolkit`이라는 이름의 CloudFormation 스택이 생성됩니다.

이 스택에는 다음과 같은 리소스가 포함될 수 있습니다:
- **S3 버킷**: Lambda 코드나 기타 자산을 저장.
- **IAM 역할**: 배포 시 필요한 권한을 설정.
- **ECR 레지스트리**: Docker 이미지를 관리할 때 사용.

**2. 특정 프로필, 계정 또는 리전에서 bootstrap**
다중 계정 또는 리전을 사용하는 경우, 특정 AWS 프로필 또는 리전에서 부트스트랩할 수 있습니다.

```bash
cdk bootstrap aws://<ACCOUNT_ID>/<REGION>
```

예를 들어, 다음 명령어는 특정 계정과 리전에 부트스트랩을 실행합니다.
```bash
cdk bootstrap aws://123456789012/us-east-1
```

**3. Custom Bootstrap**
기본 부트스트랩 리소스 외에, 커스텀 설정을 통해 고급 옵션을 추가할 수도 있습니다. 예를 들어, 특정 S3 버킷 이름을 지정하거나 사용자 정의 역할을 추가할 수 있습니다.

```bash
cdk bootstrap --bootstrap-bucket-name my-custom-bucket
```

### **Bootstrap이 필요한 상황**
1. **Lambda 코드 패키지 배포**: Lambda 함수의 코드가 CloudFormation 템플릿에 직접 포함되지 않고 S3 버킷에 업로드될 때.
2. **Docker 이미지 배포**: ECS 또는 Lambda에 Docker 이미지를 배포할 때 ECR을 사용.
3. **다수의 AWS 계정/리전에 배포**: CDK를 여러 계정이나 리전에서 사용할 때, 각 환경에 맞는 부트스트랩 리소스를 설정.

### **부트스트랩이 이미 되어 있는지 확인하기**
부트스트랩이 이미 된 계정 및 리전에서는 다시 부트스트랩할 필요가 없습니다. CloudFormation 콘솔에서 `CDKToolkit`이라는 스택을 확인하거나, 다음 명령으로 확인할 수 있습니다:

```bash
aws cloudformation describe-stacks --stack-name CDKToolkit
```

### **정리**
AWS CDK **Bootstrap**은 CDK 애플리케이션 배포를 위한 기본 리소스(S3 버킷, IAM 역할 등)를 사전에 준비하는 과정입니다. 이는 CDK를 이용해 AWS 리소스를 배포할 때 필수적인 단계로, 배포 환경을 설정하고 CDK가 원활하게 동작하도록 도와줍니다.


## AWS Lamda 생성 예시

AWS Lambda 함수를 생성하고 배포하는 절차를 AWS CLI 및 AWS SAM을 사용한 예시로 설명드리겠습니다. 이 예시는 Python으로 간단한 "Hello World" Lambda 함수를 만들고 AWS에 배포하는 과정을 다룹니다.

### **1. 사전 준비**
- AWS CLI가 설치되어 있어야 하며, AWS 자격 증명이 설정되어 있어야 합니다.
- AWS SAM CLI가 설치되어 있어야 합니다.

### **2. 프로젝트 폴더 생성**
먼저, Lambda 함수를 작성할 프로젝트 폴더를 생성합니다.

```bash
mkdir my-lambda-app
cd my-lambda-app
```

### **3. SAM 프로젝트 초기화**
SAM 프로젝트를 초기화합니다. Python을 선택하여 Lambda 함수의 기본 템플릿을 생성합니다.

```bash
sam init
```

프롬프트가 뜨면, 아래와 같이 입력합니다:
- **Which template source would you like to use?**: 1 (AWS Quick Start Templates)
- **What runtime would you like to use?**: 3 (Python 3.9)
- **Project name**: `my-lambda-app`
- **Use the default configuration?**: Y

이 명령을 실행하면 SAM 프로젝트의 기본 디렉토리 구조가 생성됩니다.

### **4. Lambda 함수 작성**
`hello_world/app.py` 파일을 열어 Lambda 함수 코드를 작성합니다. 이미 SAM 기본 템플릿으로 생성된 함수가 있기 때문에, 이 코드를 그대로 사용할 수 있습니다.

```python
def lambda_handler(event, context):
    return {
        "statusCode": 200,
        "body": "Hello, World!"
    }
```

이 코드는 간단히 "Hello, World!"를 반환하는 Lambda 함수입니다.

### **5. SAM 템플릿 설정**
SAM 템플릿 파일(`template.yaml`)을 수정하여 Lambda 함수를 정의합니다. 기본적으로 생성된 `template.yaml`을 사용할 수 있으며, 아래는 그 예시입니다:

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Resources:
  HelloWorldFunction:
    Type: AWS::Serverless::Function
    Properties:
      Handler: hello_world.app.lambda_handler
      Runtime: python3.9
      CodeUri: hello_world/
      MemorySize: 128
      Timeout: 3
      Events:
        HelloWorldApi:
          Type: Api
          Properties:
            Path: /hello
            Method: get
```

이 템플릿은 `HelloWorldFunction`이라는 Lambda 함수를 정의하고, `/hello` 경로에 대한 HTTP GET 요청이 Lambda 함수를 호출하도록 설정합니다.

### **6. SAM 애플리케이션 빌드**
다음으로, SAM 애플리케이션을 빌드합니다.

```bash
sam build
```

이 명령은 Lambda 함수와 템플릿을 패키징하여 배포할 준비를 합니다.

### **7. SAM 애플리케이션 배포**
이제 애플리케이션을 AWS에 배포합니다.

```bash
sam deploy --guided
```

`--guided` 옵션은 첫 배포 시 설정을 도와줍니다. 프롬프트가 나타나면 적절히 입력하세요:
- **Stack Name**: `my-lambda-stack` (스택 이름)
- **AWS Region**: `us-east-1` (원하는 리전)
- **Confirm changes before deploy**: `y` (배포 전 확인)
- **Allow SAM CLI IAM role creation**: `y`
- **Save arguments to samconfig.toml**: `y`

배포가 완료되면 Lambda 함수와 API Gateway가 AWS에 생성됩니다.

### **8. Lambda 함수 테스트**
배포가 완료되면 AWS에서 함수가 배포된 API Gateway 엔드포인트 URL이 표시됩니다. 해당 URL로 `curl` 또는 브라우저에서 요청을 보낼 수 있습니다.

```bash
curl https://<api-id>.execute-api.<region>.amazonaws.com/Prod/hello
```

이 요청은 Lambda 함수에서 `"Hello, World!"` 응답을 반환합니다.

### **9. 배포된 리소스 제거**
더 이상 Lambda 함수와 관련된 리소스를 사용하지 않으려면 스택을 삭제하여 비용이 발생하지 않도록 할 수 있습니다.

```bash
sam delete
```

이 명령어는 생성된 모든 리소스를 삭제합니다.

---

### **정리**:
- **프로젝트 생성**: `sam init` 명령으로 SAM 프로젝트를 초기화.
- **Lambda 함수 작성**: `hello_world/app.py` 파일에서 Lambda 함수 작성.
- **SAM 템플릿 설정**: `template.yaml`에서 Lambda 함수와 API Gateway 정의.
- **빌드 및 배포**: `sam build`로 애플리케이션을 빌드하고 `sam deploy`로 배포.
- **테스트**: 배포된 Lambda 함수의 API 엔드포인트로 요청을 보내 테스트.

## AWS Lambda S3ReadPolicy 설정

AWS SAM을 사용하여 Lambda 함수에 S3 버킷에 대한 읽기 권한을 부여하려면, Lambda 함수의 **IAM 역할**에 적절한 권한을 부여해야 합니다. 이를 위해 AWS SAM의 `Policies` 속성을 사용하여 **S3ReadPolicy**를 Lambda 함수에 추가할 수 있습니다. 이 정책은 Lambda 함수가 S3 버킷의 객체를 읽을 수 있도록 허용합니다.

다음은 AWS SAM 템플릿에서 Lambda 함수에 S3 읽기 권한을 추가하는 방법에 대한 예시입니다.

### **AWS SAM 템플릿 예시 (template.yaml)**

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Resources:
  MyLambdaFunction:
    Type: AWS::Serverless::Function
    Properties: 
      Handler: index.handler
      Runtime: nodejs14.x
      CodeUri: ./src
      # Lambda 함수에 S3 읽기 권한 부여
      Policies:
        - S3ReadPolicy:
            BucketName: !Ref MyS3Bucket  # S3 버킷 참조

  MyS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: my-sample-bucket  # S3 버킷 이름을 설정 (선택 사항)
```

### **구성 설명:**
1. **Lambda 함수 설정 (`MyLambdaFunction`)**:
   - `AWS::Serverless::Function` 리소스를 통해 Lambda 함수를 정의합니다.
   - `Policies` 속성에서 `S3ReadPolicy`를 사용하여 Lambda 함수에 지정된 S3 버킷(`MyS3Bucket`)에 대한 읽기 권한을 부여합니다.

2. **S3 버킷 설정 (`MyS3Bucket`)**:
   - `AWS::S3::Bucket` 리소스를 통해 S3 버킷을 정의합니다.
   - `BucketName`을 설정하거나 AWS에서 자동으로 생성된 버킷 이름을 사용할 수 있습니다.

### **S3ReadPolicy**:
- `S3ReadPolicy`는 Lambda 함수에 S3 버킷 내 객체를 **읽기 전용**으로 액세스할 수 있는 권한을 부여하는 AWS SAM의 정책 템플릿입니다.
- `BucketName` 속성에 접근을 허용하려는 S3 버킷을 지정합니다.

### **배포 명령**:
1. **AWS SAM 패키징 및 배포**:
   ```bash
   sam package --output-template-file packaged.yaml --s3-bucket <your-s3-bucket>
   ```

2. **AWS SAM 배포**:
   ```bash
   sam deploy --template-file packaged.yaml --stack-name my-sam-app --capabilities CAPABILITY_IAM
   ```

이 구성을 통해 Lambda 함수는 지정된 S3 버킷 내의 객체를 읽을 수 있는 권한을 갖게 됩니다.


## AWS Lambda  Mapping Template 

AWS Lambda 요청 템플릿은 주로 API Gateway와 연동할 때 사용되며, API Gateway로 들어온 요청을 Lambda 함수가 처리할 수 있는 형식으로 변환하는 역할을 합니다. 이 요청 템플릿(Request Template)은 **매핑 템플릿(Mapping Template)**이라고도 하며, **Velocity Template Language (VTL)**을 사용하여 API Gateway의 요청을 Lambda 함수로 변환하거나 가공할 수 있습니다.

### Lambda 요청 템플릿을 사용하는 이유
API Gateway는 HTTP 요청을 받아서 Lambda 함수로 전달하지만, Lambda 함수가 요구하는 형식으로 요청을 변환해야 하는 경우가 많습니다. 요청 템플릿을 사용하면 다음과 같은 상황에서 유용합니다.
- HTTP 요청의 파라미터를 가공하거나 필터링하여 Lambda로 전달
- JSON 포맷을 변경하거나 데이터를 재구성
- 특정 헤더 값이나 쿼리 파라미터를 Lambda 함수로 전달

### Lambda 요청 템플릿 구성 방법

#### 1. **API Gateway 콘솔에서 요청 템플릿 설정**
API Gateway 콘솔을 통해 요청 템플릿을 설정할 수 있습니다. 예를 들어, API Gateway에 정의된 특정 리소스의 `Method Request`에서 **Integration Request** 섹션을 설정할 수 있습니다.

#### 2. **매핑 템플릿 기본 구조**
매핑 템플릿은 VTL로 작성되며, API Gateway로 들어온 요청을 적절한 형태로 가공합니다. 예를 들어, HTTP GET 요청의 쿼리 파라미터나 POST 요청의 본문 데이터를 Lambda 함수로 전달할 수 있습니다.

### 매핑 템플릿 예시

#### GET 요청의 쿼리 파라미터를 Lambda로 전달하는 템플릿
```vtl
{
  "param1": "$input.params('param1')",
  "param2": "$input.params('param2')"
}
```

이 템플릿은 API Gateway에서 들어오는 요청의 쿼리 파라미터 `param1`, `param2`를 Lambda 함수로 전달할 JSON 객체를 생성합니다.

#### POST 요청의 JSON 본문 데이터를 전달하는 템플릿
```vtl
{
  "body": $input.body,
  "headers": {
    "Content-Type": "$input.params('Content-Type')",
    "User-Agent": "$input.params('User-Agent')"
  }
}
```

이 템플릿은 POST 요청의 본문 데이터를 Lambda로 전달하면서, `Content-Type`과 `User-Agent` 같은 헤더 값도 함께 전달합니다.

#### 경로 변수(Path Parameter)를 Lambda로 전달하는 템플릿
```vtl
{
  "id": "$input.params('id')"
}
```

이 템플릿은 `/items/{id}`와 같은 API 요청에서 경로 변수 `id`를 추출하여 Lambda로 전달합니다.

### 3. **템플릿에서 사용할 수 있는 변수들**
- **$input.body**: 요청 본문을 그대로 전달 (JSON, XML, Form data 등)
- **$input.params()**: 요청의 모든 파라미터 (경로, 쿼리, 헤더)를 얻음
- **$input.params('paramName')**: 특정 쿼리, 헤더 또는 경로 변수의 값을 가져옴
- **$input.path('$.jsonPath')**: JSON 본문에서 특정 경로의 값을 가져옴

### 전체 템플릿 예시: 복합 데이터 가공
```vtl
{
  "method": "$context.httpMethod",
  "path": "$context.resourcePath",
  "queryStringParameters": {
    "param1": "$input.params('param1')",
    "param2": "$input.params('param2')"
  },
  "headers": {
    "Content-Type": "$input.params('Content-Type')"
  },
  "body": $input.json('$')
}
```
이 템플릿은 요청의 HTTP 메서드, 경로, 쿼리 파라미터, 헤더, 그리고 요청 본문을 가공하여 Lambda 함수로 전달합니다.

### 4. **템플릿의 활용 예**
- **쿼리 파라미터나 헤더의 값 검증 및 가공**: `$input.params()`와 같은 VTL 기능을 통해 유효성 검사를 하거나 필요한 데이터를 가공한 후 Lambda로 전달.
- **서로 다른 형식의 요청을 통일하여 Lambda에서 처리**: 요청이 XML, JSON, 또는 다른 포맷일 경우 이를 하나의 공통된 JSON 형식으로 변환.

### 결론
AWS Lambda 요청 템플릿은 API Gateway로 들어오는 다양한 형식의 요청을 Lambda 함수가 이해할 수 있는 구조로 변환하는데 매우 유용합니다. VTL을 통해 유연하게 데이터를 변환하고 가공할 수 있으며, API Gateway와 Lambda의 통합을 최적화하는 데 중요한 역할을 합니다.

---

## AWS CodeBuild 테스트 보고서

AWS CodeBuild에서 **테스트 보고서**를 생성하기 위해서는 `buildspec.yml` 파일에서 테스트 결과를 수집하고 보고서를 출력하도록 설정해야 합니다. AWS CodeBuild는 여러 테스트 도구의 결과를 지원하며, 보고서는 **JUnit**, **NUnit**, **Cucumber** 등의 형식을 사용할 수 있습니다.

### 기본 구성 방법
`buildspec.yml` 파일의 **reports** 섹션에서 테스트 보고서의 경로와 형식을 지정합니다. 예를 들어, `JUnit` 테스트 보고서를 생성하고 CodeBuild 콘솔에서 이를 확인하려면 빌드 과정에서 테스트 결과 파일을 특정 디렉토리에 저장하고, 해당 경로를 보고서로 설정해야 합니다.

### `buildspec.yml` 파일 예시 (JUnit 테스트 보고서)

```yaml
version: 0.2

phases:
  install:
    commands:
      - echo "Installing dependencies..."
      - apt-get update -y
      - apt-get install -y openjdk-11-jdk
      - apt-get install -y maven
  build:
    commands:
      - echo "Building the project and running tests..."
      - mvn clean test  # Maven을 사용하여 테스트 실행
  post_build:
    commands:
      - echo "Build and test completed."

artifacts:
  files:
    - target/*.jar  # 빌드된 jar 파일을 artifacts로 저장

reports:
  JUnitReports:
    files:
      - target/surefire-reports/*.xml  # JUnit 테스트 결과 파일 경로
    base-directory: target  # 테스트 보고서가 있는 디렉토리
    discard-paths: yes  # 경로 정보를 무시하고 파일만 출력
```

### 설명:
1. **phases**:
   - **install**: 빌드 환경을 준비하는 단계입니다. 예를 들어, `Java` 및 `Maven`을 설치하고 있습니다.
   - **build**: 실제 빌드 및 테스트를 수행하는 단계로, `mvn clean test` 명령어로 Maven 프로젝트의 테스트를 실행합니다.
   - **post_build**: 빌드 후 처리 단계로, 여기서는 테스트 결과를 저장할 수 있습니다.

2. **artifacts**:
   - 빌드의 결과물(예: `.jar` 파일)을 지정합니다. `target` 디렉토리 아래의 모든 `.jar` 파일을 출력으로 설정합니다.

3. **reports**:
   - **JUnitReports**: `target/surefire-reports/`에 있는 JUnit 형식의 테스트 결과 XML 파일을 수집합니다.
   - **files**: JUnit 테스트 결과 파일들이 있는 경로를 지정합니다. 이 경우, `Maven`의 `Surefire` 플러그인이 생성하는 테스트 결과 파일을 지정합니다.
   - **base-directory**: 보고서를 저장하는 기준 디렉토리입니다. `target` 폴더 아래에 있는 파일을 참조합니다.
   - **discard-paths**: `yes`로 설정하면 경로 없이 파일만 표시됩니다.

### 또 다른 예시: Python 프로젝트에서 `pytest`를 사용하는 경우
만약 Python 프로젝트에서 `pytest`를 사용하여 테스트 결과를 CodeBuild에 보고하려면 다음과 같은 `buildspec.yml` 파일을 작성할 수 있습니다.

```yaml
version: 0.2

phases:
  install:
    commands:
      - echo "Installing dependencies..."
      - pip install -r requirements.txt
  build:
    commands:
      - echo "Running tests with pytest..."
      - pytest --junitxml=reports/test-report.xml  # pytest 결과를 JUnit XML 형식으로 저장

reports:
  PyTestReports:
    files:
      - reports/test-report.xml  # pytest 결과 파일 경로
    base-directory: reports
    discard-paths: yes
```

### 설명:
- **pytest**는 `--junitxml` 옵션을 사용하여 JUnit XML 형식의 테스트 결과 파일을 생성합니다.
- `reports/test-report.xml` 경로에 생성된 테스트 결과를 CodeBuild의 테스트 보고서로 수집합니다.

### 요약
1. `buildspec.yml` 파일에서 **reports** 섹션을 정의하여 테스트 결과 파일 경로를 지정합니다.
2. 테스트 도구에 따라 적절한 명령어로 테스트를 실행하고, 결과를 JUnit 형식으로 저장합니다.
3. CodeBuild는 `JUnit`, `NUnit`, `Cucumber`와 같은 다양한 테스트 형식을 지원합니다.

이 설정을 통해 AWS CodeBuild 콘솔에서 테스트 결과를 시각화하고 쉽게 확인할 수 있습니다.

---

## AWS AppConfig Agent Lambda 확장 

AWS AppConfig Agent Lambda 확장은 AWS AppConfig의 구성을 Lambda 함수에서 쉽게 사용할 수 있도록 해주는 기능입니다. 이를 통해 Lambda 함수가 실행될 때마다 최신 구성을 자동으로 가져오거나 업데이트된 설정을 사용할 수 있습니다.

AWS AppConfig Agent Lambda 확장을 사용하면 애플리케이션의 설정 변경을 즉시 반영할 수 있습니다. 예를 들어, 데이터베이스 연결 정보, 피처 플래그, 환경 변수 등의 설정을 Lambda 함수 실행 시 동적으로 가져올 수 있습니다.

### AppConfig Agent Lambda 확장 설정 예시

1. **AppConfig 구성 생성**: 먼저 AWS AppConfig에서 애플리케이션 구성(Profile)을 생성해야 합니다. 여기서 피처 플래그 또는 애플리케이션 설정을 정의합니다.

2. **Lambda 확장 활성화**: Lambda 함수에 AppConfig Agent Lambda 확장을 설치하고, Lambda 함수 내에서 확장된 기능을 사용하여 AppConfig 구성(Profile)을 가져옵니다.

### 1. AWS AppConfig 구성 생성
AWS AppConfig에서 구성(Profile)을 생성하는 단계입니다. 예를 들어, `application_config`이라는 구성에 피처 플래그나 환경 변수를 설정합니다.

- **Application**: MyApp
- **Configuration Profile**: application_config
- **Environment**: dev

### 2. Lambda에서 AWS AppConfig Agent 확장 사용하기
AppConfig Agent Lambda 확장을 사용하여 Lambda 함수에서 설정 값을 가져오는 방법을 보여드리겠습니다.

#### 2.1 Lambda 함수에 AppConfig 확장 추가
AppConfig Agent Lambda 확장을 Lambda 함수에 추가하려면 Lambda 함수의 **레이어**(Layer)를 사용해야 합니다. AWS가 제공하는 AppConfig Lambda 확장 레이어 ARN은 아래와 같습니다.

- **Region**에 따라 ARN이 달라질 수 있으므로 AWS Lambda 콘솔에서 "AppConfig Lambda extension"을 검색하여 해당 레이어를 추가합니다.

#### 2.2 Lambda 함수에서 AppConfig 호출
Lambda 함수 코드에서 AppConfig 구성(Profile)을 호출하여 값을 가져오는 예시입니다.

```python
import os
import requests

def lambda_handler(event, context):
    # AppConfig Agent의 설정을 가져올 수 있는 엔드포인트
    appconfig_url = os.getenv('AWS_APPCONFIG_EXTENSION_HTTP_PORT')
    config_profile_id = "your-configuration-profile-id"
    environment_id = "your-environment-id"
    application_id = "your-application-id"
    
    # AppConfig 구성 API 호출
    url = f"http://localhost:{appconfig_url}/applications/{application_id}/environments/{environment_id}/configurations/{config_profile_id}"
    
    try:
        # HTTP GET 요청을 보내서 AppConfig 구성을 가져옴
        response = requests.get(url)
        response.raise_for_status()
        config_data = response.json()

        # 구성을 출력하거나 사용할 수 있음
        print(f"Configuration data: {config_data}")
        return {
            'statusCode': 200,
            'body': config_data
        }
    except requests.exceptions.RequestException as e:
        print(f"Error fetching configuration: {e}")
        return {
            'statusCode': 500,
            'body': "Error fetching configuration"
        }
```

### 주요 구성 요소:
1. **AppConfig Agent 엔드포인트**: Lambda 환경 변수 `AWS_APPCONFIG_EXTENSION_HTTP_PORT`를 사용하여 로컬 엔드포인트에서 AppConfig 구성에 액세스할 수 있습니다.
2. **AppConfig 설정 정보**: `application_id`, `environment_id`, `configuration_profile_id`는 AppConfig에서 생성한 구성 요소에 해당하는 ID입니다.
3. **HTTP 요청**: Lambda 함수는 `requests` 라이브러리를 사용하여 AppConfig Agent로부터 최신 구성을 가져옵니다. 이 구성은 JSON 형식으로 전달되며, 함수에서 이를 처리하거나 출력할 수 있습니다.

### 3. Lambda 환경 변수 설정
Lambda 함수가 AppConfig 구성 정보를 가져올 수 있도록 환경 변수를 설정해야 합니다. Lambda 함수의 **환경 변수** 설정에서 아래 값을 추가하세요:

- `AWS_APPCONFIG_EXTENSION_HTTP_PORT`: AppConfig Agent와 통신하는 포트 (기본적으로 `2772` 사용)

### 4. AppConfig 설정을 주기적으로 가져오는 방법
Lambda 함수는 매번 실행될 때마다 AppConfig Agent를 호출하여 최신 구성을 가져올 수 있습니다. 이 방법을 사용하면 설정이 변경될 때마다 Lambda 함수에 즉시 반영할 수 있습니다.

### 요약
- AWS AppConfig Agent Lambda 확장을 사용하면 Lambda 함수가 최신 설정 값을 동적으로 가져올 수 있습니다.
- AppConfig Agent는 Lambda 함수가 실행될 때마다 HTTP API를 통해 설정 값을 가져옵니다.
- `buildspec.yml`과 환경 변수를 설정하여 AppConfig와 Lambda 간의 연동을 손쉽게 설정할 수 있습니다.

이 방법을 사용하면 빠르게 애플리케이션 설정을 변경하고, 이러한 설정을 Lambda 함수에서 동적으로 활용할 수 있습니다.

---

## AWS CodeDeploy Local Test

`AWS CodeDeploy` 에이전트를 로컬에 설치한 후, **codedeploy-local** 명령을 사용하여 배포 패키지를 검증할 수 있습니다. 이때 `--bundle-location` 옵션을 사용하여 S3 버킷에 저장된 코드 패키지를 지정할 수 있습니다. 이 방법은 실제로 배포 전에 로컬 환경에서 배포 패키지가 올바르게 구성되었는지 테스트하는 데 유용합니다.

다음은 `codedeploy-local` 명령을 사용하여 S3 버킷에서 코드 패키지를 지정하는 예시입니다.

### 예시: `codedeploy-local` 명령 사용

```bash
codedeploy-local --bundle-location s3://my-app-bucket/my-app-bundle.zip --type zip --output-dir /path/to/output/directory
```

### 각 옵션의 설명:

1. **--bundle-location**:
   - S3 버킷에 저장된 배포 패키지 경로를 지정합니다. 예시에서는 `s3://my-app-bucket/my-app-bundle.zip`에 저장된 배포 패키지를 사용합니다.
   
2. **--type**:
   - 배포 패키지의 형식을 지정합니다. `zip` 형식을 사용하고 있으며, `.tar`, `.tgz`, 또는 `.tar.gz` 형식도 가능합니다.

3. **--output-dir**:
   - 배포 결과 파일을 저장할 로컬 디렉터리를 지정합니다. 이 디렉터리에서 배포된 파일과 설치 로그를 확인할 수 있습니다.

### 필수 전제 조건:
- **AWS CLI 설치 및 구성**: AWS CLI가 설치되어 있어야 하고, S3 버킷에 접근할 수 있도록 IAM 역할 또는 자격 증명이 구성되어 있어야 합니다.
- **AWS CodeDeploy Agent 설치**: 로컬에 CodeDeploy 에이전트를 설치해야 합니다.
  
### 예시 실행 과정:
1. **S3 버킷에 배포 패키지 업로드**:
   - `my-app-bucket`이라는 S3 버킷에 `my-app-bundle.zip` 파일을 업로드합니다. 이 파일은 배포에 필요한 코드와 설정 파일을 포함합니다.

2. **로컬에서 배포 테스트**:
   - `codedeploy-local` 명령을 실행하면 지정된 S3 버킷에서 배포 패키지를 다운로드하고, 로컬 머신에 설치 및 검증 과정을 진행합니다.

3. **결과 확인**:
   - `--output-dir`에서 지정한 디렉터리에 배포된 파일을 확인할 수 있으며, 배포 시 발생한 로그도 이 디렉터리에 저장됩니다.

이 예시를 사용하면 실제 AWS CodeDeploy를 통해 배포하기 전에 로컬 환경에서 배포 패키지를 검증할 수 있습니다.

---

## AWS AppConfig 

Amazon ECS에 AWS AppConfig를 적용하면, 컨테이너화된 애플리케이션이 **동적 설정**을 사용하여 구성을 쉽게 업데이트할 수 있습니다. 이를 통해 재배포 없이 애플리케이션 설정(예: 피처 플래그, 데이터베이스 연결 정보)을 관리할 수 있습니다.

AWS AppConfig는 Amazon ECS에서 다음과 같은 방식으로 적용할 수 있습니다:
1. **AWS AppConfig 구성 프로파일**에서 설정을 생성
2. **ECS 작업(Task)**에서 AppConfig 에이전트 사용
3. **ECS 컨테이너 내에서** 애플리케이션이 AppConfig API를 사용해 동적으로 구성을 가져오는 방식

### 예시: ECS에 AWS AppConfig 적용

#### 1. **AppConfig에서 설정 구성하기**

먼저 AWS AppConfig 콘솔에서 새로운 **애플리케이션(Application)**, **환경(Environment)**, 그리고 **구성 프로파일(Configuration Profile)**을 생성합니다. 여기서 예를 들어 애플리케이션의 **피처 플래그** 또는 **환경 변수**를 정의할 수 있습니다.

- **Application**: MyApp
- **Environment**: production
- **Configuration Profile**: feature_flags

#### 2. **ECS Task Definition에 AppConfig 설정 추가**

ECS에서 AWS AppConfig를 사용하려면, **ECS 작업 정의(Task Definition)**에서 AppConfig를 호출하는 애플리케이션 코드를 사용하여 구성을 가져올 수 있습니다. 

ECS Task Definition에는 AppConfig 에이전트를 설치하거나, 애플리케이션에서 직접 AppConfig API를 호출하도록 구성할 수 있습니다. 아래는 애플리케이션이 AppConfig에서 구성을 가져오는 Python 코드 예시와 함께 ECS Task Definition 예시입니다.

#### 3. **ECS 컨테이너 내 애플리케이션에서 AppConfig API 호출**

다음은 Python 애플리케이션이 ECS 컨테이너 내에서 **AWS SDK (boto3)**를 사용하여 AppConfig로부터 설정을 가져오는 예시입니다.

```python
import os
import boto3

# AppConfig Client
client = boto3.client('appconfigdata')

def get_configuration():
    app_id = os.getenv('APPCONFIG_APPLICATION_ID')  # AppConfig 애플리케이션 ID
    env_id = os.getenv('APPCONFIG_ENVIRONMENT_ID')  # AppConfig 환경 ID
    profile_id = os.getenv('APPCONFIG_CONFIGURATION_PROFILE_ID')  # 구성 프로파일 ID
    
    # Start the configuration session
    response = client.start_configuration_session(
        ApplicationIdentifier=app_id,
        EnvironmentIdentifier=env_id,
        ConfigurationProfileIdentifier=profile_id
    )
    
    session_token = response['InitialConfigurationToken']
    
    # Get the latest configuration using the session token
    config_response = client.get_latest_configuration(
        ConfigurationToken=session_token
    )
    
    config_data = config_response['Configuration'].read()
    
    # 구성을 JSON 형식으로 파싱 (필요한 경우)
    print(f"Configuration data: {config_data}")
    
    return config_data

# Example of using the configuration
configuration = get_configuration()
```

#### 4. **ECS Task Definition 작성**

ECS Task Definition에서 환경 변수를 사용하여 AppConfig 관련 정보를 전달할 수 있습니다. 또한 필요한 AWS IAM 권한을 부여하여 애플리케이션이 AppConfig API에 접근할 수 있도록 해야 합니다.

**ECS Task Definition** 예시는 아래와 같습니다:

```json
{
  "family": "my-app-task",
  "containerDefinitions": [
    {
      "name": "my-app-container",
      "image": "my-app-image:latest",
      "memory": 512,
      "cpu": 256,
      "essential": true,
      "environment": [
        {
          "name": "APPCONFIG_APPLICATION_ID",
          "value": "your-application-id"
        },
        {
          "name": "APPCONFIG_ENVIRONMENT_ID",
          "value": "your-environment-id"
        },
        {
          "name": "APPCONFIG_CONFIGURATION_PROFILE_ID",
          "value": "your-configuration-profile-id"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/my-app",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

### 주요 구성 요소:
1. **AppConfig Client**: `boto3.client('appconfigdata')`를 사용하여 AppConfig 데이터를 가져옵니다.
2. **환경 변수**: AppConfig에서 사용할 애플리케이션 ID, 환경 ID, 구성 프로파일 ID를 환경 변수로 전달합니다.
3. **IAM 역할**: ECS Task에서 AppConfig API를 호출하려면 적절한 IAM 권한이 필요합니다. 이를 위해 ECS Task Execution Role에 아래와 같은 정책을 추가해야 합니다.

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "appconfigdata:GetLatestConfiguration",
        "appconfigdata:StartConfigurationSession"
      ],
      "Resource": "*"
    }
  ]
}
```

### 요약:
1. **AWS AppConfig에서 애플리케이션 설정을 구성**하고,
2. **ECS Task Definition**에 AppConfig와 관련된 환경 변수를 설정한 후,
3. **ECS 컨테이너 내 애플리케이션**이 AWS SDK를 통해 AppConfig API로부터 구성을 동적으로 가져올 수 있습니다.

이로써 컨테이너화된 애플리케이션에서 설정 값을 쉽게 관리하고 동적으로 업데이트할 수 있습니다.

---
## AWS SAM (serverless Application Model)

**AWS Serverless Application Model (AWS SAM)**을 사용하면 AWS Lambda, API Gateway, DynamoDB 등 여러 AWS 서비스를 서버리스 애플리케이션으로 쉽게 배포하고 관리할 수 있습니다. 이 절차는 Lambda 함수 코드를 빌드하고, 패키지화한 후, AWS에 배포하는 과정을 포함합니다.

AWS SAM으로 Lambda 애플리케이션을 빌드하는 단계는 다음과 같습니다:

### AWS SAM 빌드 절차
1. **AWS SAM 템플릿 작성**: `template.yaml` 파일로 서버리스 애플리케이션을 정의합니다.
2. **SAM CLI로 빌드**: `sam build` 명령으로 Lambda 함수 코드를 빌드합니다.
3. **SAM 패키지화**: `sam package` 명령으로 빌드된 아티팩트를 S3 버킷에 업로드하고 CloudFormation 템플릿을 업데이트합니다.
4. **SAM 배포**: `sam deploy` 명령으로 애플리케이션을 AWS에 배포합니다.

### 예시: AWS SAM을 사용한 빌드 및 배포

#### 1. AWS SAM 템플릿 작성 (`template.yaml`)

아래는 Python으로 작성된 Lambda 함수와 API Gateway를 사용하는 AWS SAM 템플릿 예시입니다.

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: Sample SAM application for AWS Lambda

Resources:
  MyLambdaFunction:
    Type: AWS::Serverless::Function
    Properties:
      Handler: app.lambda_handler
      Runtime: python3.9
      CodeUri: src/
      MemorySize: 128
      Timeout: 10
      Events:
        ApiEvent:
          Type: Api
          Properties:
            Path: /hello
            Method: get
```

**설명**:
- **Transform**: AWS SAM에서 사용할 수 있는 리소스를 정의하는 지시문입니다.
- **Resources**: Lambda 함수와 그에 연동된 API Gateway를 정의합니다.
- **MyLambdaFunction**: Lambda 함수 이름.
- **Handler**: Lambda 함수의 엔트리 포인트 (예: `app.py` 파일 내의 `lambda_handler` 함수).
- **CodeUri**: Lambda 함수 코드가 위치한 디렉터리.
- **Events**: API Gateway를 통해 Lambda 함수를 호출하는 이벤트 설정입니다.

#### 2. Lambda 함수 코드 작성 (`src/app.py`)

아래는 간단한 Lambda 함수 코드 예시입니다.

```python
def lambda_handler(event, context):
    return {
        'statusCode': 200,
        'body': 'Hello, AWS SAM!'
    }
```

#### 3. SAM CLI로 애플리케이션 빌드

터미널에서 **`sam build`** 명령을 실행하여 애플리케이션을 빌드합니다.

```bash
sam build
```

이 명령은 **`template.yaml`** 파일에서 정의된 Lambda 함수를 찾아 해당 코드를 컴파일 및 준비합니다. 기본적으로 Lambda 함수가 있는 폴더 (`src/`)에 대해 의존성을 설치하고, 준비된 패키지를 `.aws-sam` 폴더에 빌드합니다.

#### 4. SAM 패키지화

빌드된 애플리케이션을 S3 버킷에 업로드하고, CloudFormation 스택을 생성하거나 업데이트하기 위한 템플릿을 준비합니다.

```bash
sam package \
    --output-template-file packaged.yaml \
    --s3-bucket my-sam-app-bucket
```

**설명**:
- **--output-template-file**: 빌드된 패키지를 사용하여 S3에 업로드된 Lambda 함수와 리소스를 참조하는 새 CloudFormation 템플릿 (`packaged.yaml`)을 생성합니다.
- **--s3-bucket**: Lambda 코드를 업로드할 S3 버킷입니다. 미리 생성된 버킷이어야 합니다.

#### 5. SAM 배포

S3에 업로드된 패키지를 사용하여 애플리케이션을 배포합니다.

```bash
sam deploy \
    --template-file packaged.yaml \
    --stack-name my-sam-app \
    --capabilities CAPABILITY_IAM
```

**설명**:
- **--template-file**: `sam package` 명령에서 생성된 템플릿 (`packaged.yaml`)을 사용합니다.
- **--stack-name**: AWS CloudFormation 스택의 이름을 지정합니다.
- **--capabilities**: Lambda 함수가 IAM 역할을 사용하도록 허용하는 권한을 부여합니다.

#### 6. 애플리케이션 배포 후 출력 확인

배포 후 API Gateway의 엔드포인트와 같은 출력을 확인할 수 있습니다. **`sam deploy`** 명령 실행 후, API Gateway 엔드포인트 URL이 출력됩니다.

```bash
Successfully created/updated stack - my-sam-app in region us-east-1
API Gateway endpoint: https://abcd1234.execute-api.us-east-1.amazonaws.com/Prod/hello
```

이제 `https://abcd1234.execute-api.us-east-1.amazonaws.com/Prod/hello` 엔드포인트에 브라우저나 Postman 등으로 접속하면 `Hello, AWS SAM!` 응답을 받을 수 있습니다.

### 요약

1. **`sam build`**: Lambda 함수와 그 의존성을 컴파일하고 패키징합니다.
2. **`sam package`**: 빌드된 코드를 S3에 업로드하고 CloudFormation 템플릿을 준비합니다.
3. **`sam deploy`**: CloudFormation 스택을 생성하거나 업데이트하여 애플리케이션을 AWS에 배포합니다.

이와 같은 AWS SAM 빌드 및 배포 절차는 서버리스 애플리케이션을 쉽고 빠르게 관리할 수 있게 해줍니다.

## AWS SAM IAM 역할 부여 방법

AWS SAM을 사용하여 Lambda 함수에 S3 버킷에 대한 읽기 권한을 부여하려면, Lambda 함수의 **IAM 역할**에 적절한 권한을 부여해야 합니다. 이를 위해 AWS SAM의 `Policies` 속성을 사용하여 **S3ReadPolicy**를 Lambda 함수에 추가할 수 있습니다. 이 정책은 Lambda 함수가 S3 버킷의 객체를 읽을 수 있도록 허용합니다.

다음은 AWS SAM 템플릿에서 Lambda 함수에 S3 읽기 권한을 추가하는 방법에 대한 예시입니다.

### **AWS SAM 템플릿 예시 (template.yaml)**

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Resources:
  MyLambdaFunction:
    Type: AWS::Serverless::Function
    Properties: 
      Handler: index.handler
      Runtime: nodejs14.x
      CodeUri: ./src
      # Lambda 함수에 S3 읽기 권한 부여
      Policies:
        - S3ReadPolicy:
            BucketName: !Ref MyS3Bucket  # S3 버킷 참조

  MyS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: my-sample-bucket  # S3 버킷 이름을 설정 (선택 사항)
```

### **구성 설명:**
1. **Lambda 함수 설정 (`MyLambdaFunction`)**:
   - `AWS::Serverless::Function` 리소스를 통해 Lambda 함수를 정의합니다.
   - `Policies` 속성에서 `S3ReadPolicy`를 사용하여 Lambda 함수에 지정된 S3 버킷(`MyS3Bucket`)에 대한 읽기 권한을 부여합니다.

2. **S3 버킷 설정 (`MyS3Bucket`)**:
   - `AWS::S3::Bucket` 리소스를 통해 S3 버킷을 정의합니다.
   - `BucketName`을 설정하거나 AWS에서 자동으로 생성된 버킷 이름을 사용할 수 있습니다.

### **S3ReadPolicy**:
- `S3ReadPolicy`는 Lambda 함수에 S3 버킷 내 객체를 **읽기 전용**으로 액세스할 수 있는 권한을 부여하는 AWS SAM의 정책 템플릿입니다.
- `BucketName` 속성에 접근을 허용하려는 S3 버킷을 지정합니다.

### **배포 명령**:
1. **AWS SAM 패키징 및 배포**:
   ```bash
   sam package --output-template-file packaged.yaml --s3-bucket <your-s3-bucket>
   ```

2. **AWS SAM 배포**:
   ```bash
   sam deploy --template-file packaged.yaml --stack-name my-sam-app --capabilities CAPABILITY_IAM
   ```

이 구성을 통해 Lambda 함수는 지정된 S3 버킷 내의 객체를 읽을 수 있는 권한을 갖게 됩니다.


## AWS SAM과 Amplify 비교

AWS SAM(AWS Serverless Application Model)과 AWS Amplify는 둘 다 AWS의 서비스로, 서버리스 애플리케이션 개발을 지원하지만 다른 목적과 사용 사례를 가지고 있습니다. 이 둘의 관계는 간접적이며, 특정 애플리케이션 아키텍처에 따라 함께 사용할 수 있지만, 각각의 주요 기능과 목적이 다릅니다. 예시를 통해 설명하겠습니다.

### 1. **AWS SAM (Serverless Application Model)**

**주요 역할**: AWS SAM은 주로 서버리스 백엔드 애플리케이션을 개발하는 데 사용됩니다. 이는 AWS Lambda, API Gateway, DynamoDB, SNS 등과 같은 AWS 서버리스 서비스를 설정하고 배포하는 데 도움을 줍니다. SAM은 서버리스 애플리케이션을 선언적인 템플릿 형식으로 작성하게 해주며, 배포를 간편하게 도와줍니다.

- **사용 예시**:
  - 사용자가 Lambda 함수로 이루어진 서버리스 API를 개발할 때, SAM 템플릿을 사용해 API Gateway, Lambda 함수, DynamoDB 테이블 등을 정의하고, 이를 배포할 수 있습니다.
  - SAM CLI를 통해 로컬 환경에서 Lambda 함수를 테스트하고, CI/CD 파이프라인을 설정할 수 있습니다.

### 2. **AWS Amplify**

**주요 역할**: AWS Amplify는 풀스택 애플리케이션 개발을 지원하며, 주로 프런트엔드 개발자들이 쉽게 백엔드 서비스를 통합할 수 있도록 도와줍니다. Amplify는 웹 또는 모바일 애플리케이션의 프런트엔드 및 백엔드를 함께 개발할 수 있게 지원하며, API, 인증, 스토리지, GraphQL 서비스 등을 손쉽게 설정하게 도와줍니다.

- **사용 예시**:
  - 프런트엔드 개발자가 React 기반의 웹 애플리케이션을 개발하는 중 백엔드로 Amplify를 사용하여 Cognito 인증, GraphQL API (AppSync), 그리고 S3 스토리지 등을 간편하게 연결할 수 있습니다.
  - Amplify Console을 통해 프런트엔드 애플리케이션을 호스팅하고, CICD 파이프라인을 설정할 수 있습니다.

### **SAM과 Amplify를 함께 사용할 수 있는 시나리오**:

**예시**:
1. **앱 아키텍처**: 프런트엔드는 React로 작성된 웹 애플리케이션이고, 백엔드는 AWS Lambda와 API Gateway로 구축된 서버리스 API입니다.
   - 프런트엔드: Amplify를 사용하여 사용자 인증(Cognito), GraphQL API(AppSync), S3 파일 업로드를 설정하고, Amplify Console로 배포 및 호스팅합니다.
   - 백엔드: AWS SAM을 사용해 서버리스 API를 정의하고, Lambda 함수와 API Gateway를 통해 RESTful API를 개발하고 배포합니다.

2. **백엔드 서비스 확장**: Amplify에서 기본적으로 제공하는 기능 외에 추가적인 서버리스 로직이 필요하다면, SAM을 통해 확장된 백엔드 서비스를 구축할 수 있습니다. 예를 들어, Amplify를 통해 GraphQL API를 설정한 후, SAM을 사용하여 맞춤형 Lambda 함수와 API Gateway를 추가로 배포할 수 있습니다.

결론적으로, AWS SAM과 AWS Amplify는 각각 서버리스 애플리케이션을 개발하는 도구들이며, Amplify는 주로 풀스택 및 프런트엔드에 포커스가 맞춰져 있고, SAM은 서버리스 백엔드 구축에 특화되어 있습니다. 특정 애플리케이션의 요구사항에 따라 두 서비스를 함께 사용할 수 있습니다.

# CI/CD

## CodeDeploy에서 appsepc.yaml 역할

**`appspec.yml`** 파일은 AWS CodeDeploy에서 애플리케이션을 배포할 때 매우 중요한 역할을 합니다. 이 파일은 **배포 시 실행해야 할 작업과, 파일이 어디로 배포될지**에 대한 지침을 제공합니다. 배포되는 애플리케이션이 EC2 인스턴스나 온프레미스 서버, 또는 Lambda 같은 서버리스 환경으로 배포되는지에 따라 **`appspec.yml`** 파일의 구조와 내용이 달라집니다.

AWS CodeDeploy는 `appspec.yml` 파일을 기반으로 배포 과정에서 필요한 작업들을 정의하고, 배포가 성공적으로 완료되기 위한 지침을 수행합니다.

### **`appspec.yml`의 주요 역할**
- **파일 배포 위치 정의**: 소스 코드나 애플리케이션 파일을 EC2 또는 온프레미스 인스턴스에 복사할 위치를 정의합니다.
- **배포 수명 주기 이벤트 정의**: 배포 전후에 특정 스크립트나 명령어를 실행할 수 있도록 설정할 수 있습니다.
- **Lambda의 경우**: Lambda 함수 버전 간 트래픽 전환과 같은 설정을 정의할 수 있습니다.

---

### **EC2 또는 온프레미스 배포에서 `appspec.yml` 예시**

```yaml
version: 0.0
os: linux
files:
  - source: /src/
    destination: /var/www/html/
hooks:
  BeforeInstall:
    - location: scripts/install_dependencies.sh
      timeout: 300
      runas: root
  AfterInstall:
    - location: scripts/configure_server.sh
      timeout: 300
      runas: root
  ApplicationStart:
    - location: scripts/start_server.sh
      timeout: 300
      runas: root
  ValidateService:
    - location: scripts/validate_service.sh
      timeout: 300
      runas: root
```

### **구성 요소 설명**:

1. **`version`**: `appspec.yml` 파일의 버전을 정의합니다. 현재 `0.0`이 사용됩니다.
2. **`os`**: 배포할 운영 체제를 정의합니다 (`linux` 또는 `windows`).
3. **`files`**: 
   - 배포할 파일의 **소스 위치**와 **대상 위치**를 정의합니다. 위 예시에서는 `/src/` 디렉토리의 파일들이 `/var/www/html/`로 복사됩니다.
4. **`hooks`**: 
   - 배포 수명 주기 단계에서 실행할 스크립트나 명령어를 정의합니다. CodeDeploy는 여러 **배포 수명 주기 이벤트**를 지원하며, 각 이벤트에서 실행할 스크립트를 설정할 수 있습니다.
     - **BeforeInstall**: 애플리케이션 파일을 복사하기 전에 실행되는 작업.
     - **AfterInstall**: 파일 복사가 완료된 후 실행되는 작업.
     - **ApplicationStart**: 애플리케이션이 시작되기 전에 실행되는 작업.
     - **ValidateService**: 서비스가 정상적으로 실행되고 있는지 확인하는 작업.

### **EC2 배포 흐름**
1. **BeforeInstall**: 의존성 설치, 환경 설정 초기화 등.
2. **AfterInstall**: 서버나 환경을 설정하는 스크립트 실행.
3. **ApplicationStart**: 서버를 시작하는 스크립트 실행.
4. **ValidateService**: 애플리케이션이 정상적으로 배포되었는지 검증.

---

### **AWS Lambda 배포에서 `appspec.yml` 예시**

Lambda 배포의 경우, `appspec.yml`은 트래픽 라우팅과 같은 Lambda 관련 설정을 정의합니다.

```yaml
version: 0.0
resources:
  - myLambdaFunction:
      type: AWS::Lambda::Function
      properties:
        name: "MyLambdaFunction"
        alias: "live"
hooks:
  BeforeAllowTraffic:
    - location: scripts/before_traffic_shift.sh
      timeout: 300
  AfterAllowTraffic:
    - location: scripts/after_traffic_shift.sh
      timeout: 300
```

### **구성 요소 설명**:

1. **`resources`**:
   - **Lambda 함수와 Alias**를 정의합니다. 여기서 `"MyLambdaFunction"`이 배포 대상 함수이며, `"live"`는 트래픽이 전환될 Lambda 함수의 alias입니다.
   
2. **`hooks`**: 
   - **BeforeAllowTraffic**: 새로운 Lambda 함수 버전으로 트래픽을 전환하기 전에 실행할 스크립트.
   - **AfterAllowTraffic**: 트래픽 전환 후에 실행할 스크립트.

### **Lambda 배포 흐름**
1. **BeforeAllowTraffic**: 트래픽을 새로운 Lambda 함수로 전환하기 전 준비 작업을 수행.
2. **AfterAllowTraffic**: 트래픽 전환 후 검증 작업을 수행.

---

### **Windows Server 배포에서 `appspec.yml` 예시**

Windows 환경에서 배포할 때의 `appspec.yml` 파일은 Linux와 비슷하지만 `powershell` 스크립트를 사용합니다.

```yaml
version: 0.0
os: windows
files:
  - source: /src/
    destination: C:\inetpub\wwwroot
hooks:
  BeforeInstall:
    - location: scripts\install_dependencies.ps1
      timeout: 300
  AfterInstall:
    - location: scripts\configure_server.ps1
      timeout: 300
  ApplicationStart:
    - location: scripts\start_server.ps1
      timeout: 300
  ValidateService:
    - location: scripts\validate_service.ps1
      timeout: 300
```

### **구성 요소 설명**:
1. **`os: windows`**: 배포 대상 운영체제가 Windows임을 나타냅니다.
2. **`hooks`**: 각 배포 수명 주기에 실행할 PowerShell 스크립트를 정의합니다.

---

### **정리**

`appspec.yml`은 AWS CodeDeploy 배포에서 중요한 역할을 하며, **어떤 파일을 어디에 배포할지**, 그리고 **배포 과정에서 어떤 스크립트가 언제 실행될지**를 정의합니다. 이를 통해 배포 자동화를 제어하고, 다양한 환경(EC2, 온프레미스, Lambda 등)에서 애플리케이션을 안정적으로 배포할 수 있습니다.


## CodePipeLine 
AWS CodePipeline을 사용하여 지속적 통합(CI) 및 지속적 배포(CD)을 구현하는 예시는 코드가 변경될 때마다 자동으로 빌드하고 테스트하며, AWS에 배포하는 파이프라인을 구성하는 방법을 설명합니다. 이 예시에서는 **AWS CodeCommit**을 소스 코드 저장소로 사용하고, **AWS CodeBuild**로 애플리케이션을 빌드하고, **AWS Lambda**로 배포하는 단계를 보여줍니다.

### **1. AWS CodePipeline 개요**
AWS CodePipeline은 코드가 변경될 때마다 빌드, 테스트, 배포를 자동화하여 빠르고 안정적인 릴리스를 가능하게 합니다. CodePipeline의 주요 구성 요소는 다음과 같습니다:
- **Source**: 코드 저장소, 예를 들어 AWS CodeCommit, GitHub 등.
- **Build**: 코드 빌드 단계, AWS CodeBuild를 통해 수행.
- **Deploy**: AWS Lambda, ECS, S3 등으로 배포.

### **2. 사전 준비**
- **AWS CodeCommit**에 코드 저장소가 있어야 합니다.
- **AWS CodeBuild**에 빌드 스펙 파일을 설정해야 합니다.
- **AWS Lambda** 배포 준비가 되어 있어야 합니다.

### **3. CodePipeline 파이프라인 구성 예시**

#### **Step 1: AWS CodePipeline 생성**
AWS Management Console에서 CodePipeline을 생성하거나, AWS CLI 또는 CloudFormation으로 설정할 수 있습니다. 여기서는 CloudFormation 템플릿을 사용한 예시를 설명합니다.

#### **CloudFormation 템플릿 예시 (pipeline.yaml)**

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Resources:
  # S3 버킷 생성: 파이프라인 아티팩트 저장소로 사용
  PipelineArtifactsBucket:
    Type: AWS::S3::Bucket

  # CodePipeline 역할 생성
  PipelineRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: codepipeline.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: CodePipelinePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                  - s3:ListBucket
                Resource: 
                  - !Sub "arn:aws:s3:::${PipelineArtifactsBucket}/*"
              - Effect: Allow
                Action:
                  - codebuild:StartBuild
                  - codebuild:BatchGetBuilds
                Resource: "*"
              
  # CodeBuild 역할 생성
  CodeBuildRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: codebuild.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: CodeBuildPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                Resource: 
                  - !Sub "arn:aws:s3:::${PipelineArtifactsBucket}/*"
              - Effect: Allow
                Action:
                  - lambda:UpdateFunctionCode
                Resource: "*"

  # CodeBuild 프로젝트 정의
  CodeBuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: MyAppBuild
      Source:
        Type: CODECOMMIT
        Location: "https://git-codecommit.us-east-1.amazonaws.com/v1/repos/my-repo"
      Environment:
        ComputeType: BUILD_GENERAL1_SMALL
        Image: "aws/codebuild/standard:5.0"
        Type: LINUX_CONTAINER
      ServiceRole: !GetAtt CodeBuildRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Cache:
        Type: NO_CACHE

  # CodePipeline 정의
  MyPipeline:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      RoleArn: !GetAtt PipelineRole.Arn
      ArtifactStore:
        Type: S3
        Location: !Ref PipelineArtifactsBucket
      Stages:
        - Name: Source
          Actions:
            - Name: SourceAction
              ActionTypeId:
                Category: Source
                Owner: AWS
                Version: "1"
                Provider: CodeCommit
              OutputArtifacts:
                - Name: SourceOutput
              Configuration:
                RepositoryName: "my-repo"
                BranchName: "main"
              RunOrder: 1

        - Name: Build
          Actions:
            - Name: BuildAction
              ActionTypeId:
                Category: Build
                Owner: AWS
                Version: "1"
                Provider: CodeBuild
              InputArtifacts:
                - Name: SourceOutput
              OutputArtifacts:
                - Name: BuildOutput
              Configuration:
                ProjectName: !Ref CodeBuildProject
              RunOrder: 1

        - Name: Deploy
          Actions:
            - Name: DeployAction
              ActionTypeId:
                Category: Deploy
                Owner: AWS
                Version: "1"
                Provider: Lambda
              InputArtifacts:
                - Name: BuildOutput
              Configuration:
                FunctionName: "my-lambda-function"
              RunOrder: 1
```

### **구성 요소 설명**:
1. **S3 버킷 (PipelineArtifactsBucket)**: 파이프라인 아티팩트(소스 코드 및 빌드된 파일)를 저장하기 위한 S3 버킷을 생성합니다.
2. **IAM 역할 (PipelineRole, CodeBuildRole)**: CodePipeline과 CodeBuild가 리소스에 액세스할 수 있도록 역할과 권한을 설정합니다.
3. **CodeBuild 프로젝트 (CodeBuildProject)**: 소스 코드를 빌드하고 Lambda 함수로 배포할 때 필요한 빌드 프로젝트를 정의합니다.
4. **CodePipeline 정의 (MyPipeline)**: 3개의 스테이지(Source, Build, Deploy)로 이루어진 파이프라인을 정의합니다.
   - **Source**: AWS CodeCommit에서 소스 코드를 가져옵니다.
   - **Build**: AWS CodeBuild에서 소스 코드를 빌드합니다.
   - **Deploy**: 빌드된 코드를 AWS Lambda로 배포합니다.

### **4. BuildSpec 파일**
CodeBuild는 `buildspec.yml` 파일을 사용해 빌드 단계를 정의합니다. 이 파일은 프로젝트 루트에 위치해야 하며, 빌드 및 배포 단계를 지정할 수 있습니다.

#### **buildspec.yml 예시**:
```yaml
version: 0.2

phases:
  install:
    commands:
      - echo Installing dependencies...
      - pip install -r requirements.txt

  build:
    commands:
      - echo Build started...
      - zip function.zip app.py
      - echo Build completed.

artifacts:
  files:
    - function.zip
```

### **5. 파이프라인 생성 및 실행**
CloudFormation 템플릿을 배포하여 CodePipeline을 생성합니다.

```bash
aws cloudformation deploy \
  --template-file pipeline.yaml \
  --stack-name my-pipeline-stack \
  --capabilities CAPABILITY_IAM
```

배포가 완료되면 파이프라인이 실행되고, CodeCommit의 소스 코드가 변경될 때마다 CodeBuild를 통해 빌드하고, Lambda 함수로 배포됩니다.

### **6. CodePipeline 확인 및 테스트**
- **CodeCommit**에 코드를 푸시하면, CodePipeline이 자동으로 트리거되어 파이프라인을 실행합니다.
- **AWS Management Console**에서 CodePipeline을 모니터링하고 각 단계의 상태를 확인할 수 있습니다.

### **정리**:
이 예시에서는 AWS CodePipeline을 사용하여 코드 저장소(CodeCommit)에서 소스 코드를 가져와 CodeBuild로 빌드하고, AWS Lambda로 배포하는 CI/CD 파이프라인을 구축하는 방법을 다뤘습니다. 이를 통해 코드 변경 시 자동으로 빌드 및 배포가 가능하며, 코드 배포의 효율성과 신뢰성을 크게 향상시킬 수 있습니다.

# 보안 및 권한 관리

## IAM policy,role 생성후 인스턴스 프로필에 연결

IAM 정책을 추가하고 이를 역할에 연결한 후, 인스턴스 프로필에 연결하는 과정을 단계별로 설명하겠습니다. 이 예시에서는 AWS CLI를 사용하여 작업을 수행합니다.

### **1단계: IAM 정책 생성**

IAM 정책을 생성하여 특정 권한을 정의합니다. 예를 들어, S3에 대한 읽기 권한을 추가하는 정책을 생성합니다.

```bash
aws iam create-policy --policy-name MyS3ReadPolicy --policy-document '{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::my-bucket/*"
        }
    ]
}'
```

### **2단계: IAM 역할 생성**

IAM 역할을 생성하고, 이 역할에 위에서 만든 정책을 연결합니다.

```bash
aws iam create-role --role-name MyEC2Role --assume-role-policy-document '{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "ec2.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}'
```

### **3단계: 정책을 역할에 연결**

이제 생성한 정책을 역할에 연결합니다.

```bash
aws iam attach-role-policy --role-name MyEC2Role --policy-arn arn:aws:iam::123456789012:policy/MyS3ReadPolicy
```

> 여기서 `123456789012`는 AWS 계정 ID입니다. 자신의 계정 ID로 바꾸세요.

### **4단계: 인스턴스 프로필 생성**

인스턴스 프로필을 생성하여 EC2 인스턴스가 역할을 사용할 수 있도록 합니다.

```bash
aws iam create-instance-profile --instance-profile-name MyInstanceProfile
```

### **5단계: 역할을 인스턴스 프로필에 추가**

생성한 IAM 역할을 인스턴스 프로필에 추가합니다.

```bash
aws iam add-role-to-instance-profile --instance-profile-name MyInstanceProfile --role-name MyEC2Role
```

### **6단계: EC2 인스턴스 시작 시 역할 연결**

EC2 인스턴스를 시작할 때 생성한 인스턴스 프로필을 연결합니다.

```bash
aws ec2 run-instances --image-id ami-0abcdef1234567890 --instance-type t2.micro --iam-instance-profile Name=MyInstanceProfile
```

> 여기서 `ami-0abcdef1234567890`는 사용하고자 하는 AMI ID로 교체하세요.

### **정리**

이 과정을 통해 IAM 정책을 생성하고, 이를 역할에 연결한 후 인스턴스 프로필에 추가하여 EC2 인스턴스가 해당 권한을 사용할 수 있도록 설정할 수 있습니다. 필요한 권한에 따라 정책을 조정하고, AWS CLI 또는 AWS Management Console을 통해 구성할 수 있습니다.


## AWS Cognito 사용자 pool 예시

AWS Cognito를 사용하는 예시는 **사용자 인증**과 **권한 부여**를 쉽게 설정하는 방법입니다. AWS Cognito는 **사용자 풀(User Pool)**과 **ID 풀(Identity Pool)**을 통해 사용자 관리를 할 수 있으며, 다양한 애플리케이션에 로그인 기능을 쉽게 통합할 수 있습니다. 

여기서는 AWS Cognito **User Pool**을 사용하여 **사용자 등록 및 로그인**을 구현하는 방법을 단계별로 설명하겠습니다. 이 예시는 AWS SDK를 사용하여 웹 애플리케이션에서 사용자 인증을 처리하는 과정을 다룹니다.

### **1. AWS Cognito 설정**
먼저, AWS Console에서 Cognito User Pool을 설정합니다.

#### **User Pool 생성**
1. **AWS Cognito 콘솔**에서 **Manage User Pools**를 선택하고 **Create a User Pool**을 클릭합니다.
2. **User Pool Name**을 입력하고, 기본 설정을 사용하거나 사용자 정의 설정을 통해 인증 방식, 비밀번호 정책 등을 설정합니다.
3. **MFA (Multi-Factor Authentication)** 및 **OTP 설정**을 선택할 수 있습니다.
4. **App Clients**를 설정하는 단계에서 **Client Name**을 설정하고, 필요한 경우 **Secret key**는 비활성화할 수 있습니다(웹 애플리케이션에서는 비밀키를 사용하지 않는 것이 일반적입니다).
5. User Pool을 생성한 후, **App Client ID**를 기록해 둡니다. 이후 사용자 인증에 사용됩니다.

### **2. AWS Amplify로 Cognito 통합 (JavaScript 예시)**

AWS Amplify 라이브러리를 사용하면 AWS Cognito와 손쉽게 통합할 수 있습니다. 아래는 사용자 등록, 로그인, 로그아웃 기능을 포함한 간단한 예시입니다.

#### **설정 단계**
먼저, AWS Amplify를 설치하고, 프로젝트에서 Cognito를 설정합니다.

```bash
npm install aws-amplify @aws-amplify/ui-react
```

#### **Amplify 설정**
애플리케이션에서 AWS Amplify를 사용하기 위해 **Amplify.configure**를 설정합니다.

```javascript
// src/aws-exports.js
const awsConfig = {
  Auth: {
    region: "us-east-1", // Cognito User Pool이 있는 AWS 리전
    userPoolId: "us-east-1_XXXXXXXXX", // 생성한 User Pool ID
    userPoolWebClientId: "XXXXXXXXXX", // 생성한 App Client ID
  }
};

export default awsConfig;
```

`App.js` 또는 애플리케이션의 진입 파일에서 AWS Amplify를 설정합니다.

```javascript
import Amplify from 'aws-amplify';
import awsConfig from './aws-exports';

Amplify.configure(awsConfig);
```

### **3. 사용자 등록(Sign-Up)**
사용자 등록(Sign-Up) 기능을 구현하려면 AWS Amplify의 `Auth.signUp()` 메서드를 사용합니다.

```javascript
import { Auth } from 'aws-amplify';
import { useState } from 'react';

function SignUp() {
  const [username, setUsername] = useState('');
  const [password, setPassword] = useState('');
  const [email, setEmail] = useState('');

  const handleSignUp = async () => {
    try {
      const signUpResponse = await Auth.signUp({
        username,
        password,
        attributes: {
          email,          // optional
        }
      });
      console.log('Sign-up successful:', signUpResponse);
    } catch (error) {
      console.error('Error signing up:', error);
    }
  };

  return (
    <div>
      <input
        placeholder="Username"
        onChange={(e) => setUsername(e.target.value)}
      />
      <input
        type="password"
        placeholder="Password"
        onChange={(e) => setPassword(e.target.value)}
      />
      <input
        placeholder="Email"
        onChange={(e) => setEmail(e.target.value)}
      />
      <button onClick={handleSignUp}>Sign Up</button>
    </div>
  );
}

export default SignUp;
```

### **4. 사용자 확인(Verification)**
사용자가 이메일로 받은 확인 코드(verification code)를 입력하여 계정을 활성화해야 합니다. 이 과정도 `Auth.confirmSignUp()` 메서드를 사용하여 처리할 수 있습니다.

```javascript
import { Auth } from 'aws-amplify';
import { useState } from 'react';

function ConfirmSignUp() {
  const [username, setUsername] = useState('');
  const [code, setCode] = useState('');

  const handleConfirmSignUp = async () => {
    try {
      await Auth.confirmSignUp(username, code);
      console.log('Account confirmed!');
    } catch (error) {
      console.error('Error confirming sign up', error);
    }
  };

  return (
    <div>
      <input
        placeholder="Username"
        onChange={(e) => setUsername(e.target.value)}
      />
      <input
        placeholder="Verification Code"
        onChange={(e) => setCode(e.target.value)}
      />
      <button onClick={handleConfirmSignUp}>Confirm Sign Up</button>
    </div>
  );
}

export default ConfirmSignUp;
```

### **5. 로그인(Sign-In)**
사용자 로그인을 처리하는 방법은 다음과 같이 `Auth.signIn()`을 사용합니다.

```javascript
import { Auth } from 'aws-amplify';
import { useState } from 'react';

function SignIn() {
  const [username, setUsername] = useState('');
  const [password, setPassword] = useState('');

  const handleSignIn = async () => {
    try {
      const user = await Auth.signIn(username, password);
      console.log('Sign-in successful:', user);
    } catch (error) {
      console.error('Error signing in', error);
    }
  };

  return (
    <div>
      <input
        placeholder="Username"
        onChange={(e) => setUsername(e.target.value)}
      />
      <input
        type="password"
        placeholder="Password"
        onChange={(e) => setPassword(e.target.value)}
      />
      <button onClick={handleSignIn}>Sign In</button>
    </div>
  );
}

export default SignIn;
```

### **6. 로그아웃(Sign-Out)**
사용자가 로그아웃을 하려면 `Auth.signOut()` 메서드를 사용하면 됩니다.

```javascript
import { Auth } from 'aws-amplify';

function SignOut() {
  const handleSignOut = async () => {
    try {
      await Auth.signOut();
      console.log('Signed out');
    } catch (error) {
      console.error('Error signing out', error);
    }
  };

  return (
    <button onClick={handleSignOut}>Sign Out</button>
  );
}

export default SignOut;
```

### **7. 현재 사용자 확인**
로그인한 사용자의 정보를 확인하고 싶을 때는 `Auth.currentAuthenticatedUser()` 메서드를 사용합니다.

```javascript
import { Auth } from 'aws-amplify';
import { useEffect, useState } from 'react';

function CurrentUser() {
  const [user, setUser] = useState(null);

  useEffect(() => {
    const fetchUser = async () => {
      try {
        const currentUser = await Auth.currentAuthenticatedUser();
        setUser(currentUser);
        console.log('Current user:', currentUser);
      } catch (error) {
        console.error('Error fetching current user', error);
      }
    };

    fetchUser();
  }, []);

  if (!user) {
    return <div>No user logged in</div>;
  }

  return (
    <div>
      <h3>Welcome, {user.username}!</h3>
    </div>
  );
}

export default CurrentUser;
```

---

### **정리**
AWS Cognito를 사용하면 사용자 인증 기능을 쉽게 구현할 수 있습니다. Amplify 라이브러리를 사용하면 Cognito와의 통합이 간편해지며, 사용자 등록, 로그인, 로그아웃, 인증 확인 등의 작업을 손쉽게 처리할 수 있습니다. AWS SDK와 Amplify를 사용하여 웹 애플리케이션에서 AWS Cognito를 이용한 인증을 설정하는 이 예시는 기본적인 사용자 인증 흐름을 이해하는 데 도움을 줍니다.


## AWS  Cognito Authorizer 구성 

Amazon Cognito 사용자 풀을 생성하고 API Gateway에서 Cognito Authorizer를 구성하는 과정을 단계별로 설명해 드릴게요.

### 1. Amazon Cognito 사용자 풀 생성

1. **AWS Management Console**에 로그인하고, **Cognito** 서비스로 이동합니다.
2. **Manage User Pools**를 클릭한 후, **Create a user pool**을 선택합니다.
3. 사용자 풀 이름을 입력하고, **Review defaults**를 클릭합니다.
4. 기본 설정을 검토하고, 필요에 따라 설정을 수정한 후, **Create pool**을 클릭합니다.

### 2. 사용자 풀에 앱 클라이언트 추가

1. 생성한 사용자 풀에서 **App clients** 탭으로 이동합니다.
2. **Add an app client**를 클릭하고, 클라이언트 이름을 입력합니다.
3. **Generate client secret** 옵션을 비활성화한 후, **Create app client**를 클릭합니다.

### 3. 사용자 풀에서 사용자 생성

1. 사용자 풀에서 **Users and groups** 탭으로 이동합니다.
2. **Create user**를 클릭하고 사용자 정보를 입력합니다. 사용자가 이메일 확인을 하도록 설정할 수 있습니다.

### 4. API Gateway에서 API 생성

1. AWS Management Console에서 **API Gateway**로 이동합니다.
2. **Create API**를 클릭하고, REST API를 선택한 후 **Build**를 클릭합니다.
3. API 이름을 입력하고, **Create API**를 클릭합니다.

### 5. Cognito Authorizer 구성

1. API Gateway에서 **Authorizers**를 선택하고, **Create New Authorizer**를 클릭합니다.
2. Authorizer 이름을 입력하고, Type으로 **Cognito**를 선택합니다.
3. **Cognito User Pool**을 선택하고, 이전에 생성한 사용자 풀을 선택합니다.
4. Token Source에 **Authorization**을 입력합니다. 이 값을 사용하여 요청 헤더에서 토큰을 읽어옵니다.
5. **Create**를 클릭하여 Authorizer를 생성합니다.

### 6. API 메서드 설정

1. **Resources**에서 원하는 리소스를 선택하고, 메서드를 추가합니다. 예를 들어 **GET** 메서드를 선택합니다.
2. **Method Request**에서 **Authorization**을 선택하고, 방금 만든 Cognito Authorizer를 선택합니다.
3. **Integration Request**에서 통합할 백엔드 설정을 합니다.
4. **Deploy API**를 선택하여 배포합니다. 새로운 스테이지를 생성하거나 기존 스테이지를 선택합니다.

### 7. 토큰 생성 및 API 호출

1. Cognito 사용자 풀에서 사용자가 로그인하여 ID 또는 액세스 토큰을 얻습니다. 예를 들어, 다음과 같이 Python SDK를 사용하여 로그인을 할 수 있습니다:

```python
import boto3

client = boto3.client('cognito-idp')

response = client.initiate_auth(
    ClientId='YOUR_APP_CLIENT_ID',
    AuthFlow='USER_PASSWORD_AUTH',
    AuthParameters={
        'USERNAME': 'your_username',
        'PASSWORD': 'your_password',
    }
)

id_token = response['AuthenticationResult']['IdToken']
```

2. API Gateway의 엔드포인트를 호출할 때, Authorization 헤더에 이 ID 토큰을 추가합니다:

```bash
curl -H "Authorization: YOUR_ID_TOKEN" https://your-api-id.execute-api.your-region.amazonaws.com/your-stage/your-resource
```

이제 Cognito 사용자 인증이 적용된 API Gateway를 통해 안전하게 리소스를 보호할 수 있습니다! 필요에 따라 추가적인 보안 설정이나 사용자 풀 설정을 할 수 있습니다.

